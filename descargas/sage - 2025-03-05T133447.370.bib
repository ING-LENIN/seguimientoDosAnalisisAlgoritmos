@article{doi:10.1177/0309324718763189,
author = {Behzad V Farahani and Paulo J Tavares and Jorge Belinha and PMGP Moreira},
title = {Compact tension fracture specimen: Experimental and computational implementations on stress intensity factor},
journal = {The Journal of Strain Analysis for Engineering Design},
volume = {53},
number = {8},
pages = {630–647},
year = {2018a},
doi = {10.1177/0309324718763189},
URL = {https://doi-org.crai.referencistas.com/10.1177/0309324718763189},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0309324718763189},
abstract = {This work concentrates on the characterization of the stress intensity factor range for a compact tension specimen tested under a uniaxial tensile fatigue loading condition. The experimental solution is obtained using a three-dimensional full-field optical technique, digital image correlation. The deformation field is measured and documented for distinct crack lengths. As a relevant fracture parameter, stress intensity factor is thus experimentally measured combined with a computational overdeterministic algorithm for different crack lengths. Moreover, to verify the performance of the proposed fracture model, the cracked compact tension specimen is elasto-statically resolved using advanced discretization techniques, such as the finite element method, the meshless radial point interpolation method and the meshless natural neighbour radial point interpolation method. The finite element method model is thereby analysed with ABAQUS© to enable computation of mode I stress intensity factor results based on strain energy release rate criterion for different crack measurements in addition to strain contours. Likewise, the resolution pattern is repeated for meshless methods, and analogous numerical solutions are thus obtained. Overall, the experimental and numerical stress intensity factor results are compared with an available solution (ASTM E647) exhibiting a reasonable agreement. The novelty of this investigation is the amalgamation of an experimental digital image correlation procedure with a computational overdeterministic algorithm and, most importantly, the meshless formulation performance in the linear elastic fracture mechanics.}
}

@article{doi:10.1177/0301006619872101,
author = {Ella M. Gale},
title = {Miller, P. An Introductory Course in Computational Neuroscience},
journal = {Perception},
volume = {48},
number = {9},
pages = {897–898},
year = {2019b},
doi = {10.1177/0301006619872101},
URL = {https://doi-org.crai.referencistas.com/10.1177/0301006619872101},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0301006619872101}
}

@article{doi:10.1177/109434208800200407,
author = {Wolfgang Gentzsch},
title = {Comparison of Supercomputers and Mini- Supercomputers for Computational Fluid Dynamics Calcu Lations},
journal = {The International Journal of Supercomputing Applications},
volume = {2},
number = {4},
pages = {63–71},
year = {1988c},
doi = {10.1177/109434208800200407},
URL = {https://doi-org.crai.referencistas.com/10.1177/109434208800200407},
eprint = {https://doi-org.crai.referencistas.com/10.1177/109434208800200407},
abstract = {Computational fluid dynamics (CFD) is a powerful tool for the simulation of complex fluid dynamics problems. In the future, the progress in CFD will depend on effi cient algorithms as well as on the power and storage capacity of the computers available. A careful study and comparison of these supercomputers, therefore, is nec essary. The following paper presents a short description of the Engineering and Scientific Model Benchmark, the supercomputers and mini-supercomputers under con sideration, and a discussion of the benchmark results.}
}

@article{doi:10.1177/17504813231207948,
author = {Yuzhang Han and Minoo Modaresnezhad and Indika Dissanayake and Nikhil Mehta and Hamid Nemati},
title = {A computational linguistic analysis of the anatomy of production, consumption, and diffusion of misinformation and authentic information in social media: The case of the COVID-19 pandemic},
journal = {Discourse & Communication},
volume = {18},
number = {2},
pages = {159–215},
year = {2024d},
doi = {10.1177/17504813231207948},
URL = {https://doi-org.crai.referencistas.com/10.1177/17504813231207948},
eprint = {https://doi-org.crai.referencistas.com/10.1177/17504813231207948},
abstract = {Social media has become a powerful conduit for misinformation during major public events. As a result, an extant body of research has emerged on misinformation and its diffusion. However, the research is fragmented and has mainly focused on understanding the content of misinformation messages. Little attention is paid to the production and consumption of misinformation. This study presents the results of a detailed comparative analysis of the production, consumption, and diffusion of misinformation with authentic information. Our findings, based on extensive use of computational linguistic analyses of COVID-19 pandemic-related messages on the Twitter platform, revealed that misinformation and authentic information exhibit very different characteristics in terms of their contents, production, diffusion, and their ultimate consumption. To support our study, we carefully selected a sample of 500 widely propagated messages confirmed by fact-checking websites as misinformation or authentic information about pandemic-related topics from the Twitter platform. Detailed computational linguistic analyses were performed on these messages and their replies (N = 198,750). Additionally, we analyzed approximately 1.2 million Twitter user accounts responsible for producing, forwarding, or replying to these messages. Our extensive and detailed findings were used to develop and propose a theoretical framework for understanding the diffusion of misinformation on social media. Our study offers insights for social media platforms, researchers, policymakers, and online information consumers about how misinformation spreads over social media platforms.}
}

@article{doi:10.1177/14780771231170272,
author = {Andrew Kudless},
title = {Hierarchies of bias in artificial intelligence architecture: Collective, computational, and cognitive},
journal = {International Journal of Architectural Computing},
volume = {21},
number = {2},
pages = {256–279},
year = {2023e},
doi = {10.1177/14780771231170272},
URL = {https://doi-org.crai.referencistas.com/10.1177/14780771231170272},
eprint = {https://doi-org.crai.referencistas.com/10.1177/14780771231170272},
abstract = {This paper examines the prevalence of bias in artificial intelligence text-to-image models utilized in the architecture and design disciplines. The rapid pace of advancements in machine learning technologies, particularly in text-to-image generators, has significantly increased over the past year, making these tools more accessible to the design community. Accordingly, this paper aims to critically document and analyze the collective, computational, and cognitive biases that designers may encounter when working with these tools at this time. The paper delves into three hierarchical levels of operation and investigates the possible biases present at each level. Starting with the training data for large language models (LLM), the paper explores how these models may create biases privileging English-language users and perspectives. The paper subsequently investigates the digital materiality of models and how their weights generate specific aesthetic results. Finally, the report concludes by examining user biases through their prompt and image selections and the potential for platforms to perpetuate these biases through the application of user data during training.}
}

@article{doi:10.1068/b230313,
author = {Y T Liu},
title = {Restructuring Shapes in Terms of Emergent Subshapes: A Computational and Cognitive Model},
journal = {Environment and Planning B: Planning and Design},
volume = {23},
number = {3},
pages = {313–328},
year = {1996f},
doi = {10.1068/b230313},
URL = {https://doi-org.crai.referencistas.com/10.1068/b230313},
eprint = {https://doi-org.crai.referencistas.com/10.1068/b230313},
abstract = {In order to interpret the current state of a design, designers possess the powerful, spontaneous ability to restructure shapes in terms of emergent subshapes. In this paper a theoretical model of restructuring shapes is presented, one that aims to recognize explicit and implicit emergent subshapes computationally and to explain cognitively some critical phenomena of designers’ visual behaviors. A computing procedure using two neuron-like connectionist networks and two attentional techniques serves as the vehicle to mimic some critical empirical phenomena. By a comparison of the computational and empirical variables embedded in the subshape viewing processes, the internal behavior of the model has been further clarified, and some hypothetical viewpoints have been cross-validated.}
}

@article{doi:10.1177/154193120104500444,
author = {Michael D. McNeese},
title = {The Use of Ubiquitous Computing/Computational Neuroscience for Distributed Battlefield Management},
journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
volume = {45},
number = {4},
pages = {473–477},
year = {2001g},
doi = {10.1177/154193120104500444},
URL = {https://doi-org.crai.referencistas.com/10.1177/154193120104500444},
eprint = {https://doi-org.crai.referencistas.com/10.1177/154193120104500444},
abstract = {Military missions are increasingly contingent upon the ‘emergent qualities’ of distributed cognition. Cognition is situated and shared across multiple agents, objects, and environments. The total information surround is evolutionary, chaotic, and presents workers with ill-defined dilemmas that proliferate across geopolitical boundaries under stressed conditions. Crew members are bombarded with multiple constraints as they encounter automation, situational awareness, and information warfare. To address these concerns the use of computational neuroscience/ubiquitous computing technologies are described. Ubiquitous computing means that computing elements are not integrated in a single workstation but are ubiquitous; they are distributed as everyday objects in an operative work environment. When complemented with evolutionary computing technology, computer structures (cellular thoughtonoma) are designed to ‘genetically evolve’ through natural selection to be ‘fit’ with environmental, technological, and worker demands. This paper discusses the symbiosis underlying thoughtonomous technologies and describes possibilities to radically redefine intelligent interaction and collaboration.}
}

@article{doi:10.1177/109434208800200407,
author = {Yi Qin and Jianhuang Wu and Qingmao Hu and Dhanjoo N. Ghista and Kelvin K.L. Wong},
title = {Computational evaluation of smoothed particle hydrodynamics for implementing blood flow modelling through CT reconstructed arteries},
journal = {The International Journal of Supercomputing Applications},
volume = {25},
number = {2},
pages = {63–71},
year = {2017h},
doi = {10.1177/109434208800200407},
URL = {https://doi-org.crai.referencistas.com/10.1177/109434208800200407},
eprint = {https://doi-org.crai.referencistas.com/10.1177/109434208800200407},
abstract = {Computational fluid dynamics (CFD) is a powerful tool for the simulation of complex fluid dynamics problems. In the future, the progress in CFD will depend on effi cient algorithms as well as on the power and storage capacity of the computers available. A careful study and comparison of these supercomputers, therefore, is nec essary. The following paper presents a short description of the Engineering and Scientific Model Benchmark, the supercomputers and mini-supercomputers under con sideration, and a discussion of the benchmark results.}
}

@article{doi:10.2190/ET.39.1.d,
author = {Gurmukh Singh and Khalid Siddiqui and Mankiran Singh and Satpal Singh},
title = {Modeling Mendel’s Laws on Inheritance in Computational Biology and Medical Sciences},
journal = {Journal of Educational Technology Systems},
volume = {39},
number = {1},
pages = {31–46},
year = {2010i},
doi = {10.2190/ET.39.1.d},
URL = {https://doi-org.crai.referencistas.com/10.2190/ET.39.1.d},
eprint = {https://doi-org.crai.referencistas.com/10.2190/ET.39.1.d},
abstract = {The current research article is based on a simple and practical way of employing the computational power of widely available, versatile software MS Excel 2007 to perform interactive computer simulations for undergraduate/graduate students in biology, biochemistry, biophysics, microbiology, medicine in college and university classroom setting. To accomplish this important motive, we developed the necessary computer algorithm, which used a built-in pseudo-random number generating function in MS Excel 2007, to computer model two basic Mendel’s Laws of heredity for plant and animal species. We performed more than 18,000 computer simulations to investigate the behavior of dominant and recessive genes to verify two basic Mendel’s Laws of heredity. Our simulation work corroborates the experimental observations of Mendel’s research on inheritance in Pisum hybrid species. When we compare our results of simulated data with that of experiments done on Drosophila melanogaster, fruit fly extensively being used as a model organism to study genetics and development, an exceedingly good agreement between the simulated and the experimental data has been observed for the F2 generation.}
}

@article{doi:10.1177/15500594211018545,
author = {Caglar Uyulan and Sara de la Salle and Turker T. Erguzel and Emma Lynn and Pierre Blier and Verner Knott and Maheen M. Adamson and Mehmet Zelka and Nevzat Tarhan},
title = {Depression Diagnosis Modeling With Advanced Computational Methods: Frequency-Domain eMVAR and Deep Learning},
journal = {Clinical EEG and Neuroscience},
volume = {53},
number = {1},
pages = {24–36},
year = {2022j},
doi = {10.1177/15500594211018545},
note = {PMID:34080925},
URL = {https://doi-org.crai.referencistas.com/10.1177/15500594211018545},
eprint = {https://doi-org.crai.referencistas.com/10.1177/15500594211018545},
abstract = {Electroencephalogram (EEG)-based automated depression diagnosis systems have been suggested for early and accurate detection of mood disorders. EEG signals are highly irregular, nonlinear, and nonstationary in nature and are traditionally studied from a linear viewpoint by means of statistical and frequency features. Since, linear metrics present certain limitations and nonlinear methods have proven to be an efficient tool in understanding the complexities of the brain in the identification of underlying behavior of biological signals, such as electrocardiogram, EEG and magnetoencephalogram and thus, can be applied to all nonstationary signals. Various nonlinear algorithms can be used in the analysis of EEG signals. In this research paper, we aim to develop a novel methodology for EEG-based depression diagnosis utilizing 2 advanced computational techniques: frequency-domain extended multivariate autoregressive (eMVAR) and deep learning (DL). We proposed a hybrid method comprising a pretrained ResNet-50 and long-short term memory (LSTM) to capture depression-specific information and compared with a strong conventional machine learning (ML) framework having eMVAR connectivity features. The following 8 causality measures, which interpret the interaction mechanisms among spectrally decomposed oscillations, were used to extract features from multivariate EEG time series: directed coherence (DC), directed transfer function (DTF), partial DC (PDC), generalized PDC (gPDC), extended DC (eDC), delayed DC (dDC), extended PDC (ePDC), and delayed PDC (dPDC). The classification accuracies were 84% with DC, 85% with DTF, 95.3% with PDC, 95.1% with gPDC, 84.8% with eDC, 84.6% with dDC, 84.2% with ePDC, and 95.9% with dPDC for the eMVAR framework. Through a DL framework (ResNet-50 + LSTM), the classification accuracy was achieved as 90.22%. The results demonstrate that our DL methodology is a competitive alternative to the strong feature extraction-based ML methods in depression classification.}
}

