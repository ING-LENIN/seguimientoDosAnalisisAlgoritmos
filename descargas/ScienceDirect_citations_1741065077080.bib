@article{LEESON2008630,
title = {Cognitive ability, personality, and academic performance in adolescence},
journal = {Personality and Individual Differences},
volume = {45},
number = {7},
pages = {630-635},
year = {2008},
issn = {0191-8869},
doi = {https://doi.org/10.1016/j.paid.2008.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S0191886908002444},
author = {Peter Leeson and Joseph Ciarrochi and Patrick C.L. Heaven},
keywords = {Cognitive ability, Personality, Academic performance, Adolescents, Hope, Self-esteem, Attributional style, Psychometric },
abstract = {Does positive thinking predict variance in school grades over and above that predicted by cognitive ability? Six hundred and thirty nine high school students participated in a three-year longitudinal study that predicted grades using cognitive ability and three positive thinking variables – self-esteem, hope, and attributional style. Hope, positive attributional style and cognitive ability predicted higher grades, whilst self-esteem was a less consistent predictor of academic performance. Structural equation modelling revealed significant paths from cognitive ability, gender, and a second order positive thinking factor to grades. The results suggest that intelligence, gender, and positive thinking each play a unique role in predicting academic performance in youth. Some suggestions for further research are made.}
}
@article{WANG2016747,
title = {Towards felicitous decision making: An overview on challenges and trends of Big Data},
journal = {Information Sciences},
volume = {367-368},
pages = {747-765},
year = {2016},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2016.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0020025516304868},
author = {Hai Wang and Zeshui Xu and Hamido Fujita and Shousheng Liu},
keywords = {Big Data, Data deluge, Decision making, Data analysis, Data-intensive applications, Computational social science},
abstract = {The era of Big Data has arrived along with large volume, complex and growing data generated by many distinct sources. Nowadays, nearly every aspect of the modern society is impacted by Big Data, involving medical, health care, business, management and government. It has been receiving growing attention of researches from many disciplines including natural sciences, life sciences, engineering and even art & humanities. It also leads to new research paradigms and ways of thinking on the path of development. Lots of developed and under-developing tools improve our ability to make more felicitous decisions than what we have made ever before. This paper presents an overview on Big Data including four issues, namely: (i) concepts, characteristics and processing paradigms of Big Data; (ii) the state-of-the-art techniques for decision making in Big Data; (iii) felicitous decision making applications of Big Data in social science; and (iv) the current challenges of Big Data as well as possible future directions.}
}
@article{BATT2002185,
title = {Lateral thinking: 2-D interpretation of thermochronology in convergent orogenic settings},
journal = {Tectonophysics},
volume = {349},
number = {1},
pages = {185-201},
year = {2002},
note = {Low Temperature Thermochronology: From Tectonics to Landscape Evolution},
issn = {0040-1951},
doi = {https://doi.org/10.1016/S0040-1951(02)00053-7},
url = {https://www.sciencedirect.com/science/article/pii/S0040195102000537},
author = {Geoffrey E. Batt and Mark T. Brandon},
keywords = {Lateral motion, Thermochronology, Orogenic regions},
abstract = {Lateral motion of material relative to the regional thermal and kinematic frameworks is important in the interpretation of thermochronology in convergent orogens. Although cooling ages in denuded settings are commonly linked to exhumation, such data are not related to instantaneous behavior but rather to an integration of the exhumation rates experienced between the thermochronological ‘closure’ at depth and subsequent exposure at the surface. The short spatial wavelength variation of thermal structure and denudation rate typical of orogenic regions thus renders thermochronometers sensitive to lateral motion during exhumation. The significance of this lateral motion varies in proportion with closure temperature, which controls the depth at which isotopic closure occurs, and hence, the range of time and length scales over which such data integrate sample histories. Different chronometers thus vary in the fundamental aspects of the orogenic character to which they are sensitive. Isotopic systems with high closure temperature are more sensitive to exhumation paths and the variation in denudation and thermal structure across a region, while those of lower closure temperature constrain shorter-term behaviour and more local conditions. Discounting lateral motion through an orogenic region and interpreting cooling ages purely in terms of vertical exhumation can produce ambiguous results because variation in the cooling rate can result from either change in kinematics over time or the translation of samples through spatially varying conditions. Resolving this ambiguity requires explicit consideration of the physical and thermal framework experienced by samples during their exhumation. This can be best achieved through numerical simulations coupling kinematic deformation to thermal evolution. Such an approach allows the thermochronological implications of different kinematic scenarios to be tested, and thus provides an important means of assessing the contribution of lateral motion to orogenic evolution.}
}
@article{JACKSON201386,
title = {Airflow reversal and alternating corkscrew vortices in foredune wake zones during perpendicular and oblique offshore winds},
journal = {Geomorphology},
volume = {187},
pages = {86-93},
year = {2013},
issn = {0169-555X},
doi = {https://doi.org/10.1016/j.geomorph.2012.12.037},
url = {https://www.sciencedirect.com/science/article/pii/S0169555X13000081},
author = {Derek W.T. Jackson and Meiring Beyers and Irene Delgado-Fernandez and Andreas C.W. Baas and Andrew J. Cooper and Kevin Lynch},
keywords = {Computational fluid dynamics, Aeolian, Foredunes, Transport, Airflow modelling, Lee side eddies},
abstract = {On all sandy coastlines fringed by dunes, understanding localised air flow allows us to examine the potential sand transfer between the beach and dunes by wind-blown (Aeolian) action. Traditional thinking into this phenomenon had previously included only onshore winds as effective drivers of this transfer. Recent research by the authors, however, has shown that offshore air-flow too can contribute significantly, through lee-side back eddies, to the overall windblown sediment budget to coastal dunes. Under rising sea levels and increased erosion scenarios, this is an important process in any post-storm recovery of sandy beaches. Until now though, full visualisation in 3D of this newly recognised mechanism in offshore flows has not been achieved. Here, we show for the first time, this return flow eddy system using 3D computational fluid dynamics modelling, and reveal the presence of complex corkscrew vortices and other phenomena. The work highlights the importance of relatively small surface undulations in the dune crest which act to induce the spatial patterns of airflow (and transport) found on the adjacent beach.}
}
@article{ZENASNI2009353,
title = {Perception of emotion, alexithymia and creative potential},
journal = {Personality and Individual Differences},
volume = {46},
number = {3},
pages = {353-358},
year = {2009},
issn = {0191-8869},
doi = {https://doi.org/10.1016/j.paid.2008.10.030},
url = {https://www.sciencedirect.com/science/article/pii/S0191886908004108},
author = {F. Zenasni and T.I. Lubart},
keywords = {Creativity, Ability EI, Alexythimia, Emotional creativity, Divergent thinking},
abstract = {Theoretical proposals suggest that emotional intelligence (EI) may favor creativity. In the present paper, two studies are reported with French adults to examine the degree to which the ability to identify emotion is related to creative performance. This component of ability EI was hypothesized to be positively associated with a divergent thinking task involving emotional information. Contrary to our expectations, the first study (n=95) indicated that ability to identify emotions in faces and images was negatively related to idea generation ability. The second study (n=100) including a measure of alexithymia confirmed this relation. Moreover, evaluating emotional creativity, we observed a significant negative link between the ability to identify emotions and the tendency to experience emotions differently from those of others. We discuss these results suggesting an opposition between consensual/convergent thinking concerning emotions (ability EI) and divergent thinking.}
}
@article{GADALLA2023200201,
title = {Concepts and experiments on psychoanalysis driven computing},
journal = {Intelligent Systems with Applications},
volume = {18},
pages = {200201},
year = {2023},
issn = {2667-3053},
doi = {https://doi.org/10.1016/j.iswa.2023.200201},
url = {https://www.sciencedirect.com/science/article/pii/S2667305323000261},
author = {Minas Gadalla and Sotiris Nikoletseas and José Roberto {de A. Amazonas} and José D.P. Rolim},
keywords = {Lacanian discourses, Psychoanalysis computing, GPT-3},
abstract = {This research investigates the effective incorporation of the human factor and user perception in text-based interactive media. In such contexts, the reliability of user texts is often compromised by behavioural and emotional dimensions. To this end, several attempts have been made in the state of the art, to introduce psychological approaches in such systems, including computational psycholinguistics, personality traits and cognitive psychology methods. In contrast, our method is fundamentally different since we employ a psychoanalysis-based approach; in particular, we use the notion of Lacanian discourse types, to capture and deeply understand real (possibly elusive) characteristics, qualities and contents of texts, and evaluate their reliability. As far as we know, this is the first time computational methods are systematically combined with psychoanalysis. We believe such psychoanalytic framework is fundamentally more effective than standard methods, since it addresses deeper, quite primitive elements of human personality, behaviour and expression which usually escape methods functioning at “higher”, conscious layers. In fact, this research is a first attempt to form a new paradigm of psychoanalysis-driven interactive technologies, with broader impact and diverse applications. To exemplify this generic approach, we apply it to the case-study of fake news detection; we first demonstrate certain limitations of the well-known Myers–Briggs Type Indicator (MBTI) personality type method, and then propose and evaluate our new method of analysing user texts and detecting fake news based on the Lacanian discourses psychoanalytic approach.}
}
@article{SUN2025129677,
title = {StereoSqueezeNet: With fewer parameters but higher accuracy than SqueezeNet},
journal = {Neurocomputing},
volume = {627},
pages = {129677},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.129677},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225003492},
author = {Qiaoyan Sun and Jianfei Chen},
keywords = {SSNet, Stereo, SqueezeNet, Network compression, Network parameters},
abstract = {Convolutional neural networks (CNNs) have evolved from the initial LeNet to date, and network models have become increasingly deep and comprehensive. It has been proven that deeper networks have better fitting effects, but the corresponding parameter size and computational complexity increase rapidly. With the continuous development of mobile Internet technology, portable devices have been rapidly popularized, and users have put forward more and more demands. Thus, how to design efficient and high-performance lightweight convolutional neural networks (CNNs) is the key to solve this challenging problem. Recently, this type of convolutional neural networks (CNNs)--lightweight convolutional neural networks (CNNs), which adopt the design concept of compression networks and maintain high accuracy with fewer parameters, has attracted increasing attention. SqueezeNet is a lightweight CNN adapting to edge device deployment. Its number of parameters is only 1/50 of AlexNet, but it achieves the same accuracy as AlexNet. In order to make the network more lightweight, inspired by SqueezeNet, MobileNet, SENet, SKNet, AlexNet, etc., in this paper we propose StereoSqueezeNet, using much fewer parameters but achieving even better accuracy than SqueezeNet.}
}
@article{ARUN2009S1115,
title = {P03-116 Damage to object oriented programming in the brain explains many of the psychopathological features of schizophrenia},
journal = {European Psychiatry},
volume = {24},
pages = {S1115},
year = {2009},
note = {17th EPA Congress - Lisbon, Portugal, January 2009, Abstract book},
issn = {0924-9338},
doi = {https://doi.org/10.1016/S0924-9338(09)71348-3},
url = {https://www.sciencedirect.com/science/article/pii/S0924933809713483},
author = {C.P. Arun},
abstract = {Introduction
Modern computers often use programs that incorporate a programming technique called Object Oriented Programming (OOP), allowing users to manipulate complex ‘computational objects’ such as menus, screen windows, etc with very little effort, say the click of a mouse. OOP deals with structures called objects and allows time and computational effort saving devices such as inheritance, polymorphism and encapsulation. We examine whether the brain itself may use OOP and if representation of objects suffers a breakdown in schizophrenia.
Review of literature
Previous models fail to provide a unifying explanation with a computational basis that could explain the psychopathology in schizophrenia. METHODS Using the object oriented programming language JavaTM we designed a system of self-objects named ‘hand’, ‘action monitor’ etc interacting with non-self objects ‘scissors’, ‘hammer’, ‘wall’, etc. In computational experiments, we allow the ‘action monitor’ to fail; the features of disparate objects are allowed to merge, some features of an object are allowed to be shared with other objects, etc.
Results
By transposing only a few lines of code, it is possible to duplicate various features of the psychopathology of schizophrenia.
Discussion
Our model can demonstrate overinclusion (overabstraction), concrete thinking (underabstraction), loss of ego boundaries (conjoining of disparate objects), delusions (misattribution of object function), lack of insight (poor monitoring of object activity) and passivity (loss of monitoring and misattribution of object activity).
Conclusion
The brain must use the OOP model in its computations. Failure of object representation and manipulation must lie at the core of the psychopathology of schizophrenia.}
}
@article{MARENDA20232152,
title = {Sliding pendulum isolators without secretes},
journal = {Procedia Structural Integrity},
volume = {44},
pages = {2152-2157},
year = {2023},
note = {XIX ANIDIS Conference, Seismic Engineering in Italy},
issn = {2452-3216},
doi = {https://doi.org/10.1016/j.prostr.2023.01.275},
url = {https://www.sciencedirect.com/science/article/pii/S2452321623002846},
author = {Ivan Marenda and Agostino Marioni and Marco Banfi and Roberto Dalpedri},
keywords = {friction coefficient, pendulum device, contact, isolation system},
abstract = {Over the last decades, anti-seismic devices have gained increasing interest in the civil engineering field. The introduction of the base isolation system has led to a new concept in the construction panorama in terms of human life safety, a new way of thinking on new constructions, improvement and retrofitting on existent structures. Therefore, rubber and friction isolators have been deeply investigated to hence performances and predict dynamic behaviour during an earthquake. While the response of the former is characterised by the composition of the elastomeric compound, the latter features special materials able to dissipate energy by moving on smooth surfaces. This paper focuses on friction pendulum devices and addresses its attention on the behaviour of sliding materials. It is well-known that stick-slip phenomenon occurs when friction excitation is present and, in the anti-seismic field is important to reduce it and have a well-representative mathematical law able to describe it. Therefore, Hirun International after performing several treatments of the sliding materials has set up a special processing to guarantee a stable response of the HI-M material used on pendulum devices. The paper, after a brief presentation of the special sliding material, shows a comparison between the material with and without the treatment in terms of the force-displacement law. The paper also analyses in detail the cinematic behaviour of the sliding pendulum with one or two main sliding surfaces, with and without central articulation and determines the stress distribution in the sliding surfaces for the different cases.}
}
@article{WEBB2008360,
title = {The role of teacher instructional practices in student collaboration},
journal = {Contemporary Educational Psychology},
volume = {33},
number = {3},
pages = {360-381},
year = {2008},
note = {Collaborative Discourse, Argumentation, and Learning},
issn = {0361-476X},
doi = {https://doi.org/10.1016/j.cedpsych.2008.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0361476X0800026X},
author = {Noreen M. Webb and Megan L. Franke and Marsha Ing and Angela Chan and Tondra De and Deanna Freund and Dan Battey},
keywords = {Instructional practices, Student collaboration},
abstract = {Prior research on collaborative learning identifies student behaviors that significantly predict student achievement, such as giving explanations of one’s thinking. Less often studied is the role of teachers’ instructional practices in collaboration among students. This article investigates the extent to which teachers engage in practices that support students’ explanations of their thinking, and how these teacher practices might be related to the nature of explanations that students give when asked by the teacher to collaborate with each other. The teachers observed here, all of whom received specific instruction in eliciting the details of student thinking, varied significantly in the extent to which they asked students to elaborate on their suggestions. This variation corresponded to variation across classrooms in the nature and extent of student explanations during collaborative conversations and to differences in student achievement.}
}
@article{AKTAYEVA2022285,
title = {Aesthetic education: the process of teaching mathematics with the open-source software},
journal = {Transportation Research Procedia},
volume = {63},
pages = {285-293},
year = {2022},
note = {X International Scientific Siberian Transport Forum — TransSiberia 2022},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2022.06.015},
url = {https://www.sciencedirect.com/science/article/pii/S2352146522002708},
author = {Alena Aktayeva and Elena Zubareva and Aibek Dautov and Kymbat Saginbayeva and Rozamgul Niyazova and Sergey Khan and Aigerim Shonasheva},
keywords = {Aesthetic education, mathematical education, software, computer programs},
abstract = {In the article one of leading aims of educating mathematics is examined is aesthetic education of student facilities of mathematics. Presentation of aesthetic beauty at her decisions possibility of students is investigated, specifying them on the decision of one problem in several ways that assists the detailed consideration of idea of aesthetic education, through Open-source Software. The technical capabilities and elegant ease of use of systems Open-source Software provides a seamless, integrated and constantly expanding system that covers the breadth and depth of mathematical computing, and is available seamlessly through any web browser along with all modern systems used in the educational process. The article will describe understanding of beauty the decision of a problem; methods of decisions that are accompanied by the use make possible a uniquely flexible and convenient approach to charting and information visualization in a mathematical calculate. Such sort of activity assists aesthetic education, allowing to develop a culture and logical thinking, forming at students a different choice, grace of decision of problems.}
}
@article{IWASE20211,
title = {Towards a Noncompliant Pedagogy of the Image: Reading Negentropic Bifurcatory Potentials in Video Images},
journal = {Video Journal of Education and Pedagogy},
volume = {6},
number = {1},
pages = {1-27},
year = {2021},
issn = {2364-4583},
doi = {https://doi.org/10.1163/23644583-bja10020},
url = {https://www.sciencedirect.com/science/article/pii/S236445832300023X},
author = {Masayuki Iwase and Joff P. N. Bradley},
keywords = {urban film-making, critique, metamodelization, global mnemotechnical system, proletarianized knowledge, mnemonic control, artificial and living engines, machinic enslavement, negentropic bifurcation, Deleuze, Heidegger, Virilio, time-image, lectosign, spiritual automation, zooming-in/out, autistic milieus, diffractive becoming, radical pedagogy},
abstract = {The authors explore the noncompliant pedagogy of the image based on their video Autopoietic Veering: Schizo Socius of Tokyo and Vancouver (2021). It is not the kind of trendy modelized video abstract or kinetic presentation eagerly promoted by international publishers; it is a cross-cultural collaborative work intended to generate affirmative temporal ruptures of entropic habitual modes of seeing, memorizing, and thinking of human and nonhuman life in the cities of Tokyo (Japan) and Vancouver (Canada). The authors elucidate Stiegler’s (2015b) concept of a “global mnemotechnical system” that stores and produces human memories in vast digital archives and databases (tertiary retentions) through “mnemonic control” (Parisi & Goodman, 2011). The authors repurpose video images to interrupt and recontrol human perception and memories as “living engines” (Lazzarato, 2006). They foreground the philosophical work of Deleuze, Heidegger, and Virilio to rethink and revive the creative act of “critique” (Foucault, 1997) through “metamodelization” (Guattari, 1995; Manning, 2020); therefore, they plug these apparently incommensurable modes of thinking into their readings of the video’s images. They read the images as “time-images” and focus on their five dimensions that possibly activate “spiritual automation” (Deleuze, 1989), which they assess as “negentropic bifurcatory” potentials (Bradley & Kennedy, 2019).}
}
@article{HAWES201560,
title = {Effects of mental rotation training on children’s spatial and mathematics performance: A randomized controlled study},
journal = {Trends in Neuroscience and Education},
volume = {4},
number = {3},
pages = {60-68},
year = {2015},
issn = {2211-9493},
doi = {https://doi.org/10.1016/j.tine.2015.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S2211949315000083},
author = {Zachary Hawes and Joan Moss and Beverly Caswell and Daniel Poliszczuk},
keywords = {Spatial thinking, Mental rotation, Spatial training, Computerized cognitive training, Mathematics education, STEM},
abstract = {The purpose of the current study was to (i) investigate the malleability of children’s spatial thinking, and (ii) the extent to which training-related gains in spatial thinking generalize to mathematics performance. Sixty-one 6- to 8-year-olds were randomly assigned to either computerized mental rotation training or literacy training. Training took place on iPad devices over a 6-week period as part of regular classroom activity. Results revealed that in comparison to the control group, children who received spatial training demonstrated significant gains on two measures of mental rotation and marginally significant improvements on an untrained mental transformation task; a finding that suggests that training may have had a general effect on children’s spatial ability. However, contrary to theoretical claims and prior empirical findings, there was no evidence that spatial training transferred to mathematics performance.}
}
@article{LOPEZORTEGA20133459,
title = {Computer-assisted creativity: Emulation of cognitive processes on a multi-agent system},
journal = {Expert Systems with Applications},
volume = {40},
number = {9},
pages = {3459-3470},
year = {2013},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2012.12.054},
url = {https://www.sciencedirect.com/science/article/pii/S095741741201295X},
author = {Omar López-Ortega},
keywords = {Computer-assisted creativity, Cognitive processes, Agent-oriented programming, Recursive systems},
abstract = {For creativity to be computed, it is paramount to understand the cognitive processes involved, which have been elucidated by either surveying creative people or discovering regions of the human brain that activate during creative endeavors. From this scattering, the author proposes a holistic framework to describe them and their interaction. Hence, creativity can be regarded as a meta process which coordinates autonomous cognitive processes such as planning or divergent thinking. To represent the interplay of cognitive processes around creativity, models are developed in the Agent Unified Modeling Language (AUML). Then, the execution of each process is delegated to autonomous agents and a global coordination protocol is devised. The implementation of the MAS is done on the JADE platform. Two modules of the resultant system are exemplified: opus planning and divergent exploration. The coordination protocol is also presented. The domain in which the software system is tested is the creation of musical pieces.}
}
@article{LI201985,
title = {Government accounting optimization based on computational linguistics},
journal = {Cognitive Systems Research},
volume = {57},
pages = {85-91},
year = {2019},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2018.10.017},
url = {https://www.sciencedirect.com/science/article/pii/S1389041718304650},
author = {Jiyou Li},
keywords = {Computational linguistics, Accounting optimization, Research},
abstract = {The level of moral development and moral intensity in cognitive psychology will not only affect the ethical behavior of accountants, but also have a direct impact on the quality and level of accounting work. Therefore, in this paper, the ethical behavior of accountants was analyzed from the perspective of cognitive psychology. Computer-aided data mining techniques were introduced, and government accounting risk assessment management of financial accountants was studied. In this paper, the principle of cognitive psychology to measure the ethical level of accountants was first described. The predicament of moral judgments was analyzed and an optimization plan to improve the ethical intention of accountants was proposed. Support Vector Machine classification technology in data mining was studied to explore how to conduct effective and reliable evaluation, so as to provide a scientific basis for decision-making in improving accounting management. After the simulation experiment, it is proved that continuously improving the ethical standards of accountants and strengthening the forecast of accounting risks can continue to optimize the accounting office management.}
}
@article{MUST20167,
title = {Predicting the Flynn Effect through word abstractness : Results from the National Intelligence Tests support Flynn's explanation},
journal = {Intelligence},
volume = {57},
pages = {7-14},
year = {2016},
issn = {0160-2896},
doi = {https://doi.org/10.1016/j.intell.2016.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S0160289616300253},
author = {Olev Must and Aasa Must and Jaan Mikk},
keywords = {Flynn Effect, National Intelligence Tests, Abstract thinking, Guessing, Tork, Estonia},
abstract = {The current study investigates the Flynn Effect (FE) and its relation to abstract thinking ability. We compare two cohorts of Estonian students (1933/36, n=888; 2006, n=912) using the Concepts (Logical Selection) subtest of the Estonian adaptation of the National Intelligence Tests (NIT). The item presentation order of the subtest correlates with the abstractness of the words used in the items (r=.609) of the subtest. The different test results (right, wrong and missing answers) were analysed in order to make an estimate of the FE magnitude. The FE for abstract thinking ability of those samples was 1.06 Hedges' g (adjusted for guessing). The magnitude of the FE is dependent upon the degree of difficulty of the items (an item's difficulty is estimated by determining its abstractness and its familiarity to students). The more difficult part of the subtest (the second half) showed a FE=1.80 whereas the easier part (the first half) of the subtest showed a FE=.72. Word abstractness was a strong predictor of all the testing results in both cohorts (Beta=.700). The familiarity of words used in the test items has no correlation with the test results if word abstractness is controlled in both cohorts. Our findings support Flynn's explanation that the FE is primarily an indicator of the rise in abstract thinking ability.}
}
@article{LIU2024100012,
title = {Investigating coacervates as drug carriers using molecular dynamics},
journal = {Precision Medicine and Engineering},
volume = {1},
number = {2},
pages = {100012},
year = {2024},
issn = {2950-4821},
doi = {https://doi.org/10.1016/j.preme.2024.100012},
url = {https://www.sciencedirect.com/science/article/pii/S2950482124000123},
author = {Yang Liu and Rongrong Zou and Yiwei Wang and Minghao Wang and Fan Fan and Yeqiang Zhou and Huixu Xie and Mingming Ding},
keywords = {Drug delivery, Coacervate, Molecular dynamics, Machine learning, Protein encapsulation},
abstract = {Coacervates show promise in drug delivery systems due to their biocompatibility, versatility, and outstanding ability to penetrate cells. With the advent of all-atom (AA) and coarse-grained (CG) models, these computational tools function as ‘computational microscopes’, providing valuable insights to complement experimental research. This review covers the latest innovations in coacervate-based drug delivery systems. It summarizes the molecular properties and phase behavior of coacervates composed of polyelectrolytes, intrinsically disordered proteins (IDPs), and other biomolecules, along with their interactions with carried drugs and cell membranes. Additionally, this review highlights current challenges and limitations in this fast-moving field and proposes potential avenues for future research.}
}
@incollection{HERLIHY201469,
title = {Chapter 4 - Colorless Wait-Free Computation},
editor = {Maurice Herlihy and Dmitry Kozlov and Sergio Rajsbaum},
booktitle = {Distributed Computing Through Combinatorial Topology},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {69-95},
year = {2014},
isbn = {978-0-12-404578-1},
doi = {https://doi.org/10.1016/B978-0-12-404578-1.00004-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780124045781000048},
author = {Maurice Herlihy and Dmitry Kozlov and Sergio Rajsbaum},
keywords = {Configurations, Executions, Layered executions, Layered protocols, Processes, Protocols, Schedules, Tasks},
abstract = {We outline the basic connection between distributed computing and combinatorial topology in terms of two formal models: a conventional operational model, in which systems consist of communicating state machines whose behaviors unfold over time, and the combinatorial model, in which all possible behaviors are captured statically using topological notions. We start with one particular system model (shared memory) and focus on a restricted (but important) class of problems (so-called “colorless” tasks).}
}
@article{SHEFFIELD20221149,
title = {Belief Updating and Paranoia in Individuals With Schizophrenia},
journal = {Biological Psychiatry: Cognitive Neuroscience and Neuroimaging},
volume = {7},
number = {11},
pages = {1149-1157},
year = {2022},
issn = {2451-9022},
doi = {https://doi.org/10.1016/j.bpsc.2022.03.013},
url = {https://www.sciencedirect.com/science/article/pii/S2451902222000799},
author = {Julia M. Sheffield and Praveen Suthaharan and Pantelis Leptourgos and Philip R. Corlett},
keywords = {Belief updating, Computational psychiatry, Delusions, Paranoia, Volatility, Worry},
abstract = {Background
Persecutory delusions are among the most common delusions in schizophrenia and represent the extreme end of the paranoia continuum. Paranoia is accompanied by significant worry and distress. Identifying cognitive mechanisms underlying paranoia is critical for advancing treatment. We hypothesized that aberrant belief updating, which is related to paranoia in human and animal models, would also contribute to persecutory beliefs in individuals with schizophrenia.
Methods
Belief updating was assessed in 42 participants with schizophrenia and 44 healthy control participants using a 3-option probabilistic reversal learning task. Hierarchical Gaussian Filter was used to estimate computational parameters of belief updating. Paranoia was measured using the Positive and Negative Syndrome Scale and the revised Green et al. Paranoid Thoughts Scale. Unusual thought content was measured with the Psychosis Symptom Rating Scale and the Peters et al. Delusions Inventory. Worry was measured using the Dunn Worry Questionnaire.
Results
Paranoia was significantly associated with elevated win-switch rate and prior beliefs about volatility both in schizophrenia and across the whole sample. These relationships were specific to paranoia and did not extend to unusual thought content or measures of anxiety. We observed a significant indirect effect of paranoia on the relationship between prior beliefs about volatility and worry.
Conclusions
This work provides evidence that relationships between belief updating parameters and paranoia extend to schizophrenia, may be specific to persecutory beliefs, and contribute to theoretical models implicating worry in the maintenance of persecutory delusions.}
}
@article{RUNNELS201563,
title = {Capturing plasticity effects in overdriven shocks on the finite scale},
journal = {Mathematics and Computers in Simulation},
volume = {111},
pages = {63-79},
year = {2015},
issn = {0378-4754},
doi = {https://doi.org/10.1016/j.matcom.2014.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S0378475414003334},
author = {Scott R. Runnels},
keywords = {Shocks, Plasticity, Hardening, Hydrodynamics, Radial return},
abstract = {An ordinary differential equation (ODE) form of the radial return algorithm, which is essentially a Prandtl-Reuss material model, is combined with a strain-rate hardening model to produce an ODE that describes deviatoric stress through a prescribed density rise. An analytical solution is found to the resulting ODE for a specific choice of one of the hardening model’s parameters. That solution is used to prove that if the prescribed density rise is allowed to be infinitely thin, i.e., like a shock in the mathematical sense, the resulting deviatoric stress is still bounded. In other words, the singularity is integrable; integration of the radial return ODE regularizes the infinite strain rate and resulting yield stress in the presence of an ideal shock singularity. The analytical tools developed for this line of thinking are applied to study the variation of deviatoric stress through a nearly shock-like density rise using different density rise profiles, revealing the impact of the shape choice. The tools are also used to compute what rise times are needed to converge upon the correct value of deviatoric stress through a shock; the results indicate that most contemporary hydrocodes cannot be expected to achieve those rise times. A demonstration of connecting the analytical tools to a hydrocode, using surrogate numerical shock shapes, is provided thereby opening the door for using such surrogates to perform sub-grid computations of converged shock behavior for strain-rate hardening materials.}
}
@article{HU2024101646,
title = {A flexible BERT model enabling width- and depth-dynamic inference},
journal = {Computer Speech & Language},
volume = {87},
pages = {101646},
year = {2024},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2024.101646},
url = {https://www.sciencedirect.com/science/article/pii/S0885230824000299},
author = {Ting Hu and Christoph Meinel and Haojin Yang},
keywords = {Grafting, Dynamic inference, Large Language Models, Deep learning},
abstract = {Fine-tuning and inference on Large Language Models like BERT have become increasingly expensive regarding memory cost and computation resources. The recently proposed computation-flexible BERT models facilitate their deployment in varied computational environments. Training such flexible BERT models involves jointly optimizing multiple BERT subnets, which will unavoidably interfere with one another. Besides, the performance of large subnets is limited by the performance gap between the smallest subnet and the supernet, despite efforts to enhance the smaller subnets. In this regard, we propose layer-wise Neural grafting to boost BERT subnets, especially the larger ones. The proposed method improves the average performance of the subnets on six GLUE tasks and boosts the supernets on all GLUE tasks and the SQuAD data set. Based on the boosted subnets, we further build an inference framework enabling practical width- and depth-dynamic inference regarding different inputs by combining width-dynamic gating modules and early exit off-ramps in the depth dimension. Experimental results show that the proposed framework achieves a better dynamic inference range than other methods in terms of trading off performance and computational complexity on four GLUE tasks and SQuAD. In particular, our best-tradeoff inference result outperforms other fixed-size models with similar amount of computations. Compared to BERT-Base, the proposed inference framework yields a 1.3-point improvement in the average GLUE score and a 2.2-point increase in the F1 score on SQuAD, while reducing computations by around 45%.}
}
@incollection{KENDRICK2008685,
title = {Chapter 17 The Supporting Role of Molecular Modelling and Computational Chemistry in Polymer Analysis},
editor = {John M. Chalmers and Robert J. Meier},
series = {Comprehensive Analytical Chemistry},
publisher = {Elsevier},
volume = {53},
pages = {685-734},
year = {2008},
booktitle = {Molecular Characterization and Analysis of Polymers},
issn = {0166-526X},
doi = {https://doi.org/10.1016/S0166-526X(08)00417-0},
url = {https://www.sciencedirect.com/science/article/pii/S0166526X08004170},
author = {John Kendrick},
abstract = {Publisher Summary
Molecular modeling covers a wide range of techniques and the calculation of an even wider range of properties. Although for polymers, the possibility of treating a polymer chain quantum mechanically is formidable, it is clear that the modeling approach allows calculations on monomers, dimmers, and oligomers to guide the interpretation of many spectroscopic observations with great success. For those systems, where longer times scales and larger size scales are important, molecular mechanics and molecular dynamics methods are available, but the issue of the force field and the approximations that it introduces remain significant. The key to the change in attitude to modeling and its role have to lie in the availability of mature algorithms with well-known and well-understood properties. The density functional theory method in quantum mechanics has introduced a new era in applications of quantum mechanical methods.}
}
@article{JIANG201814,
title = {Computational intelligence techniques for maximum power point tracking in PV systems: A review},
journal = {Renewable and Sustainable Energy Reviews},
volume = {85},
pages = {14-45},
year = {2018},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2018.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S1364032118300054},
author = {Lian L. Jiang and R. Srivatsan and Douglas L. Maskell},
keywords = {Maximum power point tracking, PV system, Computational intelligence algorithm, Heuristic algorithm, Global tracking, Partial shading},
abstract = {Maximum power point (MPP) tracking (MPPT) is an important technique for maximizing the power extraction from photovoltaic (PV) systems under varying climatic conditions. In an array of PV modules it is possible to observe multiple peaks in the power versus voltage (P-V) curve due to the current versus voltage (I–V) PV cell mismatch caused by differences in the received irradiance, such as occurs during partial shading. In these circumstances, the ability of the MPPT devices to track the global MPP of the PV array directly influences the system efficiency. In the literature, various MPPT techniques have been proposed. Among them, computational intelligence (CI) algorithm based MPPT methods have demonstrated the ability to find the global MPP. This paper presents a detailed and specific review of CI- based MPPT techniques. Each method type is classified into one of several subcategories according to its application strategy. The various ways of applying CI into MPPTs are analyzed in detail. The advantages and disadvantages of each method are discussed and compared. The purpose of this study is to provide a compendium on CI-based MPPT techniques for users to understand and select an appropriate method based on application requirements and system constraints.}
}
@article{THAKIRABED20232293,
title = {The computation intelligent system of role of parental leadership in organizational familiarity in Iraqi Airways employees},
journal = {Materials Today: Proceedings},
volume = {80},
pages = {2293-2301},
year = {2023},
note = {SI:5 NANO 2021},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2021.06.318},
url = {https://www.sciencedirect.com/science/article/pii/S221478532104709X},
author = {Marwan {Thakir Abed}},
keywords = {Parental leadership, Organizational familiarity, Empowerment, Iraqi Airways},
abstract = {The research aimed to know the effect of parental leadership represented by (benevolent leadership, moral leadership, and authoritarian leadership) found in the research sample, in the organizational familiarity (employee morale, empowerment, and objective merit), the research relied on the questionnaire as a key instrument to collect the necessary data to meet its goal. As (60) forms were distributed to find the level of availability of parental leadership and organizational harmony, while (56) forms were retrieved. A set of statistical methods were used, represented by normal distribution, stability factor (Alpha Kronbach), reliability, arithmetic mean, standard deviation, and coefficient Simple correlation Pearson, multiple regression coefficient. The results showed that there is a positive correlation and effect relationship with statistically significant between parental leadership with its dimensions (benevolent leadership, moral leadership, authoritarian leadership) and organizational affiliation with its dimensions (employee morale, empowerment, and merit's Objectivity), and the research showed a direct impact relationship between parental leadership and the organizational affiliation of the studied sample. Accordingly, the research concluded that the study sample should pay attention to the nature and type of empowering workers in order to give them freedom and independence in making decisions regarding the tasks assigned to them.}
}
@article{HOYTE2006S348,
title = {Computational model of levator ani muscle stretch during vaginal delivery},
journal = {Journal of Biomechanics},
volume = {39},
pages = {S348},
year = {2006},
note = {Abstracts of the 5th World Congress of Biomechanics},
issn = {0021-9290},
doi = {https://doi.org/10.1016/S0021-9290(06)84382-4},
url = {https://www.sciencedirect.com/science/article/pii/S0021929006843824},
author = {L. Hoyte and P. Krysl and G. Chukkapalli and A. Majumdar and D.J. Choi and A. Trivedi and S.K. Warfield and M.S. Damaser}
}
@article{CRILLY2021309,
title = {The Evolution of “Co-evolution” (Part I): Problem Solving, Problem Finding, and Their Interaction in Design and Other Creative Practices},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {7},
number = {3},
pages = {309-332},
year = {2021},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2021.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S2405872621000915},
author = {Nathan Crilly},
keywords = {Design process, Design thinking, Creativity, Design history, Interdisciplinarity},
abstract = {One of the most influential descriptions of design activity emphasizes how problems and solutions “co-evolve.” This concept has somehow escaped critical review and cross-disciplinary comparison, resulting in a fragmented approach to the subject. Reviewing the published literature on design co-evolution reveals that the term is used to refer to a range of distinct concepts, and the study of co-evolution has generated a number of elaborations and alternatives. Reviewing the broader literature in design and other disciplines further reveals that discussions of design co-evolution are disconnected from the history of relevant concepts in design research, and disconnected from a range of relevant concepts in other disciplines that describe creative work. Here I examine what the different concepts of design co-evolution are, how they have been modified and what they are related to. This leads to questioning the distinction between problems and solutions, defining them in relative terms, and drawing a connection between design co-evolution and design fixation.}
}
@article{GALTIER201683,
title = {Radiative transfer and spectroscopic databases: A line-sampling Monte Carlo approach},
journal = {Journal of Quantitative Spectroscopy and Radiative Transfer},
volume = {172},
pages = {83-97},
year = {2016},
note = {Eurotherm Conference No. 105: Computational Thermal Radiation in Participating Media V},
issn = {0022-4073},
doi = {https://doi.org/10.1016/j.jqsrt.2015.10.016},
url = {https://www.sciencedirect.com/science/article/pii/S0022407315003192},
author = {Mathieu Galtier and Stéphane Blanco and Jérémi Dauchet and Mouna {El Hafi} and Vincent Eymet and Richard Fournier and Maxime Roger and Christophe Spiesser and Guillaume Terrée},
keywords = {Radiative transfer, Monte Carlo method, Null-collision, Line sampling, Statistical approach, Spectroscopic databases},
abstract = {Dealing with molecular-state transitions for radiative transfer purposes involves two successive steps that both reach the complexity level at which physicists start thinking about statistical approaches: (1) constructing line-shaped absorption spectra as the result of very numerous state-transitions, (2) integrating over optical-path domains. For the first time, we show here how these steps can be addressed simultaneously using the null-collision concept. This opens the door to the design of Monte Carlo codes directly estimating radiative transfer observables from spectroscopic databases. The intermediate step of producing accurate high-resolution absorption spectra is no longer required. A Monte Carlo algorithm is proposed and applied to six one-dimensional test cases. It allows the computation of spectrally integrated intensities (over 25cm−1 bands or the full IR range) in a few seconds, regardless of the retained database and line model. But free parameters need to be selected and they impact the convergence. A first possible selection is provided in full detail. We observe that this selection is highly satisfactory for quite distinct atmospheric and combustion configurations, but a more systematic exploration is still in progress.}
}
@article{WANG20231225,
title = {Parameterization Design of 3D Fractal Images in Packaging Design Based on Genetic Algorithm},
journal = {Procedia Computer Science},
volume = {228},
pages = {1225-1232},
year = {2023},
note = {3rd International Conference on Machine Learning and Big Data Analytics for IoT Security and Privacy},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.11.104},
url = {https://www.sciencedirect.com/science/article/pii/S187705092301935X},
author = {Jinxia Wang},
keywords = {Genetic Algorithm, Packaging Design, 3D Fractal Image, NSGA - II},
abstract = {Packaging design, as an important element in product appearance, can directly affect customers' sensory perception of the product. Many universities even offer packaging design majors, which mainly use natural science and aesthetic knowledge to promote product sales. However, many old brands remain complacent and their packaging design still adopts traditional thinking, which to some extent affects their sales. Therefore, this article decided to use genetic algorithms as a tool to parameterize the 3D fractal images in packaging design, aiming to create more creative and eye-catching packaging designs. At the end of this article, an experiment was conducted on two branches of a certain brand. Branch 1 tried out the new design provided in this article, while Branch 2 continued to use the original design. After Branch 1 fully adopted the design, sales skyrocketed, from the original daily sales of 50-60 units to 70-85 units. Branch 2 remained unchanged, with a sharp contrast.}
}
@incollection{TIWARI2025389,
title = {Chapter 13 - Quantitative data analysis methods for air quality prediction},
editor = {Ranjeet S. Sokhi},
booktitle = {Air Quality},
publisher = {Elsevier},
pages = {389-409},
year = {2025},
isbn = {978-0-12-822591-2},
doi = {https://doi.org/10.1016/B978-0-12-822591-2.00013-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128225912000135},
author = {Pushp Raj Tiwari and Saurabh Kumar},
keywords = {Machine learning, data science, statistics, statistical applications, artificial intelligence},
abstract = {A quantitative research study gathers numerical data, which needs to be examined to make conclusions. Critical thinking regarding data analysis is facilitated primarily by quantitative data analysis. The purpose of data analysis is to identify the underlying trends, patterns, and connections in the context of a study. In quantitative data analysis, the focus is not just on applying statistical tests to existing data, but also on leveraging those tests as a means of deriving accurate insights from the data. This chapter aims to give a thorough theoretical review of current methodologies, related computational techniques, and dataset applications. A wide range of topics is covered, focusing on various statistical tests, interpolation, extrapolation, regression, modeling uncertainty analysis, machine learning methods, GIS techniques, data visualization tools etc. Each of these topics is extensively explored and discussed in terms of relevant literature and methods for air quality data and its applications.}
}
@article{CHINTA20248181,
title = {Cascade reactions of HDDA-benzynes with tethered cyclohexadienones: strain-driven events originating from ortho-annulated benzocyclobutenes††Electronic supplementary information (ESI) available. CCDC 2302618–2302621. For ESI and crystallographic data in CIF or other electronic format see DOI: https://doi.org/10.1039/d4sc00571f},
journal = {Chemical Science},
volume = {15},
number = {21},
pages = {8181-8189},
year = {2024},
issn = {2041-6520},
doi = {https://doi.org/10.1039/d4sc00571f},
url = {https://www.sciencedirect.com/science/article/pii/S2041652024006813},
author = {Bhavani Shankar Chinta and Dorian S. Sneddon and Thomas R. Hoye},
abstract = {Intramolecular net [2 + 2] cycloadditions between benzyne intermediates and an electron-deficient alkene to give benzocyclobutene intermediates are relatively rare. Benzynes are electrophilic and generally engage nucleophiles or electron-rich π-systems. We describe here reactions in which an alkene of a tethered enone traps thermally generated benzynes in a variety of interesting ways. The number of atoms that link the benzyne to C4 of a cyclohexa-2,5-dienone induces varying amounts of strain in the intermediates and products. This leads to a variety of different reaction outcomes by way of various strain-releasing events that are mechanistically intriguing. This work demonstrates an underappreciated class of strain that originates from the adjacent fusion of two rings to both C1–C2 and C2–C3 of a benzenoid ring – i.e. ‘ortho-annulation strain’. DFT computations shed considerable light on the mechanistic diversions among various reaction pathways as well as allow more fundamental evaluation of the strain in a homologous series of ortho-annulated carbocycles.}
}
@article{DENEF20071096,
title = {Computational complexity of the landscape: Part I},
journal = {Annals of Physics},
volume = {322},
number = {5},
pages = {1096-1142},
year = {2007},
issn = {0003-4916},
doi = {https://doi.org/10.1016/j.aop.2006.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S0003491606001382},
author = {Frederik Denef and Michael R. Douglas},
abstract = {We study the computational complexity of the physical problem of finding vacua of string theory which agree with data, such as the cosmological constant, and show that such problems are typically NP hard. In particular, we prove that in the Bousso–Polchinski model, the problem is NP complete. We discuss the issues this raises and the possibility that, even if we were to find compelling evidence that some vacuum of string theory describes our universe, we might never be able to find that vacuum explicitly. In a companion paper, we apply this point of view to the question of how early cosmology might select a vacuum.}
}
@article{LEE2021100737,
title = {Turbulent boundary layer trailing-edge noise: Theory, computation, experiment, and application},
journal = {Progress in Aerospace Sciences},
volume = {126},
pages = {100737},
year = {2021},
issn = {0376-0421},
doi = {https://doi.org/10.1016/j.paerosci.2021.100737},
url = {https://www.sciencedirect.com/science/article/pii/S0376042121000427},
author = {Seongkyu Lee and Lorna Ayton and Franck Bertagnolio and Stephane Moreau and Tze Pei Chong and Phillip Joseph},
keywords = {Trailing-edge noise, Aeroacoustics, Turbulent boundary layer},
abstract = {When the pressure fluctuations caused by turbulence vorticity in the boundary layer are scattered by a sharp trailing edge, acoustic energy is generated and propagated to the far field. This trailing edge noise is emitted from aircraft wings, turbomachinery blades, wind turbine blades, helicopter blades, etc. Being dominant at high frequencies, this trailing-edge noise is a key element that annoys human hearing. This article covers virtually the entire landscape of modern research into trailing-edge noise including theoretical developments, numerical simulations, wind tunnel experiments, and applications of trailing-edge noise. The theoretical approach includes Green’s function formulations, Wiener–Hopf methods that solve the mixed boundary-value problem, Howe’s and Amiet’s models that relate the wall pressure spectrum to acoustic radiation. Recent analytical developments for poroelasticity and serrations are also included. We discuss a hierarchy of numerical approaches that range from semi-empirical schemes that estimate the wall pressure spectrum using mean-flow and turbulence statistics to high-fidelity unsteady flow simulations such as Large Eddy Simulation (LES) or Direct Numerical Simulation (DNS) that resolve the sound generation and scattering process based on the first-principles flow physics. Wind tunnel experimental research that provided benchmark data for numerical simulations and unravel flow physics is reviewed. In each theoretical, numerical, and experimental approach, noise control methods for mitigating trailing-edge noise are discussed. Finally, highlights of practical applications of trailing-edge noise prediction and reduction to wind turbine noise, fan noise, and rotorcraft noise are given. The current challenges in each approach are summarized with a look toward the future developments. The review could be useful as a primer for new researchers or as a reference point to the state of the art for experienced professionals.}
}
@article{AKCAOGLU201472,
title = {Cognitive outcomes from the Game-Design and Learning (GDL) after-school program},
journal = {Computers & Education},
volume = {75},
pages = {72-81},
year = {2014},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2014.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0360131514000372},
author = {Mete Akcaoglu and Matthew J. Koehler},
keywords = {Game-design, Problem-solving, Quasi-experimental, Constructionism},
abstract = {The Game-Design and Learning (GDL) initiative engages middle school students in the process of game-design in a variety of in-school, after-school, and summer camp settings. The goal of the GDL initiative is to leverage students' interests in games and design to foster their problem-solving and critical reasoning skills. The present study examines the effectiveness of an after-school version of the GDL program using a quasi-experimental design. Students enrolled in the GDL program were guided in the process of designing games aimed at solving problems. Compared to students in a control group who did not attend the program (n = 24), the children who attended the GDL program (n = 20) showed a significant increase in their problem-solving skills. The results provide empirical support for the hypothesis that participation in the GDL program leads to measurable cognitive changes in children's problem-solving skills. This study bears important implications for educators and theory.}
}
@article{ALTARABICHI2023118528,
title = {Fast Genetic Algorithm for feature selection — A qualitative approximation approach},
journal = {Expert Systems with Applications},
volume = {211},
pages = {118528},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.118528},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422016049},
author = {Mohammed Ghaith Altarabichi and Sławomir Nowaczyk and Sepideh Pashami and Peyman Sheikholharam Mashhadi},
keywords = {Feature selection, Evolutionary computation, Genetic Algorithm, Particle Swarm Intelligence, Fitness approximation, Meta-model, Optimization},
abstract = {Evolutionary Algorithms (EAs) are often challenging to apply in real-world settings since evolutionary computations involve a large number of evaluations of a typically expensive fitness function. For example, an evaluation could involve training a new machine learning model. An approximation (also known as meta-model or a surrogate) of the true function can be used in such applications to alleviate the computation cost. In this paper, we propose a two-stage surrogate-assisted evolutionary approach to address the computational issues arising from using Genetic Algorithm (GA) for feature selection in a wrapper setting for large datasets. We define “Approximation Usefulness” to capture the necessary conditions to ensure correctness of the EA computations when an approximation is used. Based on this definition, we propose a procedure to construct a lightweight qualitative meta-model by the active selection of data instances. We then use a meta-model to carry out the feature selection task. We apply this procedure to the GA-based algorithm CHC (Cross generational elitist selection, Heterogeneous recombination and Cataclysmic mutation) to create a Qualitative approXimations variant, CHCQX. We show that CHCQX converges faster to feature subset solutions of significantly higher accuracy (as compared to CHC), particularly for large datasets with over 100K instances. We also demonstrate the applicability of the thinking behind our approach more broadly to Swarm Intelligence (SI), another branch of the Evolutionary Computation (EC) paradigm with results of PSOQX, a qualitative approximation adaptation of the Particle Swarm Optimization (PSO) method. A GitHub repository with the complete implementation is available.22https://github.com/Ghaith81/Fast-Genetic-Algorithm-For-Feature-Selection.}
}
@article{CHU20181,
title = {Supporting scientific modeling through curriculum-based making in elementary school science classes},
journal = {International Journal of Child-Computer Interaction},
volume = {16},
pages = {1-8},
year = {2018},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2017.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S2212868917300545},
author = {Sharon Lynn Chu and Elizabeth Deuermeyer and Francis Quek},
keywords = {Making, Maker movement, Children, Science, Science models, Scientific modeling, Model thinking, Electronics, Programming},
abstract = {Our work investigates how Making may be used in the context of scientific modeling in formal elementary school science classes. This paper presents an investigation of fourth- and fifth-grade students engaging in Making activities to create simulation, concept-process, and illustrative models in the science classroom. Based on video analyses of the Making-based class sessions, a generalized process model was developed for each type of science model. In addition, cross-cutting themes were found in Making-based science modeling: first, there are two loops that intersect and interact with each other (modeling for Making and modeling for Science content), and they interrelate in various ways depending on science model type; and second, showcasing Making products (sharing with peers, teachers, or helpers) is a primary factor that determines students’ overall engagement with science in the activity. We suggest that Making-based science kit and lesson design needs to support students to showcase their Making output, on top of science-related reflections, and to consider the balance between Making and science activity. We conclude that Making has the potential to support the development of scientific model thinking in the elementary science classroom, but much further research is needed in this area.}
}
@article{ZILLES20101072,
title = {The computational complexity of avoiding spurious states in state space abstraction},
journal = {Artificial Intelligence},
volume = {174},
number = {14},
pages = {1072-1092},
year = {2010},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2010.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0004370210000950},
author = {Sandra Zilles and Robert C. Holte},
keywords = {Abstraction, Heuristic search, Planning},
abstract = {Abstraction is a powerful technique for speeding up planning and search. A problem that can arise in using abstraction is the generation of abstract states, called spurious states, from which the goal state is reachable in the abstract space but for which there is no corresponding state in the original space from which the goal state can be reached. Spurious states can be harmful, in practice, because they can create artificial shortcuts in the abstract space that slow down planning and search, and they can greatly increase the memory needed to store heuristic information derived from the abstract space (e.g., pattern databases). This paper analyzes the computational complexity of creating abstractions that do not contain spurious states. We define a property—the downward path preserving property (DPP)—that formally captures the notion that an abstraction does not result in spurious states. We then analyze the computational complexity of (i) testing the downward path preserving property for a given state space and abstraction and of (ii) determining whether this property is achievable at all for a given state space. The strong hardness results shown carry over to typical description languages for planning problems, including sas+ and propositional strips. On the positive side, we identify and illustrate formal conditions under which finding downward path preserving abstractions is provably tractable.}
}
@article{SELBY20001491,
title = {Computational Aspects of Complex Securities},
journal = {Journal of Economic Dynamics and Control},
volume = {24},
number = {11},
pages = {1491-1497},
year = {2000},
issn = {0165-1889},
doi = {https://doi.org/10.1016/S0165-1889(99)00084-6},
url = {https://www.sciencedirect.com/science/article/pii/S0165188999000846},
author = {Michaël J.P Selby}
}
@article{CREELY2025101727,
title = {Creative partnerships with generative AI. Possibilities for education and beyond},
journal = {Thinking Skills and Creativity},
volume = {56},
pages = {101727},
year = {2025},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101727},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124002682},
author = {Edwin Creely and Jo Blannin},
keywords = {Generative AI, Creative production, Posthumanism, Education, Autoethnography, Alterity relations},
abstract = {The impact of generative artificial intelligence (AI) on creative production in industry and education is just beginning to be experienced and understood. This impact is likely to accelerate and become even more significant as the computational potential of generative AI grows through training on more diverse and more extensive language models and data sets. Emerging research in this new field suggests that previous models of understanding the interactions between machine and human may no longer be sufficient in a world of generative AI. The significant question is how emerging generative AI technologies will relate to and be a part of human creativity and creative outputs. In this article, we adopt a posthuman stance and conceive of creative output involving generative AI and humans in terms of a yet-to-be-fully-realised and emergent relationship that will likely become more integrated and complex. To investigate and experiment with this relational notion, each of us (as part of an autoethnographic approach) developed a creative output using ChatGPT: a poem and a multimodal narrative. We then employed the idea of alterity relations from the American philosopher of technology, Don Ihde, to conceive of the possibilities and limitations in working relationally and productively with generative AI. As two academics working in teacher education, we applied our learning from this exploration to possibilities in educational contexts. In this article, we offer several important implications and provocations for practitioners, researchers, educators and policymakers, not only in terms of practical concerns but also for rethinking the nature of the creative output.}
}
@article{ATALLAH2022B2,
title = {Society for Maternal-Fetal Medicine Special Statement: Cognitive bias and medical error in obstetrics—challenges and opportunities},
journal = {American Journal of Obstetrics and Gynecology},
volume = {227},
number = {2},
pages = {B2-B10},
year = {2022},
issn = {0002-9378},
doi = {https://doi.org/10.1016/j.ajog.2022.04.033},
url = {https://www.sciencedirect.com/science/article/pii/S0002937822003143},
author = {Fouad Atallah and Rebecca F. Hamm and Christina M. Davidson and C. Andrew Combs},
keywords = {decision-making, diagnostic error, disparities, implicit bias, inequity, medical error, racism},
abstract = {The processes of diagnosis and management involve clinical decision-making. However, decision-making is often affected by cognitive biases that can lead to medical errors. This statement presents a framework of clinical thinking and decision-making and shows how these processes can be bias-prone. We review examples of cognitive bias in obstetrics and introduce debiasing tools and strategies. When an adverse event or near miss is reviewed, the concept of a cognitive autopsy—a root cause analysis of medical decision-making and the potential influence of cognitive biases—is promoted as part of the review process. Finally, areas for future research on cognitive bias in obstetrics are suggested.}
}
@article{KUMAR20101805,
title = {A generalized computational approach to stability of static equilibria of nonlinearly elastic rods in the presence of constraints},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {199},
number = {25},
pages = {1805-1815},
year = {2010},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2010.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S0045782510000654},
author = {Ajeet Kumar and Timothy J. Healey},
keywords = {Stability, Elasticity, Rods, Constraints},
abstract = {We present a generalized approach to stability of static equilibria of nonlinearly elastic rods, subjected to general loading, boundary conditions and constraints (of both point-wise and integral type), based upon the linearized dynamics stability criterion. Discretization of the governing equations leads to a non-standard (singular) generalized eigenvalue problem. A new efficient sparse-matrix-friendly algorithm is presented to determine its few left-most eigenvalues, which, in turn, yield stability/instability information. For conservative problems, the eigenvalue problem arising from the linearized dynamics stability criterion is also shown to be equivalent to that arising in the determination of constrained local minima of the potential energy. We illustrate the method with several examples. A novel variational formulation for extensible and unshearable rods is also proposed within the context of one of the example problems.}
}
@article{BENSASSI20233123,
title = {Fuzzy knowledge based assessment system for K-12 Scientific Reasoning Competencies},
journal = {Procedia Computer Science},
volume = {225},
pages = {3123-3132},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.306},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923014643},
author = {Manel BenSassi and Henda Ben Ghezala},
keywords = {Learning analytics, educational recommendations, fuzzy competencies assessment, knowledge representation, fuzzy ontology, Scientific Reasoning competencies},
abstract = {Developing Scientific Reasoning (SR) competencies at an early age, are challenging to meet expectation of the 4th sustainable development goal. Hence, educators and educational decision-makers try to embed these competencies into such subjects as the arts, language, technology, economics, mathematics and science, using an inter-disciplinary approach. In this context, this paper proposes a fuzzy knowledge-based solution to build practical pupils, educators, and decision-makers recommender system to support the development of SR competencies in a data driver manner. Our system consists of:(1) inferring and computational module that calculates in a fuzzy manner the global appreciation to each SR-competencies. (2) recommendation module that aims to help learners, educators and decision makers to assess the degree of development of SR competencies and to get alternative suggestion of remediation. The proposed solution has been tested on the last two levels of science education in four Tunisian elementary schools in different regions. A preliminary analysis showed that the learning process should be more focused on Tunisian pupil's profile, and that investigation and collaborative based learning should be applied further in Tunisian classroom.}
}
@article{NOROOZI2019295,
title = {Multidisciplinary innovations and technologies for facilitation of self-regulated learning},
journal = {Computers in Human Behavior},
volume = {100},
pages = {295-297},
year = {2019},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2019.07.020},
url = {https://www.sciencedirect.com/science/article/pii/S0747563219302638},
author = {Omid Noroozi and Sanna Järvelä and Paul A. Kirschner},
abstract = {Technology-enhanced learning environments provide ample opportunities for learners to self-regulate their learning processes and activities for achieving the intended learning outcomes in various disciplines from soft to hard sciences and from humanities to the natural and social sciences. This special issue discusses the emerging technological advancements and cutting-edge research on self-regulated learning dealing with different cognitive, motivational, emotional, and social processes of learning both at the individual and group levels. Specifically, it discusses how to optimally use advanced technologies to facilitate learners’ self-regulated learning for achieving their own individual learning needs and goals. In this special issue, seven researchers/research teams from the fields of collaborative learning, computational thinking, educational psychology, and learning analytics presented contributions to self-regulated learning with the goal of stimulating cross-border discussion in the field.}
}
@article{BAKEEVA2022676,
title = {Increasing the student talking time parameter under the digitalization in transport engineering learning},
journal = {Transportation Research Procedia},
volume = {63},
pages = {676-685},
year = {2022},
note = {X International Scientific Siberian Transport Forum — TransSiberia 2022},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2022.06.062},
url = {https://www.sciencedirect.com/science/article/pii/S2352146522003179},
author = {L Bakeeva and L Brylevskaya and L Gonchar and E Pastukhova and Y Romanova and O Skepko},
keywords = {Digitalization of education, transport engineering, student talking time, study-train-explain methodology},
abstract = {The most recent information technologies have become an integral part of modern life. As the study shows, along with the obvious benefits, their use can lead to negative consequences, namely the loss of communication and soft skills, changes in the ability to absorb information, decreased motivation to acquire new knowledge among the younger age group. The authors propose a new methodology for organizing the educational process Study-Train-Explain. The aim of the method is to increase the Student Talking Time parameter to develop the skills of mathematical data analysis, systematic and analytical thinking to master the methods of description and construction of mathematical model of the phenomenon or process. These competencies are extremely in demand in the professional field related to the organization of transportation and operation of transport-technological machines and complexes under the conditions of digitalization of global processes. The article presents an algorithm and the results of the experimental training process carried out by the authors according to the specified methodology.}
}
@article{AGRE19951,
title = {Computational research on interaction and agency},
journal = {Artificial Intelligence},
volume = {72},
number = {1},
pages = {1-52},
year = {1995},
issn = {0004-3702},
doi = {https://doi.org/10.1016/0004-3702(94)00054-5},
url = {https://www.sciencedirect.com/science/article/pii/0004370294000545},
author = {Philip E. Agre},
abstract = {Recent research in artificial intelligence has developed computational theories of agents' involvements in their environments. Although inspired by a great diversity of formalisms and architectures, these research projects are unified by a common concern: using principled characterizations of agents' interactions with their environments to guide analysis of living agents and design of artificial ones. This article offers a conceptual framework for such theories, surveys several other fields of research that hold the potential for dialogue with these new computational projects, and summarizes the principal contributions of the articles in this special double volume. It also briefly describes a case study in these ideas—a computer program called Toast that acts as a short-order breakfast cook. Because its designers have discovered useful structures in the world it inhabits, Toast can employ an extremely simple mechanism to decide what to do next.}
}
@article{ONGUR2025220,
title = {Embracing complexity in psychiatry—from reductionistic to systems approaches},
journal = {The Lancet Psychiatry},
volume = {12},
number = {3},
pages = {220-227},
year = {2025},
issn = {2215-0366},
doi = {https://doi.org/10.1016/S2215-0366(24)00334-1},
url = {https://www.sciencedirect.com/science/article/pii/S2215036624003341},
author = {Dost Öngür and Martin P Paulus},
abstract = {Summary
The understanding and treatment of psychiatric disorders present unique challenges due to these conditions' multifaceted nature, comprising dynamic interactions between biological, psychological, social, and environmental factors. Traditional reductionistic approaches often simplify these conditions into linear cause-and-effect relationships, overlooking the complexity and interconnectedness inherent in psychiatric disorders. Advances in complex systems approaches provide a comprehensive framework to capture and quantify the non-linear and emergent properties of psychiatric disorders. This Personal View emphasises the importance of identifying rules for generative models that govern brain and behaviour over time, which might contribute to personalised assessments and interventions for psychiatric disorders. For instance, mood fluctuations in bipolar disorder can be understood through dynamical systems modelling, which identifies modifiable parameters, such as circadian disruption, that can be addressed through targeted therapies such as light therapy. Similarly, recognition of depression as an emergent property arising from complex interactions highlights the need for integrated treatment strategies that enhance adaptive reactions in the individual. A framework for quantifying multilevel interactions and network dynamics can help researchers and clinicians to understand the interplay between neural circuits, behaviours, and social contexts. Probabilistic models and self-organisation concepts contribute to building concrete dynamical systems models of mental disorders, facilitating early identification of risk states and promoting resilience through adaptive interventions delivered with optimal timing. Embracing these complex systems approaches in psychiatry could capture the true nature of psychiatric disorders as properties of a dynamic complex system and not the manifestation of any lesion or insult. This line of thinking might improve diagnosis and treatment, offering new hope for individuals affected by psychiatric conditions and paving the way for more effective, personalised mental health care.}
}
@incollection{BALAKRISHNAN202131,
title = {Chapter 2 - Computational intelligence in healthcare and biosignal processing},
editor = {Janmenjoy Nayak and Bighnaraj Naik and Danilo Pelusi and Asit Kumar Das},
booktitle = {Handbook of Computational Intelligence in Biomedical Engineering and Healthcare},
publisher = {Academic Press},
pages = {31-64},
year = {2021},
isbn = {978-0-12-822260-7},
doi = {https://doi.org/10.1016/B978-0-12-822260-7.00015-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128222607000157},
author = {Nagaraj Balakrishnan and Valentina E. Balas and Arunkumar Rajendran},
keywords = {ANN, Clustering, Data classification, Data mining, Deep clustering networks, Deep learning},
abstract = {In this new era, technological advancement toward the mission of a better tomorrow is reaching its limit because the exploration of the advanced possibilities of Artificial Intelligence is bounded with certain limitations. The application of analyzing various features of biosignal processing is key in the fields of medicine and healthcare. Biosignals such as Electroencephalogram (EEG), Electrocardiogram (ECG), Electromyography (EMG), Electrooculography (EOG), Galvanic Skin Response(GSR), and Magnetoencephalography (MEG) is already giving deep insight into the human body toward the identification of diverse nature and disorders. In recent years, the research toward analyzing biosignal gained interest among many researchers. The primary limitation for the algorithms to analyze these signals for more possibilities of insight is its uncertainty. Even though the algorithms of Artificial Intelligence have the capabilities to unravel the mysteries, it is bounded with specific difficulties. The machine learning algorithms designed to manage uncertain data but lacks accuracy due to many factors. Also, complete supervision is needed in a training process that involves the extraction and selection of adequate features for the training. The deep learning method (a subset of machine learning) comes into the picture due to one of these facts. This, indeed, as a supervised learning method, needs a massive volume of data to train to reach the accuracy goal. The deep learning algorithm plays a significant role in today's Artificial Intelligence–based applications. However, this platform needs many requirements, such as (a) high computational power like graphical processing units (GPU); (b) similar to machine learning methods, a massive labeled dataset for supervised learning; (c) adequate parameter selection to avoid overfitting or underfitting. To overcome the problems highlighted, the strategy of adopting the behaviors of unsupervised learning (performed by the clustering algorithm) in the deep learning methodology is needed. To achieve the goal, two-phase operations were processed, such as (1) transformation of the data elements into a latent feature space (Z) is processed through a nonlinear mapping of deep learning networks; (2) clustering the latent feature space to k-clusters, and simultaneously, the clustering loss is fed to the deep learning network for the next iteration of operation concerning the objective function convergence analyzed by the Kullback–Leibler divergence. Various strategies of enhancing the nature of deep learning methods and clustering methodologies for an unsupervised learning process are addressed in this chapter.}
}
@article{BERGER2016337,
title = {Cognitive hierarchies in the minimizer game},
journal = {Journal of Economic Behavior & Organization},
volume = {130},
pages = {337-348},
year = {2016},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2016.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S0167268116301639},
author = {Ulrich Berger and Hannelore {De Silva} and Gerlinde Fellner-Röhling},
keywords = {Behavioral game theory, Experimental games, Poisson cognitive hierarchy, Level- model, Minimizer game},
abstract = {Experimental tests of choice predictions in one-shot games show only little support for Nash equilibrium (NE). Poisson Cognitive Hierarchy (PCH) and level-k (LK) are behavioral models of the thinking-steps variety where subjects differ in the number of levels of iterated reasoning they perform. Camerer et al. (2004) claim that substituting the Poisson parameter τ=1.5 yields a parameter-free PCH model (pfPCH) which predicts experimental data considerably better than NE. We design a new multi-person game, the Minimizer Game, as a testbed to compare initial choice predictions of NE, pfPCH and LK. Data obtained from two large-scale online experiments strongly reject NE and LK, but are well in line with the point-prediction of pfPCH.}
}
@article{FOLTZ2023127,
title = {Reflections on the nature of measurement in language-based automated assessments of patients' mental state and cognitive function},
journal = {Schizophrenia Research},
volume = {259},
pages = {127-139},
year = {2023},
note = {Language and Speech Analysis in Schizophrenia and Related Psychoses},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2022.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S0920996422002833},
author = {Peter W. Foltz and Chelsea Chandler and Catherine Diaz-Asper and Alex S. Cohen and Zachary Rodriguez and Terje B. Holmlund and Brita Elvevåg},
keywords = {Natural language processing, Speech technologies, Artificial intelligence},
abstract = {Modern advances in computational language processing methods have enabled new approaches to the measurement of mental processes. However, the field has primarily focused on model accuracy in predicting performance on a task or a diagnostic category. Instead the field should be more focused on determining which computational analyses align best with the targeted neurocognitive/psychological functions that we want to assess. In this paper we reflect on two decades of experience with the application of language-based assessment to patients' mental state and cognitive function by addressing the questions of what we are measuring, how it should be measured and why we are measuring the phenomena. We address the questions by advocating for a principled framework for aligning computational models to the constructs being assessed and the tasks being used, as well as defining how those constructs relate to patient clinical states. We further examine the assumptions that go into the computational models and the effects that model design decisions may have on the accuracy, bias and generalizability of models for assessing clinical states. Finally, we describe how this principled approach can further the goal of transitioning language-based computational assessments to part of clinical practice while gaining the trust of critical stakeholders.}
}
@article{VEITAS201716,
title = {Living Cognitive Society: A ‘digital’ World of Views},
journal = {Technological Forecasting and Social Change},
volume = {114},
pages = {16-26},
year = {2017},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2016.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0040162516300610},
author = {Viktoras Veitas and David Weinbaum},
keywords = {Cognitive system, Living society, Information and communication technologies, Future social governance, Individuation, Cognitive development},
abstract = {The current social reality is characterized by all-encompassing change, which disrupts existing social structures at all levels. Yet the approach based on the ontological primacy of stable and often hierarchical structures is still prevalent in theoretical and, most importantly, practical thinking about social systems. We propose a conceptual framework for thinking about a dynamically changing social system: the Living Cognitive Society. Importantly, we show how it follows from a much broader philosophical framework, guided by the theory of individuation, which emphasizes the importance of relationships and interactive processes in the evolution of a system. The framework addresses society as a living cognitive system – an ecology of interacting social subsystems – each of which is also a living cognitive system. We argue that this approach can help us to conceive sustainable social systems that will thrive in the circumstances of accelerating change. The Living Cognitive Society is explained in terms of its fluid structure, dynamics and the mechanisms at work. We then discuss the disruptive effects of Information and Communication Technologies on the mechanisms at work. We conclude by delineating a major topic for future research – distributed social governance – which focuses on processes of coordination rather than on stable structures within global society.}
}
@article{ZHU2024115675,
title = {Identifying influential nodes in social networks via improved Laplacian centrality},
journal = {Chaos, Solitons & Fractals},
volume = {189},
pages = {115675},
year = {2024},
issn = {0960-0779},
doi = {https://doi.org/10.1016/j.chaos.2024.115675},
url = {https://www.sciencedirect.com/science/article/pii/S096007792401227X},
author = {Xiaoyu Zhu and Rongxia Hao},
keywords = {Social network, Influential nodes, Centrality measure, Improved Laplacian centrality},
abstract = {Identifying influential nodes in social networks has significant applications in terms of social analysis and information dissemination. How to capture the crucial features of influential nodes without increasing the computational complexity is an urgent issue to be solved in the context of big data. Laplacian centrality (LC) measures nodal influence by computing nodes' degree, making it extremely low complexity. However, there is still significant room for improvement. Consequently, we propose the improved Laplacian centrality (ILC) to identify influential nodes based on the concept of self-consistent. Identifying results on 9 real networks prove that ILC is superior to LC and other 6 classical measures in terms of ranking accuracy, top-k nodes identification and discrimination capability. Moreover, the computational complexity of ILC has not significantly increased compared to LC, and remains the linear order of magnitude O(m). Additionally, ILC has excellent robustness and universality such that there is no need to adjust parameters according to different network structures.}
}
@article{PRINA2024132735,
title = {Machine learning as a surrogate model for EnergyPLAN: Speeding up energy system optimization at the country level},
journal = {Energy},
volume = {307},
pages = {132735},
year = {2024},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2024.132735},
url = {https://www.sciencedirect.com/science/article/pii/S036054422402509X},
author = {Matteo Giacomo Prina and Mattia Dallapiccola and David Moser and Wolfram Sparber},
keywords = {Energy system modelling, Energy scenarios, Energy planning, Machine learning},
abstract = {In the field of energy system modelling, increasing complexity and optimization analysis are essential for understanding the most effective decarbonization options. However, the growing need for intricate models leads to increased computational time, which can hinder progress in research and policy-making. This study aims to address this issue by integrating machine learning algorithms with EnergyPLAN and EPLANopt, a coupling of EnergyPLAN software and a multi-objective evolutionary algorithm, to expedite the optimization process while maintaining accuracy. By saving computational time, we can increase the number of evaluations, thereby enabling deeper exploration of uncertainty in energy system modelling. Although machine learning models have been widely employed as surrogate models to accelerate optimization problems, their application in energy system modeling at the national scale, while preserving high temporal resolution and extensive sector-coupling, remains scarce. Several machine learning models were evaluated, and an artificial neural network was selected as the most effective surrogate model. The findings demonstrate that incorporating this surrogate model within the optimization process reduces computational time by 64 % compared to the conventional EPLANopt approach, while maintaining an accuracy level close to that obtained by running EPLANopt without the surrogate model.}
}
@article{ALIABADI2000243,
title = {Stabilized-finite-element/interface-capturing technique for parallel computation of unsteady flows with interfaces},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {190},
number = {3},
pages = {243-261},
year = {2000},
issn = {0045-7825},
doi = {https://doi.org/10.1016/S0045-7825(00)00200-0},
url = {https://www.sciencedirect.com/science/article/pii/S0045782500002000},
author = {Shahrouz Aliabadi and Tayfun E. Tezduyar},
abstract = {We present the stabilized-finite-element/interface-capturing (SFE/IC) method developed for parallel computation of unsteady flow problems with two-fluid interfaces and free surfaces. The SFE/IC method involves stabilized formulations, an interface-sharpening technique, and the enforcement of global mass conservation for each fluid. The SFE/IC method has been efficiently implemented on the CRAY T3E parallel supercomputer. A number of 2D test problems are presented to demonstrate how the SFE/IC method works and the accuracy it attains. We also show how the SFE/IC method can be very effectively applied to 3D simulation of challenging flow problems, such as two-fluid interfaces in a centrifuge tube and operational stability of a partially filled tanker truck driving over a bump.}
}
@article{WANG2016357,
title = {Research on Application of Abduction to Fire Investigation},
journal = {Procedia Engineering},
volume = {135},
pages = {357-362},
year = {2016},
note = {2015 International Conference on Performance-based Fire and Fire Protection Engineering (ICPFFPE 2015)},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2016.01.142},
url = {https://www.sciencedirect.com/science/article/pii/S1877705816001466},
author = {Shi Wang and Zhong-jun Shu},
keywords = {Fire investigation, Abduction, Logical thinking},
abstract = {To solve the problem of fire investigation caused by lack of exacting logical reasoning, it is of significance in helping that abduction, an important logical thinking should be introduced to the field of fire investigation. This paper first analyzes the fundamental reasoning forms of abduction as well as its general situation of application. Combined with practical work experience, the mode of application of abduction to fire investigation is put forward. The author shows it in detail by analyzing a real fire case. It is north noting that some matters needing attention in application are presented in the end. This paper will be conductive to constructing the right logical reasoning model in fire investigation.}
}
@article{DINU20242902,
title = {An integrated benchmark for verbal creativity testing of LLMs and humans},
journal = {Procedia Computer Science},
volume = {246},
pages = {2902-2911},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.380},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924024141},
author = {Anca Dinu and Andra Maria Florescu},
keywords = {LLM creativity, AI creativity, verbal creativity tests, human-machine comparison},
abstract = {Until fairly recently, creativity was a human-specific characteristic. Computational creativity or artificial creativity was established as a domain in the late 90’s, with different fields such as verbal, musical, or graphical creativity. With the latest technological advances and the appearance of Large Language Models (LLMs), creativity as a feature of machines gained more and more interest in the scientific community. The scope of this study is twofold: to design a comprehensive benchmark for verbal creativity assessment of LLMs and then to run the same creativity tests on different LLMs as well as on humans, for a direct comparison. We aimed to raise the replicability and extensibility of the creativity assessment of LLMs. Hence, we adapted different types of creativity tests and different criteria from psychology to fit the LLMs profile. We also employed computer-assisted evaluation methods, by using the Open Creativity Scoring with Artificial Intelligence (OCSAI), as we wanted to focus exclusively on automated approaches to assessing creativity. We quantitatively and qualitatively analyzed the data set of both human and machine-generated answers and interpreted the results. Finally, we provide both the original verbal creativity test that we have designed, and the curated data comprising all the collected answers, from the LLMs and from the humans that participated in this research.}
}
@article{MARCHETTI20121517,
title = {Mindwandering heightens the accessibility of negative relative to positive thought},
journal = {Consciousness and Cognition},
volume = {21},
number = {3},
pages = {1517-1525},
year = {2012},
issn = {1053-8100},
doi = {https://doi.org/10.1016/j.concog.2012.05.013},
url = {https://www.sciencedirect.com/science/article/pii/S1053810012001420},
author = {Igor Marchetti and Ernst H.W. Koster and Rudi {De Raedt}},
keywords = {Mindwandering, Negative cognitions, Mood, Depression, Individual differences},
abstract = {Mindwandering (MW) is associated with both positive and negative outcomes. Among the latter, negative mood and negative cognitions have been reported. However, the underlying mechanisms linking mindwandering to negative mood and cognition are still unclear. We hypothesized that MW could either directly enhance negative thinking or indirectly heighten the accessibility of negative thoughts. In an undergraduate sample (n=79) we measured emotional thoughts during the Sustained Attention on Response Task (SART) which induces MW, and accessibility of negative cognitions by means of the Scrambled Sentences Task (SST) after the task. We also measured depressive symptoms and rumination. Results show that in individuals with elevated levels of depressive symptoms MW during SART predicts higher accessibility of negative thoughts after the task, rather than negative thinking during the task. These findings contribute to our understanding of the underlying mechanisms of MW and provide insight into the relationship between task-involvement and affect.}
}
@article{HU2022116276,
title = {Multi granularity based label propagation with active learning for semi-supervised classification},
journal = {Expert Systems with Applications},
volume = {192},
pages = {116276},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116276},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421015840},
author = {Shengdan Hu and Duoqian Miao and Witold Pedrycz},
keywords = {Semi-supervised learning, Granular computing, Multi granularity, Label propagation, Active learning, Three-way decision},
abstract = {Semi-supervised learning (SSL) methods, which exploit both the labeled and unlabeled data, have attracted a lot of attention. One of the major categories of SSL methods, graph-based semi-supervised learning (GBSSL) learns labels of unlabeled data on an adjacency graph, where neighborhood sparse graph is often used to reduce computational complexity. However, the neighborhood size is difficult to set. Instead of assigning a concrete value of neighborhood size, we propose a new label propagation algorithm called multi granularity based label propagation (MGLP) and developed from the view of granular computing. In MGLP, labels of unlabeled data are learned by two classic label propagation processes with diverse neighborhood size k, where granular computing delivers a guiding strategy to leverage multiple level neighborhood information granules, and three-way decision acts as an active learning strategy to select the unlabeled data for further annotating. Through the iterative procedures of label propagating, data annotating and data subset updating, the ultimate pseudo label accuracy of unlabeled data may be higher. Theoretically, the accuracy of pseudo labels is enhanced in some scenarios. Experimentally, the results of simulation studies on ten benchmark datasets, show that the proposed method MGLP can rise pseudo labels accuracy by 8.6% than LP (label propagation), 6.5% than LNP (linear neighborhood propagation), 6.4% than LPSN (label propagation through sparse neighborhood), 4.5% than Adaptive-NP (adaptive neighborhood propagation) and 4.6% than CRLP (consensus rate-based label propagation). It also provides a novel way to annotate data.}
}
@article{BEHR199399,
title = {Computation of incompressible flows with implicit finite element implementations on the Connection Machine},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {108},
number = {1},
pages = {99-118},
year = {1993},
issn = {0045-7825},
doi = {https://doi.org/10.1016/0045-7825(93)90155-Q},
url = {https://www.sciencedirect.com/science/article/pii/004578259390155Q},
author = {M. Behr and A. Johnson and J. Kennedy and S. Mittal and T. Tezduyar},
abstract = {Two implicit finite element formulations for incompressible flows have been implemented on the Connection Machine supercomputers and successfully applied to a set of time-dependent problems. The stabilized space-time formulation for moving boundaries and interfaces, and a new stabilized velocity-pressure-stress formulation are both described, and significant aspects of the implementation of these methods on massively parallel architectures are discussed. Several numerical results for flow problems involving moving as well as fixed cylinders and airfoils are reported. The parallel implementation, taking full advantage of the computational speed of the new generation of supercomputers, is found to be a significant asset in fluid dynamics research. Its current capability to solve large-scale problems, especially when coupled with the potential for growth enjoyed by massively parallel computers, make the implementation a worthwhile enterprise.}
}
@article{GLASSMAN20101412,
title = {Pragmatism, connectionism and the internet: A mind’s perfect storm},
journal = {Computers in Human Behavior},
volume = {26},
number = {6},
pages = {1412-1418},
year = {2010},
note = {Online Interactivity: Role of Technology in Behavior Change},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2010.04.019},
url = {https://www.sciencedirect.com/science/article/pii/S0747563210000956},
author = {Michael Glassman and Min Ju Kang},
keywords = {Internet, Dewey, Connectionism, Democracy},
abstract = {This paper explores that natural relationships between Pragmatic theory of knowing, the dynamic structuring of the mind and thinking suggested by connectionist theory, and the way information is distributed and organized through the world wide web (www). We suggest that these three “innovations” can be brought together to offer a better understanding of the way the human mind works. The internet and the information revolution may finally offer the opportunity to use and develop inductive learning practices and information based social inquiry in ways Pragmatic philosophers envisioned a hundred years ago, while the recent rise of connectionist and cognitive architecture works provides a concrete context for such developments. This confluence of process represents the type of synergy that only history can offer. The information revolution – exemplified by both the rise of connectionism and the internet – is the apotheosis of the Pragmatic revolution – bringing together radical empiricism and democratization of information in community practice. We offer three important realizations in our understanding of how information is organized and thinking progresses made possible by burgeoning virtual communities on the internet – open source thinking, scale-free networks, and interrelationships in the development of blogs to illustrate our thesis.}
}
@article{DEKKER2017554,
title = {Rasmussen's legacy and the long arm of rational choice},
journal = {Applied Ergonomics},
volume = {59},
pages = {554-557},
year = {2017},
note = {The Legacy of Jens Rasmussen},
issn = {0003-6870},
doi = {https://doi.org/10.1016/j.apergo.2016.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S0003687016300254},
author = {Sidney W.A. Dekker},
keywords = {Rasmussen, Rational choice, Human error, Second victim, Incidents},
abstract = {Rational choice theory says that operators and others make decisions by systematically and consciously weighing all possible outcomes along all relevant criteria. This paper first traces the long historical arm of rational choice thinking in the West to Judeo-Christian thinking, Calvin and Weber. It then presents a case study that illustrates the consequences of the ethic of rational choice and individual responsibility. It subsequently examines and contextualizes Rasmussen's legacy of pushing back against the long historical arm of rational choice, showing that bad outcomes are not the result of human immoral choice, but the product of normal interactions between people and systems. If we don't understand why people did what they did, Rasmussen suggested, it is not because people behaved inexplicably, but because we took the wrong perspective.}
}
@article{20213190,
title = {Eunji Cheong},
journal = {Neuron},
volume = {109},
number = {20},
pages = {3190-3192},
year = {2021},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2021.09.027},
url = {https://www.sciencedirect.com/science/article/pii/S0896627321007005},
abstract = {In Korea, the pandemic has elevated scientists as trusted sources for both policy decisions and dinner table conversation. In an interview with Neuron, Eunji Cheong discusses how we need to support future generations by fostering scientific thinking, patience, and flexibility.}
}
@article{HONDA201718,
title = {The difference in foresight using the scanning method between experts and non-experts},
journal = {Technological Forecasting and Social Change},
volume = {119},
pages = {18-26},
year = {2017},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2017.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S004016251730313X},
author = {Hidehito Honda and Yuichi Washida and Akihito Sudo and Yuichiro Wajima and Keigo Awata and Kazuhiro Ueda},
keywords = {Foresight, Scanning method, Divergent thinking, Difference between experts and non-experts, Creativity},
abstract = {We examined the factors that produce differences in generating scenarios on the near future using the scanning method. Participants were asked to briefly read (scan) 151 articles about new technology, the latest customs, fashion, social change, value system transition, or emerging social problems, and then to generate three scenarios about the near future based on the articles. We compared the generated scenarios between scanning method experts and non-experts with no prior experience with the scanning method. We found that experts generated more unique scenarios than non-experts did, and that experts and non-experts differed in the diversity of articles referenced when generating scenarios. We discuss the relationship between the present findings and previous findings on divergent thinking.}
}
@article{OBERKAMPF2002209,
title = {Verification and validation in computational fluid dynamics},
journal = {Progress in Aerospace Sciences},
volume = {38},
number = {3},
pages = {209-272},
year = {2002},
issn = {0376-0421},
doi = {https://doi.org/10.1016/S0376-0421(02)00005-2},
url = {https://www.sciencedirect.com/science/article/pii/S0376042102000052},
author = {William L. Oberkampf and Timothy G. Trucano},
abstract = {Verification and validation (V&V) are the primary means to assess accuracy and reliability in computational simulations. This paper presents an extensive review of the literature in V&V in computational fluid dynamics (CFD), discusses methods and procedures for assessing V&V, and develops a number of extensions to existing ideas. The review of the development of V&V terminology and methodology points out the contributions from members of the operations research, statistics, and CFD communities. Fundamental issues in V&V are addressed, such as code verification versus solution verification, model validation versus solution validation, the distinction between error and uncertainty, conceptual sources of error and uncertainty, and the relationship between validation and prediction. The fundamental strategy of verification is the identification and quantification of errors in the computational model and its solution. In verification activities, the accuracy of a computational solution is primarily measured relative to two types of highly accurate solutions: analytical solutions and highly accurate numerical solutions. Methods for determining the accuracy of numerical solutions are presented and the importance of software testing during verification activities is emphasized. The fundamental strategy of validation is to assess how accurately the computational results compare with the experimental data, with quantified error and uncertainty estimates for both. This strategy employs a hierarchical methodology that segregates and simplifies the physical and coupling phenomena involved in the complex engineering system of interest. A hypersonic cruise missile is used as an example of how this hierarchical structure is formulated. The discussion of validation assessment also encompasses a number of other important topics. A set of guidelines is proposed for designing and conducting validation experiments, supported by an explanation of how validation experiments are different from traditional experiments and testing. A description is given of a relatively new procedure for estimating experimental uncertainty that has proven more effective at estimating random and correlated bias errors in wind-tunnel experiments than traditional methods. Consistent with the authors’ contention that nondeterministic simulations are needed in many validation comparisons, a three-step statistical approach is offered for incorporating experimental uncertainties into the computational analysis. The discussion of validation assessment ends with the topic of validation metrics, where two sample problems are used to demonstrate how such metrics should be constructed. In the spirit of advancing the state of the art in V&V, the paper concludes with recommendations of topics for future research and with suggestions for needed changes in the implementation of V&V in production and commercial software.}
}
@article{BRIMKOV20071631,
title = {Digital hyperplane recognition in arbitrary fixed dimension within an algebraic computation model},
journal = {Image and Vision Computing},
volume = {25},
number = {10},
pages = {1631-1643},
year = {2007},
note = {Discrete Geometry for Computer Imagery 2005},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2006.06.013},
url = {https://www.sciencedirect.com/science/article/pii/S0262885606002988},
author = {Valentin E. Brimkov and Stefan Dantchev},
keywords = {Digital hyperplane, Digital plane recognition, Integer programming, Euclidean algorithm},
abstract = {In this paper we present an algorithm for the integer linear programming (ILP) problem within an algebraic model of computation and use it to solve the following digital plane segment recognition problem: Given a set of points M={p1,p2,…,pm}⊆Rn, decide whether M is a portion of a digital hyperplane and, if so, determine its analytical representation. In our setting p1, p2, …,pm may be arbitrary points (possibly, with rational and/or irrational coefficients) and the dimension n may be any arbitrary fixed integer. We reduce this last problem to an ILP to which our general integer programming algorithm applies. It performs O(mlogD) arithmetic operations, where D is a bound on the norm of the domain elements. For the special case of problem dimension two, we propose an elementary algorithm that takes advantage of the specific geometry of the problem and appears to be optimal. It implies an efficient algorithm for digital line segment recognition.}
}
@article{REDKO2016105,
title = {Epistemological foundations of investigation of cognitive evolution},
journal = {Biologically Inspired Cognitive Architectures},
volume = {18},
pages = {105-115},
year = {2016},
issn = {2212-683X},
doi = {https://doi.org/10.1016/j.bica.2016.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S2212683X16300597},
author = {Vladimir G. Red’ko},
keywords = {Modeling of cognitive evolution, Cognitive agents, Animal cognitive features, Epistemological foundations},
abstract = {Epistemological foundations for modeling of cognitive evolution are characterized. Cognitive evolution is the evolution of cognitive abilities of biological organisms. The important result of this evolution is the human thinking, which is used at scientific cognition of nature. The related epistemological viewpoints of David Hume, Immanuel Kant, Konrad Lorenz, and Eugene Wigner are outlined. The sketch program for future investigations of cognitive evolution is proposed; initial models of these studies are outlined. According to the presented analysis, it is possible to believe the following. Investigations of cognitive evolution are directed to analyze the fundamental problems: “Why is human thinking applicable to cognition of nature?”, “How did human thinking origin in the process of biological evolution?” There are powerful backgrounds for considered investigations: (1) models of autonomous cognitive agents, (2) biological investigations of animal cognitive features. Studies of cognitive evolution would have broad interdisciplinary relations. These studies should contribute significantly to the development of the scientific point of view.}
}
@incollection{TOPLAK202253,
title = {3 - Development of the ability to detect and override miserly information processing},
editor = {Maggie E. Toplak},
booktitle = {Cognitive Sophistication and the Development of Judgment and Decision-Making},
publisher = {Academic Press},
pages = {53-87},
year = {2022},
isbn = {978-0-12-816636-9},
doi = {https://doi.org/10.1016/B978-0-12-816636-9.00011-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128166369000116},
author = {Maggie E. Toplak},
keywords = {Miserly information processing, Dual process models, Children and youth, Development, Ratio bias, Belief bias syllogisms, Cognitive reflection},
abstract = {Several judgment and decision-making tasks require overriding an incorrect response that is signaled by miserly information processes. The successful detection and override of conflict between heuristic and analytic processes has been a focus of dual processes models, especially in adult samples. These miserly processing tendencies have also been described in developmental samples. The measurement of resistance to miserly information processing has been assessed using several tasks, including ratio bias, belief bias syllogisms, cognitive reflection, and disjunctive thinking tasks. Several of these tasks have been studied in developmental samples, including in the longitudinal study described in this volume. There is evidence to suggest that resistance to miserly information processing is measurable in children and youth. While judgment and decision-making tasks vary in the degree to which override of miserly processing is required, individuals also vary in their ability to resist miserly processing tendencies. Individual differences in resistance to miserly information processing serve as an additional foundation to support rational thinking performance.}
}
@article{ROBERTS2024100502,
title = {New approach methodologies (NAMs) in drug safety assessment: A vision of the future},
journal = {Current Opinion in Toxicology},
volume = {40},
pages = {100502},
year = {2024},
issn = {2468-2020},
doi = {https://doi.org/10.1016/j.cotox.2024.100502},
url = {https://www.sciencedirect.com/science/article/pii/S2468202024000445},
author = {Ruth A. Roberts},
keywords = {3Rs, NAMs, FTIH, Drug development, ICH, Nanobots},
abstract = {Much progress has been made in reducing and refining animal use in toxicology testing, but progress in the use of new approach methodologies (NAMs) to replace animals is disappointing. There are many highly sophisticated NAMs available, but societal, regulatory and political barriers to their implementation remain. Change requires vision, starting with imagining a future where we are successful. Specifically, this would comprise the registration of safe and effective medicines without animal tests. How do we achieve this vision? Thinking differently, in silico methods could be used to provide a detailed assessment of target- and modality-related toxicological risks, coupled with modelling of exposure. In vitro NAMs such as microphysiological systems, microelectrode array and ion channel panels could then be employed to address hypothetical risks. Finally, the safety of first time in human trials could be assessed and assured using circulating nanobots that measure conventional clinical pathology parameters alongside new biomarkers such as circulating tissue DNA. This may seem the stuff of fantasy, but imagination is key to shaping a better future and all change starts with a vision, however far-fetched it may seem today.}
}
@article{BAYNE201332,
title = {Thought},
journal = {New Scientist},
volume = {219},
number = {2935},
pages = {32-39},
year = {2013},
issn = {0262-4079},
doi = {https://doi.org/10.1016/S0262-4079(13)62293-9},
url = {https://www.sciencedirect.com/science/article/pii/S0262407913622939},
author = {Tim Bayne},
abstract = {Conscious or unbidden, thoughts fill our heads from morning to night. But what are they, and what exactly is thinking? Join philosopher Tim Bayne on a journey into the fantastic, elusive and ceaseless world our minds create}
}
@article{FREYBERG20231,
title = {The morphological paradigm in robotics},
journal = {Studies in History and Philosophy of Science},
volume = {100},
pages = {1-11},
year = {2023},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2023.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0039368123000742},
author = {Sascha Freyberg and Helmut Hauser},
keywords = {Bionics, Embodied cognition, Morphology, Morphological computation, Soft robotics, Principles of orientation and control},
abstract = {In the paper, we are going to show how robotics is undergoing a shift in a bionic direction after a period of emphasis on artificial intelligence and increasing computational efficiency, which included isolation and extreme specialization. We assemble these new developments under the label of the morphological paradigm. The change in its paradigms and the development of alternatives to the principles that dominated robotics for a long time contains a more general epistemological significance. The role of body, material, environment, interaction and the paradigmatic status of biological and evolutionary systems for the principles of control are crucial here. Our focus will be on the introduction of the morphological paradigm in a new type of robotics and to contrast the interests behind this development with the interests shaping former models. The article aims to give a clear account of the changes in principles of orientation and control as well as concluding general observation in terms of historical epistemology, suggesting further political-epistemological analysis.}
}
@article{HAMMIA2024517,
title = {Enhancing Real-time Simultaneous Localization and Mapping with FPGA-based EKF-SLAM's Hardware Architecture},
journal = {Procedia Computer Science},
volume = {236},
pages = {517-526},
year = {2024},
note = {International Symposium on Green Technologies and Applications (ISGTA’2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.05.061},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924010779},
author = {Slama Hammia and Anas Hatim and Abdelilah Haijoub},
keywords = {EKF-SLAM, Simultaneous Localization and Mapping, Green Technologies, FPGA},
abstract = {Simultaneous Localization and Mapping enable a mobile robot that is exploring an uncharted environment to localize itself and calculate its path within the map. In the context of green technologies and applications, there is a growing need for efficient SLAM solutions that not only provide accurate localization and mapping but also minimize power consumption. EKF-SLAM is a SLAM solution based on the Extended Kalman Filter, it is well known In the domain of robotics for its ability to handle non-linear models, its ability to handle noise related to the sensors, and its extremely high degree of precision. To guarantee real-time performance, the EKF-SLAM implementation requires a high-performance hardware architecture. In light of this challenge, researchers are thinking about using parallel processing platforms like FPGAs, which can provide the required level of performance and meet strict constraints on physics, computing capacity, and electrical power. This study describes a hardware architecture's implementation design for EKF-SLAM on an FPGA platform. The entire design is built on the Cyclone 2 FPGA, which has a maximum speed of 114 MHz and 18577 LUTs, creating a highly efficient hardware architecture.}
}
@incollection{KRAAK2020141,
title = {Geovisualization},
editor = {Audrey Kobayashi},
booktitle = {International Encyclopedia of Human Geography (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {141-151},
year = {2020},
isbn = {978-0-08-102296-2},
doi = {https://doi.org/10.1016/B978-0-08-102295-5.10552-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780081022955105529},
author = {Menno-Jan Kraak},
keywords = {Alternative visualization, Cartography, Cognition, Coordinated multiple views, Geocomputation, Geovisualization, Information visualization, Interfaces, Maps, Representation, Spatiotemporal data, Usability, Visual analytics, Visual exploration, Visual representation, Visual thinking},
abstract = {Due to technological developments and societal needs cartography, scientific visualization, image analysis and remote sensing, information visualization, exploratory data analysis, visual analytics, and GIScience have undergone fundamental changes in recent years. Interactivity and dynamics allow not only maps and diagrams to present known facts but also to analyze and explore unknown data. The environment in which the maps and diagrams are used has also changed and often includes coordinated multiple views display via the Internet. Such environments allow for simultaneous alternative views of the data and stimulate visual thinking, resulting in geovisualization.}
}
@article{LI2023104935,
title = {Development of a distributed MR-IoT method for operations and maintenance of underground pipeline network},
journal = {Tunnelling and Underground Space Technology},
volume = {133},
pages = {104935},
year = {2023},
issn = {0886-7798},
doi = {https://doi.org/10.1016/j.tust.2022.104935},
url = {https://www.sciencedirect.com/science/article/pii/S0886779822005764},
author = {Wei Li and Zhoujing Ye and Yajian Wang and Hailu Yang and Songli Yang and Zhenlong Gong and Linbing Wang},
keywords = {Underground Pipeline Network, Mixed Reality, IoT Cloud Platform, Data Communication, Operation and Maintenance},
abstract = {The underground pipeline network (UPN) is an essential infrastructure and plays an irreplaceable role in national defense and urban activities. The complexity of structural environment and management makes its operation and maintenance difficult. To solve this problem, a distributed mixed reality (MR) and internet of things (IoT) system is developed through game thinking. Firstly, digital models are created based on design drawings and real-world environments, and then an MR system for the UPN is built by the game engine and the OpenXR platform. Secondly, an IoT cloud platform is built to connect with the MR system based on the API sets and cloud services; the data communication between sensors and MR devices is linked with the Socket method, and the data filtering model is constructed by the Kalman algorithm to realize the information exchange between the field workers and the backend managers. Finally, the National Center for Materials Service Safety at the University of Science and Technology Beijing (NCMS_USTB) is used as the experimental site to test this system, and its underground sewage and rainwater pipeline network are used to simulate the key problems in the operation and maintenance. The effect of the application shows that there is potential technical complementarity between the MR and IoT, and the distributed MR-IoT approach can be used as a new technical reference for the operation and maintenance of the UPN.}
}
@article{DENNER2012240,
title = {Computer games created by middle school girls: Can they be used to measure understanding of computer science concepts?},
journal = {Computers & Education},
volume = {58},
number = {1},
pages = {240-249},
year = {2012},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2011.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0360131511001849},
author = {Jill Denner and Linda Werner and Eloy Ortiz},
keywords = {Construction of computer games, Secondary education, Programming, After-school},
abstract = {Computer game programming has been touted as a promising strategy for engaging children in the kinds of thinking that will prepare them to be producers, not just users of technology. But little is known about what they learn when programming a game. In this article, we present a strategy for coding student games, and summarize the results of an analysis of 108 games created by middle school girls using Stagecast Creator in an after school class. The findings show that students engaged in moderate levels of complex programming activity, created games with moderate levels of usability, and that the games were characterized by low levels of code organization and documentation. These results provide evidence that game construction involving both design and programming activities can support the learning of computer science concepts.}
}
@article{FLANIGAN2017179,
title = {Implicit intelligence beliefs of computer science students: Exploring change across the semester},
journal = {Contemporary Educational Psychology},
volume = {48},
pages = {179-196},
year = {2017},
issn = {0361-476X},
doi = {https://doi.org/10.1016/j.cedpsych.2016.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S0361476X16300479},
author = {Abraham E. Flanigan and Markeya S. Peteranetz and Duane F. Shell and Leen-Kiat Soh},
keywords = {Motivation, Implicit intelligence beliefs, Computer science, Self-regulation, Engagement},
abstract = {This study investigated introductory computer science (CS1) students’ implicit beliefs of intelligence. Referencing Dweck and Leggett’s (1988) framework for implicit beliefs of intelligence, we examined how (1) students’ implicit beliefs changed over the course of a semester, (2) these changes differed as a function of course enrollment and students’ motivated self-regulated engagement profile, and (3) implicit beliefs predicted student learning based on standardized course grades and performance on a computational thinking knowledge test. For all students, there were significant increases in entity beliefs and significant decreases in incremental beliefs across the semester. However, examination of effect sizes suggests that significant findings for change across time were driven by changes in specific subpopulations of students. Moreover, results showed that students endorsed incremental belief more strongly than entity belief at both the beginning and end of the semester. Furthermore, the magnitude of changes differed based on students’ motivated self-regulated engagement profiles. Additionally, students’ achievement outcomes were weakly predicted by their implicit beliefs of intelligence. Finally, results showed that the relationship between changes in implicit intelligence beliefs and student achievement varied across different CS1 courses. Theoretical implications for implicit intelligence beliefs and recommendations for STEM educators are discussed.}
}
@article{RUSSWINKEL2011336,
title = {Predicting temporal errors in complex task environments: A computational and experimental approach},
journal = {Cognitive Systems Research},
volume = {12},
number = {3},
pages = {336-354},
year = {2011},
note = {Special Issue on Complex Cognition},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2010.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S1389041711000143},
author = {Nele Russwinkel and Leon Urbas and Manfred Thüring},
keywords = {Cognitive modelling, Time perception, Working memory, Expectations, Surprise, ACT-R},
abstract = {Management in complex environments requires knowledge about temporal contingencies. Expectations about durations enable us to prepare for important events in good time, but also to detect irregularities. Unfortunately, time perception is not invariant. Situational aspects as well as features of the task at hand may dramatically change our sense of time. Particularly under varying workload conditions, temporal distortions may lead to performance errors. A valid and reliable model of time perception must account for these characteristics. Based on the cognitive architecture ACT-R (Anderson et al., 2004), we developed a computational model in line with this requirement. Specific emphasis was placed on mechanisms of coordinative working memory which seem to influence time encoding and perception. The model’s assumptions were tested in three steps. First, the model was applied to account for time distortions ‘a posteriori’. Effects of varying working memory demands reported by Dutke (2005) were replicated and explained by simulations of the model. Second, the model was used for predicting effects ‘a priori’. Augmenting Dutke’s (2005) approach by switching between different degrees of memory demands, predictions of time distortions were derived from the model. These predictions were compared with experimental data. Central assumptions of the model were supported, but there were also some deviations that the model had not captured. Based on the conclusions from the results of the experiment, a second a priori testing addressed temporal expectations in a complex task using a micro-world scenario. The results support the interpretation of the previous experiment and provide new insights for modelling time perception. In summary, our results indicate that coordinative working memory – in contrast to general attention – causes differences in timing performance. This characteristic is captured by our approach. The model we propose heavily relies on mechanisms of working memory and can be applied to explain effects for different time intervals, under a variety of experimental conditions and in different task environments.}
}
@article{FRANTZ2003265,
title = {Herbert Simon. Artificial intelligence as a framework for understanding intuition},
journal = {Journal of Economic Psychology},
volume = {24},
number = {2},
pages = {265-277},
year = {2003},
note = {The Economic Psychology of Herbert A. Simon},
issn = {0167-4870},
doi = {https://doi.org/10.1016/S0167-4870(02)00207-6},
url = {https://www.sciencedirect.com/science/article/pii/S0167487002002076},
author = {Roger Frantz},
keywords = {Herbert Simon, Intuition, Artificial intelligence, Bounded rationality, Economics and psychology},
abstract = {Herbert Simon made overlapping substantive contributions to the fields of economics, psychology, cognitive science, artificial intelligence, decision theory, and organization theory. Simon’s work was motivated by the belief that neither the human mind, human thinking and decision making, nor human creativity need be mysterious. It was after he helped create “thinking” machines that Simon came to understand human intuition as subconscious pattern recognition. In doing so he showed that intuition need not be associated with magic and mysticism, and that it is complementary with analytical thinking. This paper will show how the overlaps in his work and especially his work on AI affected his view towards intuition.}
}
@article{FU20012567,
title = {Analytical and computational description of effect of grain size on yield stress of metals},
journal = {Acta Materialia},
volume = {49},
number = {13},
pages = {2567-2582},
year = {2001},
issn = {1359-6454},
doi = {https://doi.org/10.1016/S1359-6454(01)00062-3},
url = {https://www.sciencedirect.com/science/article/pii/S1359645401000623},
author = {H.-H. Fu and D.J. Benson and M.A. Meyers},
keywords = {Nanocrystalline materials, Grain size, Hall–Petch},
abstract = {Four principal factors contribute to grain-boundary strengthening: (a) the grain boundaries act as barriers to plastic flow; (b) the grain boundaries act as dislocation sources; (c) elastic anisotropy causes additional stresses in grain-boundary surroundings; (d) multislip is activated in the grain-boundary regions, whereas grain interiors are initially dominated by single slip, if properly oriented. As a result, the regions adjoining grain boundaries harden at a rate much higher than grain interiors. A phenomenological constitutive equation predicting the effect of grain size on the yield stress of metals is discussed and extended to the nanocrystalline regime. At large grain sizes, it has the Hall–Petch form, and in the nanocrystalline domain the slope gradually decreases until it asymptotically approaches the flow stress of the grain boundaries. The material is envisaged as a composite, comprised of the grain interior, with flow stress σfG, and grain boundary work-hardened layer, with flow stress σfGB. The predictions of this model are compared with experimental measurements over the mono, micro, and nanocrystalline domains. Computational predictions are made of plastic flow as a function of grain size incorporating differences of dislocation accumulation rate in grain-boundary regions and grain interiors. The material is modeled as a monocrystalline core surrounded by a mantle (grain-boundary region) with a high work hardening rate response. This is the first computational plasticity calculation that accounts for grain size effects in a physically-based manner. A discussion of statistically stored and geometrically necessary dislocations in the framework of strain-gradient plasticity is introduced to describe these effects. Grain-boundary sliding in the nanocrystalline regime is predicted from calculations using the Raj–Ashby model and incorporated into the computations; it is shown to predispose the material to shear localization.}
}
@article{ERBOZ202587,
title = {Electromagnetic radiation and biophoton emission in neuronal communication and neurodegenerative diseases},
journal = {Progress in Biophysics and Molecular Biology},
volume = {195},
pages = {87-99},
year = {2025},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2024.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S0079610724001159},
author = {Aysin Erboz and Elif Kesekler and Pier Luigi Gentili and Vladimir N. Uversky and Orkid Coskuner-Weber},
keywords = {Electromagnetic radiation, Biophotons, Neurodegenerative diseases, Neuron communication, Intrinsically disordered proteins},
abstract = {The intersection of electromagnetic radiation and neuronal communication, focusing on the potential role of biophoton emission in brain function and neurodegenerative diseases is an emerging research area. Traditionally, it is believed that neurons encode and communicate information via electrochemical impulses, generating electromagnetic fields detectable by EEG and MEG. Recent discoveries indicate that neurons may also emit biophotons, suggesting an additional communication channel alongside the regular synaptic interactions. This dual signaling system is analyzed for its potential in synchronizing neuronal activity and improving information transfer, with implications for brain-like computing systems. The clinical relevance is explored through the lens of neurodegenerative diseases and intrinsically disordered proteins, where oxidative stress may alter biophoton emission, offering clues for pathological conditions, such as Alzheimer's and Parkinson's diseases. The potential therapeutic use of Low-Level Laser Therapy (LLLT) is also examined for its ability to modulate biophoton activity and mitigate oxidative stress, presenting new opportunities for treatment. Here, we invite further exploration into the intricate roles the electromagnetic phenomena play in brain function, potentially leading to breakthroughs in computational neuroscience and medical therapies for neurodegenerative diseases.}
}
@article{OGBUNU2024R913,
title = {C. Brandon Ogbunu},
journal = {Current Biology},
volume = {34},
number = {20},
pages = {R913-R915},
year = {2024},
issn = {0960-9822},
doi = {https://doi.org/10.1016/j.cub.2024.09.022},
url = {https://www.sciencedirect.com/science/article/pii/S0960982224012338},
author = {C. Brandon Ogbunu}
}
@article{PAZBARUCH2023101294,
title = {Cognitive abilities and creativity: The role of working memory and visual processing},
journal = {Thinking Skills and Creativity},
volume = {48},
pages = {101294},
year = {2023},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2023.101294},
url = {https://www.sciencedirect.com/science/article/pii/S1871187123000640},
author = {Nurit Paz-Baruch and Rotem Maor},
keywords = {Cognitive abilities, Creativity, Working memory, Visual processing},
abstract = {Recent studies have revealed the importance of cognitive abilities in creative thinking. However, most research addressed adults and only a few studies have examined the ways these correlations are manifested among young children. The present study explores the role of various cognitive abilities in creativity among school children. Measures of creativity, visual-spatial working memory (VSWM), verbal short-term memory (STM), working memory (WM), and visual processing (VP) were administered to 331 students in Grades 4 and 5. Cluster analysis was used to group students' creativity levels. A multivariate analysis of variance (MANOVA) was conducted to test differences in cognitive abilities across the three clusters. Group differences between high and moderate level creativity students and low creativity students were found regarding VP abilities in the following tests: VSWM, visual discrimination (VD), and Raven's Colored Progressive Matrices (RCPM). Group differences between high creativity students and low creativity students were also found on verbal STM and WM. Additionally, structural equation modeling (SEM) analysis revealed that VP can significantly account for unique variances associated with creativity, while verbal STM and WM are not significantly related to creativity. These findings enlighten the cognitive processes underlying creativity in young children.}
}
@article{KLATT2009536,
title = {Perspectives for process systems engineering—Personal views from academia and industry},
journal = {Computers & Chemical Engineering},
volume = {33},
number = {3},
pages = {536-550},
year = {2009},
note = {Selected Papers from the 17th European Symposium on Computer Aided Process Engineering held in Bucharest, Romania, May 2007},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2008.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S0098135408001737},
author = {Karsten-Ulrich Klatt and Wolfgang Marquardt},
keywords = {Review, Modeling, Design, Optimization, Control, Operations, Numerical algorithms, Software, Computer-aided process engineering (CAPE)},
abstract = {Process systems engineering (PSE) has been an active research field for almost 50 years. Its major achievements include methodologies and tools to support process modeling, simulation and optimization (MSO). Mature, commercially available technologies have been penetrating all fields of chemical engineering in academia as well as in industrial practice. MSO technologies have become a commodity, they are not a distinguishing feature of the PSE field any more. Consequently, PSE has to reassess and to reposition its future research agenda. Emphasis should be put on model-based applications in all PSE domains including product and process design, control and operations. Furthermore, systems thinking and systems problem solving have to be prioritized rather than the mere application of computational problem solving methods. This essay reflects on the past, present and future of PSE from an academic and industrial point of view. It redefines PSE as an active and future-proof research field which can play an active role in providing enabling technologies for product and process innovations in the chemical industries and beyond.}
}
@article{MORRIS2015,
title = {Efficacy of a Web-Based, Crowdsourced Peer-To-Peer Cognitive Reappraisal Platform for Depression: Randomized Controlled Trial},
journal = {Journal of Medical Internet Research},
volume = {17},
number = {3},
year = {2015},
issn = {1438-8871},
doi = {https://doi.org/10.2196/jmir.4167},
url = {https://www.sciencedirect.com/science/article/pii/S1438887115000783},
author = {Robert R Morris and Stephen M Schueller and Rosalind W Picard},
keywords = {Web-based intervention, crowdsourcing, randomized controlled trial, depression, cognitive behavioral therapy, mental health, social networks},
abstract = {Background
Self-guided, Web-based interventions for depression show promising results but suffer from high attrition and low user engagement. Online peer support networks can be highly engaging, but they show mixed results and lack evidence-based content.
Objective
Our aim was to introduce and evaluate a novel Web-based, peer-to-peer cognitive reappraisal platform designed to promote evidence-based techniques, with the hypotheses that (1) repeated use of the platform increases reappraisal and reduces depression and (2) that the social, crowdsourced interactions enhance engagement.
Methods
Participants aged 18-35 were recruited online and were randomly assigned to the treatment group, “Panoply” (n=84), or an active control group, online expressive writing (n=82). Both are fully automated Web-based platforms. Participants were asked to use their assigned platform for a minimum of 25 minutes per week for 3 weeks. Both platforms involved posting descriptions of stressful thoughts and situations. Participants on the Panoply platform additionally received crowdsourced reappraisal support immediately after submitting a post (median response time=9 minutes). Panoply participants could also practice reappraising stressful situations submitted by other users. Online questionnaires administered at baseline and 3 weeks assessed depression symptoms, reappraisal, and perseverative thinking. Engagement was assessed through self-report measures, session data, and activity levels.
Results
The Panoply platform produced significant improvements from pre to post for depression (P=.001), reappraisal (P<.001), and perseverative thinking (P<.001). The expressive writing platform yielded significant pre to post improvements for depression (P=.02) and perseverative thinking (P<.001), but not reappraisal (P=.45). The two groups did not diverge significantly at post-test on measures of depression or perseverative thinking, though Panoply users had significantly higher reappraisal scores (P=.02) than expressive writing. We also found significant group by treatment interactions. Individuals with elevated depression symptoms showed greater comparative benefit from Panoply for depression (P=.02) and perseverative thinking (P=.008). Individuals with baseline reappraisal deficits showed greater comparative benefit from Panoply for depression (P=.002) and perseverative thinking (P=.002). Changes in reappraisal mediated the effects of Panoply, but not the expressive writing platform, for both outcomes of depression (ab=-1.04, SE 0.58, 95% CI -2.67 to -.12) and perseverative thinking (ab=-1.02, SE 0.61, 95% CI -2.88 to -.20). Dropout rates were similar for the two platforms; however, Panoply yielded significantly more usage activity (P<.001) and significantly greater user experience scores (P<.001).
Conclusions
Panoply engaged its users and was especially helpful for depressed individuals and for those who might ordinarily underutilize reappraisal techniques. Further investigation is needed to examine the long-term effects of such a platform and whether the benefits generalize to a more diverse population of users.
Trial Registration
ClinicalTrials.gov NCT02302248; https://clinicaltrials.gov/ct2/show/NCT02302248 (Archived by WebCite at http://www.webcitation.org/6Wtkj6CXU).}
}
@article{KIMSEY1994113,
title = {Parallel computation of impact dynamics},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {119},
number = {1},
pages = {113-121},
year = {1994},
issn = {0045-7825},
doi = {https://doi.org/10.1016/0045-7825(94)00079-4},
url = {https://www.sciencedirect.com/science/article/pii/0045782594000794},
author = {K.D. Kimsey and M.A. Olson},
abstract = {This paper discusses a parallel algorithm and data structures for implementing multimaterial, two-step Eulerian finite difference solution schemes on hypercube architectures. Selected problems in impact dynamics have been modeled on the Connection Machine model CM5, and the results are compared with computational results reported in the literature, as well as direct comparison with experimental data.}
}
@incollection{ESFELD2015131,
title = {Atomism and Holism: Philosophical Aspects},
editor = {James D. Wright},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {131-135},
year = {2015},
isbn = {978-0-08-097087-5},
doi = {https://doi.org/10.1016/B978-0-08-097086-8.63003-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780080970868630039},
author = {Michael Esfeld},
keywords = {Atomism, Collectivism, Confirmation, Externalism, Holism, Human nature, Individualism, Internalism, Meaning, Ontological dependence, Rationality, Rule-following, Thought},
abstract = {In the philosophy of the social sciences, atomism is the view that human beings can be thinking, rational beings independently of social relations. Holism, by contrast, is the view that social relations are essential to human beings insofar as they are thinking, rational beings. This article first provides an overview of different sorts of atomism and holism (see Section Types of Atomism and Holism). It then briefly sketches the historical background of these notions in modern philosophy (Section The Historical Background of Atomism and Holism). The main part is a systematic characterization of atomism and holism (see Section A Characterization of Atomism and Holism) and a summary of the most important arguments for both these positions (see Section Arguments for Atomism and Holism).}
}
@article{MATHESON2020116697,
title = {The role of the motor system in generating creative thoughts},
journal = {NeuroImage},
volume = {213},
pages = {116697},
year = {2020},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2020.116697},
url = {https://www.sciencedirect.com/science/article/pii/S1053811920301841},
author = {Heath E. Matheson and Yoed N. Kenett},
keywords = {Motor system, Creativity, Simulations, Embodied cognition, Grounded cognition, Divergent thinking, Improvisation},
abstract = {Neurocognitive research is pertinent to developing mechanistic models of how humans generate creative thoughts. Such models usually overlook the role of the motor cortex in creative thinking. The framework of embodied or grounded cognition suggests that creative thoughts (e.g. using a shoe as a hammer, improvising a piano solo) are partially served by simulations of motor activity associated with tools and their use. The major hypothesis stemming from the embodied or grounded account is that, while the motor system is used to execute actions, simulations within this system also support higher-order cognition, creativity included. That is, the cognitive process of generating creative output, not just executing it, is deeply embedded in motor processes. Here, we highlight a collection of neuroimaging research that implicates the motor system in generating creative thoughts, including some evidence for its functionally necessary role in generating creative output. Specifically, the grounded or embodied framework suggests that generating creative output may, in part, rely on motor simulations of possible actions, and that these simulations may by partially implemented in the motor regions themselves. In such cases, action simulations (i.e. reactivating or re-using the motor system), do not result in overt action but instead are used to support higher-order cognitive goals like generating creative uses or improvising.}
}
@incollection{ZIMMERMAN2005255,
title = {VIII - Development of Theory with Computation},
editor = {M. Olivucci},
series = {Theoretical and Computational Chemistry},
publisher = {Elsevier},
volume = {16},
pages = {255-278},
year = {2005},
booktitle = {Computational Photochemistry},
issn = {1380-7323},
doi = {https://doi.org/10.1016/S1380-7323(05)80025-1},
url = {https://www.sciencedirect.com/science/article/pii/S1380732305800251},
author = {Howard E. Zimmerman}
}
@article{SUI2001529,
title = {Terrae Incognitae and Limits of Computation: Whither GIScience?},
journal = {Computers, Environment and Urban Systems},
volume = {25},
number = {6},
pages = {529-533},
year = {2001},
issn = {0198-9715},
doi = {https://doi.org/10.1016/S0198-9715(01)00027-8},
url = {https://www.sciencedirect.com/science/article/pii/S0198971501000278},
author = {Daniel Sui}
}
@article{HICKOK2011407,
title = {Sensorimotor Integration in Speech Processing: Computational Basis and Neural Organization},
journal = {Neuron},
volume = {69},
number = {3},
pages = {407-422},
year = {2011},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2011.01.019},
url = {https://www.sciencedirect.com/science/article/pii/S0896627311000675},
author = {Gregory Hickok and John Houde and Feng Rong},
abstract = {Sensorimotor integration is an active domain of speech research and is characterized by two main ideas, that the auditory system is critically involved in speech production and that the motor system is critically involved in speech perception. Despite the complementarity of these ideas, there is little crosstalk between these literatures. We propose an integrative model of the speech-related “dorsal stream” in which sensorimotor interaction primarily supports speech production, in the form of a state feedback control architecture. A critical component of this control system is forward sensory prediction, which affords a natural mechanism for limited motor influence on perception, as recent perceptual research has suggested. Evidence shows that this influence is modulatory but not necessary for speech perception. The neuroanatomy of the proposed circuit is discussed as well as some probable clinical correlates including conduction aphasia, stuttering, and aspects of schizophrenia.}
}
@article{WOLFE197853,
title = {The rise of network thinking in anthropology},
journal = {Social Networks},
volume = {1},
number = {1},
pages = {53-64},
year = {1978},
issn = {0378-8733},
doi = {https://doi.org/10.1016/0378-8733(78)90012-6},
url = {https://www.sciencedirect.com/science/article/pii/0378873378900126},
author = {Alvin W. Wolfe},
abstract = {The encyclopedic inventory of the first half of the twentieth century, “Anthropology Today”, published in 1953, gave little inkling that within a few decades developing trends in social theory, in field experience, in electronic data processing, and in mathematics would combine to bring to prominence a distinctive theoretical approach using a quite formal network model for social systems. Now, sophisticated mathematics and computer programming permit sophisticated network models — networks seen as sets of links, networks seen as generated structures, and networks seen as flow processes. Although network thinking has shown a dramatic rise from the “Anthropology Today” of 1953 to the current anthropology of 1978, it is predicted to soar in the next quarter century, much of the weighty burden of network analysis having been lifted from us by ever more rapid electronic data processing.}
}
@article{CHEN2014740,
title = {On the Systematic Method to Enhance the Epiphany Ability of Individuals},
journal = {Procedia Computer Science},
volume = {31},
pages = {740-746},
year = {2014},
note = {2nd International Conference on Information Technology and Quantitative Management, ITQM 2014},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.05.322},
url = {https://www.sciencedirect.com/science/article/pii/S1877050914004992},
author = {Ailing Chen and Wei Liu and Zhihui Wu and Jun Zhang},
keywords = {Prototype heuristics, epiphany, extenics, Theory of Creativity, sytematic scheme ;},
abstract = {Epiphany is a crucial stage in the process of creative thinking. The prototype heuristic theory has proved that the individual epiphany ability depends on the individual's ability to get out of the fetter of mental fixation, activate the prototype and acquire the key heuristic information from the activated prototype. Based on this theory, this present research combines the findings of extenics, TRIZ and theory of creativity to have developed a systematic method on enhancing individual epiphany ability. Supported by information technology, the method takes theory of creativity as its methodology, extension strategy generation as its framework, element theory its database and knowledge management its feedback chain. The research aims to cultivate creative thinking and eventually enhance the creativity of individuals.}
}
@article{FERNANDEZFONTECHA2022101067,
title = {Examining the relations between semantic memory structure and creativity in second language},
journal = {Thinking Skills and Creativity},
volume = {45},
pages = {101067},
year = {2022},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2022.101067},
url = {https://www.sciencedirect.com/science/article/pii/S1871187122000700},
author = {Almudena Fernández-Fontecha and Yoed N. Kenett},
keywords = {Creativity, Semantic network, L2, Bilingualism, Semantic fluency},
abstract = {Creativity is related to a higher flexible semantic memory structure, which could explain greater fluency of ideas. Extensive research has identified a positive connection between creativity and bi-/multilingualism mainly in contexts where two languages or more concur in daily communicative interactions. Yet, creativity has received scant attention in regard to L2 (second or foreign language) acquisition that mainly takes place in classroom situations. The scarce research points to a positive relationship between creativity and L2 fluency – understood as the number of words produced. We apply computational network science analysis and Forward Flow methods to examine lexical organization patterns of a low creativity (LC) and high creativity (HC) group of 12th grade Spanish English as a Foreign Language (EFL) learners. The participants completed two fluency tasks, where they generated animal names in their L2, and also L1 – used here as a control measure. EFL proficiency was controlled. Our analyses revealed that the HC individuals were more fluent in L1 and L2, generated more remote responses, and exhibited a more flexible and efficiently structured semantic memory in both languages, with a greater effect of creativity in L2. Contrary to previous research, the L2 semantic memory network exhibited a less random organization. Differences in the L2 learning conditions are adduced as likely causes of this result.}
}
@article{OXMAN2006229,
title = {Theory and design in the first digital age},
journal = {Design Studies},
volume = {27},
number = {3},
pages = {229-265},
year = {2006},
note = {Digital Design},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2005.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X05000840},
author = {Rivka Oxman},
keywords = {digital design, design theory, design methodology, design thinking},
abstract = {Digital design and its growing impact on design and production practices have resulted in the need for a re-examination of current design theories and methodologies in order to explain and guide future research and development. The present research postulates the requirements for a conceptual framework and theoretical basis of digital design; reviews the recent theoretical and historical background; and defines a generic schema of design characteristics through which the paradigmatic classes of digital design are formulated. The implication of this research for the formulation of ‘digital design thinking’ is presented and discussed.}
}
@incollection{YETURU20233,
title = {Chapter 1 - Object-oriented basis of artificial intelligence methodologies},
editor = {Steven G. Krantz and Arni S.R. {Srinivasa Rao} and C.R. Rao},
series = {Handbook of Statistics},
publisher = {Elsevier},
volume = {49},
pages = {3-46},
year = {2023},
booktitle = {Artificial Intelligence},
issn = {0169-7161},
doi = {https://doi.org/10.1016/bs.host.2023.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S0169716123000251},
author = {Kalidas Yeturu},
keywords = {Object oriented, Vector representation, Induction, Deduction, Machine learning, Artificial intelligence},
abstract = {If O2 is for I, then what is O2 for AI? What is oxygen for humans is what is object-oriented thinking for artificial intelligent systems. Much the same way as humans need O2 knowingly or unknowingly, the first step in designing an AI system requires the application of object-oriented principles either explicitly or implicitly. The basis of the definition of state in AI is a description of the concept of interest as an object with properties. The idea of an object extends beyond typical noun forms that describe elements of the real world. The verb forms are included as well with -able suffixes such as runnable, serializable, and executable. In the software world, the first step in modeling a business requirement is the identification of objects of interest and defining their properties and interactions. For instance, in the case of web services, a service is an object; in the case of database systems, a table or a transaction is an object; or in the case of large-scale integration, electronic components are objects. The concept of an object extends beyond the software realm and into the mathematical world in an implicit form. Functional analysis is an old topic in mathematics where each function is an object indeed. The concept of space in mathematics relates closely to the possible value ranges of all attributes of an object. Mathematical operators are the same as methods of objects. It is day-to-day practical life in any modern operating system software dealing with process objects and applications such as Python scripts involving function objects. In this chapter, the application of object-oriented thinking to convert a business requirement to a machine learning (ML) formulation is presented with examples. The five steps of supervised ML formulation based on vector representations of input and output, mapping function, loss function, and data set are clarified. The scope and limitation of ML formulation as against general AI methodology are discussed to demystify popular myths. This chapter also reveals the secret behind the success of deep learning methodology as automatic differentiation involving function objects.}
}
@incollection{GARDNER202427,
title = {Chapter 2 - Ethics and the smart city},
editor = {Nicole Gardner},
booktitle = {Scaling the Smart City},
publisher = {Elsevier},
pages = {27-49},
year = {2024},
series = {Smart Cities},
isbn = {978-0-443-18452-9},
doi = {https://doi.org/10.1016/B978-0-443-18452-9.00004-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780443184529000045},
author = {Nicole Gardner},
keywords = {Design, process, Ethics, Ethics by design, Material ethics, Philosophy of technology, Postphenomenology, Practical ethics, Smart city, Urban technology, Value-sensitive design},
abstract = {Examining who (and what) stands to gain and lose in the smart city, and what kind of urban life smart cities create, are questions of a philosophical and ethical import. Since the early 2010s scholars and journalists have critiqued the smart city paradigm and examined its various projects and experimental initiatives to surface its ethical dimensions and significance. The smart city's rhetorical swing from tech-centric to human-centric and from smart city to smart citizen is construed here as a further effort to create the image of a more ethical smart city. Consequently, the topic of ethics has also intersected with the smart city in particular ways, and predominantly through the lens of data governance and the protection of privacy rights. This chapter argues for an expanded approach to smart city ethics. It proposes a focus on urban technology design to bridge the gap between a micro-ethical focus on data ethics and macro-level political-ethical critique. Bringing philosophical thinking on technology together with a design-led approach to urban technology is argued to provide a further way to draw out a potentially different set of ethical concerns and to explore how urban life can be lived with technology.}
}
@article{BROSSEAU2003373,
title = {Computational electromagnetics and the rational design of new dielectric heterostructures},
journal = {Progress in Materials Science},
volume = {48},
number = {5},
pages = {373-456},
year = {2003},
issn = {0079-6425},
doi = {https://doi.org/10.1016/S0079-6425(02)00013-0},
url = {https://www.sciencedirect.com/science/article/pii/S0079642502000130},
author = {C. Brosseau and A. Beroual},
abstract = {Dielectric properties of heterogeneous materials for various condensed-matter systems have been gaining world-wide attention over the past 50 or so years in the design (or engineering) of materials structures for desired properties and functional purposes. These applications range from cable and current limiters to sensors. These multiscale systems lead to challenging problems of connecting micro- or meso-structural features to macroscopic materials response, i.e. permittivity, conductivity. This article first reviews progress made at that time of the underlying physics of dielectric heterostructures and points out the missing elements that have led to a resurgence of interest in these and related materials. Recent advances in computational electromagnetics provide unparalleled control over morphology in this class of materials to produce a seemingly unlimited number of exquisitely structured materials endowed with tailored electromagnetic, and other physical properties. In the text to follow, we illustrate how an ab initio computational technique can be used to accurately characterize structure–dielectric property relationships of periodic heterostructures in the quasistatic limit. More specifically, we have carried out two-dimensional (2D) and three-dimensional (3D) numerical studies of two-component materials in which equal-sized inclusions, with shape and orientation and possibly fused together, are fixed in a periodic square (2D) or cubic (3D) array. Boundary-integral equations (BIE) are derived from Green's theorem and are solved for the local field with appropriate periodicity conditions on a unit cell of the structures using the field calculation package PHI3D. A number of illustrative examples shows how this computational technique can provide very accurate predictions for the complex effective permittivity of translationally-invariant heterostructures. The performance of the method is also compared with those of other computational and analytical techniques. We comment on how this computational method helps identify some important characteristics for rationalizing and predicting the structure of composite materials in terms of the nature, size, shape and orientation of their constituents.}
}
@article{JOEL2002535,
title = {Actor–critic models of the basal ganglia: new anatomical and computational perspectives},
journal = {Neural Networks},
volume = {15},
number = {4},
pages = {535-547},
year = {2002},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(02)00047-3},
url = {https://www.sciencedirect.com/science/article/pii/S0893608002000473},
author = {Daphna Joel and Yael Niv and Eytan Ruppin},
keywords = {Basal ganglia, Dopamine, Reinforcement learning, Actor–critic, Dimensionality reduction, Evolutionary computation, Behavioral switching, Striosomes/patches},
abstract = {A large number of computational models of information processing in the basal ganglia have been developed in recent years. Prominent in these are actor–critic models of basal ganglia functioning, which build on the strong resemblance between dopamine neuron activity and the temporal difference prediction error signal in the critic, and between dopamine-dependent long-term synaptic plasticity in the striatum and learning guided by a prediction error signal in the actor. We selectively review several actor–critic models of the basal ganglia with an emphasis on two important aspects: the way in which models of the critic reproduce the temporal dynamics of dopamine firing, and the extent to which models of the actor take into account known basal ganglia anatomy and physiology. To complement the efforts to relate basal ganglia mechanisms to reinforcement learning (RL), we introduce an alternative approach to modeling a critic network, which uses Evolutionary Computation techniques to ‘evolve’ an optimal RL mechanism, and relate the evolved mechanism to the basic model of the critic. We conclude our discussion of models of the critic by a critical discussion of the anatomical plausibility of implementations of a critic in basal ganglia circuitry, and conclude that such implementations build on assumptions that are inconsistent with the known anatomy of the basal ganglia. We return to the actor component of the actor–critic model, which is usually modeled at the striatal level with very little detail. We describe an alternative model of the basal ganglia which takes into account several important, and previously neglected, anatomical and physiological characteristics of basal ganglia–thalamocortical connectivity and suggests that the basal ganglia performs reinforcement-biased dimensionality reduction of cortical inputs. We further suggest that since such selective encoding may bias the representation at the level of the frontal cortex towards the selection of rewarded plans and actions, the reinforcement-driven dimensionality reduction framework may serve as a basis for basal ganglia actor models. We conclude with a short discussion of the dual role of the dopamine signal in RL and in behavioral switching.}
}
@article{ALOUPIS2015135,
title = {Classic Nintendo games are (computationally) hard},
journal = {Theoretical Computer Science},
volume = {586},
pages = {135-160},
year = {2015},
note = {Fun with Algorithms},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2015.02.037},
url = {https://www.sciencedirect.com/science/article/pii/S0304397515001735},
author = {Greg Aloupis and Erik D. Demaine and Alan Guo and Giovanni Viglietta},
keywords = {Nintendo games, Video games, Computational complexity, NP-hardness, PSPACE-hardness},
abstract = {We prove NP-hardness results for five of Nintendo's largest video game franchises: Mario, Donkey Kong, Legend of Zelda, Metroid, and Pokémon. Our results apply to generalized versions of Super Mario Bros. 1–3, The Lost Levels, and Super Mario World; Donkey Kong Country 1–3; all Legend of Zelda games; all Metroid games; and all Pokémon role-playing games. In addition, we prove PSPACE-completeness of the Donkey Kong Country games and several Legend of Zelda games.}
}
@incollection{CAMERON200789,
title = {Designing Computational Clusters for Performance and Power},
editor = {Marvin V. Zelkowitz},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {69},
pages = {89-153},
year = {2007},
booktitle = {Architectural Issues},
issn = {0065-2458},
doi = {https://doi.org/10.1016/S0065-2458(06)69002-5},
url = {https://www.sciencedirect.com/science/article/pii/S0065245806690025},
author = {Kirk W. Cameron and Rong Ge and Xizhou Feng},
abstract = {Power consumption in computational clusters has reached critical levels. High-end cluster performance improves exponentially while the power consumed and heat dissipated increase operational costs and failure rates. Yet, the demand for more powerful machines continues to grow. In this chapter, we motivate the need to reconsider the traditional performance-at-any-cost cluster design approach. We propose designs where power and performance are considered critical constraints. We describe power-aware and low power techniques to reduce the power profiles of parallel applications and mitigate the impact on performance.}
}
@article{DRAGGIOTIS1998157,
title = {On the computation of multigluon amplitudes},
journal = {Physics Letters B},
volume = {439},
number = {1},
pages = {157-164},
year = {1998},
issn = {0370-2693},
doi = {https://doi.org/10.1016/S0370-2693(98)01015-6},
url = {https://www.sciencedirect.com/science/article/pii/S0370269398010156},
author = {Petros Draggiotis and Ronald H.P. Kleiss and Costas G. Papadopoulos},
abstract = {A computational algorithm based on recursive equations is developed in order to estimate multigluon production processes at high energy hadron colliders. The partonic reactions gg→(n−2)g with n≤9 are studied and comparisons with known approximations are presented.}
}
@incollection{YANG20133,
title = {1 - Swarm Intelligence and Bio-Inspired Computation: An Overview},
editor = {Xin-She Yang and Zhihua Cui and Renbin Xiao and Amir Hossein Gandomi and Mehmet Karamanoglu},
booktitle = {Swarm Intelligence and Bio-Inspired Computation},
publisher = {Elsevier},
address = {Oxford},
pages = {3-23},
year = {2013},
isbn = {978-0-12-405163-8},
doi = {https://doi.org/10.1016/B978-0-12-405163-8.00001-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780124051638000016},
author = {Xin-She Yang and Mehmet Karamanoglu},
keywords = {Algorithm, ant algorithm, bee algorithm, bat algorithm, bio-inspired, cuckoo search, firefly algorithm, harmony search, particle swarm optimization, swarm intelligence, metaheuristics},
abstract = {Swarm intelligence (SI) and bio-inspired computing in general have attracted great interest in almost every area of science, engineering, and industry over the last two decades. In this chapter, we provide an overview of some of the most widely used bio-inspired algorithms, especially those based on SI such as cuckoo search, firefly algorithm, and particle swarm optimization. We also analyze the essence of algorithms and their connections to self-organization. Furthermore, we highlight the main challenging issues associated with these metaheuristic algorithms with in-depth discussions. Finally, we provide some key, open problems that need to be addressed in the next decade.}
}
@article{BENTON20001135,
title = {Computational modelling of interleaved first- and second-order motion sequences and translating 3f+4f beat patterns},
journal = {Vision Research},
volume = {40},
number = {9},
pages = {1135-1142},
year = {2000},
issn = {0042-6989},
doi = {https://doi.org/10.1016/S0042-6989(00)00026-2},
url = {https://www.sciencedirect.com/science/article/pii/S0042698900000262},
author = {Christopher P. Benton and Alan Johnston and Peter W. McOwan},
keywords = {Motion perception, Computational modelling, Second-order, Feature tracking},
abstract = {Despite detailed psychophysical, neurophysiological and electrophysiological investigation, the number and nature of independent and parallel motion processing mechanisms in the visual cortex remains controversial. Here we use computational modelling to evaluate evidence from two psychophysical studies collectively thought to demonstrate the existence of three separate and independent motion processing channels. We show that the pattern of psychophysical results can largely be accounted for by a single mechanism. The results demonstrate that a low-level luminance based approach can potentially provide a wider account of human motion processing than generally thought possible.}
}