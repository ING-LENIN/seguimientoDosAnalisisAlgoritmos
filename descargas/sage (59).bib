@article{doi:10.1177/1094342012474997,
author = {Miguel O Bernabeu and James Southern and Nicholas Wilson and Peter Strazdins and Jonathan Cooper and Joe Pitt-Francis},
title = {Chaste: A case study of parallelisation of an open source finite-element solver with          applications to computational cardiac electrophysiology simulation},
journal = {The International Journal of High Performance Computing Applications},
volume = {28},
number = {1},
pages = {13–32},
year = {2014a},
doi = {10.1177/1094342012474997},
URL = {https://doi-org.crai.referencistas.com/10.1177/1094342012474997},
eprint = {https://doi-org.crai.referencistas.com/10.1177/1094342012474997},
abstract = {The simulation of cardiac electrophysiology is a mature field in computational physiology. Recent advances in medical imaging, high-performance computing and numerical methods mean that computational models of electrical propagation in human heart tissue are ripe for use in patient-specific simulation for diagnosis, for prognosis and for selection of treatment methods. However, in order to move in this direction, it is necessary to make efficient use of modern petascale computing resources. This paper focuses on an existing open source simulation framework (Chaste) and documents work done to improve the parallel scaling on a small range of electrophysiology benchmark problems. These benchmarks involve the numerical solution of the monodomain or bidomain equations via the finite-element method. At the beginning of this study the electrophysiology libraries within Chaste were already enabled to run in parallel and were able to solve for electrical propagation using the monodomain or bidomain equations, but parallel efficiency dropped rapidly when run on more than about 64 processors. Throughout the course of the study, improvements were made to problem definition input; geometric mesh partitioning; finite-element assembly of large, sparse linear systems; problem-specific matrix preconditioning; numerical solution of the linear system; and output of the approximate solution. The consequence of these improvements is that, at the end of the study, Chaste is able to solve a monodomain benchmark problem in close to real time. While some of the improvements made to the parallel Chaste code are specific to cardiac electrophysiology, many of the techniques documented in this paper are generic to the parallel finite-element method in other scientific application areas.}
}

@article{doi:10.3233/FUN-2000-44403,
author = {Stéphane Demri and Jarosław Stepaniuk},
title = {Computational Complexity of Multimodal Logics \newline Based on     Rough Sets},
journal = {Fundamenta Informaticae},
volume = {44},
number = {4},
pages = {373–396},
year = {2000b},
doi = {10.3233/FUN-2000-44403},
URL = {https://doi-org.crai.referencistas.com/10.3233/FUN-2000-44403},
eprint = {https://doi-org.crai.referencistas.com/10.3233/FUN-2000-44403},
abstract = {We characterize the computational complexity of a family of approximation multimodal logics in which interdependent modal connectives are part of the language. Those logics have been designed to reason in presence of incomplete information in the sense of rough set theory. More precisely, we show that all the logics have a PSPACE-complete satisfiability problem and we define a family of tolerance approximation multimodal logics whose satisfiability is EXPTIME-complete. This illustrates that the PSPACE upper bound for this kind of multimodal logics is a very special feature of such logics. The PSPACE upper bounds are established by adequately designing Ladner-style tableaux-based procedures whereas the EXPTIME lower bound is established by reduction from the global satisfiability problem for the standard modal logic B.}
}

@article{doi:10.3233/HSM-120777,
author = {Kurt M. Gehlert and Thomas Ressler and Donoxti Baylon},
title = {Global challenges demand global education of systems thinking},
journal = {Human Systems Management},
volume = {32},
number = {2},
pages = {79–94},
year = {2013c},
doi = {10.3233/HSM-120777},
URL = {https://doi-org.crai.referencistas.com/10.3233/HSM-120777},
eprint = {https://doi-org.crai.referencistas.com/10.3233/HSM-120777},
abstract = {This article is an appeal to incorporate systems thinking into topics and courses in business education and the social sciences. After reviewing the lack of systems thinking and systems theory in American education, its negative impact on decision making and risk analysis, the authors demonstrate how to weave systems thinking and systems theory into the existing curricula, and how to assess the effectiveness of such pedagogy on the decision making and risk analysis process.}
}

@article{doi:10.1177/17504813231177280,
author = {Jonathan Hendrickx and Annelien Van Remoortere and Michael Opgenhaffen},
title = {News packaging during a pandemic: A computational analysis of news diffusion via Facebook},
journal = {Discourse & Communication},
volume = {17},
number = {6},
pages = {701–720},
year = {2023d},
doi = {10.1177/17504813231177280},
URL = {https://doi-org.crai.referencistas.com/10.1177/17504813231177280},
eprint = {https://doi-org.crai.referencistas.com/10.1177/17504813231177280},
abstract = {Facebook remains the most important platform where social media editors package and try to ‘sell’ media outlets’ online news articles to audiences. In one of the first studies of its kind, we assess how this practice was effectuated during the first year of the COVID-19 pandemic. We use computational analysis to determine the polarity, subjectivity and use of some linguistics features in the status messages of 140,359 Facebook posts of 17 mainstream and alternative news titles from Flanders (Belgium) between March 2020 and 2021. Among other things, we find that status messages score considerably higher than headlines in terms of polarity and subjectivity, and that they, along with the use of question and interrogation marks, peaked in the first months of the pandemic. We contextualise our findings within existing scholarship and wider trends in increasingly digitised and globalised media societies.}
}

@article{doi:10.1177/01436244241268071,
author = {Amos Kalua and James Jones and Francine Battaglia and Elizabeth Grant},
title = {Framework for integrated multi-scale computational fluid dynamics simulations in natural ventilation design},
journal = {Building Services Engineering Research and Technology},
volume = {45},
number = {6},
pages = {733–753},
year = {2024e},
doi = {10.1177/01436244241268071},
URL = {https://doi-org.crai.referencistas.com/10.1177/01436244241268071},
eprint = {https://doi-org.crai.referencistas.com/10.1177/01436244241268071},
abstract = {The wind flow field constitutes an important input parameter for computational fluid dynamics (CFD) simulations that are used in architectural design for the design and analysis of natural ventilation strategies.  Despite indications that the wind flow field may vary between places, CFD simulations that do not adequately account for this potential variation are still commonplace. This may significantly compromise the integrity and accuracy of the CFD simulations. This study was a two-pronged investigation with the ultimate objective of contributing towards efforts aimed at improving the accuracy of the CFD simulations. Firstly, a framework for integrated meso-scale and micro-scale CFD simulations was developed. Secondly, the newly developed framework was then implemented by deploying it to study the variation of the wind flow field between a reference meteorological station, and a selected local building site. The findings confirmed the indications that the wind flow field might vary spatially. The integrated multi-scale framework that was developed as part of the study was not only able to capture the wind flow field variation, but it also provided a way to quantify it, ultimately, leading to the generation of a more accurate wind flow field characterization representative of the local conditions. Through its ability to integrate multiple spatial scales that typically influence one another, this framework can help to enhance the accuracy and integrity of the CFD simulations that are used for natural ventilation design. Practical application: The findings from this study can be particularly useful when undertaking spatially integrated CFD simulations to design and analyse natural ventilation strategies in the building design process.}
}

@article{doi:10.1177/14782103231177107,
author = {J Jacob Kirksey and Kristin Mansell and Teresa Lansford},
title = {Literacy, numeracy, and problem-solving skills of adults with disabilities in STEM fields},
journal = {Policy Futures in Education},
volume = {22},
number = {3},
pages = {427–453},
year = {2024f},
doi = {10.1177/14782103231177107},
URL = {https://doi-org.crai.referencistas.com/10.1177/14782103231177107},
eprint = {https://doi-org.crai.referencistas.com/10.1177/14782103231177107},
abstract = {To aid in the development of a globally competitive workforce, federal policymakers have expressed the priority of preparing students and adults with disabilities to succeed in science, technology, engineering, and mathematics (STEM) fields. Yet, no research has examined the extent to which information-processing, literacy, numeracy, and problem-solving skills in technologically rich environments may associate with having a STEM degree for various disability populations. This study analyzed the United States nationally representative data from the Programme for the International Assessment of Adult Competencies (PIAAC) to examine associations between adult skills and having a STEM degree for people with and without disabilities. No direct associations were found between adult skills and having a STEM degree for people with learning disabilities or for people without disabilities. These groups’ information processing, literacy, numeracy, and problem-solving skills were not determining factors in STEM degree attainment. However, findings suggest a significant association between problem-solving skills and having a STEM degree for people with visual and/or hearing impairments. Policy implications are discussed.}
}

@article{doi:10.1177/0306419020950250,
author = {Yucheng Liu and Silas Whitaker and Connor Hayes and Jared Logsdon and Logan McAfee and Riley Parker},
title = {Establishment of an experimental-computational framework for promoting Project-based learning for vibrations and controls education},
journal = {International Journal of Mechanical Engineering Education},
volume = {50},
number = {1},
pages = {158–175},
year = {2022g},
doi = {10.1177/0306419020950250},
URL = {https://doi-org.crai.referencistas.com/10.1177/0306419020950250},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0306419020950250},
abstract = {A curriculum enhancement project of embedding MATLAB and Simulink to a mechanical engineering (ME) vibrations and controls course is presented in this paper. MATLAB/Simulink is a popular software tool for vibration analysts and control designers, which is consistently regarded as one of the most in-demand technical skills that employers are looking for. In the past, the ME students at Mississippi State University (MSU) did not have the training opportunity to use MATLAB/Simulink for design and analysis of vibration and control systems. With the support of a teaching grants, the author created an experimental lab section to ask students to design and build vibration and control devices, and integrated these device into his vibrations and controls course. In this study, the author develops a computer lab section based on the implementation of MATLAB/Simulink, which complements with the experimental lab section to provide the students with a full lab experience. The experimental-computational lab allows the students to not only observe and characterize the dynamic response of vibration and control systems through experimental operations and measurements, but also validate experimental results and confirm experimental phenomena through computational analysis. As well as exploring dynamic behaviors of the systems in a variety of conditions through numerical simulations with different settings. An example of student project is presented to show an experimental-computational study conducted by a student team using MATLAB/Simulink software tool and self-developed data acquisition systems based on a base excitation model demonstrated in class. A questionnaire was conducted at the end of that class and results confirms that the implementation of MATLAB/Simulink into the course effectively develops the ME students’ programming skills and strengthens their capacity in modeling, simulating, and analyzing vibration, control, and other dynamic systems. The developed computational lab and the current experimental lab complementarily promote student understanding of principles and concepts conveyed in classroom lectures.}
}

@article{doi:10.1177/0002716215569220,
author = {Henri Pettersson},
title = {De-idealising the educational ideal of critical thinking},
journal = {The ANNALS of the American Academy of Political and Social Science},
volume = {18},
number = {3},
pages = {225–245},
year = {2020h},
doi = {10.1177/0002716215569220},
URL = {https://doi-org.crai.referencistas.com/10.1177/0002716215569220},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0002716215569220},
abstract = {There is considerable controversy surrounding the study of presidential debates, particularly efforts to connect their content and impact. Research has long debated whether the citizenry reacts to what candidates say, how they say it, or simply how they appear. This study uses detailed coding of the first 2012 debate between Barack Obama and Mitt Romney to test the relative influence of the candidates’ verbal persuasiveness and nonverbal features on viewers’ “second screen” behavior—their use of computers, tablets, and mobile phones to enhance or extend the televised viewing experience. To examine these relationships, we merged two datasets: (1) a shot-by-shot content analysis coded for functional, tonal, and visual elements of both candidates’ communication behavior during the debate; and (2) corresponding real-time measures, synched and lagged, of the volume and sentiment of Twitter expression about Obama and Romney. We find the candidates’ facial expressions and physical gestures to be more consistent and robust predictors of the volume and valence of Twitter expression than candidates’ persuasive strategies, verbal utterances, and voice tone during the debate.}
}

@article{doi:10.1177/0002716215569220,
author = {Dhavan V. Shah and Alex Hanna and Erik P. Bucy and Chris Wells and Vidal Quevedo},
title = {The Power of Television Images in a Social Media Age: Linking Biobehavioral and Computational Approaches via the Second Screen},
journal = {The ANNALS of the American Academy of Political and Social Science},
volume = {659},
number = {1},
pages = {225–245},
year = {2015i},
doi = {10.1177/0002716215569220},
URL = {https://doi-org.crai.referencistas.com/10.1177/0002716215569220},
eprint = {https://doi-org.crai.referencistas.com/10.1177/0002716215569220},
abstract = {There is considerable controversy surrounding the study of presidential debates, particularly efforts to connect their content and impact. Research has long debated whether the citizenry reacts to what candidates say, how they say it, or simply how they appear. This study uses detailed coding of the first 2012 debate between Barack Obama and Mitt Romney to test the relative influence of the candidates’ verbal persuasiveness and nonverbal features on viewers’ “second screen” behavior—their use of computers, tablets, and mobile phones to enhance or extend the televised viewing experience. To examine these relationships, we merged two datasets: (1) a shot-by-shot content analysis coded for functional, tonal, and visual elements of both candidates’ communication behavior during the debate; and (2) corresponding real-time measures, synched and lagged, of the volume and sentiment of Twitter expression about Obama and Romney. We find the candidates’ facial expressions and physical gestures to be more consistent and robust predictors of the volume and valence of Twitter expression than candidates’ persuasive strategies, verbal utterances, and voice tone during the debate.}
}

@article{doi:10.2304/pfie.2014.12.6.832,
author = {Hüseyin Tolu},
title = {The Politics of the ICT4ED (Fatih) Project in Turkey},
journal = {Policy Futures in Education},
volume = {12},
number = {6},
pages = {832–849},
year = {2014j},
doi = {10.2304/pfie.2014.12.6.832},
URL = {https://doi-org.crai.referencistas.com/10.2304/pfie.2014.12.6.832},
eprint = {https://doi-org.crai.referencistas.com/10.2304/pfie.2014.12.6.832},
abstract = {Information and communications technology (ICT) is crucial in any contemporary society, especially if its online presence is to be widely significant, but, in a national context, it is important to investigate whether there is a compelling ICT ‘politic’ in the education sector in Turkey. This study specifically focuses on the ICT for Educational Development (ICT4ED) (Fatih) project, valued at US$8 billion, which is an embodiment of future educational reform in centralist Turkey. The study investigates the level of policy-making capacity within the scope of the Fatih project, which promises to fully integrate ICT into education in order to solve many educational issues, such as establishing entrepreneurialism in education, improving ICT sectors, exporting educational services to other nations for profit, and, ultimately, meeting the overarching purpose of Turkey becoming a competitive nation. The discourse of the government is to explore technological opportunities within education in order to create new ‘profitable’ avenues that conceive education as a ‘commodity’ and a ‘private good’, which is another feature of fragmented centralisation through public-private partnership(s) for both covert and overt privatisations. While the Fatih project defines the future as having new, ‘fully integrated ICT in education’, this study presents three main normative arguments — with regard to the project’s political execution, technical development and philosophical conception — to refute its objectives and highlight that it is destined to fail, and to suggest what urgent matters the ICT4ED politic should highlight in future education.}
}

