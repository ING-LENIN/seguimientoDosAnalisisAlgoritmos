This study identifies the principal elements that ought to be taken into consideration when allocating tasks and roles to individuals with ASD in software development.}
}
@article{CROSS2018160,
title = {A brief history of the Design Thinking Research Symposium series},
journal = {Design Studies},
volume = {57},
pages = {160-164},
year = {2018},
note = {Designing in the Wild},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2018.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X18300243},
author = {Nigel Cross}
}
@article{LEISTI2016340,
title = {The effect of introspection on judgment and decision making is dependent on the quality of conscious thinking},
journal = {Consciousness and Cognition},
volume = {42},
pages = {340-351},
year = {2016},
issn = {1053-8100},
doi = {https://doi.org/10.1016/j.concog.2016.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S1053810016300599},
author = {Tuomas Leisti and Jukka Häkkinen},
keywords = {Judgment and decision making, Analytic and intuitive thinking, Dual process theories, Visual choice, Introspection, Individual differences},
abstract = {That introspection may impair certain judgments and result in fabrication has been attributed to a distracting shift from more adaptive intuitive processing to more analytic and conscious processing. This phenomenon was studied in an experiment where participants made multidimensional visual choices. It was found that the effect of this shift on decision-making performance was dependent on the quality of the explanations during introspection, while the performance in silent conditions was not. Therefore, it appears that the effect of introspection on judgments is not only influenced by the thinking mode per se, but also by the individual’s ability to approach the decision problem analytically.}
}
@article{CHEESEMAN2020100817,
title = {Investigating young students’ multiplicative thinking: The 12 little ducks problem},
journal = {The Journal of Mathematical Behavior},
volume = {60},
pages = {100817},
year = {2020},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2020.100817},
url = {https://www.sciencedirect.com/science/article/pii/S073231232030081X},
author = {Jill Cheeseman and Ann Downton and Anne Roche and Sarah Ferguson},
keywords = {Visualization, Multiplicative reasoning, Children's drawings, Early mathematics, Problem solving},
abstract = {Children’s multiplicative thinking as the visualization of equal group structures and the enumeration the composite units was the subject of this study. The results were obtained from a small sample of Australian children (n = 18) in their first year of school (mean age 5 years 6 months) who participated in a lesson taught by their classroom teacher. The 12 Little Ducks problem stimulated children to visualize and to draw different ways of making equal groups. Fifteen children (83 %) could identify and create equal groups; eight of these children (44 %) could also quantify the number of groups they formed. These findings show that some young children understand early multiplicative ideas and can visualize equal group situations and communicate about these through their drawings and talk. The study emphasises the value of encouraging mathematical visualization from an early age; using open thought-provoking problems to reveal children’s thinking; and promoting drawing as a form of mathematical communication.}
}
@article{BROOMHALL201756,
title = {Upward counterfactual thinking and depression: A meta-analysis},
journal = {Clinical Psychology Review},
volume = {55},
pages = {56-73},
year = {2017},
issn = {0272-7358},
doi = {https://doi.org/10.1016/j.cpr.2017.04.010},
url = {https://www.sciencedirect.com/science/article/pii/S0272735816301714},
author = {Anne Gene Broomhall and Wendy J. Phillips and Donald W. Hine and Natasha M. Loi},
keywords = {Counterfactual-related depression, Upward counterfactual thinking, Regret, Functional theory, Depression},
abstract = {This meta-analysis examined the strength of association between upward counterfactual thinking and depressive symptoms. Forty-two effect sizes from a pooled sample of 13,168 respondents produced a weighted average effect size of r=.26, p<.001. Moderator analyses using an expanded set of 96 effect sizes indicated that upward counterfactuals and regret produced significant positive effects that were similar in strength. Effects also did not vary as a function of the theme of the counterfactual-inducing situation or study design (cross-sectional versus longitudinal). Significant effect size heterogeneity was observed across sample types, methods of assessing upward counterfactual thinking, and types of depression scale. Significant positive effects were found in studies that employed samples of bereaved individuals, older adults, terminally ill patients, or university students, but not adolescent mothers or mixed samples. Both number-based and Likert-based upward counterfactual thinking assessments produced significant positive effects, with the latter generating a larger effect. All depression scales produced significant positive effects, except for the Psychiatric Epidemiology Research Interview. Research and theoretical implications are discussed in relation to cognitive theories of depression and the functional theory of upward counterfactual thinking, and important gaps in the extant research literature are identified.}
}
@article{TAPPIN2020104375,
title = {Bayesian or biased? Analytic thinking and political belief updating},
journal = {Cognition},
volume = {204},
pages = {104375},
year = {2020},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2020.104375},
url = {https://www.sciencedirect.com/science/article/pii/S0010027720301943},
author = {Ben M. Tappin and Gordon Pennycook and David G. Rand},
keywords = {Political beliefs, Bayesian updating, Cognitive sophistication, Polarization},
abstract = {A surprising finding from U.S. opinion surveys is that political disagreements tend to be greatest among the most cognitively sophisticated opposing partisans. Recent experiments suggest a hypothesis that could explain this pattern: cognitive sophistication magnifies politically biased processing of new information. However, the designs of these experiments tend to contain several limitations that complicate their support for this hypothesis. In particular, they tend to (i) focus on people's worldviews and political identities, at the expense of their other, more specific prior beliefs, (ii) lack direct comparison with a politically unbiased benchmark, and (iii) focus on people's judgments of new information, rather than on their posterior beliefs following exposure to the information. We report two studies designed to address these limitations. In our design, U.S. subjects received noisy but informative signals about the truth or falsity of partisan political questions, and we measured their prior and posterior beliefs, and cognitive sophistication, operationalized as analytic thinking inferred via performance on the Cognitive Reflection Test. We compared subjects' posterior beliefs to an unbiased Bayesian benchmark. We found little evidence that analytic thinking magnified politically biased deviations from the benchmark. In contrast, we found consistent evidence that greater analytic thinking was associated with posterior beliefs closer to the benchmark. Together, these results are inconsistent with the hypothesis that cognitive sophistication magnifies politically biased processing. We discuss differences between our design and prior work that can inform future tests of this hypothesis.}
}
@article{MEKERN201947,
title = {Computational models of creativity: a review of single-process and multi-process recent approaches to demystify creative cognition},
journal = {Current Opinion in Behavioral Sciences},
volume = {27},
pages = {47-54},
year = {2019},
note = {Creativity},
issn = {2352-1546},
doi = {https://doi.org/10.1016/j.cobeha.2018.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S2352154618301256},
author = {Vera Mekern and Bernhard Hommel and Zsuzsika Sjoerds},
abstract = {Creativity is a compelling but heterogeneous phenomenon. As opposed to big-C creativity, which is regarded as limited to the rare brilliant mind, little-c creativity is indispensable in adaptive everyday behavior, serving to adjust to changing circumstances and challenges. Computational approaches help demystify human creativity by offering insights into the underlying mechanisms and their characteristics. Recently proposed computational models to creative cognition often focus on either divergent or convergent problem-solving, but some start to integrate these processes into broader cognitive frameworks. We briefly review the state-of-the-art in the field and point out theoretical overlap. We extract basic principles that most existing models agree on and desiderata on the way towards a comprehensive model.}
}
@article{HUANG2024100651,
title = {Deepening children’s STEM learning through making and creative writing},
journal = {International Journal of Child-Computer Interaction},
volume = {40},
pages = {100651},
year = {2024},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2024.100651},
url = {https://www.sciencedirect.com/science/article/pii/S2212868924000199},
author = {Joey Huang and Ariel Han and Ana Villanueva and Ziyi Liu and Zhengzhe Zhu and Karthik Ramani and Kylie Peppler},
keywords = {Creative writing, STEAM learning, Internet of things (IoT), Computational thinking, Physical computing, STEAM practices},
abstract = {Current trends demonstrate that researchers and K-12 educators are moving towards integrating computational thinking (CT) concepts outside of the computer science (CS) classroom (Lee et al., 2020). However, one of the present challenges includes a lack of engaging learning content and instruction for translating computational concepts that non-CS instructors can bring into their classrooms. Our research team developed the Grove-Blockly platform, a website that employs block-based programming and physical computing elements with simulations to support CT learning and IoT practices. We designed a 5-day workshop with the National Writing Project for students to engage in STEAM learning through making and creative writing. By examining students’ learning through the processes and outcomes of making, coding, and creative writing, we aim to better understand how learning occurs at the intersections of making, writing, and computing. The findings show students’ positive learning outcomes of CT and physical computing from the workshop. Mainly, students gained a deeper understanding of IoT elements (e.g., sensors, actuators) through the process of making and creative writing. This work provides empirical evidence on how students learn CT and computational practices through making and creative writing. Finally, we discuss how the engagement of STEAM practices supports and empowers students’ learning of CT and physical computing through the creation of e-crafts by students.}
}
@article{MANSON2010857,
title = {Assessing and refining an undergraduate computational science curriculum},
journal = {Procedia Computer Science},
volume = {1},
number = {1},
pages = {857-865},
year = {2010},
note = {ICCS 2010},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2010.04.094},
url = {https://www.sciencedirect.com/science/article/pii/S1877050910000955},
author = {J. Russell Manson and Robert J. Olsen},
keywords = {Computational science education, Computational thinking, Curriculum development, Assessment, Placement diagnostics, Force Concept Inventory (FCI), Rubrics},
abstract = {We describe our experiences with curriculum development and learning assessment in a new undergraduate computational science program. We report on the development and pilot testing of assessment tools in both core and cognate courses. Specifically, we detail a diagnostic assessment that predicted success in our introductory computational science course with reasonable reliability; we give an account of our use of an existing assessment tool to investigate how introducing computational thinking in a cognate course influences learning of the traditional course material; and we discuss developing a pancurriculum rubric for scoring computational science projects.}
}
@article{ZIVKOVIL2016102,
title = {A Model of Critical Thinking as an Important Attribute for Success in the 21st Century},
journal = {Procedia - Social and Behavioral Sciences},
volume = {232},
pages = {102-108},
year = {2016},
note = {International Conference on Teaching and Learning English as an Additional Language, GlobELT 2016, 14-17 April 2016, Antalya, Turkey},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2016.10.034},
url = {https://www.sciencedirect.com/science/article/pii/S1877042816312666},
author = {SlaĿana ŽivkoviĿ},
keywords = {Critical thinking, ESP, engineering},
abstract = {The aim of this paper is to suggest a specific teaching approach which employs a critical thinking model, as well as to show the possibilities for structuring professional knowledge and enhancing learning efficiency. Entering the world of global competition, the emphasis is on the need to prepare students to be communicative, collaborative, creative, innovative, to think critically and analytically, and to be able to effectively solve real-world problems. With higher-order thinking skills, which are essential for absorbing knowledge as well as for work performance, students will become effective communicators, critical and dynamic thinkers, competent problem solvers and career experts. By utilizing innovative pedagogy to support teaching and learning goals, students will be more likely to achieve their full potential and have their voices heard. The paper focuses on critical thinking for undergraduate ESP engineering students. Those students need strong critical thinking skills which are essential to get to the root of problems and find reasonable solutions. A model of critical thinking is designed to help those students to develop their thinking skills and prepare for a global, complex society.}
}
@article{LI2021104,
title = {Shifting the focus away from binary thinking of statistical significance and towards education for key stakeholders: revisiting the debate on whether it's time to de-emphasize or get rid of statistical significance},
journal = {Journal of Clinical Epidemiology},
volume = {137},
pages = {104-112},
year = {2021},
issn = {0895-4356},
doi = {https://doi.org/10.1016/j.jclinepi.2021.03.033},
url = {https://www.sciencedirect.com/science/article/pii/S0895435621001153},
author = {Guowei Li and Stephen D Walter and Lehana Thabane},
keywords = {-value, Statistical significance, Hypothesis testing, Critical thinking, Education, Reporting},
abstract = {There has been a long-standing controversy among scientists regarding the appropriate use of P-values and statistical significance in clinical research. This debate has resurfaced through recent calls to modify the threshold of P-value required to declare significance, or to retire statistical significance entirely. In this article, we revisit the issue by discussing: i) the connection between statistical thinking and evidence-based practice; ii) some history of statistical significance and P-values; iii) some practical challenges with statistical significance or P-value thresholds in clinical research; iv) the on-going debate on what to do with statistical significance; v) suggestions to shift the focus away from binary thinking of statistical significance and towards education for key stakeholders on research essentials including statistical thinking, critical thinking, good reporting, basic clinical research concepts and methods, and more. We then conclude with remarks and illustrations of the potential deleterious public health consequences of poor methods including selective choice of analysis approach and misguided reliance on binary use of P-values to report and interpret scientific findings.}
}
@article{ORTOLEVA2013903,
title = {The price of flexibility: Towards a theory of Thinking Aversion},
journal = {Journal of Economic Theory},
volume = {148},
number = {3},
pages = {903-934},
year = {2013},
issn = {0022-0531},
doi = {https://doi.org/10.1016/j.jet.2012.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S002205311300032X},
author = {Pietro Ortoleva},
keywords = {Cost of thinking, Contemplation cost, Bounded rationality, Preference over menus, Preference for flexibility, Choice overload},
abstract = {We study the behavior of an agent who dislikes large choice sets because of the ‘cost of thinking’ involved in choosing from them. Focusing on preferences over lotteries of menus, we introduce the notion of Thinking Aversion. We characterize preferences as the difference between an affine evaluation of the content of the menu and a function that assigns to each menu a thinking cost. We provide conditions for which this cost can be seen as the cost that the agent has to sustain to figure out her preferences in order to make a choice.}
}
@article{BASARAN2012862,
title = {An Exploration of Affective and Demographic Factors Regarding Mathematical Thinking and Reasoning of University Students},
journal = {Procedia - Social and Behavioral Sciences},
volume = {47},
pages = {862-867},
year = {2012},
note = {Cyprus International Conference on Educational Research (CY-ICER-2012)North Cyprus, US08-10 February, 2012},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2012.06.748},
url = {https://www.sciencedirect.com/science/article/pii/S1877042812024846},
author = {Seren Basaran and Giray Berberoglu},
keywords = {Affective, Analysis of Variance (ANOVA), Demographic, Mathematical Thinking and Reasoning, Multivariate Analysis of Variance (MANOVA)},
abstract = {The purpose of this study is two-fold: It aims to determine the factors that are influential in undergraduate students’ approaches to studying, self-efficacy, problem solving strategies, competency in mathematical thinking and reasoning; to identify any gender, grade level, and regional differences among the identified factors and on the overall competency in mathematical thinking and reasoning of undergraduate students and prospective teachers. The factors were identified through the adopted survey of approaches to studying and the competency test on mathematical thinking nd reasoning that was designed by the researcher. The scales were administered to 431 undergraduate students of mathematics, elementary and secondary mathematics education in Ankara and in Northern Cyprus and to prospective teachers of classroom teacher education and early childhood education of teacher training academy in Northern Cyprus. Exploratory and confirmatory factor analyses were employed to determine the factors and the differences with respect to gender, region and grade level separately and their dual, triple interaction effects were investigated through two two-way MANOVA and a three-way ANOVA analyses. Results showed that significant gender, grade level differences across identified dimensions of the survey and region, gender and grade level differences across the dimensions of the test and on the total test.}
}
@article{MIR20241,
title = {Orchestration of Genetic Alterations in PSEN1 and PSEN2 Genes in Development of Alzheimer's Disease through Computational Analysis},
journal = {Global Medical Genetics},
volume = {11},
number = {1},
pages = {1-12},
year = {2024},
issn = {2699-9404},
doi = {https://doi.org/10.1055/s-0043-1777849},
url = {https://www.sciencedirect.com/science/article/pii/S2699940425000128},
author = {Asif Mir and Zainab Kamran and Wajid Iqbal},
keywords = {► dementia, ►  and , ► mutational analysis, ► docking, ► phylogenetic history},
abstract = {Dementia is a syndrome that can cause a number of progressive illnesses that affect memory, thinking, and ability to perform everyday tasks. Alzheimer's disease (AD) is the most common cause of dementia and represents a major public health problem. AD is a progressive disease, where in early stages there is mild memory loss and in late-stage patient loses the ability to carry on a conversation. AD (for which there is no exact cause and cure known so far) is the sixth leading cause of deaths in the United States. Every 68 second someone develops AD. This study focuses on protein structure modeling of genes presenilin 1 and 2 (PSEN1 and PSEN2) and their mutated forms (Asn141Tyr found in Chinese family, Gly34Ser identified in a Japanese patient, and Arg62Cys & Val214Leu identified in the Korean patients). It also involves wild and mutant type comparison, protein interaction studies, docking and phylogenetic history based on representative ortholog species and also sheds insight into the comparative evolutionary rates of coding sequence across various orthologs. This study gives a time and cost-effective analysis of genes (PSEN1 and PSEN2) underlying AD and genetic alterations that drive development and causes of disease.}
}
@article{YIN2010167,
title = {A pipe route design methodology by imitating human imaginal thinking},
journal = {CIRP Annals},
volume = {59},
number = {1},
pages = {167-170},
year = {2010},
issn = {0007-8506},
doi = {https://doi.org/10.1016/j.cirp.2010.03.096},
url = {https://www.sciencedirect.com/science/article/pii/S0007850610000971},
author = {Y.H. Yin and C. Zhou and J.Y. Zhu},
keywords = {Design methodology, Artificial intelligence, Human imaginal thinking},
abstract = {Pipe system design like aero-engine, not only a typical NP-hard problem in limited 3D space, must also extraordinarily depend on human experience. This paper presents a methodology for designing compact pipe systems by fully imitating human's imaginal thinking based on image. The feasible workspace is represented as images of the holistic layout of pipes on the basis of human experience. The improved visible graph imitating human pipe-routing behaviour is conducted to form possible edge sequence tree. Moreover, the global optimal pipe path is generated from the tree. The simulation demonstrated the effectiveness of the pipe route design methodology.}
}
@article{SINANERZURUMLU20156,
title = {Sustainable mining development with community using design thinking and multi-criteria decision analysis},
journal = {Resources Policy},
volume = {46},
pages = {6-14},
year = {2015},
note = {Application of multi-criteria decision making/operations research techniques for sustainable management in mining and minerals},
issn = {0301-4207},
doi = {https://doi.org/10.1016/j.resourpol.2014.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0301420714000683},
author = {S. {Sinan Erzurumlu} and Yaman O. Erzurumlu},
keywords = {Design thinking, Decision analysis, Sustainability, Sustainable development, Small scale mining},
abstract = {The economic and social outcomes of mining development can be enhanced by positioning local communities central to development activities. Conventional approaches have failed to respond to the needs of the community without this involvement in decision making. Accordingly, novel development approaches for community involvement and sustainability have to recognize the complex nature of social systems in which mining sector exists. The objective of this paper is to develop a community-centered approach by integrating rapid and participatory nature of design thinking with multi-criteria decision analysis (MCDA) in order to support sustainable development. While design thinking engages multiple stakeholders for generating alternatives, MCDA provides metrics for assessing these alternatives. Drawing on an example from a small scale mining development in Central America, this paper shows that early community involvement and rigorous impact assessment on a regular basis motivate community involvement and give value to the social outcome of mining development.}
}
@incollection{TSATSE20233501,
title = {Teaching strategies for the effective use of computational tools within the Chemical Engineering curriculum},
editor = {Antonios C. Kokossis and Michael C. Georgiadis and Efstratios Pistikopoulos},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {52},
pages = {3501-3506},
year = {2023},
booktitle = {33rd European Symposium on Computer Aided Process Engineering},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-443-15274-0.50559-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044315274050559X},
author = {A. Tsatse and E. Sorensen},
keywords = {Chemical Engineering, Process Systems Engineering, problem-based learning, computational tools},
abstract = {This work discusses the rationale behind, and strategies followed, when delivering chemical engineering modules which have a significant requirement of computational work, and how to coordinate this delivery across an entire curriculum. It will be shown how the complicated aspects of PSE-related subjects can be considered and introduced to students through several modules spread across UCL Chemical Engineering Year 2 programme, and how student learning is supported, whilst providing them with the best opportunity for applying their new computational knowledge and skills and for innovation. It will also be discussed how this procedure prepares students for their capstone design project in Year 3, indicating that this approach has several benefits, including but not limited to, students’ understanding of PSE tools and the development of their critical engineering thinking.}
}
@article{ANDERSEN20191,
title = {Empowering educators by developing professional practice in digital fabrication and design thinking},
journal = {International Journal of Child-Computer Interaction},
volume = {21},
pages = {1-16},
year = {2019},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2019.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S2212868918301223},
author = {Hanne Voldborg Andersen and Kati Pitkänen},
keywords = {Digital fabrication, Design thinking, Education, Teachers, Principals, Professional development},
abstract = {The world is becoming increasingly automated, and the ability to deal with technologies is seen as important in society and working life. Digital fabrication (DF) and design thinking (DT) have been suggested as approaches to developing students’ understanding of technology and their agency in a digitised world. However, nowadays teachers are not being trained in this field. In order to prepare the next generation for a rapidly changing and unknown future heavily influenced by computing it thus seems necessary to focus on the professional development (PD) of teachers. This study investigates how development of professional practice can be conducted to empower teachers and principals to implement DF and DT activities in schools. Initially, the paper gives an overview of nine educational initiatives in the field, followed by a closer examination of the Danish FabLab@SCHOOLdk organisation. The paper identifies the different PD programmes aimed at empowering in-service teachers, pedagogues, and principals in the field of DF and DT. As the main contribution to the research community, the study identifies five important stakeholders that are supporting and operating in synergy inside the FabLab@SCHOOLdk initiative as well as the surrounding gatekeepers with influence on the development processes. The paper further illustrates how the stakeholders operate in the organisation to enable educators to apply DF and DT in schools and discusses the development of professional practice in this field. Finally, a 1:1:1 -model for realising research-based suggestions in PD programmes is presented.}
}
@article{ZETSCHE201856,
title = {Shedding light on the association between repetitive negative thinking and deficits in cognitive control – A meta-analysis},
journal = {Clinical Psychology Review},
volume = {63},
pages = {56-65},
year = {2018},
issn = {0272-7358},
doi = {https://doi.org/10.1016/j.cpr.2018.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S0272735817305421},
author = {Ulrike Zetsche and Paul-Christian Bürkner and Lars Schulze},
keywords = {Repetitive negative thinking, Rumination, Worry, Cognitive control, Inhibition, Discarding},
abstract = {Individuals who experience recurrent negative thoughts are at elevated risk for mood and anxiety disorders. It is thus essential to understand why some individuals get stuck in recurrent negative thinking (RNT), whereas others are able to disengage eventually. Theoretical models propose that individuals high in recurrent negative thinking suffer from deficits in controlling the contents of working memory. Empirical findings, however, are inconclusive. In this meta-analysis, we synthesize findings from 94 studies to examine the proposed association between RNT and deficits in cognitive control. We included numerous effect sizes not reported in the primary publications. Moderator analyses tested the influence of variables, such as stimuli valence, cognitive control function (e.g., shifting, discarding), or type of RNT (i.e., rumination or worry). Results demonstrated an association between repetitive negative thinking and deficits in only one specific cognitive control function, namely difficulty discarding no longer relevant material from working memory (r = −0.20). This association remained significant after controlling for level of psychopathology. There was no substantial association between RNT and deficits in any other cognitive control function. All other moderators were not significant. We discuss limitations (e.g., primary sample sizes, reliability of paradigms) and highlight implications for future research and clinical interventions.}
}
@article{BARR2015473,
title = {The brain in your pocket: Evidence that Smartphones are used to supplant thinking},
journal = {Computers in Human Behavior},
volume = {48},
pages = {473-480},
year = {2015},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2015.02.029},
url = {https://www.sciencedirect.com/science/article/pii/S0747563215001272},
author = {Nathaniel Barr and Gordon Pennycook and Jennifer A. Stolz and Jonathan A. Fugelsang},
keywords = {Smartphone use, Internet use, Cognitive miserliness, Dual-process theories, Extended mind, Situated cognition},
abstract = {With the advent of Smartphone technology, access to the internet and its associated knowledge base is at one’s fingertips. What consequences does this have for human cognition? We frame Smartphone use as an instantiation of the extended mind—the notion that our cognition goes beyond our brains—and in so doing, characterize a modern form of cognitive miserliness. Specifically, that people typically forego effortful analytic thinking in lieu of fast and easy intuition suggests that individuals may allow their Smartphones to do their thinking for them. Our account predicts that individuals who are relatively less willing and/or able to engage effortful reasoning processes may compensate by relying on the internet through their Smartphones. Across three studies, we find that those who think more intuitively and less analytically when given reasoning problems were more likely to rely on their Smartphones (i.e., extended mind) for information in their everyday lives. There was no such association with the amount of time using the Smartphone for social media and entertainment purposes, nor did boredom proneness qualify any of our results. These findings demonstrate that people may offload thinking to technology, which in turn demands that psychological science understand the meshing of mind and media to adequately characterize human experience and cognition in the modern era.}
}
@article{ORCIK2014830,
title = {Thinking Styles and Product Development Project Types: How to Match Them?},
journal = {Procedia Engineering},
volume = {69},
pages = {830-837},
year = {2014},
note = {24th DAAAM International Symposium on Intelligent Manufacturing and Automation, 2013},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2014.03.060},
url = {https://www.sciencedirect.com/science/article/pii/S1877705814003063},
author = {Anja Orcik and Petar Vrgovic and Zeljko Tekic},
keywords = {Thinking styles, Brain Dominance Instrument, Product development projects, Problem solving},
abstract = {Focusing on the characteristics of different thinking styles and different product development project types, we suggest that people should adapt their thinking strategies according to the challenge they face and choose a thinking style that is a best match for the type of project they are working on. Even though people can perform well in more than one thinking style, they can be more successful if they adequately choose the most appropriate one for solving the problem in front of them. Considering that different thinking styles have different ideas and conclusions as results, we propose how to match them to a specific product development project type that has a certain degree of change in the product as a deliverable. For further research, these findings open the possibility to define the most appropriate creative problem solving methods and techniques that spur and support a specific style of thinking.}
}
@article{LEZAK2016143,
title = {Systems thinking and environmental concern},
journal = {Journal of Environmental Psychology},
volume = {46},
pages = {143-153},
year = {2016},
issn = {0272-4944},
doi = {https://doi.org/10.1016/j.jenvp.2016.04.005},
url = {https://www.sciencedirect.com/science/article/pii/S027249441630024X},
author = {Stephen B. Lezak and Paul H. Thibodeau},
keywords = {Systems thinking, Environmental psychology, Climate change, Science communication, Reasoning, Decision-making},
abstract = {Systems thinking is thought to facilitate complex decision-making, but relatively little is known about its psychological underpinning. We present three studies that situate a measure of the construct in relation to other dispositional measures that have received more attention in environmental psychology and by testing whether the mindset predicts behavior in a set of novel decision making tasks. In Study 1, we find that systems thinkers tend to believe in scientific consensus, recognize risks posed by climate change, and support policy interventions to address climate change; systems thinking was negatively related to conspiracist and free-market ideation. In Studies 2 and 3 we find that systems thinkers ascribe more value to the natural world — both in monetary terms as well as on social and ecological grounds. The findings suggest that models of environmental cognition can be improved by measuring peoples' tendency to engage in systems thinking.}
}
@article{BUCARO201935,
title = {Enhancing auditors' critical thinking in audits of complex estimates},
journal = {Accounting, Organizations and Society},
volume = {73},
pages = {35-49},
year = {2019},
issn = {0361-3682},
doi = {https://doi.org/10.1016/j.aos.2018.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0361368218303246},
author = {Anthony C. Bucaro},
keywords = {Systems-thinking, Reductionist-thinking, Complex estimates, Auditor judgment, Professional judgment, Critical thinking},
abstract = {Audit practitioners, standards, and regulators continually emphasize the importance of professional judgment in the audit of complex processes and financial estimates. Despite this increasing call for more thoughtful analysis, research and inspection reports seem to suggest that auditors tend to make mechanistic audit decisions in such situations. This experiment evaluates auditor participants' improved application of professional judgment in the audit of complex estimates when taught a specific critical thinking methodology from system dynamics. Results indicate that emphasizing the use of professional judgment is not sufficient to decrease auditors' mechanistic mentality. As expected, however, auditors primed to take a systems-thinking perspective are better able to evaluate the complexity of the situation and to more effectively apply professional judgment. These results suggest that the goal of improving professional judgment can be achieved with an underlying change to the way auditors think.}
}
@article{EISENBERG20171,
title = {Machines and minds: The new cognitive science, and the potential evolution of children’s intuitions about thinking},
journal = {International Journal of Child-Computer Interaction},
volume = {14},
pages = {1-4},
year = {2017},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2017.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S2212868917300041},
author = {Michael Eisenberg and Sherry Hsi and HyunJoo Oh}
}
@article{HASS2017344,
title = {Semantic search during divergent thinking},
journal = {Cognition},
volume = {166},
pages = {344-357},
year = {2017},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2017.05.039},
url = {https://www.sciencedirect.com/science/article/pii/S0010027717301622},
author = {Richard W. Hass},
keywords = {Divergent thinking, Creativity, Memory search, Memory foraging, Semantic memory},
abstract = {Divergent thinking, as a method of examining creative cognition, has not been adequately analyzed in the context of modern cognitive theories. This article casts divergent thinking responding in the context of theories of memory search. First, it was argued that divergent thinking tasks are similar to semantic fluency tasks, but are more constrained, and less well structured. Next, response time distributions from 54 participants were analyzed for temporal and semantic clustering. Participants responded to two prompts from the alternative uses test: uses for a brick and uses for a bottle, for two minutes each. Participants’ cumulative response curves were negatively accelerating, in line with theories of search of associative memory. However, results of analyses of semantic and temporal clustering suggested that clustering is less evident in alternative uses responding compared to semantic fluency tasks. This suggests either that divergent thinking responding does not involve an exhaustive search through a clustered memory trace, but rather that the process is more exploratory, yielding fewer overall responses that tend to drift away from close associates of the divergent thinking prompt.}
}
@article{SHUKLA2021100415,
title = {Leveraging Blockchain Technology for Indian Healthcare system: An assessment using value-focused thinking approach},
journal = {The Journal of High Technology Management Research},
volume = {32},
number = {2},
pages = {100415},
year = {2021},
issn = {1047-8310},
doi = {https://doi.org/10.1016/j.hitech.2021.100415},
url = {https://www.sciencedirect.com/science/article/pii/S1047831021000158},
author = {Rashmi G. Shukla and Anuja Agarwal and Vidhu Shekhar},
keywords = {Blockchain Technology, Value-focused thinking, Indian Healthcare system, Stakeholder perspectives, Strategic planning, Assessment},
abstract = {Indian Healthcare system is a complex and distinguished structure due to variety of factors viz. population size it serves, presence of organized and unorganized services of healthcare, economic disparity and governance structure among others. Extant research emphasizes on the aspects like transparency, trust, disintermediation, non-repudiation, benchmarking of processes and practices, traceability and data integrity among others to stimulate the Indian Healthcare system for an improvised and more effective format. Blockchain Technology is recent innovation that offers many of these aforementioned aspects as a feature to the host systems. However, it is critical to understand and articulate the utility of Blockchain Technology specific to the Indian Healthcare system. Further, it is important to gauge the requirement elicitation of key stakeholders for Blockchain Technology adoption in Indian Healthcare system w.r.t any attribute prioritization/customization or design considerations (Consensus mechanism, type of blockchain, smart contracts etc.). There have been some research works on aspects of Blockchain applications in Indian Healthcare but lack a strong perspective of stakeholder requirements. We use Value-Focused Thinking framework based on discussions with the stakeholders to address the above mentioned research premise. We identify Fundamental Objectives and Strategic Objectives from the stakeholder interactions that contribute to the strategic goal. This is a niche work with a significant analytical contribution from the information systems perspective of Blockchain Technology adoption in the Indian Healthcare ecosystem given the light of premises from realms of human agents, behavioural and applications requirement from a stakeholder viewpoint.}
}
@article{WOLFENGAGEN2018246,
title = {The Typing System to Provide Compositional Thinking About Data Flows},
journal = {Procedia Computer Science},
volume = {123},
pages = {246-251},
year = {2018},
note = {8th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2017 (Eighth Annual Meeting of the BICA Society), held August 1-6, 2017 in Moscow, Russia},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.01.038},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918300395},
author = {Viacheslav E. Wolfengagen and Larisa Yu. Ismailova and Sergey V. Kosikov},
keywords = {problem domain dynamics, Web tangling, semantic, support data flows, type system, ho-motopy theory},
abstract = {The paper considers the approach to solving the problem of preventing the information system vulnerability that arises due to the insertion and / or performance of a semantically incorrect script (XSS-vulnerability). The solution of this task suggests modelling the information exchange between active objects. Modelling is supposed to be carried out within the framework of the basic applicative computing system, in which the code fragments can be modelled by applicative objects. An important part of the task is to check the correctness of the scenarios composition, which requires the tools make compositional thinking about data flows, both when they are processed by scripts and contain them. The correctness is proposed to be provided by supporting the fairly strong typing system that excludes incorrect combinations of scenarios. The type system is assumed to be immersed into the applicative environment. The system is proposed to be built on the basis of the homotopy type theory, which ensures, in particular, the introduction of independent and dependent types, as well as the definition of recursion and induction principles for them. Partial approbation of typing constructions is performed with the example of the problem of semantic support for the implementation of the best available technologies (BAT).}
}
@article{FISCHER2012303,
title = {Deep thinking increases task-set shielding and reduces shifting flexibility in dual-task performance},
journal = {Cognition},
volume = {123},
number = {2},
pages = {303-307},
year = {2012},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2011.11.015},
url = {https://www.sciencedirect.com/science/article/pii/S0010027712000157},
author = {Rico Fischer and Bernhard Hommel},
keywords = {Cognitive control, PRP, Multi-tasking, Crosstalk, Response-category compatibility, Creativity, Convergent and divergent thinking},
abstract = {Performing two tasks concurrently is difficult, which has been taken to imply the existence of a structural processing bottleneck. Here we sought to assess whether and to what degree one’s multitasking abilities depend on the cognitive-control style one engages in. Participants were primed with creativity tasks that either called for divergent thinking—which were suspected to induce a holistic, flexible task processing mode, or convergent thinking—which were assumed to induce a systematic, focused processing mode. Participants showed reduced cross-talk between tasks and increased task-component switching costs (dual-task costs) for the convergent-thinking group compared to both, a divergent-thinking group and a neutral control group. The results suggest that the cognitive-control style people engage in prior to the task predicts their multitasking performance.}
}
@article{OKEEFE202195,
title = {Thinking beyond boundaries: A growth theory of interest enhances integrative thinking that bridges the arts and sciences},
journal = {Organizational Behavior and Human Decision Processes},
volume = {162},
pages = {95-108},
year = {2021},
issn = {0749-5978},
doi = {https://doi.org/10.1016/j.obhdp.2020.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S0749597820303939},
author = {Paul A. O'Keefe and E.J. Horberg and Anandita Sabherwal and Gabrielle C. Ibasco and Adlin {Binti Zainal}},
keywords = {Attention, Implicit theories, Innovation, Integrative thinking, Interest, Mindsets},
abstract = {Innovations often arise when people bridge seemingly disparate areas of knowledge, such as the arts and sciences. What leads people to make connections that others might miss? We examined the role of implicit theories of interest—the belief that interests are relatively fixed (a fixed theory of interest) or developed (a growth theory of interest) among people with established interests either in the area of arts or sciences. A stronger growth theory predicted that participants spontaneously noticed more stimuli from the area outside their interests (Studies 2 and 3) and generated better integrative ideas (Study 1). Furthermore, they were more likely to generate ideas that bridged the arts and sciences (Study 2), which was also found after inducing fixed or growth theories, establishing causality (Study 3). Finally,perceived utility of the outside area mediated this relation (Study 4). These results suggest that a growth theory may be important for integrative thinking and innovation across traditional disciplinary boundaries.}
}
@article{FANG2025105264,
title = {Understanding the gender divide in digital literacy in four European countries: A comprehensive decomposition analysis using unconditional quantile regression},
journal = {Computers & Education},
volume = {229},
pages = {105264},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105264},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525000326},
author = {Guangbao Fang and Jiaxin Wang and Philip Wing Keung Chan and Penelope Kalogeropoulos},
keywords = {Gender divide, Computer and information literacy, Computational thinking, Oaxaca-Blinder decomposition, Unconditional quantile regression decomposition},
abstract = {Digital literacy is crucial for adolescents’ future, yet significant gender divides persist, particularly in Computer and Information Literacy (CIL) and Computational Thinking (CT). This study examines the gender divide in CIL and CT among adolescents in four European countries, highlighting the gender-based disparities in digital literacy development. Based on ICILS 2018 data, this research identifies factors contributing to gender divides in CIL and CT using regression and decomposition methods. Findings indicate that females outperform males in CIL, while males excel in CT. Gender divides decrease as the percentiles of students’ proficiency levels increase. The explained portion of the gender divide in CIL and CT is consistently smaller than the unexplained portion across countries, suggesting that gender divide or unobserved factors may drive these divides. A comparison of OLS regression results with decomposition approaches indicates that the factors influencing digital literacy development differ from those contributing to the gender divide. Variation in the factors contributing to gender divides is greater across countries than within countries for both CIL and CT. These findings highlight the need to consider national digital environments and socio-cultural contexts in addressing gender divides in digital literacy. This study offers insights for policymakers and educators to address the gender divide in digital literacy.}
}
@article{BARTOLONI2022102413,
title = {Towards designing society 5.0 solutions: The new Quintuple Helix - Design Thinking approach to technology},
journal = {Technovation},
volume = {113},
pages = {102413},
year = {2022},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2021.102413},
url = {https://www.sciencedirect.com/science/article/pii/S0166497221001942},
author = {Sara Bartoloni and Ernesto Calò and Luca Marinelli and Federica Pascucci and Luca Dezi and Elias Carayannis and Gian Marco Revel and Gian Luca Gregori},
keywords = {Society 5.0, Industry 4.0, Quintuple helix innovation ecosystem, Design thinking, Healthcare, Social entrepreneurship},
abstract = {The integration of Industry 4.0 (I4.0) technologies within society is pivotal for resolving many challenges that the world and its population are facing presently—global pandemics, ageing populations, and climate change. However, academics and practitioners still struggle to fully understand I4.0 outcomes outside of the manufacturing domain, thereby unravelling their potential for society at large. In this scenario, Society 5.0 (S5.0) is arising as a new paradigm that places humans at the centre of innovation. To foster the effective integration of technology into society and to better understand how to design S5.0 configurations and solutions, the authors developed a conceptual model applying the Design Thinking (DT) approach to the Quintuple Helix (QH) innovation framework. The proposed QH–DT model was found to be suitable for allowing the knowledge flow among the actors involved in the design and implementation of the S5.0 solution. The model was then explained through its application in a healthcare project—the SMARTAGE. By adopting an action research methodology, the results explain how it becomes possible to build complex human-centric healthcare solutions.}
}
@article{OXMAN200463,
title = {Think-maps: teaching design thinking in design education},
journal = {Design Studies},
volume = {25},
number = {1},
pages = {63-91},
year = {2004},
issn = {0142-694X},
doi = {https://doi.org/10.1016/S0142-694X(03)00033-4},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X03000334},
author = {Rivka Oxman},
keywords = {design cognition, computational models, design education, design teaching, design knowledge},
abstract = {A pedagogical framework for design learning and design teaching termed Think-Maps is introduced, presented and demonstrated. In this framework, domain knowledge becomes explicit as a significant component to be taught and transferred in design education. The Think-Maps framework proposes that by constructing a conceptual map that reflects one’s thinking in a domain, we make explicit the knowledge learned. The learner constructs structured representations of concepts and their relationships to other concepts and fills these structures with the content of the specific design domain or design task. This resulting structured representation of knowledge can later be accessed and expanded in additional processes of design thinking. Web-Pad — a computational tool that implements these ideas is presented and illustrated. Web-Pad is used for organizing and representing conceptual maps of a specific domain. The Think-Maps framework and the Web-Pad tool are demonstrated in an educational environment.}
}
@article{KUDELIC2024102454,
title = {On the theory of quantum and towards practical computation: A review},
journal = {Journal of Computational Science},
volume = {83},
pages = {102454},
year = {2024},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2024.102454},
url = {https://www.sciencedirect.com/science/article/pii/S1877750324002473},
author = {Robert Kudelić},
keywords = {Quantum computation, Fundamentals, Review, History, Open questions, Quantum phenomena, Technology, Algorithm design pattern, Application},
abstract = {Quantum computing exposes the brilliance of quantum mechanics through computer science (in theory and otherwise), giving oneself a marvelous and exhilarating journey to go through. This review article leads along that journey with a historical and current outlook on quantum computation that is geared toward computer experts (via algorithmics) but also to experts from other disciplines as well. It is an article that will open an entering wedge through which one will be able to bring himself up to speed on quantum computation and challenges/limitations thereof. We are indeed in luck to be living in an age where computing is being reinvented, and not only seeing history in the making firsthand but, in fact, having the opportunity to be the ones who are reinventing—and that is quite a thought.}
}
@article{KIM2017134,
title = {Workshop design for enhancing the appropriateness of idea generation using analogical thinking},
journal = {International Journal of Innovation Studies},
volume = {1},
number = {2},
pages = {134-143},
year = {2017},
issn = {2096-2487},
doi = {https://doi.org/10.1016/j.ijis.2017.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S2096248717300024},
author = {Eunyoung Kim},
keywords = {Analogical thinking, Appropriateness in ideas generated, Trial and error, Categorization, Deliberation},
abstract = {As technologies advance and replace human labor in a variety of settings, we focus our attention on human creativity for generating new ideas. Business organizations, more than ever, recognize that they need employees who think creatively to maintain their competitive edge. Nonetheless, there is a lack of research assessing new ideas and influential factors in generating innovative ideas. The aim of this study is to identify the factors that influence the creation of innovative ideas. We conducted two different types of workshops with 22 subjects and 23 subjects each. In the first workshop, subjects were asked to generate new business ideas through analogical thinking. As a result, half of the participants generated appropriate ideas, and three influential factors were determined: categorization skill, deliberation, and trial and error. The second workshop was designed to facilitate participants to enhance these three factors. As a result, 70% of the participants could generate appropriate ideas. By identifying influential factors, this paper suggests a procedure for designing an innovation workshop that enables the creation of appropriate ideas.}
}
@article{KEREN2014400,
title = {Kindergarten Social Assistive Robot (KindSAR) for children’s geometric thinking and metacognitive development in preschool education: A pilot study},
journal = {Computers in Human Behavior},
volume = {35},
pages = {400-412},
year = {2014},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2014.03.009},
url = {https://www.sciencedirect.com/science/article/pii/S0747563214001319},
author = {Guy Keren and Marina Fridin},
keywords = {Architecture for educational technology system, Elementary education, Intelligent tutoring systems, Interactive learning environments, Interdisciplinary projects},
abstract = {Kindergarten Social Assistive Robot (KindSAR) is an innovative tool promotes children’s development through social interaction. This pilot study demonstrates how KindSAR can assist educational staff in the teaching of geometric thinking and in promoting the metacognitive development by engaging children in interactive play activities. Children’s reactions and performances were video recorded for analysis. Most children exhibited positive interaction with the robot and a high level of enjoyment. Our results showed that their performances on geometric thinking and metacognitive tasks were improved while they “played” with the robot. To measure children’s learning we have developed a novel measure of cognitive learning, which we call “velocity of learning”. This study demonstrates the feasibility and expected benefits of incorporating KindSAR in preschool education.}
}
@article{REN2020101487,
title = {Critical thinking predicts academic performance beyond general cognitive ability: Evidence from adults and children},
journal = {Intelligence},
volume = {82},
pages = {101487},
year = {2020},
issn = {0160-2896},
doi = {https://doi.org/10.1016/j.intell.2020.101487},
url = {https://www.sciencedirect.com/science/article/pii/S0160289620300659},
author = {Xuezhu Ren and Yan Tong and Peng Peng and Tengfei Wang},
keywords = {Critical thinking skill, Critical thinking disposition, Academic performance, General cognitive ability},
abstract = {The present research investigated whether critical thinking predicts academic performance above and beyond general cognitive ability. Both critical thinking (CT) skills and dispositions were investigated in order to obtain a complete picture of CT and its relations to academic performance and general cognitive ability including fluid intelligence, working memory and processing speed. Measures of these variables were administrated to both university young adults (N = 232, study 1, a self-report scale was used for assessing academic performance) and primary school children (N = 158, study 2). Both studies showed that CT indicated by skills and dispositions made unique contributions to academic performance even when general cognitive ability was controlled for. Further, it was mainly CT dispositions that uniquely contributed to academic performance while the contribution of CT skills to academic performance largely overlapped with general cognitive ability. Our findings provide a first step toward understanding CT as a distinct construct from general cognitive ability in relation to learning and academic performance.}
}
@article{CHEN2015441,
title = {Individual differences in verbal creative thinking are reflected in the precuneus},
journal = {Neuropsychologia},
volume = {75},
pages = {441-449},
year = {2015},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2015.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S0028393215300865},
author = {Qun-Lin Chen and Ting Xu and Wen-Jing Yang and Ya-Dan Li and Jiang-Zhou Sun and Kang-Cheng Wang and Roger E. Beaty and Qing-Lin Zhang and Xi-Nian Zuo and Jiang Qiu},
keywords = {Verbal creativity, Local functional homogeneity, Cortical morphology, Precuneus},
abstract = {There have been many structural and functional imaging studies of creative thinking, but combining structural and functional magnetic resonance imaging (MRI) investigations with respect to creative thinking is still lacking. Thus, the aim of the present study was to explore the associations among inter-individual verbal creative thinking and both regional homogeneity and cortical morphology of the brain surface. We related the local functional homogeneity of spontaneous brain activity to verbal creative thinking and its dimensions—fluency, originality, and flexibility—by examining these inter-individual differences in a large sample of 268 healthy college students. Results revealed that people with high verbal creative ability and high scores for the three dimensions of creativity exhibited lower regional functional homogeneity in the right precuneus. Both cortical volume and thickness of the right precuneus were positively associated with individual verbal creativity and its dimensions. Moreover, originality was negatively correlated with functional homogeneity in the left superior frontal gyrus and positively correlated with functional homogeneity in the right occipito-temporal gyrus. In contrast, flexibility was positively correlated with functional homogeneity in the left superior and middle occipital gyrus. These findings provide additional evidence of a link between verbal creative thinking and brain structure in the right precuneus—a region involved in internally-focused attention and effective semantic retrieval—and further suggest that local functional homogeneity of verbal creative thinking has neurobiological relevance that is likely based on anatomical substrates.}
}
@incollection{PIERREROBERTSON2025695,
title = {Literacies},
editor = {David Baker and Lucy Ellis},
booktitle = {Encyclopedia of Libraries, Librarianship, and Information Science (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {695-702},
year = {2025},
isbn = {978-0-323-95690-1},
doi = {https://doi.org/10.1016/B978-0-323-95689-5.00116-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780323956895001164},
author = {Petronetta Pierre-Robertson},
keywords = {Algorithmic literacy, Artificial intelligence, Computational thinking, Computer literacy, Critical literacy, Digital literacy, Information literacy, Internet literacy, Librarians and literacy, Libraries and literacy, Literacy, Media literacy, New literacies, Technology literacy, Transliteracy.},
abstract = {This entry provides the definition, etymology and history of literacy. It comments on the expansion of literacy in the technological age to embrace new literacies. It then defines ten literacies that can be incorporated under the concept of new literacies. These are information literacy and associated literacies like digital literacy, digital media literacy, internet literacy, technology literacy, computer literacy, computational thinking, critical literacy, algorithmic literacy, and transliteracy. It touches on the importance of new literacies in today’s continuously evolving digital world and gives trends for the future, with specific reference to Artificial Intelligence (AI). The relevance of libraries and librarians concerning each of the literacies is included.}
}
@article{WESSELTOLVIG201639,
title = {Revisiting the thinking-for-speaking hypothesis: Speech and gesture representation of motion in Danish and Italian},
journal = {Journal of Pragmatics},
volume = {99},
pages = {39-61},
year = {2016},
issn = {0378-2166},
doi = {https://doi.org/10.1016/j.pragma.2016.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S0378216616301539},
author = {Bjørn Wessel-Tolvig and Patrizia Paggio},
keywords = {Thinking-for-speaking, Cross-linguistic variation, Conceptualization, Gesture},
abstract = {Many studies try to explain thought processes based on verbal data alone and often take the linguistic variation between languages as evidence for cross-linguistic thought processes during speaking. We argue that looking at co-speech gestures might broaden the scope and shed new light on different thinking-for-speaking patterns. Data comes from a corpus study investigating the relationship between speech and gesture in two typologically different languages: Danish, a satellite-framed language and Italian, a verb-framed language. Results show cross-linguistic variation in how motion components are mapped onto linguistic constituents, but also show how Italian speakers to some degree deviate from standard verb-framed lexicalization patterns, and use typical satellite-framed constructions. Co-speech gestures, when they occur, largely follow the patterns used in speech, with a notable exception: In 28% of the cases, in fact, Italian speakers express manner in path-only speech constructions gesturally. This finding suggests that gestures may be instrumental in revealing what semantic components speakers attend to while speaking; in other words, purely verbal data may not fully account for the thinking part of the thinking-for-speaking hypothesis.}
}
@incollection{TOPLAK2022185,
title = {9 - The emergence of rational thinking in development: Conclusions and future directions},
editor = {Maggie E. Toplak},
booktitle = {Cognitive Sophistication and the Development of Judgment and Decision-Making},
publisher = {Academic Press},
pages = {185-211},
year = {2022},
isbn = {978-0-12-816636-9},
doi = {https://doi.org/10.1016/B978-0-12-816636-9.00004-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128166369000049},
author = {Maggie E. Toplak},
keywords = {Stimulus equivalence, Cognitive sophistication, Rational thinking, Development, Resistance to miserly information processing, Process and knowledge dimensions, Children and youth},
abstract = {Cognitive sophistication concerns whether people who display more complex and sophisticated cognition also tend to give the normative response. Importantly, the issue of stimulus equivalence in developmental samples is much less of a problem in studies that use multiple indicators of cognitive sophistication, not just age differences. These multiple indicators can be used as converging evidence in triangulating developmental trends on rational thinking tasks. Age differences were obtained in childhood and early adolescence in the longitudinal developmental study, but not later in adolescence on all performance-based measures, including cognitive abilities and rational thinking tasks. Resistance to miserly information processing tasks can be used as an additional indicator of cognitive sophistication to correlate with response patterns on rational thinking tasks in developmental samples. Although such tasks do measure other aspects of process and knowledge (cognitive ability and numeracy), they also tap in part the participant’s ability to detect conflicts between normatively correct responses and rapidly emitted Type 1 processing. Task factors, particularly the process and knowledge demands of each rational thinking task, also contribute to explaining developmental patterns on these tasks. Identifying sources of cognitive failures on rational thinking tasks in children and youth can be mapped onto real-world correlates and provide new directions for training of these skills and abilities.}
}
@article{LINDGAARD201783,
title = {Once More, with Feeling: Design Thinking and Embodied Cognition},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {3},
number = {2},
pages = {83-92},
year = {2017},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2017.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S2405872617300291},
author = {Karin Lindgaard and Heico Wesselius},
keywords = {Design thinking, Embodied cognition, Metaphor, Visual thinking, Felt sense},
abstract = {While leaders in business and industry maintain their interest in design thinking, academic discussions of the concept have become less common. This article examines design thinking in relation to developments in cognitive science and embodied cognition. We examine an influential theory of metaphor as central to cognition, along with theoretical nuances of the body, perception, and feeling. We argue that some material design practices may augment the creative process. We propose a broad interdisciplinary account for the role that feeling plays in design and cognition both.}
}
@article{ZHANG2021118762,
title = {The neurobiological basis of divergent thinking: Insight from gene co-expression network-based analysis},
journal = {NeuroImage},
volume = {245},
pages = {118762},
year = {2021},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2021.118762},
url = {https://www.sciencedirect.com/science/article/pii/S105381192101034X},
author = {Shun Zhang and Xiaolei Yang and Si Si and Jinghuan Zhang},
keywords = {Divergent thinking, Creativity, Genetics, GWAS, Gene co-expression network},
abstract = {Although many efforts have been made to explore the genetic basis of divergent thinking (DT), there is still a gap in the understanding of how these findings relate to the neurobiology of DT. In a combined sample of 1,682 Chinese participants, by integrating GWAS with previously identified brain-specific gene co-expression network modules, this study explored for the first time the functional brain-specific gene co-expression networks underlying DT. The results showed that gene co-expression network modules in anterior cingulate cortex, caudate, amygdala and substantia nigra were enriched with DT association signals. Further functional enrichment analysis showed that these DT-related gene co-expression network modules were enriched for key biological process and cellular component related to myelination, suggesting that cortical and sub-cortical grey matter myelination may serve as important neurobiological basis of DT. Although the underlying mechanisms need to be further refined, this exploratory study may provide new insight into the neurobiology of DT.}
}
@article{MENNIES2021102050,
title = {The relationship between executive functioning and repetitive negative thinking in youth: A systematic review of the literature},
journal = {Clinical Psychology Review},
volume = {88},
pages = {102050},
year = {2021},
issn = {0272-7358},
doi = {https://doi.org/10.1016/j.cpr.2021.102050},
url = {https://www.sciencedirect.com/science/article/pii/S0272735821000933},
author = {Rebekah J. Mennies and Lindsey C. Stewart and Thomas M. Olino},
keywords = {Rumination, Worry, Obsessions, Executive functioning, Shifting, Inhibition},
abstract = {Repetitive negative thinking (RNT) and executive functioning (EF) deficits are each characteristic of many forms of youth psychopathology. Extensive work has examined the relationship between rumination, a form of RNT, and EF in adults. However, less is known about the relationship between RNT more broadly and EF in youth, for whom these constructs are developing and emerging. Here, we systematically and qualitatively reviewed 27 studies on the associations between EF (e.g., shifting, inhibition, working memory) and RNT (e.g., rumination, worry, obsessions) in youth. All forms of RNT were more commonly positively associated with questionnaire-reported EF problems in daily life, most frequently in the domain of shifting. Task-based assessments of EF were less consistently associated with RNT in youth, with no strong pattern of presence vs. absence of associations. Further, limited longitudinal work has been conducted on this topic to date. This review integrates initial work with regard to RNT and EF deficits in a still-developing population, and discusses clear future need for longitudinal, multi-method assessments of the relationship between RNT and EF subtypes in youth.}
}
@article{HAMANN2024153975,
title = {Predictive, integrative, and regulatory aspects of AI-driven computational toxicology – Highlights of the German Pharm-Tox Summit (GPTS) 2024},
journal = {Toxicology},
volume = {509},
pages = {153975},
year = {2024},
issn = {0300-483X},
doi = {https://doi.org/10.1016/j.tox.2024.153975},
url = {https://www.sciencedirect.com/science/article/pii/S0300483X24002567},
author = {Ute Haßmann and Sigrid Amann and Nelly Babayan and Simone Fankhauser and Tina Hofmaier and Thomas Jakl and Monika Nendza and Helga Stopper and Sven Marcel Stefan and Robert Landsiedel},
keywords = {German Pharma-Tox Summit (GPTS), Computational Toxicology, Artificial intelligence (AI) In silico methods, Computer-aided pattern analysis, Generic Approach to Risk Management (GRA)},
abstract = {The 9th German Pharm-Tox Summit (GPTS) and the 90th Annual Meeting of the German Society for Experimental and Clinical Pharmacology and Toxicology (DGPT) took place in Munich from March 13–15, 2024. The event brought together over 700 participants from around the world to discuss cutting-edge developments in the fields of pharmacology and toxicology as well as scientific innovations and novel insights. A key focus of the conference was on the rapidly increasing role of computational toxicology, artificial intelligence (AI), and machine learning (ML) into the field, marking a shift away from traditional methods and allowing the reduction of animal testing as primary tool for toxicological risk assessment. Tools such as Toxometris.ai showcased the potential of AI-based risk assessments for predicting carcinogenicity, offering more ethical and efficient alternatives. Additionally, computer-driven models like computer-aided pattern analysis (C@PA) for drug toxicity prediction were presented, emphasizing the growing role of chem- and bioinformatic applications in computational sciences. Throughout the summit, there was a strong focus on the need for regulatory innovation to support the adoption of these advanced technologies and ensure the safety and sustainability of chemical substances and drugs.}
}
@article{YU201917,
title = {A review of computational toys and kits for young children},
journal = {International Journal of Child-Computer Interaction},
volume = {21},
pages = {17-36},
year = {2019},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2019.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S2212868918300825},
author = {Junnan Yu and Ricarose Roque},
keywords = {Coding, Early childhood, Computational thinking},
abstract = {This paper presents a review of computational toys and kits that enable young children (ages 7 years old and under) to explore computational ideas and practices. We collected 30 computational kits, including 13 physical kits, 8 virtual kits, and 9 hybrid kits, and performed a qualitative analysis of these kits. We examined the kits across four different perspectives: how they are designed, how they support children to explore computational concepts and practices, how they enable children to engage in a range of projects and activities, and how they enable children to explore other domains of knowledge. Based on the analysis, we present design suggestions and opportunities to expand the possibilities in what computational ideas and other domains of knowledge children can explore, how children can engage in computing, and what kinds of projects children can make. While many kits enable the exploration of some computational concepts and practices, we see opportunities to expand how these concepts can be supported, as well as the new concepts and domains children could explore. We also see possibilities to include new modes of expression such as body motion or new media such as light and sound. Finally, we see possibilities for whom designers can better support, such as more explicit roles for adult caregivers and expanding possibilities for children from underrepresented groups in computing. This qualitative study reveals the commonalities across existing kits and highlights ways for designers and researchers to expand the possibilities for children to create, explore, and play with computing.}
}
@article{WAKABAYASHI2011304,
title = {Spatial thinking in geographic information science: a review of past studies and prospects for the future},
journal = {Procedia - Social and Behavioral Sciences},
volume = {21},
pages = {304-313},
year = {2011},
note = {International Conference: Spatial Thinking and Geographic Information Sciences 2011},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2011.07.031},
url = {https://www.sciencedirect.com/science/article/pii/S1877042811013541},
author = {Yoshiki Wakabayashi and Toru Ishikawa},
keywords = {geographic information science, spatial thinking, spatial concepts, spatial representations, spatial reasoning},
abstract = {In recent years, the relationship between geographic information science (GIScience) and spatial thinking has attracted much attention in English-speaking countries. Nevertheless, vagueness remains concerning the concept of spatial thinking and its components. The aim of this paper is to review previous studies on the relationship between GIScience and spatial thinking, and to clarify the elements of spatial thinking and related terms. After discussing the basic elements of spatial thinking, it explores the relationship between GIScience and spatial thinking by dividing it into two aspects: the role of geographic information systems (GIS) in education on spatial thinking, and the role of spatial thinking in GIScience. Concerning the former, potential roles of GIS in spatial thinking education, particularly in geography and STEM disciplines, are suggested. Concerning the latter, the relationships between the body of knowledge on GIS education and the elements of spatial thinking are examined. Finally, the present situation and future prospects for studies on spatial thinking and GIScience in Japan are briefly discussed.}
}
@article{JIN2024104114,
title = {DVRT: Design and evaluation of a virtual reality drone programming teaching system},
journal = {Computers & Graphics},
volume = {125},
pages = {104114},
year = {2024},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2024.104114},
url = {https://www.sciencedirect.com/science/article/pii/S0097849324002498},
author = {Zean Jin and Yulong Bai and Wei Song and Qinghe Yu and Xiaoxin Yue and Xiang Jia},
keywords = {Virtual reality, STEM, Graphical programming, Drones},
abstract = {Virtual Reality (VR) is an immersive virtual environment generated through computer technology. VR teaching, by utilizing an immersive learning model, offers innovative learning methods for Science, Technology, Engineering and Mathematics (STEM) education as well as programming education. This study developed a Drone Virtual Reality Teaching (DVRT) system aimed at beginners in drone operation and programming, with the goal of addressing the challenges in traditional drone and programming education, such as difficulty in engaging students and lack of practicality. Through the system's curriculum, students learn basic drone operation skills and advanced programming techniques. We conducted a course experiment primarily targeting undergraduate students who are beginners in drone operation. The test results showed that most students achieved scores above 4 out of 5, indicating that DVRT can effectively promote the development of users' comprehensive STEM literacy and computational thinking, thereby demonstrating the great potential of VR technology in STEM education. Through this innovative teaching method, students not only gain knowledge but also enjoy the fun of immersive learning.}
}
@article{MALONEY2020102939,
title = {Higher math anxious people have a lower need for cognition and are less reflective in their thinking},
journal = {Acta Psychologica},
volume = {202},
pages = {102939},
year = {2020},
issn = {0001-6918},
doi = {https://doi.org/10.1016/j.actpsy.2019.102939},
url = {https://www.sciencedirect.com/science/article/pii/S0001691819302793},
author = {Erin A. Maloney and Fraulein Retanal},
keywords = {Math anxiety, Cognitive reflection test, Need for cognition},
abstract = {There exists a large body of literature seeking to understand the relation between math anxiety and success in mathematics. While most of this literature focuses on domain specific relations (i.e., how math anxiety impacts thinking about mathematics), in the current work we examine important relations between math anxiety and domain general factors. Specifically, we test three hypotheses: (1) that higher-math-anxious individuals have a lower need for and enjoyment of exerting cognitive effort, (2) that math anxiety mediates a relation between ones’ propensity for cognitive effort and their achievement in mathematics, and (3) that higher-math-anxious individuals are less reflective in their thinking, and that this is not limited to questions that are heavily reliant on mathematical reasoning. As predicted, we uncovered relations between math anxiety and the domain-general constructs of need for cognition and cognitive reflection. Importantly, these negative relations hold even after controlling for math ability, general anxiety, and gender of the participant. The results are discussed in terms of implications for our understanding of the construct of math anxiety. Proficiency in mathematics is a major advantage in industrialised nations. Unfortunately, many people experience math-anxiety (Richardson & Suinn, 1972), becoming nervous when engaging in math tasks and avoiding math and math-related professions. As a result, those with math anxiety tend to severely limit their future career and earning opportunities (Chipman, Krantz, & Silver, 1992; Hembree, 1990). The resulting shortage of adults prepared to work in the sciences, technology, engineering, and mathematics field (STEM) has negative consequences at the national level, particularity as societies become increasingly dependent upon technology (Beilock & Maloney, 2015; Chipman et al., 1992; Maloney & Beilock, 2012). Worldwide, increased math-anxiety is linked to decreased math achievement (Foley et al., 2017; Lee, 2009), and this is not limited to academic situations. Math-anxious nurses, for example, are more likely than non-math-anxious nurses to make poor drug calculations (Mcmullan, Jones, & Lea, 2012); math-anxious women are more likely than their peers to engage in poor financial planning (McKenna & Nickols, 1988), and math anxiety is negatively linked to the ability to interpret health statistics (Silk & Parrott, 2014). Given that math-anxiety is related to important and detrimental consequences in people’s daily lives, it is vital that we work to understand the behavioural and cognitive differences between those who are high and low in math-anxiety.}
}
@article{KASHEFI2012117,
title = {Supporting Engineering Students’ Thinking and Creative Problem Solving through Blended Learning},
journal = {Procedia - Social and Behavioral Sciences},
volume = {56},
pages = {117-125},
year = {2012},
note = {International Conference on Teaching and Learning in Higher Education in conjunction with Regional Conference on Engineering Education and Research in Higher Education},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2012.09.638},
url = {https://www.sciencedirect.com/science/article/pii/S1877042812041006},
author = {Hamidreza Kashefi and Zaleha Ismail and Yudariah Mohammad Yusof},
keywords = {Blended learning, Creative Problem Solving, Engineering Mathematics, mathematical thinking, mathematical powers},
abstract = {Creative Problem Solving as a framework to encourage whole-brain thinking which employs different thinking skills and tools is not sufficiently emphasized in universities. Research findings indicate that for most engineering students, mathematics has always been one of the most difficult courses to study. Previous researches tried to overcome students’ difficulties in the engineering mathematics by using some methods based on supporting mathematical thinking. In this paper, we shall discuss and propose a learning environment for supporting students’ thinking and creative problem solving in engineering mathematics. Blended learning is suggested as an environment to support students’ thinking powers through creative problem solving.}
}
@article{WARD201980,
title = {Fast and slow thinking in distressing delusions: A review of the literature and implications for targeted therapy},
journal = {Schizophrenia Research},
volume = {203},
pages = {80-87},
year = {2019},
note = {Cognitive Therapies for Schizophrenia},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2017.08.045},
url = {https://www.sciencedirect.com/science/article/pii/S0920996417305212},
author = {Thomas Ward and Philippa A. Garety},
keywords = {Paranoia, Persecutory, Dual process, Belief flexibility, Jumping to conclusions, Bias Against Disconfirmatory Evidence (BADE), mHealth, eHealth, Digital therapy},
abstract = {The recent literature on reasoning biases in psychosis and delusions is reviewed. The state-of-the-art knowledge from systematic reviews and meta-analyses on the evidence for jumping to conclusions is briefly summarised, before a fuller discussion of the more recent empirical literature on belief flexibility as applied to delusions. The methodology and evidence in relation to studies of belief flexibility and the Bias Against Disconfirmatory Evidence (BADE) across the delusional continuum will be critically appraised, and implications drawn for improving cognitive therapy. It will be proposed that dual process models of reasoning, which Kahneman (Kahneman, 2011) popularised as ‘fast and slow thinking’, provide a useful theoretical framework for integrating further research and informing clinical practice. The emergence of therapies which specifically target fast and slow thinking in people with distressing delusions will be described.}
}
@article{BERS2023394,
title = {Coding as another language: Research-based curriculum for early childhood computer science},
journal = {Early Childhood Research Quarterly},
volume = {64},
pages = {394-404},
year = {2023},
issn = {0885-2006},
doi = {https://doi.org/10.1016/j.ecresq.2023.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0885200623000571},
author = {Marina Umaschi Bers and Jessica Blake-West and Madhu Govind Kapoor and Tess Levinson and Emily Relkin and Apittha Unahalekhaka and Zhanxia Yang},
keywords = {Design-based research, Coding, Computational Thinking, Powerful Ideas, ScratchJr},
abstract = {This paper describes the iterative research and evaluation of the Coding as Another Language (CAL) curriculum that utilizes the free ScratchJr programming language in kindergarten to second grade. CAL was designed using principles of three theoretical frameworks: Curriculum Research Framework (CRF), which proposes different phases in the creation of research-based curriculum; Constructionism, which presents a computationally-rich project-based methodology based on identifying powerful ideas from a learning domain; and Positive Technological Development, which intentionally integrates socio-emotional and ethical dimensions into curricular experiences. The pedagogical foundation of CAL involves the understanding of coding as a literacy, that is, putting developmentally-appropriate powerful ideas of computer science in conversation with those taught in language arts. The paper first describes CAL and then presents results from both a pilot study and a cluster randomized controlled trial that set to evaluate CAL's feasibility and impact on students’ learning outcomes. Our findings showed that the CAL curriculum was not only feasible to implement, but also effective for improving coding skills. However, CAL's impact on computational thinking is less clear given that in the cluster randomized controlled trial, both the control and the intervention groups improved equally on a measure of computational thinking.}
}
@article{HARDY20241737,
title = {Computational design of de novo bioenergetic membrane proteins},
journal = {Biochemical Society Transactions},
volume = {52},
number = {4},
pages = {1737-1745},
year = {2024},
issn = {1470-8752},
doi = {https://doi.org/10.1042/BST20231347},
url = {https://www.sciencedirect.com/science/article/pii/S1470875224001466},
author = {Benjamin J. Hardy and Paul Curnow},
keywords = {bioenergetics, protein design, transmembrane proteins},
abstract = {The major energy-producing reactions of biochemistry occur at biological membranes. Computational protein design now provides the opportunity to elucidate the underlying principles of these processes and to construct bioenergetic pathways on our own terms. Here, we review recent achievements in this endeavour of ‘synthetic bioenergetics’, with a particular focus on new enabling tools that facilitate the computational design of biocompatible de novo integral membrane proteins. We use recent examples to showcase some of the key computational approaches in current use and highlight that the overall philosophy of ‘surface-swapping’ — the replacement of solvent-facing residues with amino acids bearing lipid-soluble hydrophobic sidechains — is a promising avenue in membrane protein design. We conclude by highlighting outstanding design challenges and the emerging role of AI in sequence design and structure ideation.}
}
@article{DESHPANDE20244449,
title = {The evolution of computational research in a data-centric world},
journal = {Cell},
volume = {187},
number = {17},
pages = {4449-4457},
year = {2024},
issn = {0092-8674},
doi = {https://doi.org/10.1016/j.cell.2024.07.045},
url = {https://www.sciencedirect.com/science/article/pii/S0092867424008390},
author = {Dhrithi Deshpande and Karishma Chhugani and Tejasvene Ramesh and Matteo Pellegrini and Sagiv Shiffman and Malak S. Abedalthagafi and Saleh Alqahtani and Jimmie Ye and Xiaole Shirley Liu and Jeffrey T. Leek and Alvis Brazma and Roel A. Ophoff and Gauri Rao and Atul J. Butte and Jason H. Moore and Vsevolod Katritch and Serghei Mangul},
abstract = {Summary
Computational data-centric research techniques play a prevalent and multi-disciplinary role in life science research. In the past, scientists in wet labs generated the data, and computational researchers focused on creating tools for the analysis of those data. Computational researchers are now becoming more independent and taking leadership roles within biomedical projects, leveraging the increased availability of public data. We are now able to generate vast amounts of data, and the challenge has shifted from data generation to data analysis. Here we discuss the pitfalls, challenges, and opportunities facing the field of data-centric research in biology. We discuss the evolving perception of computational data-driven research and its rise as an independent domain in biomedical research while also addressing the significant collaborative opportunities that arise from integrating computational research with experimental and translational biology. Additionally, we discuss the future of data-centric research and its applications across various areas of the biomedical field.}
}
@article{KARVETSKI2022688,
title = {What do forecasting rationales reveal about thinking patterns of top geopolitical forecasters?},
journal = {International Journal of Forecasting},
volume = {38},
number = {2},
pages = {688-704},
year = {2022},
issn = {0169-2070},
doi = {https://doi.org/10.1016/j.ijforecast.2021.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0169207021001473},
author = {Christopher W. Karvetski and Carolyn Meinel and Daniel T. Maxwell and Yunzi Lu and Barbara A. Mellers and Philip E. Tetlock},
keywords = {Geopolitical forecasting, Psycholinguistic vocabularies, Integrative complexity, Comparison class, Natural language processing, LIWC},
abstract = {Geopolitical forecasting tournaments have stimulated the development of methods for improving probability judgments of real-world events. But these innovations have focused on easier-to-quantify variables, like personnel selection, training, teaming, and crowd aggregation—bypassing messier constructs, like qualitative properties of forecasters’ rationales. Here, we adapt methods from natural language processing (NLP) and computational text analysis to identify distinctive reasoning strategies in the rationales of top forecasters, including: (a) cognitive styles, such as dialectical complexity, that gauge tolerance of clashing perspectives and efforts to blend them into coherent conclusions and (b) the use of comparison classes or base rates to inform forecasts. In addition to these core metrics, we explore metrics derived from the Linguistic Inquiry and Word Count (LIWC) program. Applying these tools to multiple tournaments and to forecasters of widely varying skill (from Mechanical Turkers to carefully culled “superforecasters”) revealed that: (a) top forecasters show higher dialectical complexity in their rationales and use more comparison classes; (b) experimental interventions, like training and teaming, that boost accuracy also influence NLP profiles of rationales, nudging them in a “superforecaster” direction.}
}
@article{PINTO20151,
title = {Six thinking hats: A novel metalearner for intelligent decision support in electricity markets},
journal = {Decision Support Systems},
volume = {79},
pages = {1-11},
year = {2015},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2015.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S0167923615001438},
author = {Tiago Pinto and João Barreto and Isabel Praça and Tiago M. Sousa and Zita Vale and E.J. {Solteiro Pires}},
keywords = {Artificial intelligence, Decision support system, Electricity market, Genetic algorithm, Multiagent simulation, Machine learning},
abstract = {The energy sector has suffered a significant restructuring that has increased the complexity in electricity market players' interactions. The complexity that these changes brought requires the creation of decision support tools to facilitate the study and understanding of these markets. The Multiagent Simulator of Competitive Electricity Markets (MASCEM) arose in this context, providing a simulation framework for deregulated electricity markets. The Adaptive Learning strategic Bidding System (ALBidS) is a multiagent system created to provide decision support to market negotiating players. Fully integrated with MASCEM, ALBidS considers several different strategic methodologies based on highly distinct approaches. Six Thinking Hats (STH) is a powerful technique used to look at decisions from different perspectives, forcing the thinker to move outside its usual way of thinking. This paper aims to complement the ALBidS strategies by combining them and taking advantage of their different perspectives through the use of the STH group decision technique. The combination of ALBidS' strategies is performed through the application of a genetic algorithm, resulting in an evolutionary learning approach.}
}
@article{KASHEFI20125534,
title = {Fostering Mathematical Thinking in the Learning of Multivariable Calculus Through Computer-Based Tools},
journal = {Procedia - Social and Behavioral Sciences},
volume = {46},
pages = {5534-5540},
year = {2012},
note = {4th WORLD CONFERENCE ON EDUCATIONAL SCIENCES (WCES-2012) 02-05 February 2012 Barcelona, Spain},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2012.06.471},
url = {https://www.sciencedirect.com/science/article/pii/S1877042812022070},
author = {Hamidreza Kashefi and Zaleha Ismail and Yudariah Mohammad Yusof and Roselainy Abdul Rahman},
keywords = {Computer-based Learning, Mathematical Thinking, Multivariable Calculus, Student's Obstacles},
abstract = {Calculus as a prerequisite course to other advanced mathematics courses is one of the important and difficult courses for undergraduate students in many fields of study. Mathematical thinking is an important method to support students in the learning of calculus and specifically multivariable calculus. Researchers endeavour to support student's mathematical thinking in calculus with or without computer-based tools. The main goal of this paper is to illustrate the importance of using computer-based tools for fostering student's mathematical thinking to overcome their obstacles in multivariable calculus.}
}
@article{ZHANG2021100861,
title = {Predetermined accommodations with a standardized testing protocol: Examining two accommodation supports for developing fraction thinking in students with mathematical difficulties},
journal = {The Journal of Mathematical Behavior},
volume = {62},
pages = {100861},
year = {2021},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2021.100861},
url = {https://www.sciencedirect.com/science/article/pii/S0732312321000225},
author = {Dake Zhang and F.D. Rivera},
keywords = {Mathematical difficulties, Fraction, Accommodation},
abstract = {This study examined the effects of two pre-determined accommodations that were provided in a standardized testing. The two accommodations were meant to help students with difficulties in mathematics (SDMs) engage in unit thinking, reasoning, and coordination and consequently improve their ability to process fraction tasks. 23 middle school SDMs took the following tests and were asked to explain their solutions: a baseline fraction test without any accommodation; an annotated test with bolded information and additional simplified explanations; and a warming- up test that involved whole-number multiplicative reasoning tasks followed by the baseline test. Results show that while SDMs were able to construct and coordinate fraction units to solve fraction problems when appropriate accommodations were provided, standardized assessment with a predetermined “one-size-fits -all” accommodation could not meet the specific needs of all students with mathematics learning difficulties.}
}
@article{BRIER201792,
title = {Peircean cosmogony's symbolic agapistic self-organization as an example of the influence of eastern philosophy on western thinking},
journal = {Progress in Biophysics and Molecular Biology},
volume = {131},
pages = {92-107},
year = {2017},
note = {Integral Biomathics 2017: The Necessary Conjunction of Western and Eastern Thought Traditions for Exploring the Nature of Mind and Life},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2017.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S0079610717301281},
author = {Søren Brier},
keywords = {Cosmogony, Peircean semiotic philosophy: cybersemiotics, Info-computationalism, It-from-bit cosmogony, Philosophy of science, Interdisciplinarity, Advaita Vedanta philosophy, Buddhist philosophy, Transcendentalists philosophy, Multi-universe theory, Developing laws, Irreversible time, Sustained criticality},
abstract = {Charles S. Peirce developed a process philosophy featuring a non-theistic agapistic evolution from nothingness. It is an Eastern inspired alternative to the Western mechanical ontology of classical science also inspired by the American transcendentalists. Advaitism and Buddhism are the two most important Eastern philosophical traditions that encompass scientific knowledge and the idea of spontaneous evolutionary development. This article attempts to show how Peirce's non-mechanistic triadic semiotic process theory is suited better to embrace the quantum field view than mechanistic and information-based views are with regard to a theory of the emergence of consciousness. Peirce views the universe as a reasoning process developing from pure potentiality to the fully ordered rational Summon Bonum. The paper compares this with John Archibald Wheeler's “It from bit” cosmogony based on quantum information science, which leads to the info-computational view of nature, mind and culture. However, this theory lacks a phenomenological foundation. David Chalmers' double aspect interpretation of information attempts to overcome the limitations of the info-computational view. Chalmers supplements Batesonian and Wheelerian info-computationalism – both of which lack a phenomenological aspect - with a dimension that corresponds to the phenomenological aspect of reality. However, he does not manage to produce an integrated theory of the development of meaning and rationality. Alex Hankey's further work goes some way towards establishing a theory that can satisfy Husserl's criteria for consciousness - such as a sense of being and time - but Hankey's dependence on Chalmers' theory is still not able to account for what the connection between core consciousness and the physical world is.}
}
@article{KRAKAUER2022267,
journal = {Studies in History and Philosophy of Science},
volume = {92},
pages = {267-269},
year = {2022},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2021.05.014},
url = {https://www.sciencedirect.com/science/article/pii/S0039368121000789},
author = {John W. Krakauer}
}
@article{KRUGLANSKI2020413,
title = {All Thinking is ‘Wishful’ Thinking},
journal = {Trends in Cognitive Sciences},
volume = {24},
number = {6},
pages = {413-424},
year = {2020},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2020.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S1364661320300796},
author = {Arie W. Kruglanski and Katarzyna Jasko and Karl Friston},
keywords = {epistemic motivation, active inference, surprise},
abstract = {People often seek new information and eagerly update their beliefs. Other times they avoid information or resist revising their beliefs. What explains those different reactions? Answers to this question often frame information processing as a competition between cognition and motivation. Here, we dissolve this dichotomy by bringing together two theoretical frameworks: epistemic motivation and active inference. Despite evolving from different intellectual traditions, both frameworks attest to the indispensability of motivational considerations to the epistemic process. The imperatives that guide model construction under the epistemic motivation framework can be mapped onto key constructs in active inference. Drawing these connections offers a way of articulating social psychological constructs in terms of Bayesian computations and provides a generative testing ground for future work.}
}
@article{WEGERIF2010613,
title = {Exploring creative thinking in graphically mediated synchronous dialogues},
journal = {Computers & Education},
volume = {54},
number = {3},
pages = {613-621},
year = {2010},
note = {Learning in Digital Worlds: Selected Contributions from the CAL 09 Conference},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2009.10.015},
url = {https://www.sciencedirect.com/science/article/pii/S0360131509003054},
author = {Rupert Wegerif and Bruce M. McLaren and Marian Chamrada and Oliver Scheuer and Nasser Mansour and Jan Mikšátko and Mriga Williams},
keywords = {CSCL, Discourse analysis, Dialogic, Creativity, Artificial intelligence, Graphical interfaces},
abstract = {This paper reports on an aspect of the EC funded Argunaut project which researched and developed awareness tools for moderators of online dialogues. In this study we report on an investigation into the nature of creative thinking in online dialogues and whether or not this creative thinking can be coded for and recognized automatically such that moderators can be alerted when creative thinking is occurring or when it has not occurred after a period of time. We outline a dialogic theory of creativity, as the emergence of new perspectives from the interplay of voices, and the testing of this theory using a range of methods including a coding scheme which combined coding for creative thinking with more established codes for critical thinking, artificial intelligence pattern-matching techniques to see if our codes could be read automatically from maps and ‘key event recall’ interviews to explore the experience of participants. Our findings are that: (1) the emergence of new perspectives in a graphical dialogue map can be recognized by our coding scheme supported by a machine pattern-matching algorithm in a way that can be used to provide awareness indicators for moderators; (2) that the trigger events leading to the emergence of new perspectives in the online dialogues studied were most commonly disagreements and (3) the spatial representation of messages in a graphically mediated synchronous dialogue environment such as Digalo may offer more affordance for creativity than the much more common scrolling text chat environments. All these findings support the usefulness of our new account of creativity in online dialogues based on dialogic theory and demonstrate that this account can be operationalised through machine coding in a way that can be turned into alerts for moderators.}
}
@article{SPUZIC20161,
title = {The synergy of creativity and critical thinking in engineering design: The role of interdisciplinary augmentation and the fine arts},
journal = {Technology in Society},
volume = {45},
pages = {1-7},
year = {2016},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2015.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X15000925},
author = {S. Spuzic and R. Narayanan and K. Abhary and H.K. Adriansen and S. Pignata and F. Uzunovic and Xu Guang},
keywords = {Design, Interaction, Quality, Criticality, Creativity, Aesthetics},
abstract = {Analysis of the impact of interaction and experience on quality components such as “usability”, “producibility”, “reliability”, “sustainability” and “aesthetics” is presented using the case of engineering design, a discipline that traditionally has an image of being a strictly calculated, rigid framework. It has been widely recognised that engineering design encompasses two ways of thinking—creative and critical. A central argument that the synergy of creativity and criticality is significantly enhanced by connecting true interdisciplinary augmentation with the fine arts is discussed along with reflecting on the importance of such an approach in higher education.}
}

@article{OXMAN20171,
title = {Parametric design thinking},
journal = {Design Studies},
volume = {52},
pages = {1-3},
year = {2017},
note = {Parametric Design Thinking},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2017.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X17300480},
author = {Rivka Oxman}
}
@article{LAI2021104287,
title = {Investigating the impact of a flipped programming course using the DT-CDIO approach},
journal = {Computers & Education},
volume = {173},
pages = {104287},
year = {2021},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2021.104287},
url = {https://www.sciencedirect.com/science/article/pii/S0360131521001640},
author = {Chin-Feng Lai and Hua-Xu Zhong and Po-Sheng Chiu},
keywords = {Flipped classroom, Design thinking, Teaching/learning strategies, 21st-century abilities, Computational thinking},
abstract = {Currently, flipped learning requires a framework that will give novices and students the ability to face the complex problems encountered in programming courses. It is necessary to design a design thinking learning framework that addresses independent learning and specific processes that will improve students' 21st-century skills. The existing literature has not implemented flipped programming courses from a design thinking perspective (Cook & Bush, 2018), which would thus be an innovative approach to designing teaching methods and investigating the effects of this framework. The purpose of this study was to develop analyze, observe, reflect, conceive, design, implement, and operate (Crawley et al., 2007) a DT-CDIO model and to investigate the relationship of the flow experience to computational thinking and cognitive load in order to understand the impact of the flow experience on a flipped programming course. The participants in this study comprised 40 pre-service education students (Male = 17; Female = 23). The partial least squares (PLS) method was used for the data analysis to test the model. This study was intended to obtain and evaluate significant differences between the students' flow experience and their computational thinking ability and cognitive load. The results indicated that the DT-CDIO pedagogy filled a long-standing gap related to a lack of reflective pedagogy and design thinking problems. The flow experience negatively impacted creativity and problem solving ability. Meanwhile, intrinsic cognitive load negatively impacted the flow experience. Germane cognitive load positively impacted the flow experience. In particular, the flow experience is a crucial factor that can be used to predict various computational thinking skills in a programming curriculum. More importantly, this study provides important insights into the implications of the DT-CDIO approach and other related factors.}
}
@article{SMITH2023100616,
title = {A research agenda for computational empowerment for emerging technology education},
journal = {International Journal of Child-Computer Interaction},
volume = {38},
pages = {100616},
year = {2023},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2023.100616},
url = {https://www.sciencedirect.com/science/article/pii/S2212868923000533},
author = {Rachel Charlotte Smith and Marie-Monique Schaper and Mariana Aki Tamashiro and Maarten {Van Mechelen} and Marianne Graves Petersen and Ole Sejer Iversen},
keywords = {Computational empowerment, Emerging technologies, Ethical and societal implications, Technology education, Teenagers},
abstract = {The article proposes a research agenda for computational empowerment for emerging technologies in the field of child–computer interaction (CCI) – in artificial intelligence (AI), machine learning (ML), the internet of things (IoT), augmented reality (AR), and virtual reality (VR). This research agenda includes three levels of operation for future studies: (1) participatory practice, capable of engaging teachers and students in co-developing and designing approaches for teaching and learning emerging technologies, (2) educational principles for integrating technological and societal aspects of emerging technologies, and (3) digital tools for engaging students in construction of and critical reflection on emerging technologies. The research agenda was developed from longitudinal studies of the respective emerging technologies in Danish K–12 education, participatory design research with in-service teachers, development of novel tools and technologies, and literature studies of current CCI research. The paper addresses current gaps in the CCI literature and contributes a coherent approach and guiding questions for future CCI research on computational empowerment for emerging technology in education.}
}
@article{AGNETIS2019100110,
title = {Integrating lean thinking and mathematical optimization: A case study in appointment scheduling of hematological treatments},
journal = {Operations Research Perspectives},
volume = {6},
pages = {100110},
year = {2019},
issn = {2214-7160},
doi = {https://doi.org/10.1016/j.orp.2019.100110},
url = {https://www.sciencedirect.com/science/article/pii/S2214716018301969},
author = {Alessandro Agnetis and Caterina Bianciardi and Nicola Iasparra},
keywords = {Appointment scheduling, Hematological treatments, Lean thinking},
abstract = {This paper addresses the relationship between lean thinking and mathematical optimization. We discuss the roles of the two approaches, using as a reference case study the appointment scheduling process in a hematological center of a large Italian hospital. We report on how lean tools have been deployed to improve the process, we present a mathematical optimization model and discuss its implementation. Our aim is to show that the joint use of lean thinking and mathematical optimization can disclose large benefits when they are properly integrated in the improvement process. In our case study, simulated experiments point out that the average patient lead time could be decreased by more than 30%.}
}
@article{SHINOHARA2024249,
title = {A computation design method for architectural artifacts adapted from traditional Kagome bamboo basketry techniques},
journal = {Frontiers of Architectural Research},
volume = {13},
number = {2},
pages = {249-264},
year = {2024},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2023.11.007},
url = {https://www.sciencedirect.com/science/article/pii/S2095263523001061},
author = {Hiroyuki Shinohara and Tung Hoi Peter Chan},
keywords = {Traditional bamboo craft, Triaxial material interlacing, Bamboo, Computational design methods, Mesh block combination system, Architectural woven artifact},
abstract = {This study is a digital form-finding and manual fabrication experiment in woven architectural design, with one traditional weaving style, Kagome, used to scale the craft up into an architectural-scale bamboo woven artifact. Kagome is a trihexagonal pattern employed in traditional bamboo basketry as a triaxial weaving system, resulting in an object with a self-bracing capacity without the use of fasteners owing to its interlacing lattices. Although existing studies and tools have addressed triaxial weaving design and representation, the current consideration of the advantages of weaving with bamboo is insufficient. To address this research gap, this study develops a computational design method based on studies on bamboo basketry. This allows for the representation and exploration of design geometries using combinations of regular triangular meshes for the fabrication of Kagome woven bamboo artifacts. A full-scale mock-up was fabricated to evaluate the effectiveness of the method. The mock-up demonstrated the self-bracing properties of Kagome, but there were discrepancies between the mock-up and the design. Factors affecting bamboo weaving on an architectural scale have been identified within this study to inform future research on woven bamboo structures.}
}
@article{MURIASCLOSAS2025105597,
title = {Computational modelling of CAR T-cell therapy: from cellular kinetics to patient-level predictions},
journal = {eBioMedicine},
volume = {113},
pages = {105597},
year = {2025},
issn = {2352-3964},
doi = {https://doi.org/10.1016/j.ebiom.2025.105597},
url = {https://www.sciencedirect.com/science/article/pii/S2352396425000416},
author = {Adrià Murias-Closas and Clara Prats and Gonzalo Calvo and Daniel López-Codina and Eulàlia Olesti},
keywords = {CAR T therapy, Cancer models, Computational biology, Pharmacokinetics, Cancer immunotherapy, Haematological cancer},
abstract = {Summary
Chimeric Antigen Receptor (CAR) T-cell therapy is characterised by the heterogeneous cellular kinetic profile seen across patients. Unlike traditional chemotherapy, which displays predictable dose-exposure relationships resulting from well-understood pharmacokinetic processes, CAR T-cell dynamics rely on complex biologic factors that condition treatment response. Computational approaches hold potential to explore the intricate cellular dynamics arising from CAR T therapy, yet their ability to improve cancer treatment remains elusive. Here we present a comprehensive framework through which to understand, construct, and classify CAR T-cell kinetics models. Current approaches often rely on adapted empirical pharmacokinetic methods that overlook dynamics emerging from cellular interactions, or intricate theoretical multi-population models with limited clinical applicability. Our review shows that the utility of a model does not depend on the complexity of its design but on the strategic selection of its biological constituents, implementation of suitable mathematical tools, and the availability of biological measures from which to fit the model.}
}
@article{KIELING2015967,
title = {Here/In This Issue and There/Abstract Thinking: Randomized Controlled Trials in the Era of Big Data},
journal = {Journal of the American Academy of Child & Adolescent Psychiatry},
volume = {54},
number = {12},
pages = {967-968},
year = {2015},
issn = {0890-8567},
doi = {https://doi.org/10.1016/j.jaac.2015.09.012},
url = {https://www.sciencedirect.com/science/article/pii/S0890856715006437},
author = {Christian Kieling}
}
@article{MCGOWEN2013527,
title = {Flexible thinking and met-befores: Impact on learning mathematics},
journal = {The Journal of Mathematical Behavior},
volume = {32},
number = {3},
pages = {527-537},
year = {2013},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2013.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S0732312313000552},
author = {Mercedes A. McGowen and David O. Tall},
keywords = {Flexible thinking, Met-befores, Mathematical symbols, Minus sign, Supportive aspects of function, Problematic aspects of minus sign, Formative assessment},
abstract = {In this paper we study the difficulties resulting from changes in meaning of the minus sign, from an operation on numbers, to a sign designating a negative number, to the additive inverse of an algebraic symbol on students in two-year colleges and universities. Analysis of the development of algebra reveals that these successive meanings that the student has met before often become problematic, leading to a fragile knowledge structure that lacks flexibility and leads to confusion and long-term disaffection. The problematic aspects that arise from changes in meaning of the minus sign are identified and the iconic function machine is utilized as a supportive strategy, along with formative assessment to encourage teachers and learners to seek more flexible and effective ways of making sense of increasingly sophisticated mathematics.}
}
@article{ANDERSEN2023100576,
title = {The situated power of computational empowerment},
journal = {International Journal of Child-Computer Interaction},
volume = {36},
pages = {100576},
year = {2023},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2023.100576},
url = {https://www.sciencedirect.com/science/article/pii/S2212868923000132},
author = {Lars Bo Andersen and Oliver Alexander Tafdrup and Thilde Emilie Møller and Mads Middelboe Rehder and Vibeke Schrøder},
keywords = {Power, Computational empowerment, Situated agency, Infrastructure, Ontological politics, HCI},
abstract = {Processes of computational empowerment necessarily involve changing the relationships of power between children, digital technologies, and social contexts. However, research into computational empowerment rarely explicates a theory of power nor reflects on the dynamics of power implicated in attempts at empowerment. The purpose of this article is thus to investigate the problem of power in computational empowerment. The method applied is one of empirical philosophy. The article utilizes three paradigmatic cases describing how the power of computational empowerment is a matter of situated knowledge and agency, an outcome of invisible work, and a question of ontological politics.}
}
@article{SOEFFNER202017475,
title = {Meaning – Thinking – AI},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {17475-17480},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.2483},
url = {https://www.sciencedirect.com/science/article/pii/S240589632033189X},
author = {J. Soeffner},
keywords = {Artificial Intelligence, consciousness, cognition, meaning},
abstract = {This paper investigates on the relation between consciousness and meaning. Questioning AI’s ability to produce both, it first makes the case for a sharper terminology regarding AI’s ‘cognitive’ abilities. In arguing that meaning requires more than content production, it offers a definition of meaning that offers a clear distinction between human and non-human intelligences.}
}
@article{KIELING2015435,
title = {Here/In This Issue and There/Abstract Thinking: Precision Medicine for Child and Adolescent Psychiatry},
journal = {Journal of the American Academy of Child & Adolescent Psychiatry},
volume = {54},
number = {6},
pages = {435-436},
year = {2015},
issn = {0890-8567},
doi = {https://doi.org/10.1016/j.jaac.2015.03.009},
url = {https://www.sciencedirect.com/science/article/pii/S0890856715001823},
author = {Christian Kieling}
}
@article{ZHANG202375,
title = {Thinking and Practicing Like a Scientist?},
journal = {Asia-Pacific Science Education},
volume = {9},
number = {1},
pages = {75-105},
year = {2023},
issn = {2364-1177},
doi = {https://doi.org/10.1163/23641177-bja10057},
url = {https://www.sciencedirect.com/science/article/pii/S2364117723000038},
author = {Zhengyan Zhang and Ying-Chih Chen and Guangxi He and Hsiao-Ching She and Jhih-Cheng Chen},
keywords = {affective character, cognitive character, job character, lifestyle character, mental images of scientists},
abstract = {This study aimed to develop a valid and reliable instrument, the Mental Images of Scientists Questionnaire (MISQ), and use the instrument to examine Chinese students’ mental images of scientists’ characters across school levels, regions, living settings, and gender. The final version of the MISQ consisted of four constructs: scientists’ cognitive, affective, lifestyle, and job characters. The results showed that senior high school students gave higher scores for scientists’ cognitive character construct than junior high and elementary school students did. Students from eastern regions, which have a more highly developed economy, gave the highest scores on cognitive and affective character constructs of scientists. Students from western regions, which have a less developed economy, had a relatively negative impression of scientists. Students’ images of scientists’ affective, lifestyle, and job characters were positively correlated with their interests in pursuing scientific careers. Future research to explore the relationships between students’ mental images of scientists’ characters and students’ motivation to pursue science-related careers or to engage in scientific practices are recommended.}
}
@article{RUIZ20181,
title = {A multiple-baseline evaluation of a brief acceptance and commitment therapy protocol focused on repetitive negative thinking for moderate emotional disorders},
journal = {Journal of Contextual Behavioral Science},
volume = {9},
pages = {1-14},
year = {2018},
issn = {2212-1447},
doi = {https://doi.org/10.1016/j.jcbs.2018.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S2212144718301170},
author = {Francisco J. Ruiz and Cindy L. Flórez and María B. García-Martín and Andrea Monroy-Cifuentes and Katherine Barreto-Montero and Diana M. García-Beltrán and Diana Riaño-Hernández and Marco A. Sierra and Juan C. Suárez-Falcón and Verónica Cardona-Betancourt and Bárbara Gil-Luciano},
keywords = {Acceptance and commitment therapy, Relational frame theory, Depression, Generalized anxiety disorder, Repetitive negative thinking},
abstract = {Repetitive negative thinking (RNT) in the form of worry and rumination has been identified as a particularly counterproductive experiential avoidance strategy implicated in the onset and maintenance of emotional disorders. The current study analyzes the effect of an individual, 2-session, RNT-focused, acceptance and commitment therapy (ACT) protocol in the treatment of moderate emotional disorders. Ten adults suffering from moderate to severe emotional symptoms according to the Depression Anxiety and Stress Scale-21 (DASS-21) and the General Health Questionnaire-12 (GHQ-12) participated in the study. Participants completed 5- to 7-week baselines without showing improvement trends in the DASS-21 or the GHQ-12. Afterwards, they received the ACT protocol, and a 3-month follow-up was conducted. A Bayesian approach to analyze clinically significant changes (CSC) for single-case experimental designs (SCED) was conducted, which required at least substantial evidence of the intervention effect and scores in the nonclinical range. Nine of the 10 participants showed CSC in the GHQ-12, and 7 participants in the DASS-21. The standardized mean difference effect sizes for SCED were computed, which facilitates comparison and integration of the results with group designs. Very large effect sizes were found for emotional symptoms (d = 2.44 and 2.68), pathological worry (d = 3.14), experiential avoidance (d = 1.32), cognitive fusion (d = 2.01), repetitive thinking (d = 2.51), and valued living (d = 1.54 and 1.41). No adverse events were found. RNT-focused ACT protocols deserve further empirical tests.}
}
@article{SHAMIR2022100415,
title = {Teaching machine learning in elementary school},
journal = {International Journal of Child-Computer Interaction},
volume = {31},
pages = {100415},
year = {2022},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2021.100415},
url = {https://www.sciencedirect.com/science/article/pii/S2212868921000994},
author = {Gilad Shamir and Ilya Levin},
keywords = {Computational thinking, Constructionism, Artificial intelligence, Machine learning, Elementary school, Programming},
abstract = {The emergence and ubiquity of Artificial Intelligence in the form of Machine Learning (ML) systems have revolutionized daily life. However, scant if any attention has been paid to ML in computing education, which continues to teach rule-based programming. A new, promising research field in education consists of acquainting children with ML to foster this much-needed shift from traditional rule-driven thinking to ML-based data-driven thinking. This article presents the development of computational thinking competencies in 12-year-old students who participated in a learning-by-design or a learning-by-teaching ML course. The results, based on a qualitative and quantitative evaluation of the students’ achievements, indicate that they demonstrated computational thinking competencies at various levels. The learning by design group evidenced greater development in computational skills, whereas the learning by teaching group improved in terms of computational perspective. These findings are discussed with respect to promoting children’s problem-solving competencies within a constructionist approach to ML.}
}
@article{PENCZYNSKI201672,
title = {Strategic thinking: The influence of the game},
journal = {Journal of Economic Behavior & Organization},
volume = {128},
pages = {72-84},
year = {2016},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2016.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S0167268116300853},
author = {Stefan P. Penczynski},
keywords = {Level of reasoning, Task dependence, Virtual observability},
abstract = {In order to assess the extent to which features of a game affect the strategic sophistication of the people involved, this study investigates the relevance of differing objectives (matching/mismatching) and of virtually moving first or second in the “hide and seek” game. In three different treatments, mismatchers and matchers are not found to exhibit significantly different levels of reasoning although level averages and winning probabilities always are in favor of the matchers. Varying the virtual timing of the game has a significant impact on the shape of the level distribution. The analysis relies on intrateam communication, whose coding is shown to be stable and replicable.}
}
@article{KYRIAZIS20171,
title = {Editorial: Re-thinking ageing: a cross-disciplinary perspective (A New Era for Ageing)},
journal = {Mechanisms of Ageing and Development},
volume = {163},
pages = {1},
year = {2017},
note = {SI:A new era for ageing?},
issn = {0047-6374},
doi = {https://doi.org/10.1016/j.mad.2017.04.007},
url = {https://www.sciencedirect.com/science/article/pii/S0047637417301021},
author = {Marios Kyriazis}
}
@article{TAKAHASHI201295,
title = {Symmetrizing object and meta levels organizes thinking},
journal = {Biosystems},
volume = {107},
number = {2},
pages = {95-105},
year = {2012},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2011.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S030326471100181X},
author = {Tatsuji Takahashi and Yukio-Pegio Gunji},
keywords = {Internal measurement, Second person, Inner speech, Intermittency, Criticality, Self-organization, Finite automaton},
abstract = {We present a single non-cellular finite automaton model first shown to exhibit self-organizing behavior with intermittency and criticality, through a self-referential process. We propose a method to make self-referential contradiction a dynamic process of interaction with the selves in first person and third person description. The process represents thinking as inner dialogue with the self in second person. The dynamic effect of the rewrite shows characters proper to internal measurement, disequilibration by equilibration and transfer of inconsistency to the neighborhood by local resolution of the inconsistency. As the result, the advent of contradiction is postponed by the rewrite. The duality of internal measurement subject prevents inner dialogue in second person from lapsing into monologue. Criticality of thinking process is expressed. A probabilistic interpretation of non-determinacy weakening oracle is the key.}
}
@article{ZHEN2025121022,
title = {Beyond what was said: Neural computations underlying pragmatic reasoning in referential communication},
journal = {NeuroImage},
volume = {306},
pages = {121022},
year = {2025},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2025.121022},
url = {https://www.sciencedirect.com/science/article/pii/S1053811925000229},
author = {Shanshan Zhen and Mario Martinez-Saito and Rongjun Yu},
keywords = {Referential communication, Pragmatic reasoning, Theory of mind, Bayesian inference, fMRI},
abstract = {The ability to infer a speaker's utterance within a particular context for the intended meaning is central to communication. Yet, little is known about the underlying neurocomputational mechanisms of pragmatic inference, let alone relevant differences among individuals. Here, using a reference game combined with model-based functional magnetic resonance imaging (fMRI), we showed that an individual-level pragmatic inference model was a better predictor of listeners’ performance than a population-level model. Our fMRI results showed that Bayesian posterior probability was positively correlated with activity in the ventromedial prefrontal cortex (vmPFC) and ventral striatum and negatively correlated with activity in dorsomedial PFC, anterior insula (AI), and inferior frontal gyrus (IFG). Importantly, individual differences in higher-order reasoning were correlated with stronger activation in IFG and AI and positively modulated the vmPFC functional connectivity with AI. Our findings provide a preliminary neurocomputational account of how the brain represents Bayesian belief inferences and the neural basis of heterogeneity in such reasoning.}
}
@article{ANDERSON2025114983,
title = {Chemical mass-action systems as analog computers: Implementing arithmetic computations at specified speed},
journal = {Theoretical Computer Science},
volume = {1025},
pages = {114983},
year = {2025},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2024.114983},
url = {https://www.sciencedirect.com/science/article/pii/S0304397524006005},
author = {David F. Anderson and Badal Joshi},
keywords = {Analog computation, Computing with chemistry, Polynomial dynamical systems, Input-independent speed of computation},
abstract = {Recent technological advances allow us to view chemical mass-action systems as analog computers. In this context, the inputs to a computation are encoded as initial values of certain chemical species while the outputs are the limiting values of other chemical species. In this paper, we design chemical systems that carry out the elementary arithmetic computations of: identification, inversion, mth roots (for m≥2), addition, multiplication, absolute difference, rectified subtraction over non-negative real numbers, and partial real inversion over real numbers. We prove that these “elementary modules” have a speed of computation that is independent of the inputs to the computation. Moreover, we prove that finite sequences of such elementary modules, running in parallel, can carry out composite arithmetic over real numbers, also at a rate that is independent of inputs. Furthermore, we show that the speed of a composite computation is precisely the speed of the slowest elementary step. Specifically, the scale of the composite computation, i.e. the number of elementary steps involved in the composite, does not affect the overall asymptotic speed – a feature of the parallel computing nature of our algorithm. Our proofs require the careful mathematical analysis of certain non-autonomous systems, and we believe this analysis will be useful in different areas of applied mathematics, dynamical systems, and the theory of computation. We close with a discussion on future research directions, including numerous important open theoretical questions pertaining to the field of computation with reaction networks.}
}
@article{SCHAPER2022100537,
title = {Computational empowerment in practice: Scaffolding teenagers’ learning about emerging technologies and their ethical and societal impact},
journal = {International Journal of Child-Computer Interaction},
volume = {34},
pages = {100537},
year = {2022},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2022.100537},
url = {https://www.sciencedirect.com/science/article/pii/S2212868922000551},
author = {Marie-Monique Schaper and Rachel Charlotte Smith and Mariana Aki Tamashiro and Maarten {Van Mechelen} and Mille Skovhus Lunding and Karl-Emil Kjæer Bilstrup and Magnus Høholt Kaspersen and Kasper Løvborg Jensen and Marianne Graves Petersen and Ole Sejer Iversen},
keywords = {Computational empowerment, Emerging technologies, Ethical and societal implications, Technology education, Machine learning, Augmented reality, Teenagers},
abstract = {Whereas computational empowerment is well established in child–computer interaction research, less effort has been made to integrate this approach in practice. Building on four existing principles in child–computer interaction, namely Closeness, Embodied Learning, Design Process and Decoding, we explore how computational empowerment can be scaffolded in practice. This study was part of an interdisciplinary research project exploring emerging technologies in education (CEED). We involved 9 teachers and 26 students (14–15 y) in Denmark in teaching about machine learning and augmented reality. In the article we develop a framework for applying computational empowerment in formal educational contexts. Based on the study, we found that computational empowerment builds on distinct layers which are these four principles. Specifically, merging the principles Closeness and Embodied Learning can increase student engagement and motivation in the activities; in addition, Decoding and Design Process are key principles for promoting student awareness of the societal impacts of emerging technologies. Based on qualitative data from this intervention, we discuss the opportunities and challenges for child–computer interaction in moving toward computational empowerment in practice.}
}
@article{BARZILAI2006130,
title = {How does information technology shape thinking?},
journal = {Thinking Skills and Creativity},
volume = {1},
number = {2},
pages = {130-145},
year = {2006},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2006.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S1871187106000307},
author = {Sarit Barzilai and Anat Zohar},
keywords = {Higher order thinking strategies, Cognitive effects of information technology, Distributed cognition},
abstract = {This study revisits a classic yet still intriguing question regarding information technology (IT): what difference does IT “really” make, in terms of people's thinking? In order to explore this question, the effects of IT in authentic research settings were studied through retrospective interviews with 24 academic researchers. Analysis of the researchers’ descriptions of their learning and thinking processes shows that the effects of IT on higher order thinking strategies can be classified, following Perkins [Perkins, D. N. (1985). The fingertip effect: How information processing technology changes thinking. Educational Researcher, 14(7), 11–17], into first order effects and second order effects. First order effects of IT amplify or improve existing thinking strategies, without changing their nature, while second order effects of IT cause significant changes in the researchers’ thinking strategies. The results demonstrate that both types of effects take place in authentic research settings, often existing side by side. This article explores several examples of the ways in which IT affects higher order thinking strategies (such as forming research questions, constructing models and evaluating information), examines the types of effects created by IT, the conditions required for these effects to take place, and the role of distributed cognition.}
}
@article{HORNE2019103981,
title = {Intuitions about personal identity are rooted in essentialist thinking across development},
journal = {Cognition},
volume = {191},
pages = {103981},
year = {2019},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2019.05.018},
url = {https://www.sciencedirect.com/science/article/pii/S0010027719301428},
author = {Zachary Horne and Andrei Cimpian},
keywords = {Essentialism, Identity, Development, Self, Philosophy},
abstract = {What aspects of a person determine whether they are the same person they were in the past? This is one of the fundamental questions of research on personal identity. To date, this literature has focused on identifying the psychological states (e.g., moral beliefs, memories) that people rely on when making identity judgments. But the notion of personal identity depends on more than just psychological states. Most people also believe that the physical matter that makes up an individual is an important criterion for judging identity; changes to the physical stuff in a person’s body, even if they are not accompanied by any psychological changes, are judged to change who the person is at some level. Here, we investigate the sources of these beliefs and propose that they stem from the broader cognitive tendency to assume that unseen physical essences make things what they are—psychological essentialism. Four studies provided support for this claim. In Studies 1 and 2, exposing participants to essentialist reasoning led to stronger endorsement of physical continuity as a criterion for personal identity. Similarly, individual differences in participants’ essentialist thinking predicted the extent of their reliance on physical continuity (Study 3), and this relationship was observed even among 6- to 9-year-old children (Study 4). These studies advance theory on the psychology of personal identity by identifying a reason why people assign a central role to physical composition when judging identity.}
}
@article{YANG201140,
title = {Cognition Evolutionary Computation for System-of-systems Architecture Development},
journal = {Procedia Computer Science},
volume = {6},
pages = {40-45},
year = {2011},
note = {Complex adaptive sysytems},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2011.08.010},
url = {https://www.sciencedirect.com/science/article/pii/S1877050911004753},
author = {Feng Yang and Cihan Dagli and Weiping Wanga},
keywords = {System-of-systems, Architecture, Evolutionary Computation, Cognition Evolutionary Computation},
abstract = {The evolving nature of system-of-systems requirements and corresponding architecture, and the complex causal relationship between the architecture of system-of-systems and its emergent behavior make the problem of system-of-systems architecture development a great challenge. As a tentative effort in meeting this special challenge, a new evolutionary computation paradigm–named Cognition Evolutionary Computation(CEC) is proposed, which models the creative cognition process of divergent and convergent thinking, adaptation and innovation, that drives the co-evolution of problem space, knowledge space and solution space. The optimization algorithm for CEC uses causal probabilistic network as the knowledge representation mechanism. A theoretical framework for CEC based system-of-system architecture generation, evaluation and optimization is discussed.}
}
@article{SAINI2010185,
title = {The psychological underpinnings of relative thinking in price comparisons},
journal = {Journal of Consumer Psychology},
volume = {20},
number = {2},
pages = {185-192},
year = {2010},
issn = {1057-7408},
doi = {https://doi.org/10.1016/j.jcps.2010.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S1057740810000240},
author = {Ritesh Saini and Sweta C. Thota},
keywords = {Relative thinking, Psychophysics, Behavioral pricing, Affect, Intuition, Dual process},
abstract = {This article investigates the psychological underpinnings of relative thinking—the tendency of consumers to consider relative savings, and not just absolute savings, in their decisions to search for a deal or purchase an item. We examine how (i) cognitive load, (ii) the affective-richness of the product, and (iii) the consumer's propensity for intuitive decision-making influence relative thinking. As hypothesized, high cognitive load and affect-rich (vs. affect-poor) products, and individual level preference for intuitive decision-making aggravate this behavior. Our results present clear managerial implications along with developing a better understanding of the behavioral foundations of relative thinking.}
}
@article{STEVENS2020116990,
title = {Classifying creativity: Applying machine learning techniques to divergent thinking EEG data},
journal = {NeuroImage},
volume = {219},
pages = {116990},
year = {2020},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2020.116990},
url = {https://www.sciencedirect.com/science/article/pii/S1053811920304766},
author = {Carl E. Stevens and Darya L. Zabelina},
keywords = {Alpha, Classification, EEG, Creativity, AUT},
abstract = {Prior research has shown that greater EEG alpha power (8–13 ​Hz) is characteristic of more creative individuals, and more creative task conditions. The present study investigated the potential for machine learning to classify more and less creative brain states. Participants completed an Alternate Uses Task, in which they thought of Normal or Uncommon (more creative) uses for everyday objects (e.g., brick). We hypothesized that alpha power would be greater for Uncommon (vs. Common) uses, and that a machine learning (ML) approach would enable the reliable classification data from the two conditions. Further, we expected that ML would be successful at classifying more (vs. less) creative individuals. As expected, alpha power was significantly greater for the Uncommon than for the Normal condition. Using spectrally weighted common spatial patterns to extract EEG features, and quadratic discriminant analysis, we found that classification accuracy for the two conditions varied widely among individuals, with a mean of 63.9%. For more vs. less creative individuals, 82.3% classification accuracy was attained. These findings indicate the potential for broader adoption of machine learning in creativity research.}
}
@incollection{DAS202319,
title = {Chapter 3 - Discovery of anticancer therapeutics: Computational chemistry and Artificial Intelligence-assisted approach},
editor = {Ganji Purnachandra Nagaraju and Venkatesan Amouda and Ampasala {Dinakara Rao}},
booktitle = {Computational Methods in Drug Discovery and Repurposing for Cancer Therapy},
publisher = {Academic Press},
pages = {19-41},
year = {2023},
isbn = {978-0-443-15280-1},
doi = {https://doi.org/10.1016/B978-0-443-15280-1.00007-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780443152801000078},
author = {Subrata Das and Anupam Das Talukdar and Deepa Nath and Manabendra Dutta Choudhury},
keywords = {Artificial Intelligence, Computational chemistry, Drug repurposing, Anticancer therapeutics, Machine learning, Deep learning},
abstract = {Nowadays, cancer is causing a serious health issue worldwide. Due to inadequate detection, heterogeneity in tumor formation, chemoresistance, drug resistance, and also manifestation of metastases, the death rate is increasing. Hence, managing of these challenges needs more potent and effective anticancer drugs. The new drug development requires longer time and more cost. Therefore, in the recent technological advancement, search for alternate methods to develop new drugs is a necessary step, which can remove the complex processes, lessen cost, shorten time, and improves success rates. Drug repurposing, computational chemistry, and Artificial Intelligence-assisted approaches are new and novel way of thinking toward the development of anticancer drugs. Drug repurposing with AI can develop a novel effective and specific anticancer drug for the treatment of cancer. The application of AI helps to diagnose the actual cause of cancerous development in the patient and also to determine the doses of effective drugs to be applied for particular cancer. AI together with computational chemistry provides an enhancement to the medical system for the effective diagnosis and treatment of cancer.}
}
@article{UPHOFF201489,
title = {Systems thinking on intensification and sustainability: systems boundaries, processes and dimensions},
journal = {Current Opinion in Environmental Sustainability},
volume = {8},
pages = {89-100},
year = {2014},
note = {SI: Sustainability governance and transformation},
issn = {1877-3435},
doi = {https://doi.org/10.1016/j.cosust.2014.10.010},
url = {https://www.sciencedirect.com/science/article/pii/S1877343514000827},
author = {Norman Uphoff},
abstract = {‘Sustainable intensification’ is gaining popularity among academics and donor agencies without much examination of the ambiguities in both terms, made worse by combining them. The terms can be made more serviceable by distinguishing between definitions by extension and definitions by intension. Difficulties with the term ‘intensification’ are addressed by considering the System of Rice Intensification (SRI). This reverses Green Revolution thinking about intensification as a matter of increasing material inputs. Changes in crop management can raise food output by reducing such inputs, with increased reliance on knowledge and management that use available resources more productively and sustainably. Its initial increases in labor inputs are usually transitory. Conjunctions of different disciplines and different levels of analysis and action are considered with reference to the factors of nestedness and contingence. Subjects bearing on sustainable intensification which can benefit from disciplinary convergence include: biogeochemistry to address problems of climate change; part-time farming to adapt to changing economic opportunities; and symbiotic endophytes that can enhance crop health and growth. The concept of ‘causation’ is disaggregated to consider ‘processual’ as distinguished from ‘mechanistic’ causation. Systems thinking is likely to be more productive for addressing interactions within and between subsystems rather than for theorizing about systems as a whole.}
}
@article{CHESEBRO2024,
title = {Challenges and Frontiers in Computational Metabolic Psychiatry},
journal = {Biological Psychiatry: Cognitive Neuroscience and Neuroimaging},
year = {2024},
issn = {2451-9022},
doi = {https://doi.org/10.1016/j.bpsc.2024.10.011},
url = {https://www.sciencedirect.com/science/article/pii/S2451902224003100},
author = {Anthony G. Chesebro and Botond B. Antal and Corey Weistuch and Lilianne R. Mujica-Parodi},
keywords = {Allostasis, Circuit, Computational, Feedback, Homeostasis, Metabolic, Neural},
abstract = {One of the primary challenges in metabolic psychiatry is that the disrupted brain functions that underlie psychiatric conditions arise from a complex set of downstream and feedback processes that span multiple spatiotemporal scales. Importantly, the same circuit can have multiple points of failure, each of which results in a different type of dysregulation, and thus elicits distinct cascades downstream that produce divergent signs and symptoms. Here, we illustrate this challenge by examining how subtle differences in circuit perturbations can lead to divergent clinical outcomes. We also discuss how computational models can perform the spatially heterogeneous integration and bridge in vitro and in vivo paradigms. By leveraging recent methodological advances and tools, computational models can integrate relevant processes across scales (e.g., tricarboxylic acid cycle, ion channel, neural microassembly, whole-brain macrocircuit) and across physiological systems (e.g., neural, endocrine, immune, vascular), providing a framework that can unite these mechanistic processes in a manner that goes beyond the conceptual and descriptive to the quantitative and generative. These hold the potential to sharpen our intuitions toward circuit-based models for personalized diagnostics and treatment.}
}
@incollection{LEE201761,
title = {Chapter 4 - Cross-Cultural Differences in Thinking: Some Thoughts on Psychological Paradigms},
editor = {T.-W. Hung and T.J. Lane},
booktitle = {Rationality},
publisher = {Academic Press},
address = {San Diego},
pages = {61-73},
year = {2017},
isbn = {978-0-12-804600-5},
doi = {https://doi.org/10.1016/B978-0-12-804600-5.00004-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128046005000040},
author = {N.Y. Louis Lee},
keywords = {sudoku, mind game, piecemeal intellectual endeavours, analytic thinking, cross-cultural psychology, cognitive universals, piecemeal intellectual endeavors, holistic and analytic thinking},
abstract = {Cross-cultural psychological differences in human thinking remain a controversial and challenging subject. Critics have rightly pointed out that most existing studies on thinking have been performed on biased samples (eg, the recent notion of WEIRD: Western, educated, industrialised, rich, and democratic, in Henrich, Heine, & Norenzayan, 2010), and hence the universality of findings of such studies ought to be challenged. Yet, despite the many recent efforts in cross-cultural comparisons, two key questions remain underaddressed: are current methodologies in the psychology of thinking inherently biased toward explaining Western behavior? Or, to push even further, is the discipline of psychology itself such a product of Western culture that it limits its ability to uncover universal aspects of human thinking? This paper is a modest exploration of these two questions.}
}
@article{KIM201679,
title = {Cognitive hierarchy thinking based behavioral game model for IoT power control algorithm},
journal = {Computer Networks},
volume = {110},
pages = {79-90},
year = {2016},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2016.09.020},
url = {https://www.sciencedirect.com/science/article/pii/S138912861630319X},
author = {Sungwook Kim},
keywords = {Behavioral game, Cognitive hierarchy thinking model, Internet of Things, Power control algorithm, Mutually consistent behavior},
abstract = {The Internet of Things (IoT) describes a future world of interconnected physical objects, with several applications in the areas of smart environments. To implement the IoT concept, the research in the areas of power controlled circuits, embedded systems design, network protocols and control theory should be required. With the much advancement in these areas, the realization of IoT is becoming increasingly probable. In this paper, we propose a novel adaptive power control scheme for IoT systems. Based on the cognitive hierarchy thinking mechanism, our proposed scheme is designed as a new behavioral game model to adaptively control the power level. To effectively solve the power control problem in IoT systems, game theory is well-suited and an effective tool. The experimental result illustrates that our game-based approach can get an effective transmission power, which can make the communication rate maximal. Under dynamic IoT system environments, it is highly desirable property.}
}
@article{YUEYIM2024100319,
title = {A critical review of teaching and learning artificial intelligence (AI) literacy: Developing an intelligence-based AI literacy framework for primary school education},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100319},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100319},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X2400122X},
author = {Iris Heung {Yue Yim}},
keywords = {Artificial intelligence, AI literacy, Intelligence-based AI literacy framework, AI thinking, Primary school students, Systematic review, AI learning and teaching},
abstract = {Artificial intelligence (AI) literacy education mainly targets secondary and university students, often overlooking the unique needs of younger students. This gap in AI literacy primary school education presents theoretical and pedagogical challenges. Despite the pervasive influence of AI, which can exacerbate inequalities and raise ethical challenges, primary students often lack an understanding of AI principles and mechanisms. Recent developments in age-appropriate AI learning tools have extended AI literacy to primary schools, but AI literacy frameworks for this age group remain underdeveloped. This study aims to conceptualize AI literacy by analyzing existing theoretical frameworks and proposing a new inclusive AI literacy framework for young students. A scoping review is employed using four credible index databases, and 19 articles are selected, with 17 AI literacy frameworks identified across all educational levels, from early childhood to university. This study reveals that the predominant methodologies for developing AI literacy frameworks involve empirical research studies and literature reviews, adhering to national government or institutional standards. These frameworks commonly incorporate 1) Bloom's taxonomy or a similar progression framework, such as Use-Create-Modify, 2) constructionism, and 3) computer science perspectives such as theories of computation. The findings reveal that AI literacy is situated at the intersection of digital literacy, data literacy, computational thinking, and AI ethics, emphasizing the need for a transdisciplinary and interdisciplinary approach that encompasses both technological and societal impacts. However, the study argues that the current paradigms of AI literacy frameworks for young students often emphasize constructionist perspectives without fully considering the interactions between human and technological agents. This gap highlights the necessity for a new conceptual framework that acknowledges both human and non-human agents in AI literacy education for young students. The research contributes by conceptualizing AI literacy and guiding policymakers and curriculum designers to implement holistic AI literacy education for young students.}
}
@article{SARPKAYA20111163,
title = {Reflection of primary school 6th grade mathematics activities on the development of students mathematical thinking},
journal = {Procedia - Social and Behavioral Sciences},
volume = {15},
pages = {1163-1167},
year = {2011},
note = {3rd World Conference on Educational Sciences - 2011},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2011.03.256},
url = {https://www.sciencedirect.com/science/article/pii/S1877042811004356},
author = {Gulfem Sarpkaya and Gozdegul Arik Karamik and Neslihan Bulut},
keywords = { standards, learning and teaching process, classroom interaction},
abstract = {The purpose of this study is to investigate 6th grade math class activities with students in classroom interactions in terms of development of mathematical thinking respectively. Qualitative research methods, case study was used to work. The case has been appointed as the classroom activities. In this context, a primary school 6th grade mathematics teacher's video recordings were examined for 120minutes. Classroom communication is analyzed separately for each activity with regard to the categories. Results indicated that in learning and teaching process students and teacher carried out 8 sub-categories which belong to “Organize their mathematical thinking through communication” category.}
}
@article{BELL2024105956,
title = {Abstract 2151 First Year Chemistry CURE: An Introduction to Chemical Thinking through the Lens of Antimalarial Drug Design},
journal = {Journal of Biological Chemistry},
volume = {300},
number = {3, Supplement },
pages = {105956},
year = {2024},
note = {Discover BMB 2024},
issn = {0021-9258},
doi = {https://doi.org/10.1016/j.jbc.2024.105956},
url = {https://www.sciencedirect.com/science/article/pii/S0021925824003326},
author = {Jessica Bell and Dawn Marin and David Hecht and Ellis Bell},
keywords = {CURE, Drug development, Malaria}
}
@article{ANANDHI201741,
title = {CISTA-A: Conceptual model using indicators selected by systems thinking for adaptation strategies in a changing climate: Case study in agro-ecosystems},
journal = {Ecological Modelling},
volume = {345},
pages = {41-55},
year = {2017},
issn = {0304-3800},
doi = {https://doi.org/10.1016/j.ecolmodel.2016.11.015},
url = {https://www.sciencedirect.com/science/article/pii/S030438001630730X},
author = {Aavudai Anandhi},
keywords = {Adaptation strategies, Kansas agriculture, Climate change impacts, Conceptual model, Ogallala aquifer, Hard and soft systems thinking, Inductive and deductive approach},
abstract = {Adapting our ecosystems to climate change for sustainable management requires an understanding of three broad interconnected systems: ecosystems, climate systems and adaptive management and planning systems. Multiple factors shape adaptive responses to a changing climate because of the complexities and multi-disciplinary nature of these three systems. In this study, the conceptual model CISTA-A (CISTA for Agro-ecosystems) is developed using Indicators that are identified as using a Systems Thinking approach to Adaptation. CISTA addresses questions concerning “how to adapt” our ecosystems to climate change and has three or more layers: A base (element) layer has abiotic/biotic information (e.g. ecological, agro-hydrological, and meteorological data). One or more components (intermediate) layer(s) have ecological, agro-hydrological, and climatological indicators (e.g. length of the growing season and growing degree days) that affect the ecosystem. Indicators are identified and estimated from an element layer. In the final layer, the translation of information from indicators to adaptation strategies (incremental systems and transformational adaptation) depends on the degree of change and the level of adaptation. CISTA can stand alone or combine with existing crop/integrated assessment models to develop quantitative adaptation strategies. The use of 23 indicators and 3 empirical tests in the agro-ecosystems (AS) of Kansas, USA demonstrate the application of CISTA-A.}
}
@article{BARSALOU2017102,
title = {Define Design Thinking},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {3},
number = {2},
pages = {102-105},
year = {2017},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2017.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S2405872617301211},
author = {Lawrence W. Barsalou}
}
@article{CHEN2022108274,
title = {Can't stop thinking: The role of cognitive control in suppression-induced forgetting},
journal = {Neuropsychologia},
volume = {172},
pages = {108274},
year = {2022},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2022.108274},
url = {https://www.sciencedirect.com/science/article/pii/S0028393222001336},
author = {Suya Chen and Xinrui Mao and Yanhong Wu},
keywords = {Cognitive control, Memory suppression, Think/no-think paradigm, Intrusion, Cognitive control capacity},
abstract = {The ability to control unwanted memories is essential for emotional regulation and maintaining mental health. Previous evidence indicates that suppressing retrieval, which recruits executive control mechanisms to prevent unwanted memories entering consciousness, can cause forgetting, termed suppression-induced forgetting (SIF). Since these executive mechanisms involve multiple mental operations, we hypothesize that the efficacy of SIF may be limited by individuals’ capacity limitation of cognitive control. Here, we tested this hypothesis. Participants were assigned to two groups based on the median of their cognitive control capacity (CCC, estimated by the backward masking majority function task) and performed the think/no-think task with electrophysiological signals recorded. The results showed that the SIF effect was observed only in the high CCC group but not in the low CCC group. In accordance, repeated suppression attempts also resulted in a steeper reduction in intrusive thoughts in the high CCC group. Furthermore, ERP analysis revealed a decrease in recollection-related late parietal positivity (LPP) under the no-think condition in the high CCC group. A mediation analysis revealed that the reduced intrusive memories mediated the effect of CCC on SIF. These findings suggest that suppressing retrieval could reduce traces of the unwanted memories, making them less intrusive and harder to recall. More importantly, successful SIF is constrained by the capacity of cognitive control which may be used to ensure the coordination of multiple cognitive processes during suppression.}
}
@article{CARPO2024100001,
title = {Perspectives in computational design: A brief assessment of today's socio-technical context, promises, and challenges},
journal = {Perspectives in Architecture and Urbanism},
volume = {1},
number = {1},
pages = {100001},
year = {2024},
issn = {2950-2675},
doi = {https://doi.org/10.1016/j.pau.2024.100001},
url = {https://www.sciencedirect.com/science/article/pii/S2950267524000010},
author = {Mario Carpo},
keywords = {Computational design, Digital fabrication, Mass-customization, Robotic automation, Virtual reality, Generative artificial intelligence},
abstract = {Overwhelming factual evidence proves that digital technologies are much better suited to fixing at least some of today's socio-technical problems than the obsolete mechanical technologies we inherited from the twentieth century and which we are, at long last, phasing out. Everyone knows that digital mass-customization is cheaper, faster, smarter, and more environmentally sustainable, than the mechanical mass-production of standardized industrial goods; and everyone knows that the electronic transmission of information is cheaper, faster, smarter, and more environmentally sustainable, than the mechanical transportation of people and goods. Why then are so many neo-Luddite arguments being so vociferously and influentially evoked at all times and in all contexts to the detriment of sheer common sense? In short, why do digital technologies today—in computational design, and in general—have such a bad press?}
}
@article{LEE20147104,
title = {New Thinking Paradigm for Maintenance Innovation Design},
journal = {IFAC Proceedings Volumes},
volume = {47},
number = {3},
pages = {7104-7109},
year = {2014},
note = {19th IFAC World Congress},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20140824-6-ZA-1003.02519},
url = {https://www.sciencedirect.com/science/article/pii/S147466701642731X},
author = {Jay Lee and Maria Holgado and Hung-An Kao and Marco Macchi},
abstract = {Meanwhile the manufacturing paradigm changes towards predictive manufacturing, the role of maintenance function within manufacturing needs to be refined as a value creation function for achieving more sustainable operations. With the advent of internet of things (IoT), cloud computing, big data, PHM, and cyber-physical systems, e-maintenance necessitates new transformation. These changes are driving a new thinking paradigm for maintenance. This paper introduces new perspectives for maintenance innovation and proposes the value creation paths for maintenance transformation.}
}
@article{DUMONTHEIL201457,
title = {Development of abstract thinking during childhood and adolescence: The role of rostrolateral prefrontal cortex},
journal = {Developmental Cognitive Neuroscience},
volume = {10},
pages = {57-76},
year = {2014},
issn = {1878-9293},
doi = {https://doi.org/10.1016/j.dcn.2014.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S1878929314000516},
author = {Iroise Dumontheil},
keywords = {Adolescence, Cognitive control, Frontopolar cortex, Prefrontal cortex, Brodmann area 10, Reasoning},
abstract = {Rostral prefrontal cortex (RPFC) has increased in size and changed in terms of its cellular organisation during primate evolution. In parallel emerged the ability to detach oneself from the immediate environment to process abstract thoughts and solve problems and to understand other individuals’ thoughts and intentions. Rostrolateral prefrontal cortex (RLPFC) is thought to play an important role in supporting the integration of abstract, often self-generated, thoughts. Thoughts can be temporally abstract and relate to long term goals, or past or future events, or relationally abstract and focus on the relationships between representations rather than simple stimulus features. Behavioural studies have provided evidence of a prolonged development of the cognitive functions associated with RLPFC, in particular logical and relational reasoning, but also episodic memory retrieval and prospective memory. Functional and structural neuroimaging studies provide further support for a prolonged development of RLPFC during adolescence, with some evidence of increased specialisation of RLPFC activation for relational integration and aspects of episodic memory retrieval. Topics for future research will be discussed, such as the role of medial RPFC in processing abstract thoughts in the social domain, the possibility of training abstract thinking in the domain of reasoning, and links to education.}
}
@article{KAPSALI2011396,
title = {Systems thinking in innovation project management: A match that works},
journal = {International Journal of Project Management},
volume = {29},
number = {4},
pages = {396-407},
year = {2011},
note = {European Academy of Management (EURAM 2010) Conference},
issn = {0263-7863},
doi = {https://doi.org/10.1016/j.ijproman.2011.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S0263786311000044},
author = {Maria Kapsali},
keywords = {Systems thinking, Innovation project management},
abstract = {This paper discusses why conventional project management practices lead to the failure of publicly funded innovation deployment projects, and investigates how the use of systems thinking in project management can help projects be more successful. Based on 12 case studies of two EU innovation policies, we provide evidence that by using systemic project management, which entails providing flexibility in planning, communicating and controlling activities, innovation projects are more successful. This research refutes previous theory that claims that we should formalize to manage complexity and uncertainty. The key finding is that systems thinking methods provide the flexibility to manage innovativeness, complexity and uncertainty in innovation projects more successfully. Suggestions for further research include suggestions of how to embed flexibility in project management methods using the constructs of equifinality and causal embeddedness.}
}
@incollection{ALTMAN20201,
title = {Chapter 1 - Introduction: Smart thinking in the real world of complexity},
editor = {Morris Altman},
booktitle = {Smart Economic Decision-Making in a Complex World},
publisher = {Academic Press},
pages = {1-16},
year = {2020},
isbn = {978-0-12-811461-2},
doi = {https://doi.org/10.1016/B978-0-12-811461-2.00001-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128114612000018},
author = {Morris Altman},
keywords = {Smart thinking, Bounded rationality, Satisficing, Rationality, Decision-making environment, Capabilities, Heuristics, Errors and biases, Optimality, Externalities},
abstract = {A central theme of this chapter and of this book is that individuals are smart and this sense rational and can be expected to make smart choices. But these choices typically do not conform the behavioural norms specified by conventional economics for rational behaviour and, therefore, for rational choices. Smart thinking encompasses behaviour that is based on what the individuals deem to be the best path towards achieving their objectives. This behaviour is heavily affected by their decision-making environment as well as their decision-making capabilities, neither of which need be ideal nor fit for purpose. Smart thinking and smart decision-making therefore overlap with the concepts of bounded rationality and satisficing developed by Simon. But smart thinking or broadly rational behaviour might very well appear to be irrational from the prism of conventional economics because they typically don’t conform to conventional behavioural norms for rationality. I also argue, flowing upon Gigerenzer’s fast and frugal heuristics narrative, that adhering to these conventional behavioural norms can result in sub-optimal outcomes from the point of view of the individual decision-maker. Indeed, adopting different behavioural norms and making different choices often yield better outcomes. Being neoclassically rational can actually yield sub-optimal or inefficient outcomes. Ultimately, optimal decision-making norms is context dependent—one size does not fit all. These norms can involve either slow or fast thinking (Kahneman), dependent on circumstance. Also, in the smart thinking narrative errors and biases in decision-making can still take place, but they are correctable through experience and appropriate changes in decision-making capabilities and the decision-making environment. The latter can also correct for any externalities that are often part and parcel of smart or rational decision-making. This chapter also provides a chapter-by-chapter summary of this book.}
}
@article{TAKANO2010419,
title = {Concreteness of thinking and self-focus},
journal = {Consciousness and Cognition},
volume = {19},
number = {1},
pages = {419-425},
year = {2010},
issn = {1053-8100},
doi = {https://doi.org/10.1016/j.concog.2009.11.010},
url = {https://www.sciencedirect.com/science/article/pii/S1053810009001858},
author = {Keisuke Takano and Yoshihiko Tanno},
keywords = {Self-focus, Concreteness, Negative affect, Depression, Experience sampling},
abstract = {The present study used the experience sampling method to detect fluctuations in thinking, such as self-focus or concreteness in daily life, and to examine their relationship with depressive symptoms and concurrent negative affect. Thirty-one undergraduates recorded their negative affect, ruminative self-focus, and concreteness of thinking eight times a day for 1week. Multilevel modeling showed that individuals with increasing levels of depression showed lower levels of concreteness in their daily thinking. Further analysis revealed a significant positive association between momentary ruminative self-focus and concurrent negative affect only with low concreteness of thinking. These results suggested that individuals with increasing levels of depression chronically process self-related information on an abstract level, which reflects a malfunction of their self-regulatory cycle and might serve to maintain or even exacerbate dysphoric moods.}
}
@article{ABRAHAM2008106,
title = {Thinking about the future versus the past in personal and non-personal contexts},
journal = {Brain Research},
volume = {1233},
pages = {106-119},
year = {2008},
issn = {0006-8993},
doi = {https://doi.org/10.1016/j.brainres.2008.07.084},
url = {https://www.sciencedirect.com/science/article/pii/S0006899308018246},
author = {Anna Abraham and Ricarda I. Schubotz and D. Yves {von Cramon}},
keywords = {Mental time travel, Prospection, Episodic memory, Semantic memory, Self-referential thinking, Functional neuroimaging},
abstract = {The ability to ponder the future is a hallmark of human imagination. Neuroimaging research so far has focused on episodic prospection, or thinking about hypothetical future personal events. What has received no attention is semantic prospection or contemplating hypothetical future world events. Using functional magnetic resonance imaging (fMRI), we show a number of functional dissociations in the brain when comparing future and past thinking across personal and non-personal conceptual domains. In the prefrontal cortex, the processes of information integration and self-referential thinking in the anterior medial prefrontal cortex were differentiated from those pertaining to generative construction along the dorsal medial prefrontal cortex and adjoining regions in the superior frontal gyrus. Dorsal parts of the lateral inferior parietal lobe showed lateralization effects as a function of the divergent or convergent nature of the retrieval process corresponding to whether the accessed information referred to hypothetical or real events. While ventral parts of the bilateral inferior parietal lobe were preferentially engaged during both personal past and personal future thinking, dissociations between the areas involved in personal past versus personal future thinking were found along the medial parietal wall. All in all, these findings provide novel and critical insights into the complex interactions between different processes involved in prospective and retrospective thought as modulated by the type of processed content.}
}
@article{DIMOV2024114427,
title = {Dynamics of entrepreneurial well-being: Insights from computational theory},
journal = {Journal of Business Research},
volume = {172},
pages = {114427},
year = {2024},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2023.114427},
url = {https://www.sciencedirect.com/science/article/pii/S0148296323007865},
author = {Dimo Dimov and Joseph Pistrui},
keywords = {Entrepreneurship, Entrepreneur, Well-being, System dynamics, Computational theory, Simulation},
abstract = {We explore the dynamics of entrepreneurial performance and well-being through computational theory. Our model connects mechanisms of work-related motivation and strain processes with the unfolding of an entrepreneurial process. The simulation results show that how an entrepreneur’s energy ebbs and flows over their journey, charting certain venturing performance and levels of well-being, can be linked to distinct interplays of ambition, skill, self-regulation, and dynamism. Our work contributes a holistic account of entrepreneurship and well-being, stimulates computational modelling, and enriches discussions about the entrepreneurial future of work.}
}
@article{HICKS2021,
title = {Paired Multiple-Choice Questions Reveal Students’ Incomplete Statistical Thinking about Variation during Data Analysis},
journal = {Journal of Microbiology & Biology Education},
volume = {22},
number = {2},
year = {2021},
issn = {1935-7877},
doi = {https://doi.org/10.1128/jmbe.00112-21},
url = {https://www.sciencedirect.com/science/article/pii/S193578772100112X},
author = {Jenna Hicks and Jessica Dewey and Michael Abebe and Yaniv Brandvain and Anita Schuchardt},
keywords = {education, assessments, statistics, undergraduate, variation},
abstract = {Biologists consider variability during biological investigations. A robust quantitative understanding of variability is particularly important during data analysis, where statistics are used to quantify variation and draw conclusions about phenomena while accounting for variation.
ABSTRACT
Biologists consider variability during biological investigations. A robust quantitative understanding of variability is particularly important during data analysis, where statistics are used to quantify variation and draw conclusions about phenomena while accounting for variation. Many students struggle to correctly apply a quantitative understanding of variation to statistically analyze data. We present quantitative and qualitative analyses of introductory biology students’ responses on two pairs of multiple-choice questions querying two concepts related to the quantitative analysis of variation. More students correctly identify a mathematical expression of variation than correctly interpret it. Many students correctly interpret a nonsignificant p-value in the context of a very small sample size, but fewer students do so in the context of a large sample size. These results imply that many students have an incomplete quantitative understanding of variation. These findings suggest that instruction focusing on conceptual understanding, not procedural problem solving, may elevate students’ quantitative understanding of variation.}
}
@article{MASHAL20112045,
title = {Thinking maps enhance metaphoric competence in children with autism and learning disabilities},
journal = {Research in Developmental Disabilities},
volume = {32},
number = {6},
pages = {2045-2054},
year = {2011},
issn = {0891-4222},
doi = {https://doi.org/10.1016/j.ridd.2011.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S0891422211003155},
author = {Nira Mashal and Anat Kasirer},
keywords = {Metaphors, Intervention, Autism, Learning disabilities, Executive functions},
abstract = {The primary goal of the current study was to examine the ability of children with autism (ASD) and children with learning disabilities (LD) to improve their metaphoric competence by an intervention program using “thinking maps”. Twenty ASD children, 20 LD, and 20 typically developed (TD) children were tested on metaphors and idioms comprehension tests, homophone meaning generation test, and fluency tests. Both ASD and LD groups performed poorly compared with TD on all tests, with the LD group outperformed the ASD group in the executive function tests. The results indicate that the LD group was able to use the “thinking maps” to understand metaphors that were encountered for the first time more efficiently than the ASD group. Furthermore, in the autistic group the homophone meaning generation test, associated with mental flexibility mechanism, correlated with novel metaphors understanding, which do not rely on prior knowledge. In the learning disabilities group, conventional metaphors understanding correlated with the homophone meaning generation test.}
}
@article{HUNT2019100707,
title = {Gina’s mathematics: Thinking, tricks, or “teaching”?},
journal = {The Journal of Mathematical Behavior},
volume = {56},
pages = {100707},
year = {2019},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2019.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S0732312318301299},
author = {Jessica H. Hunt and Beth L. MacDonald and Juanita Silva},
keywords = {Learning disability, Composite unit, Fractions, Constructivism, Adaptation},
abstract = {Students with learning disabilities display a diverse array of factors that interplay with their mathematical understanding. Our aim in this paper is to discuss the extent to which one case study elementary school child with identified learning disabilities (LDs) made sense of composite units and unit fractions. We present analysis and results from multiple sessions conducted during a teaching experiment cast as one-on-one intervention. Results of a multi-phase qualitative analysis reveal two themes evident in the child’s thinking structures across the sessions: (a) Gina’s accommodations over time versus traditional progressions, and (b) Persistent factors that interacted with the child’s reasoning. Throughout the analysis, we raise questions about the child’s reasoning and what the child’s apparent knowing and learning was relying upon. When well-intentioned researchers or educators provide children interventions that promote procedures and replication of teacher-taught strategies, not only are they not serving their children’s mathematics learning needs, they may be preventing them from engaging in, reflecting upon, and coordinating actions that support the children to accommodate their thinking structures and advance their learning. Discussion and implications are shared.}
}
@article{HONG2014263,
title = {Here/In This Issue and There/Abstract Thinking: Personalized Psychiatry: Are We Almost There?},
journal = {Journal of the American Academy of Child & Adolescent Psychiatry},
volume = {53},
number = {3},
pages = {263-264},
year = {2014},
issn = {0890-8567},
doi = {https://doi.org/10.1016/j.jaac.2013.12.014},
url = {https://www.sciencedirect.com/science/article/pii/S0890856714000070},
author = {David S. Hong}
}
@article{CHERMAHINI2010458,
title = {The (b)link between creativity and dopamine: Spontaneous eye blink rates predict and dissociate divergent and convergent thinking},
journal = {Cognition},
volume = {115},
number = {3},
pages = {458-465},
year = {2010},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2010.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S0010027710000715},
author = {Soghra Akbari Chermahini and Bernhard Hommel},
keywords = {Creativity, Divergent thinking, Cognitive flexibility, Dopamine},
abstract = {Human creativity has been claimed to rely on the neurotransmitter dopamine, but evidence is still sparse. We studied whether individual performance (N=117) in divergent thinking (alternative uses task) and convergent thinking (remote association task) can be predicted by the individual spontaneous eye blink rate (EBR), a clinical marker of dopaminergic functioning. EBR predicted flexibility in divergent thinking and convergent thinking, but in different ways. The relationship with flexibility was independent of intelligence and followed an inverted U-shape function with medium EBR being associated with greatest flexibility. Convergent thinking was positively correlated with intelligence but negatively correlated with EBR, suggesting that higher dopamine levels impair convergent thinking. These findings support the claim that creativity and dopamine are related, but they also call for more conceptual differentiation with respect to the processes involved in creative performance.}
}
@article{WANG2021100968,
title = {RETRACTED: Interdisciplinary approaches to arts education: Exploring the link between creative thinking and mastering exact sciences},
journal = {Thinking Skills and Creativity},
volume = {42},
pages = {100968},
year = {2021},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2021.100968},
url = {https://www.sciencedirect.com/science/article/pii/S1871187121001838},
author = {Bin Wang and Ping-ping Li},
abstract = {This article has been retracted: please see Elsevier Policy on Article Withdrawal (https://www.elsevier.com/about/our-business/policies/article-withdrawal). This article has been retracted at the request of the Editors-in-Chief. After a thorough investigation, the Editors have concluded that the acceptance of this article was based upon the positive advice of two illegitimate reviewer reports. The reports were submitted from email accounts which were provided to the journal as suggested reviewers during the submission of the article. Although purportedly real reviewer accounts, the Editors have concluded that these were not of appropriate, independent reviewers. This manipulation of the peer-review process represents a clear violation of the fundamentals of peer review, our publishing policies, and publishing ethics standards. Apologies are offered to the reviewers whose identity was assumed and to the readers of the journal that this deception was not detected during the submission process.}
}
@article{FU2024130444,
title = {Re-thinking methane storage mechanism in highly metamorphic coalbed reservoirs — A molecular simulation considering organic components},
journal = {Energy},
volume = {293},
pages = {130444},
year = {2024},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2024.130444},
url = {https://www.sciencedirect.com/science/article/pii/S0360544224002159},
author = {Shenguang Fu and Liang Wang and Shuohao Li and Sijia Ni and Yuanping Cheng and Xiaolei Zhang and Shimin Liu},
keywords = {CH storage, Highly metamorphic coal, Coal organic components, Molecular dynamic simulation, Filling balanced distance},
abstract = {Highly metamorphic coal plays a significant role in China's energy development plan owing to its high calorific value. Its complex organic composition provides outstanding storage capabilities for methane (clean and efficient unconventional natural gas), which leads to terrible gas outburst hazards. Minimizing the main storage sites of CH4 (micropores) through organic solvent extraction provides an efficient and safe route for exploiting coal and natural gas energy sources. This phenomenon can be elucidated by the removal of the chemical components that have an adverse impact on the micropore filling theory. In this study, we constructed macromolecular models of highly metamorphic coal, and relative dynamic simulations under experiment and field conditions are performed. The corresponding CH4 storage capacity and spatial coordination distribution of the coal after five treatments were derived. Combined with the results of the micropore filling theory, it was shown that the equilibrium distance of CH4 filling in the micropore increased with the degree of extraction (from 0.351 nm for XT to 0.572 nm for XT-DMF). Also, the trend of CH4 adsorption position in the representative samples (the number of monolayer affixations decreased from 10 to 9) provides crucial support for the conclusions, and the low-potential region with a high potential difference contributes to CH4 stability. The breakthrough of this study will provide strong support and a solid theoretical basis for the efficient and safe exploitation of CBM (Coalbed methane) energy resources.}
}
@article{PENNOCK2018146,
title = {Professor Bernard (“Bernie”) Roth – His journey from kinematics to design thinking},
journal = {Mechanism and Machine Theory},
volume = {125},
pages = {146-168},
year = {2018},
issn = {0094-114X},
doi = {https://doi.org/10.1016/j.mechmachtheory.2017.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0094114X17311941},
author = {Gordon R. Pennock},
keywords = {Kinematics, Mechanism and machine science, Robotics, Stanford d.school, Creativity, Innovation, Design thinking},
abstract = {Dr. Bernard Roth (see Fig. 1) is the Rodney H. Adams Professor of Engineering at Stanford University and the co-founder and current Academic Director of the Hasso Plattner Institute of Design (also known as the d.school). His long and distinguished academic career at Stanford consists of significant and pioneering accomplishments in teaching, research, and consulting on various aspects of mechanical engineering, with a special emphasis on mechanism design. Bernie has established a worldwide reputation in the kinematic synthesis and analysis of mechanisms and is a pioneer in the field of computer controlled robot manipulators. Bernie has investigated the mathematical theory of rigid body motions and the application of these motions to the kinematic synthesis of mechanisms. He has placed a special emphasis on geometric kinematics over the more traditional time-based formulations which have allowed him to make important contributions to Burmester theory, curvature theory, and screw theory. His text book, Theoretical Kinematics, co-authored with Oene Bottema, is regarded by many kinematicians as the most elegant and rigorous treatment of this applied science. Also, his popular book The Achievement Habit: Stop Wishing, Start Doing, and Take Command of Your Life describes some of the innovative techniques that he employs in the classes, workshops, and short courses that he has offered on creativity and design thinking.}
}
@article{WOO2022101193,
title = {Problem solved, but how? An exploratory study into students’ problem solving processes in creative coding tasks},
journal = {Thinking Skills and Creativity},
volume = {46},
pages = {101193},
year = {2022},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2022.101193},
url = {https://www.sciencedirect.com/science/article/pii/S1871187122001948},
author = {Karen Woo and Garry Falloon},
keywords = {Problem solving, Computational thinking, Tinkering, Coding, Middle-school},
abstract = {Problem solving capabilities have often been reported by teachers as a key benefit from creative coding activities in school-age children. However, few studies to date have defined problem solving, and investigated how it is operationalised in interdisciplinary creative coding tasks. This study aims to build knowledge about students’ use of computational thinking and computer science concepts for problem solving when coding animated narratives. The research investigated students’ coding processes using data gathered from audio and device display recordings and semi-structured interviews. Results suggest limitations to the use of creative coding tasks if the expectation is to develop computational thinking and systematic problem solving strategies, or learn basic computer science concepts. They revealed that novice students rarely solved coding problems using optimal technically-based strategies despite being given explicit instruction on their use, opting instead to bypass problems by adjusting intended outcomes, or by using low level code translation strategies. Results demonstrate that engaging computational thinking or even demonstrating understanding of basic computer science concepts was not a requirement to produce a viable creative coding outcome. This study contributes new understanding of students’ coding practices when engaged in creative coding tasks in regular, non-specialist classrooms. Its findings challenge the commonly-held assumption that coding is a natural ‘vehicle’ to develop computational thinking and systematic approaches to problem solving. It also questions the learning that results from the non-technical, inefficient and often ineffective problem solving practices students employ during ‘creative coding’ tasks, that are frequently used by non-specialist teachers in response to curriculum requirements.}
}
@incollection{DAWES201516,
title = {Probabilistic Thinking},
editor = {James D. Wright},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {16-22},
year = {2015},
isbn = {978-0-08-097087-5},
doi = {https://doi.org/10.1016/B978-0-08-097086-8.42162-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780080970868421628},
author = {Robyn M. Dawes},
keywords = {Chance, Heuristics, Information theory, Risk, Thought},
abstract = {While games of chance have been played for thousands of years, and while experienced players often had good intuitive ideas of the relative frequencies of various outcomes, the concept of probability as referring to the ratio of favorable outcomes to total outcomes of a ‘fair’ gambling device emerged only 500 or so years ago in Western societies. That allowed evaluation of new games not yet played and later led to a more abstract conception of probability as a measure satisfying certain conditions (‘axioms’). Only in the past 150 years or so has probability had a major role in science and only in the last 50 years or so in everyday life – as, for example, in evaluating medical outcomes or technological risks or manufacturer liability. Thus, especially in attempting to assess probability in everyday situations, our intuitions are often deficient – more so than those concerning quantity, space, and time. The major problem is not, however, one of making random errors in probability judgments but of making systematic ones that result from a number of well-known and research systematic cognitive biases and heuristics, which are described in this article. These systematic departures from rational assessment do not imply that coherent and accurate probabilistic thinking is (anywhere near) impossible, but that when departures from coherence and accuracy occur, they tend to follow a predictable pattern.}
}
@article{BOOKER2010411,
title = {Developing Algebraic Thinking: using problem-solving to build from number and geometry in the primary school to the ideas that underpin algebra in high school and beyond},
journal = {Procedia - Social and Behavioral Sciences},
volume = {8},
pages = {411-419},
year = {2010},
note = {International Conference on Mathematics Education Research 2010 (ICMER 2010)},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2010.12.057},
url = {https://www.sciencedirect.com/science/article/pii/S1877042810021622},
author = {George Booker and Will Windsor},
keywords = {Algebraic thinking, Problem-solving, Constructivism},
abstract = {Algebraic thinking addresses general mathematical relationships, expressing them in increasingly sophisticated ways as activities move from seeing patterns in number, geometry and measurement to determining solutions to more and more complex problems. This paper reports on an ongoing research project investigating how working on, representing and solving structurally related problems in a variety of ways prepares students to think algebraically as they articulate and generalise their solution processes. Examples of problems and their solutions by students in a Year 7 primary classroom will be presented and analysed to highlight how a deeper investigation of mathematical problems can instigate student discourse that encourages general ways of thinking underpinning algebraic reasoning rather than simply using particular strategies or procedures for classes of problems. The results obtained so far suggest that students are able to build general ways of thinking that will lead them to an algebraic perspective of mathematics beyond the mechanics and procedures often associated with algebra. Not only will this build confidence in ways of operating that are their own, such a development also parallels the historical development of algebra itself.}
}
@incollection{DUBOIS2024xi,
title = {Preface: Pushing the boundaries of cardiovascular research through interdisciplinary approaches, innovative thinking and new technologies},
editor = {Nicole Dubois},
series = {Current Topics in Developmental Biology},
publisher = {Academic Press},
volume = {156},
pages = {xi-xii},
year = {2024},
booktitle = {Heart Development and Disease},
issn = {0070-2153},
doi = {https://doi.org/10.1016/S0070-2153(24)00043-7},
url = {https://www.sciencedirect.com/science/article/pii/S0070215324000437},
author = {Nicole C. Dubois}
}
@article{MEIER2024S91,
title = {Wellbeing Economy and Health: an applied case study of co-producing system thinking and modelling tools to inform local and national policy in England and Scotland},
journal = {The Lancet},
volume = {404},
pages = {S91},
year = {2024},
note = {Public Health Science: A National Conference Dedicated to New Research in UK Public Health},
issn = {0140-6736},
doi = {https://doi.org/10.1016/S0140-6736(24)01993-7},
url = {https://www.sciencedirect.com/science/article/pii/S0140673624019937},
author = {Petra Meier},
abstract = {Background
A Wellbeing Economy describes an economic system that places the wellbeing of current and future generations at its core, with the economy seen as a means to improved health, collective wellbeing and environmental sustainability. This paper reports our experiences of, and learning from, creating systems thinking, analysis and modelling tools for use by policy actors, and of forging university-policy partnerships to drive transformative action towards health and wellbeing.
Methods
The Systems Science in Public Health and Health Economics Research (SIPHER) works through co-production partnerships with local (Sheffield City Council), regional (Greater Manchester Combined Authority) and national (Scottish Government; Public Health Scotland) policy organisations. We designed, deployed, and triangulated between, different methods to gain an in-depth understanding of the respective policy systems, including: policy and stakeholder analysis, interviews; participatory systems mapping workshops; evidence gap mapping; dynamic spatial microsimulation and system dynamic modelling; elicitation of public preferences across different wellbeing economy outcomes; a decision support infrastructure; and community panels to shape and scrutinise our work.
Findings
Our focus was on exploring the public health and equity impacts of housing, income, work and community wealth building policies, including in response to pandemic, cost-of-living crisis and fuel poverty. Qualitative systems methods were particularly useful in articulating the multiple goals and priorities of a policy system around a shared, cohesive wellbeing narrative. Computational modelling and decision tools provided insights into targeting options, visualising trade-offs between different policy priorities (eg, overall health gains, equity gains or policy cost).
Interpretation
Co-produced qualitative analyses, data, computational models, and decision tools aided deeper exploration of systemic effects, including feedback processes and co-benefits/trade-offs that link such policies to future health and wellbeing. The process of applying diverse systems methods also led to a broadening of researcher perspectives, shifting ways-of-doing and facilitating both cross-disciplinary and cross-sector discussion and collaboration.
Funding
SIPHER is funded through the UK Prevention Research Partnership (MR/ S037578/1; MR/ S037578/2), which is funded by the British Heart Foundation, Cancer Research UK, Chief Scientist Office of the Scottish Government Health and Social Care Directorates, Engineering and Physical Sciences Research Council, Economic and Social Research Council, Health and Social Care Research and Development Division (Welsh Government), Medical Research Council, National Institute for Health Research (NIHR), Natural Environment Research Council, Public Health Agency (Northern Ireland), The Health Foundation and Wellcome.}
}
@article{JEN2010154,
title = {What is the source of cultural differences? -- Examining the influence of thinking style on the attribution process},
journal = {Acta Psychologica},
volume = {133},
number = {2},
pages = {154-162},
year = {2010},
issn = {0001-6918},
doi = {https://doi.org/10.1016/j.actpsy.2009.10.011},
url = {https://www.sciencedirect.com/science/article/pii/S0001691809001619},
author = {Chun-Hui Jen and Yunn-Wen Lien},
keywords = {Attribution, Dual-process theory of cognition, Cognitive style, Cross-cultural differences, Holistic thinking},
abstract = {The present research is intended to find out whether individuals with analytic or holistic thought have different attribution processes. Cross-cultural research has suggested that East Asians, who tend to have a holistic thought pattern, differ in cognitive process from Westerners, who tend to engage in analytic thought. However, studies that found cultural difference in attribution process may have non-equivalence problems that make it hard to interpret the causal relationship between thinking style and attribution process. The present research extends this by measuring participants’ thinking style within a single culture in order to ensure equivalence on potentially confounding variables such as prior knowledge and cognitive capacity. Two experiments demonstrate that both types of thinkers have identical attribution processes and suggest different thinking styles might relate to different tendencies toward situational information, but not to the attribution process itself.}
}
@article{XU2020101427,
title = {Teachers’ predictions of students’ mathematical thinking related to problem posing},
journal = {International Journal of Educational Research},
volume = {102},
pages = {101427},
year = {2020},
issn = {0883-0355},
doi = {https://doi.org/10.1016/j.ijer.2019.04.005},
url = {https://www.sciencedirect.com/science/article/pii/S0883035518315933},
author = {Binyan Xu and Jinfa Cai and Qimeng Liu and Stephen Hwang},
keywords = {Mathematical problem posing, Student thinking, Teachers’ predictions},
abstract = {In this study, we used two pattern-related problem-posing tasks to investigate the mathematical problem posing of fifth-, sixth-, seventh-, and eighth-grade Chinese students. We also explored their teachers’ predictions about their students’ problem posing. We found that students in higher grades were more likely than those in lower grades to pose problems that involved functional relationships in both posing task situations. A posed problem involves a functional relationship when a mathematical function is the basis of the problem. We also found a mismatch between the problems that the students generated and those that their teachers predicted they would pose. Compared to the actual problems posed by the students, the problems predicted by the teachers were more likely to involve functional relationships about the pattern and less likely to involve a particular term in the pattern. Moreover, at the higher grades, the mathematical thinking related to problem posing predicted by the teachers was of a higher order than was evidenced by the problems posed by the students. Implications and future directions for research are discussed.}
}
@article{LESINSKI2015168,
title = {Application of Value Focused Thinking and Fuzzy Systems to Assess System Architecture},
journal = {Procedia Computer Science},
volume = {61},
pages = {168-175},
year = {2015},
note = {Complex Adaptive Systems San Jose, CA November 2-4, 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.09.182},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915030124},
author = {Gene Lesinski},
keywords = {Architecture, Assessment, Fuzzy Systems, Value Focused Thinking},
abstract = {Since a majority of resources are obligated during the design phase of a system lifecycle, critical assessment of candidate functional and system architectures is vital to identify optimal architectures before proceeding to subsequent lifecycle phases. Common challenges associated with generation and evaluation of system functional architectures include search of the expansive design space and assessment of key performance attributes that are particularly “fuzzy” and qualitative in early architecture development. Several assessment approaches have been presented in the literature to address the assessment challenge to include Quality Function Deployment (QFD), Analytical Hierarchy Process (AHP), Value-Focused Thinking (VFT), and fuzzy logic. In this research we combine the use of value functions and fuzzy assessment to assess a functional and system architecture. There are several benefits of a methodology that combines value-focused thinking and fuzzy assessment. A distinct advantage of the methodology presented is the explicit inclusion of the customer in the assessment process through validation of the TPM value functions Involving the customer in TPM value function development and validation ensures the customer has direct input regarding the TPMs and their associated value across the range of discourse The methodology presented is flexible enough to assess architectures early in the process when things are “fuzzy” as well as later when subsystem and component performance are well defined. The methodology can also be used to analyze and assess impacts of interface changes within the system architecture. . The methodology is domain independent and can be coupled with executable models linked to scenarios. The assessment methodology is applied to the architecture for a soldier knowledge acquisition system for which the key performance attributes are affordability, performance, flexibility, updateability, and availability.}
}
@article{PETERS2010138,
title = {Episodic Future Thinking Reduces Reward Delay Discounting through an Enhancement of Prefrontal-Mediotemporal Interactions},
journal = {Neuron},
volume = {66},
number = {1},
pages = {138-148},
year = {2010},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2010.03.026},
url = {https://www.sciencedirect.com/science/article/pii/S0896627310001972},
author = {Jan Peters and Christian Büchel},
keywords = {SYSNEURO},
abstract = {Summary
Humans discount the value of future rewards over time. Here we show using functional magnetic resonance imaging (fMRI) and neural coupling analyses that episodic future thinking reduces the rate of delay discounting through a modulation of neural decision-making and episodic future thinking networks. In addition to a standard control condition, real subject-specific episodic event cues were presented during a delay discounting task. Spontaneous episodic imagery during cue processing predicted how much subjects changed their preferences toward more future-minded choice behavior. Neural valuation signals in the anterior cingulate cortex and functional coupling of this region with hippocampus and amygdala predicted the degree to which future thinking modulated individual preference functions. A second experiment replicated the behavioral effects and ruled out alternative explanations such as date-based processing and temporal focus. The present data reveal a mechanism through which neural decision-making and prospection networks can interact to generate future-minded choice behavior.}
}
@article{BICAKCI20222467,
title = {Thinking multiculturality in the age of hybrid threats: Converging cyber and physical security in Akkuyu nuclear power plant},
journal = {Nuclear Engineering and Technology},
volume = {54},
number = {7},
pages = {2467-2474},
year = {2022},
issn = {1738-5733},
doi = {https://doi.org/10.1016/j.net.2022.01.033},
url = {https://www.sciencedirect.com/science/article/pii/S1738573322000687},
author = {A. Salih Bıçakcı and Ayhan Gücüyener Evren},
keywords = {Nuclear power plants, Nuclear security, Security culture, Nuclear security culture, National culture, Cyber-physical security},
abstract = {Nuclear Power Plants (NPPs) are the most protected facilities among all critical infrastructures (CIs). In addition to physical security, cyber security becomes a significant concern for NPPs since swift digitalization and overreliance on computer-based systems in the facility operations transformed NPPs into targets for cyber/physical attacks. Despite technical competencies, humans are still the central component of a resilient NPP to develop an effective nuclear security culture. Turkey is one of the newcomers in the nuclear energy industry, and Turkish Akkuyu NPP has a unique model owned by an international consortium. Since Turkey has limited experience in nuclear energy industry, specific multinational and multicultural characteristics of Turkish Akkuyu NPP also requires further research in terms of the Facility's prospective nuclear security. Yet, the link between “national cultures” and “nuclear security” is underestimated in nuclear security studies. By relying on Hofstede's national culture framework, our research aims to address this gap and explore possible implications of cross-national cultural differences on nuclear security. To cope with security challenges in the age of hybrid threats, we propose a security management model which addresses the need for cyber-physical security integration to cultivate a robust nuclear security culture in a multicultural working environment.}
}
@article{BUCKINGHAM20141403,
title = {Computational Science for Undergraduate Biologists via QUT.Bio.Excel},
journal = {Procedia Computer Science},
volume = {29},
pages = {1403-1412},
year = {2014},
note = {2014 International Conference on Computational Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.05.127},
url = {https://www.sciencedirect.com/science/article/pii/S1877050914003044},
author = {Lawrence Buckingham and James M. Hogan},
keywords = {Bioinformatics, Molecular Biology, Computational Thinking, Education.},
abstract = {Molecular biology is a scientific discipline which has changed fundamentally in character over the past decade to rely on large scale datasets – public and locally generated - and their computational analysis and annotation. Undergraduate education of biologists must increasingly couple this domain context with a data-driven computational scientific method. Yet modern programming and scripting languages and rich computational environments such as R and MATLAB present significant barriers to those with limited exposure to computer science, and may require substantial tutorial assistance over an extended period if progress is to be made. In this paper we report our experience of undergraduate bioinformatics education using the familiar, ubiquitous spreadsheet environment of Microsoft Excel. We describe a configurable extension called QUT.Bio.Excel, a custom ribbon, supporting a rich set of data sources, external tools and interactive processing within the spreadsheet, and a range of problems to demonstrate its utility and success in addressing the needs of students over their studies.}
}
@article{SANDERS20121134,
title = {Investigating the Relationship Between Musical Training and Mathematical Thinking in Children},
journal = {Procedia - Social and Behavioral Sciences},
volume = {55},
pages = {1134-1143},
year = {2012},
note = {3rd. International Conference on New Horizons in Education - INTE 2012},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2012.09.607},
url = {https://www.sciencedirect.com/science/article/pii/S1877042812040694},
author = {Edel Sanders},
keywords = {music, music education, mathematics, mathematical thinking, mathematics education, cognitive correlates, spatial reasoning, spatial-temporal reasoning, Mozart Effect, Makam Effect, Ellington Effect},
abstract = {This study examines the potential for music education to enhance children's mathematical thinking. Specification of potential cognitive correlates between musical and mathematical components is sought and underpins the design (3 variables x 2 conditions each=6 groups). Nearly 200 children aged 7-8 years experienced weekly music lessons (duration=9 months). Lessons emphasized melody, rhythm or form; in half of the classes, the teacher made the musical-mathematical parallels explicit. Apart from the specific musical-mathematical foci, the lesson content was kept as constant as possible within primary school settings. Pre-tests and post-tests in musical, creative, spatial and mathematical thinking were administered. Statistical analyses will examine improvement over time while considering differences among three musical components and two conditions for each. This research addresses concerns that governments’ quests for higher standards in mathematics may result in impoverished curricula with limited access to the arts. If it is shown that musical training appears to benefit logical thinking, as hypothesized, it may add to a growing body of research suggesting that policy-makers and educationalists reconsider curriculum balance.}
}
@article{MENDOZA2019831,
title = {A methodological framework for the implementation of circular economy thinking in higher education institutions: Towards sustainable campus management},
journal = {Journal of Cleaner Production},
volume = {226},
pages = {831-844},
year = {2019},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2019.04.060},
url = {https://www.sciencedirect.com/science/article/pii/S0959652619311370},
author = {Joan Manuel F. Mendoza and Alejandro Gallego-Schmid and Adisa Azapagic},
keywords = {Corporate sustainability, Resource efficiency, Social responsibility, Stakeholder engagement, Sustainable campus management},
abstract = {Many higher education institutions have started to develop academic curricula, research capacity and outreach activities related to circular economy. However, little is known yet on how to apply circular economy thinking to sustainable campus management. In an attempt to address this gap, this paper proposes a methodological framework and guidance to help universities develop a circular economy strategy aimed at improving resource efficiency and environmental sustainability of their campus operations. The approach is compatible with sustainability management frameworks as it follows the well-known iterative process of planning, doing, checking and improving. The framework involves three main steps: analysis of current situation with respect to circular economy within the organisation; stakeholder engagement to get a buy-in and inform the development of a circular economy strategy; and implementation of the strategy following the guidelines provided within the framework. Application of the framework is illustrated through a case of the University of Manchester, demonstrating how circular economy principles can be used to benchmark existing sustainability policies and action plans. The paper also shows how engaging key stakeholders can be used to identify challenges and opportunities for embedding circular economy thinking into the university's sustainability management systems. The proposed framework and the guidelines for implementation of circular economy thinking are generic and can be applied by any institution across the higher education sector.}
}
@article{WANG201792,
title = {Neural correlates of serial order effect in verbal divergent thinking},
journal = {Neuropsychologia},
volume = {99},
pages = {92-100},
year = {2017},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2017.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0028393217300817},
author = {Meijuan Wang and Ning Hao and Yixuan Ku and Roland H. Grabner and Andreas Fink},
keywords = {Serial order effect, Divergent thinking, Creativity, Alpha, EEG},
abstract = {During the course of divergent thinking (DT), the number of generated ideas decreases while the originality of ideas increases. This phenomenon is labeled as serial order effect in DT. The present study investigated whether different executive processes (i.e., updating, shifting, and inhibition) specifically contribute to the serial order effect in DT. Participants' executive functions were measured by corresponding experimental tasks outside of the EEG lab. They were required to generate original uses of conventional objects (alternative uses task) during EEG recording. The behavioral results revealed that the originality of ideas was higher in later stage of DT (i.e., Epoch 2) than in its earlier stage (i.e., Epoch 1) for higher-shifting individuals, but showed no difference between two epochs for lower-shifting individuals. The EEG results revealed that lower-inhibition individuals showed stronger upper alpha (10–13Hz) synchronization in left frontal areas during Epoch 1 compared to during Epoch 2. For higher-inhibition individuals, no changes in upper alpha activity from Epoch 1 to Epoch 2 were found. These findings indicated that shifting and inhibition contributed to create a serial order effect in DT, perhaps because individuals suppress interference from obvious ideas and switch to new idea categories during DT, thus more original ideas appear as time passes by.}
}
@article{SJODAHL2023100573,
title = {Abstracting and decomposing in a visual programming environment},
journal = {International Journal of Child-Computer Interaction},
volume = {36},
pages = {100573},
year = {2023},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2023.100573},
url = {https://www.sciencedirect.com/science/article/pii/S2212868923000107},
author = {Anna Sjödahl and Andreas Eckert},
keywords = {21st century abilities, Computational thinking, Abstraction, Decomposition, Elementary education},
abstract = {A growing body of research concerned with computational thinking (CT) has emerged the last couple of years, but there is still a lack of consensus about the definition of CT. There are also gaps in the understanding of how young children manifest CT. With this paper, we contribute to the field by taking an action perspective with the CT of K-3 students. The analysis focus on iterative acts of abstraction and decomposition as a core process that elicits development of CT. We call these iterative acts the Abstraction/Decomposition spiral (AD spiral). By illustrating the AD spiral through the actions of two first grade students, the analysis shows how visual representation of an emerging solution, and the development of a plan are two important elements when young students solve problems in a coding context, developing their CT.}
}
@article{ROCHAJUNIOR2022984,
title = {Selection of interns for startups: an approach based on the AHP-TOPSIS-2N method and the 3DM computational platform},
journal = {Procedia Computer Science},
volume = {199},
pages = {984-991},
year = {2022},
note = {The 8th International Conference on Information Technology and Quantitative Management (ITQM 2020 & 2021): Developing Global Digital Economy after COVID-19},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.01.124},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922001259},
author = {Claudio de Souza {Rocha Junior} and Miguel Ângelo {Lellis Moreira} and Marcos {dos Santos}},
keywords = {Data Analysis, Decision-Making, Multicriteria Method, Decision Support},
abstract = {It is known that selecting competent employees according to the company’s profile is a recurring difficulty among all professionals and sectors of human resources, where decision making requires a high level of cognitive effort to make a correct and clear selection about the attributes competed. The most common ways of selecting a new employee is mostly based on several interviews, theorical and practical tests, forms and group dynamics, in the expectation that the data provided by the candidates will be the starting point for a great selection, but, in most cases, the selection is made in a way that do not use some logical think, just the empirical thinking, liable to make unjust selections or that do not meet expectations properly. Based on this fact, the objective of this work is to report the use of the multicriteria method to support decision making AHP-TOPSIS-2N through the web software Three Decision Methods to support the choice of intern for the IoT-Based startup "Riverdata". After interviews with the chosen one, it was noticed that the results were satisfactory and met the expectations of those responsible for the selection.}
}
@article{WITZIGMANN2018138,
title = {Translating nanomedicines: Thinking beyond materials? A young investigator's reply to ‘The Novelty Bubble’},
journal = {Journal of Controlled Release},
volume = {290},
pages = {138-140},
year = {2018},
issn = {0168-3659},
doi = {https://doi.org/10.1016/j.jconrel.2018.10.011},
url = {https://www.sciencedirect.com/science/article/pii/S0168365918305820},
author = {Dominik Witzigmann and Sjoerd Hak and Roy {van der Meel}}
}
@article{NAUMAN2024101870,
title = {Communication and computational resource optimization for Industry 5.0 smart devices empowered by MEC},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {36},
number = {1},
pages = {101870},
year = {2024},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2023.101870},
url = {https://www.sciencedirect.com/science/article/pii/S131915782300424X},
author = {Ali Nauman and Wali Ullah Khan and Ghadah Aldehim and Hamed Alqahtani and Nuha Alruwais and Mesfer Al Duhayyim and Kapal Dev and Hong Min and Lewis Nkenyereye},
keywords = {Industry 5.0, Mobile edge computing, Joint optimization, Computational energy efficiency, Partial offloading},
abstract = {Smart devices in Industry 5.0, such as sensors and robots, are often limited by low battery life and finite computational resources, hindering their ability to perform complex tasks. By offloading computation-intensive tasks to Mobile Edge Cloud Computing (MEC) servers at the network’s edge, businesses can achieve real-time data processing and analysis, reducing communication latency, quicker response times, and improved system reliability. This work presents an integrated framework for MEC and Industry 5.0, aimed at enhancing the performance, efficiency, and flexibility of industrial processes. In particular, we propose a joint optimization problem that maximizes computational energy efficiency by optimally allocating resources, such as processing power and computational resources, as well as device association, in the most efficient manner possible. The problem is formulated as nonconvex/nonlinear, which is intractable and poses high complexity. To solve this challenging problem, we first transform and decouple the original optimization problem into a series of subproblems using the block coordinate descent method. Then, we iteratively obtain an efficient solution using convex optimization methods. In addition, our work sheds light on the fundamental trade-off between local computation and partial offloading schemes. The results show that for small data size requirements, the performance is comparable among different schemes. However, as data size increases, our proposed hybrid scheme, which includes a partial offloading scheme, outperforms others, highlighting the effectiveness of the proposed joint optimization scheme.}
}
@article{SLADEK2008399,
title = {Why don't doctors wash their hands? A correlational study of thinking styles and hand hygiene},
journal = {American Journal of Infection Control},
volume = {36},
number = {6},
pages = {399-406},
year = {2008},
issn = {0196-6553},
doi = {https://doi.org/10.1016/j.ajic.2007.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S0196655308000655},
author = {Ruth M. Sladek and Malcolm J. Bond and Paddy A. Phillips},
abstract = {Background
The World Health Organization has identified cognitive determinants of hand hygiene as an outstanding research question. This study investigated whether doctors' preferences for a rational thinking style or an experiential thinking style are associated with hand hygiene compliance.
Methods
This was an observational study of hand hygiene practices of 32 doctors in 2 teaching hospitals in South Australia. Compliance rates were correlated with self-reported thinking styles. The doctors were observed by a trained observer during a ward round or outpatient clinic and were unaware that hand hygiene was under observation. The main outcome measures were hand hygiene compliance (hand hygiene compliance tool) and thinking style (Rational-Experiential Inventory).
Results
An overall mean compliance rate of 7.6% (standard deviation ± 7.2%) was found. Compliance was significantly positively correlated with experiential/automatic thinking (r = .46; P = .004) and the observational setting of ward rounds (vs clinics) (r = -.47; P = .003). No significant relationship was found between compliance and a rational/deliberate thinking style (r = -.01; P = .472).
Conclusions
Hand hygiene is more experiential than rational. Findings suggest that certain promotional strategies appealing to the experiential thinking mode may improve compliance, and that traditional approaches based on logic and reasoning alone probably will not work.}
}
@article{SLEEP20121038,
title = {Preparing beginning teachers to elicit and interpret students' mathematical thinking},
journal = {Teaching and Teacher Education},
volume = {28},
number = {7},
pages = {1038-1048},
year = {2012},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2012.04.005},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X12000686},
author = {Laurie Sleep and Timothy A. Boerst},
keywords = {Mathematics education, Practice-based teacher education, Formative assessment, Teaching practices, Scaffolding practice-based learning},
abstract = {This study investigated how teacher education assignments can be designed to support beginning teachers in learning to do the work of teaching. We examined beginners' formative assessment practices—in particular, their eliciting and interpreting of students' mathematical thinking—in the context of an elementary mathematics methods assignment, and the ways in which the scaffolds provided shaped their practice. We found that the scaffolds differentially supported their practice and suggest strategic improvement of the focus and organization of different types of scaffolds. Findings from the study contribute to the conceptualization and design of scaffolds for practice-based learning opportunities in teacher education.}
}
@article{CHESHMEHZANGI20161085,
title = {Multi-spatial environmental performance evaluation towards integrated urban design: A procedural approach with computational simulations},
journal = {Journal of Cleaner Production},
volume = {139},
pages = {1085-1093},
year = {2016},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2016.08.151},
url = {https://www.sciencedirect.com/science/article/pii/S0959652616313154},
author = {Ali Cheshmehzangi},
keywords = {Environmental performance evaluation, Computational Fluid Dynamics (CFD), Integrated urban design, Urban environment},
abstract = {Urban environments are significantly important in the process of design thinking for the sectors of urban design and planning. This is often neglected or weakened in the process of [urban] design development. In this respect, we can argue in favour of integrated urban design which can be achieved in various ways; one of which is the use of computational tools in simulating and modelling the urban environments for the process of design development. In this study, the application of Computational Fluid Dynamics (CFD) in simulation of urban environments is examined at various scales and stages of the urban design process. A UK case study is presented to analyse the procedure in which CFD can play an influential role to inform design. Furthermore, the study examines the practical application of CFD for integrated urban design and landscape design at micro and meso scales. Finally, this research study aims to provide a procedural model for the use of CFD tools in the process of design development.}
}
@article{LI202526,
title = {Two-stage optimization of computation offloading for ICN-assisted mobile edge computing in 6G network},
journal = {ICT Express},
volume = {11},
number = {1},
pages = {26-33},
year = {2025},
issn = {2405-9595},
doi = {https://doi.org/10.1016/j.icte.2024.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S2405959524001097},
author = {Jiajian Li and Yanjun Shi and Yu Yang},
keywords = {Information-centric network, Multi-agent reinforcement learning, Optimization-embedding offloading, 6G network},
abstract = {This paper investigates QoS-aware computation offloading issues for mobile edge computing in the 6G network. To minimize the end-to-end delay, we harness the Information-Centric Network (ICN) to ensure resource-constrained mobile user offloading computation-sensitive tasks in a distributed manner. Then, a two-stage approach based on a Multi-Agent Reinforcement Learning (MARL) algorithm entwined with optimization-embedding offloading ratio is proposed to enhance server selection for load balancing. Numeral results demonstrate that, with reference to a workshop-scale scenario, the proposed method can achieve outperformed performance in reducing delay and balancing loads on edge servers than the other four baseline schemes.}
}
@article{MOUTOUSSIS2020S111,
title = {Low Decision Acuity, a General Factor for Decision-Making Underpinned by Specific Resting-State Brain Activity, is Associated With High Aberrant Thinking in Young People},
journal = {Biological Psychiatry},
volume = {87},
number = {9, Supplement },
pages = {S111-S112},
year = {2020},
note = {75th Annual Scientific Convention and Meeting},
issn = {0006-3223},
doi = {https://doi.org/10.1016/j.biopsych.2020.02.306},
url = {https://www.sciencedirect.com/science/article/pii/S0006322320304182},
author = {Michael Moutoussis and Benjamin Garzon and Sharon Neufeld and Edward Bullmore and Dominik Bach and Francesco Rigoli and Marc Guitart-Masip and Ray Dolan}
}
@article{PEPONI2022103754,
title = {Life cycle thinking and machine learning for urban metabolism assessment and prediction},
journal = {Sustainable Cities and Society},
volume = {80},
pages = {103754},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2022.103754},
url = {https://www.sciencedirect.com/science/article/pii/S2210670722000853},
author = {Angeliki Peponi and Paulo Morgado and Peter Kumble},
keywords = {Life cycle inventory, Sensitivity analysis, ANN, Urban core, Case study, Land use planning, Urban metabolism},
abstract = {The real-world urban systems represent nonlinear, dynamical, and interconnected urban processes that require better management of their complexity. Thereby, we need to understand, measure, and assess the structure and functioning of the urban processes. We propose an innovative and novel evidence-based methodology to manage the complexity of urban processes, that can enhance their resilience as part of the concept of smart and regenerative urban metabolism with the overarching intention to better achieve sustainability. We couple Life Cycle Thinking and Machine Learning to measure and assess the metabolic processes of the urban core of Lisbon's functional urban area using multidimensional indicators and measures incorporating urban ecosystem services dynamics. We built and trained a multilayer perceptron (MLP) network to identify the metabolic drivers and predict the metabolic changes for the near future (2025). The prediction model's performance was validated using the standard deviations of the prediction errors of the data subsets and the network's training graph. The simulated results show that the urban processes related to employment and unemployment rates (17%), energy systems (10%), sewage and waste management/treatment/recycling, demography & migration, hard/soft cultural assets, and air pollution (7%), education and training, welfare, cultural participation, and habitat-ecosystems (5%), urban safety, water systems, economy, housing quality, urban void, urban fabric, and health services and infrastructure (2%), consists the salient drivers for the urban metabolic changes. The proposed research framework acts as a knowledge-based tool to support effective urban metabolism policies ensuring sustainable and resilient urban development.}
}
@incollection{RANPARA2025151,
title = {Chapter 8 - Computational intelligence–based heuristic approach for maximizing energy efficiency in sustainable transportation and mobility},
editor = {Balamurugan Balusamy and Vinayakumar Ravi and Rajesh Kumar Dhanaraj and Sudha Senthilkumar and Brindha K.},
booktitle = {Computational Intelligence in Sustainable Computing and Optimization},
publisher = {Morgan Kaufmann},
pages = {151-162},
year = {2025},
isbn = {978-0-443-23724-9},
doi = {https://doi.org/10.1016/B978-0-443-23724-9.00008-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780443237249000086},
author = {Ripal D. Ranpara},
keywords = {Artificial intelligence, Computer in society, Information retrieval, Statistical applications, Symbolic computation},
abstract = {In a time marked by increasing awareness of environmental issues and a persistent drive for energy efficiency, the realm of sustainable transportation and mobility offers a promising field for the use of computational intelligence. The focus of this study chapter is to conduct a comprehensive investigation of a heuristic strategy based on computational intelligence. The objective of this technique is to optimism energy efficiency in the context of sustainable transportation. The urgent need to decrease the environmental impact of transport systems, along with the increasing expenses of energy use, highlights the utmost importance of this study activity. Within this particular setting, the chapter effectively creates a thorough and robust basis by undertaking an intensive analysis of relevant literature. This evaluation encompasses a wide variety of issues, including sustainable transportation practice's and computational intelligence methodologies. The purpose of this extensive literature study is to identify existing research gaps and limitations, which supports the justification for the innovative heuristic method being examined. This chapter provides a comprehensive analysis of the theoretical foundations of computational intelligence and its potential application in the field of energy efficiency optimization's. The methodology section elucidates the complexities of the heuristic approach, providing a comprehensive account of how computational intelligence algorithms are incorporated to develop novel ways for conserving energy in transportation. The next sections will explore the presentation and analysis of actual data, demonstrating concrete outcomes and highlighting the advantages gained by using the computational intelligence method. The validity of this study is shown by the use of visual depictions, empirical data, and numerical measures, which provide a thorough assessment of the effectiveness of the technique. The subsequent discourse offers an advanced analysis of the study results, identifying subtle ramifications and pragmatic uses. Additionally, a comparison study is performed in relation to traditional approaches, which demonstrates the improved energy efficiency and environmental effect mitigation obtained by the use of computational intelligence. Acknowledging the inherent difficulties and methodological constraints, the chapter presents valuable perspectives on possible avenues for improvement and advancement. The last part of the chapter presents a prospective analysis of the future potential of computational intelligence in the context of sustainable transportation and mobility. By providing a comprehensive analysis of potential avenues for future study and exploring various possibilities, it highlights the continuous growth opportunities for the use of computational intelligence in enhancing energy efficiency. This study chapter presents a comprehensive investigation into the use of a computational intelligence-based heuristic technique for the purpose of improving energy efficiency in the context of sustainable transportation and mobility. The results shed light on the feasibility of this methodology and its capacity to reinvent the energy efficiency paradigm in the transportation industry, enabling the advancement of environmentally friendly, economically feasible, and sustainable transportation systems.}
}
@article{GERVAIS2015312,
title = {Override the controversy: Analytic thinking predicts endorsement of evolution},
journal = {Cognition},
volume = {142},
pages = {312-321},
year = {2015},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2015.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S0010027715001080},
author = {Will M. Gervais},
keywords = {Evolution, Creationism, Dual process theories, Supernatural beliefs, Cognitive style},
abstract = {Despite overwhelming scientific consensus, popular opinions regarding evolution are starkly divided. In the USA, for example, nearly one in three adults espouse a literal and recent divine creation account of human origins. Plausibly, resistance to scientific conclusions regarding the origins of species—like much resistance to other scientific conclusions (Bloom & Weisberg, 2007)—gains support from reliably developing intuitions. Intuitions about essentialism, teleology, agency, and order may combine to make creationism potentially more cognitively attractive than evolutionary concepts. However, dual process approaches to cognition recognize that people can often analytically override their intuitions. Two large studies (total N=1324) found consistent evidence that a tendency to engage analytic thinking predicted endorsement of evolution, even controlling for relevant demographic, attitudinal, and religious variables. Meanwhile, exposure to religion predicted reduced endorsement of evolution. Cognitive style is one factor among many affecting opinions on the origin of species.}
}
@article{BOKKON201367,
title = {Interdisciplinary implications on autism, savantism, Asperger syndrome and the biophysical picture representation: Thinking in pictures},
journal = {Cognitive Systems Research},
volume = {22-23},
pages = {67-77},
year = {2013},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2012.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S1389041712000253},
author = {I. Bókkon and V. Salari and F. Scholkmann and J. Dai and F. Grass},
keywords = {Autism, Savantism, Asperger syndrome, Biophysical pictures, Thinking in pictures},
abstract = {It seems that neurotypical individuals (people without autism) have a hidden ability for savant-like skills, and these special abilities can be accessible via top-down cortical disinhibition of the left fronto-temporal lobe by repetitive transcranial magnetic stimulation (rTMS). It is well known that enhanced visual function in striate and extrastriate areas is a common character in autists, savants and subjects with Asperger syndrome. In addition, visual cortex not only processes visual signals but also is involved in the processing of mathematical thinking and auditory signals among them. Here we argue about the essential (and more ancient) role of picture representation over linguistic representation in ASD and that extraordinary savant-like skills are due to the explicit predominance of the right hemisphere (a malfunction of top-down control processes) accompanied with prevalence of lower level detailed visual information in the right hemisphere. Our recently presented novel biophysical picture representation hypothesis (also called as intrinsic biophysical virtual visual reality) about visual perception and imagery is also briefly described and linked to the predominance of lower level and detailed visual representation in the right hemisphere that may be a common character in autism, savantism, and Asperger syndrome.}
}
@incollection{DENEYS20151,
title = {Chapter One - Heuristic Bias and Conflict Detection During Thinking},
editor = {BRIAN H. ROSS},
series = {Psychology of Learning and Motivation},
publisher = {Academic Press},
volume = {62},
pages = {1-32},
year = {2015},
issn = {0079-7421},
doi = {https://doi.org/10.1016/bs.plm.2014.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0079742114000024},
author = {Wim {De Neys}},
keywords = {Biases, Conflict Detection, Decision-making, Dual Systems, Error detection, Heuristics, Reasoning},
abstract = {Decades of reasoning and decision-making research have established that human judgment is often biased by intuitive heuristics. Although this heuristic bias is well documented and widely featured in psychology textbooks, its precise nature is less clear. A key question is whether reasoners detect the biased nature of their judgments. My research is focusing on this detection process. In a nutshell, results indicate that despite their illogical response, people demonstrate a remarkable sensitivity to possible conflict between their heuristic judgment and elementary logical or probabilistic principles. In this chapter, I present a detailed overview of the empirical studies that I have run and discuss theoretical implications. I will clarify why the empirical detection findings have led me to hypothesize that people not only have heuristic intuitions but also logical intuitions. I also explore implications for ongoing debates concerning our view of human rationality (“Are humans blind and ignorant heuristic thinkers?”), dual process theories of reasoning (“How do intuitive and deliberate thinking interact?”), and the nature of individual differences in bias susceptibility (“when and why do biased and unbiased reasoners start to diverge?”).}
}
@article{NASSAR2024101407,
title = {Toward a computational role for locus coeruleus/norepinephrine arousal systems},
journal = {Current Opinion in Behavioral Sciences},
volume = {59},
pages = {101407},
year = {2024},
issn = {2352-1546},
doi = {https://doi.org/10.1016/j.cobeha.2024.101407},
url = {https://www.sciencedirect.com/science/article/pii/S2352154624000585},
author = {Matthew R Nassar},
abstract = {Brain and behavior undergo measurable changes in their underlying state, and neuromodulators are thought to contribute to these fluctuations. Why do we undergo such changes, and what function could the underlying neuromodulatory systems perform? Here, we examine theoretical answers to these questions with respect to the locus coeruleus/norepinephrine system, focusing on peripheral markers for arousal, such as pupil diameter, which are thought to provide a window into brain-wide noradrenergic signaling. We explore a computational role for arousal systems in facilitating internal state transitions that facilitate credit assignment and promote accurate perceptions in nonstationary environments. We summarize recent work supporting this idea and highlight open questions, as well as alternative views of how arousal affects cognition.}
}
@article{STEIN2024102379,
title = {Computational tools for cellular scale biophysics},
journal = {Current Opinion in Cell Biology},
volume = {89},
pages = {102379},
year = {2024},
issn = {0955-0674},
doi = {https://doi.org/10.1016/j.ceb.2024.102379},
url = {https://www.sciencedirect.com/science/article/pii/S0955067424000589},
author = {David B. Stein and Michael J. Shelley},
abstract = {Mathematical models are indispensable for disentangling the interactions through which biological components work together to generate the forces and flows that position, mix, and distribute proteins, nutrients, and organelles within the cell. To illuminate the ever more specific questions studied at the edge of biological inquiry, such models inevitably become more complex. Solving, simulating, and learning from these more realistic models requires the development of new analytic techniques, numerical methods, and scalable software. In this review, we discuss some recent developments in tools for understanding how large numbers of cytoskeletal filaments, driven by molecular motors and interacting with the cytoplasm and other structures in their environment, generate fluid flows, instabilities, and material deformations which help drive crucial cellular processes.}
}
@article{ZHOU2021100972,
title = {RETRACTED: The influence of choral practices and passive listening to music on creative thinking},
journal = {Thinking Skills and Creativity},
volume = {42},
pages = {100972},
year = {2021},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2021.100972},
url = {https://www.sciencedirect.com/science/article/pii/S1871187121001875},
author = {Zhenyu Zhou},
abstract = {This article has been retracted: please see Elsevier Policy on Article Withdrawal (https://www.elsevier.com/about/our-business/policies/article-withdrawal). This article has been retracted at the request of the Editors-in-Chief. After a thorough investigation, the Editors have concluded that the acceptance of this article was partly based upon the positive advice of one illegitimate reviewer report. The report was submitted from an email account which was provided to the journal as a suggested reviewer during the submission of the article. Although purportedly a real reviewer account, the Editors have concluded that this was not of an appropriate, independent reviewer. This manipulation of the peer-review process represents a clear violation of the fundamentals of peer review, our publishing policies, and publishing ethics standards. Apologies are offered to the reviewer whose identity was assumed and to the readers of the journal that this deception was not detected during the submission process.}
}
@article{HALL201385,
title = {Future aircraft cabins and design thinking: optimisation vs. win-win scenarios},
journal = {Propulsion and Power Research},
volume = {2},
number = {2},
pages = {85-95},
year = {2013},
issn = {2212-540X},
doi = {https://doi.org/10.1016/j.jppr.2013.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S2212540X13000163},
author = {A. Hall and T. Mayer and I. Wuggetzer and P.R.N. Childs},
keywords = {Aircraft, Cabin, Design, Optimisation, Parameter, Decision},
abstract = {With projections indicating an increase in mobility over the next few decades and annual flight departures expected to rise to over 16 billion by 2050, there is a demand for the aviation industry and associated stakeholders to consider new forms of aircraft and technology. Customer requirements are recognized as a key driver in business. The airline is the principal customer for the aircraft manufacture. The passenger is, in turn, the airline's principal customer but they are just one of several stakeholders that include aviation authorities, airport operators, air-traffic control and security agencies. The passenger experience is a key differentiator used by airlines to attract and retain custom and the fuselage that defines the cabin envelope for the in-flight passenger experience and cabin design therefore receives significant attention for new aircraft, service updates and refurbishments. Decision making in design is crucial to arriving at viable and worthwhile cabin formats. Too little innovation will result in an aircraft manufacturer and airlines using its products falling behind its competitors. Too much may result in an over-extension with, for example, use of immature technologies that do not have the necessary reliability for a safety critical industry or sufficient value to justify the development effort. The multiple requirements associated with cabin design, can be viewed as an area for optimisation, accepting trade-offs between the various parameters. Good design, however, is often defined as developing a concept that resolves the contradictions and takes the solution towards a win-win scenario. Indeed our understanding and practice of design allows for behaviors that enhance design thinking through divergence and convergence, the use of abductive reasoning, experimentation and systems thinking. This paper explores and defines the challenges of designing the aircraft cabin of the future that will deliver on the multiple requirements using experiences from the A350 XWB and future cabin design concepts. In particular the paper explores the value of implementing design thinking insights in engineering practice and discusses the relative merits of decisions based on optimisation versus win-win scenarios for aircraft cabin design and wider applications in aerospace environments. The increasing densification of technological opportunities and shifting consumer demand coupled with highly complex systems may ultimately challenge our ability to make decisions based on optimisation balances. From an engineering design perspective optimisation tends to preclude certain strategies that deliver high quality results in consumer scenarios whereas win-win solutions may face challenges in complex technical environments.}
}
@article{KIM20151396,
title = {A Study on an Assessment Framework for the Novelty of Ideas Generated by Analogical Thinking},
journal = {Procedia - Social and Behavioral Sciences},
volume = {195},
pages = {1396-1406},
year = {2015},
note = {World Conference on Technology, Innovation and Entrepreneurship},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2015.06.435},
url = {https://www.sciencedirect.com/science/article/pii/S1877042815039142},
author = {Eunyoung Kim and Hideyuki Horii},
keywords = {analogical thinking, novelty of ideas, assessment framworks, innovation workshops, ideation for innovation},
abstract = {Although there have been many educational programs focusing on the creation of new ideas, the assessment of novelty is still a controversial issue. As an ideation tool, analogical thinking enables conceptual change, which is seen as a crucial aspect of creativity. In this regard, the use of analogy can be an important instrument to facilitate novel idea generation. Analogies are generated by superficial or structural similarities from the memory. For creating a new idea by analogy, this study regards novelty as the domain-changing influenced by structural consistency with the source ideas. Consequently, we designed an assessment framework based on the latent semantic analysis of the domains and the consistency of the underlying mechanism between the source and the new ideas. Data was collected from the 14 subjects who participated in the workshop for this study. The workshop consists of three tasks: 1) Pre-task: All subjects were asked to read the 25 cases of the collective intelligence services, which is a business model creating value from large and loosely organized groups of people working together electronically e.g. Amazon.com, Google Japanese input; 2) Categorization task: Subjects were asked to categorize each case based on the underlying mechanism of the business through group discussion; 3) Generation task: Subjects were asked to create a new service idea individually using analogical thinking. As a result, 12 ideas were created, 6 of which were assessed as novel according to our assessment framework. Among the remaining 6 ideas, 4 were assessed as having high superficial similarity in terms of the idea domain, and 2 as having neither superficial nor structural similarity with the source ideas. Although our findings suggest that the proposed assessment framework for novelty evaluation is unable to provide a ‘one-size fits-all method’, it does enable us to overcome some of the limitations of current evaluation methods which depend on subjective judgements for rating.}
}
@article{ARNEDOMORENO2025100850,
title = {Programming Fun(damentals): Using commercial video games to teach basic coding to adult learners},
journal = {Entertainment Computing},
volume = {52},
pages = {100850},
year = {2025},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2024.100850},
url = {https://www.sciencedirect.com/science/article/pii/S1875952124002180},
author = {Joan Arnedo-Moreno and David García-Solórzano},
keywords = {e-learning, Game based learning, Video games, Programming games, Computational thinking, Self-efficacy},
abstract = {The acquisition of computational thinking and coding skills is of special significance in helping adult learners keep pace with a new context where those skills are required for many parts of the workforce. However, there is an agreement in the scientific literature that important challenges exist, such as keeping student engagement and the requirement of developing problem-solving skills, and not just learning the code syntax. The inclusion of digital Game-Based Learning (GBL) has shown great potential. To better understand how it can be helpful to adult learners in STEM degrees, a study was conducted on the application of two very popular commercial video games in different introductory programming courses at an online university, during the introduction of basic programming topics (CS1). The methods combined a descriptive qualitative and a quantitative approach, using a reflective journals and questionnaires, which helped students consider and express their experiences, how they interacted with the games, how the games helped them better understand the topics, and realize their personal progress and potential. Results showed that the use of these games as educational resources had a positive impact in their engagement and sense of self-efficacy, but only if some important instructional considerations are taken into account.}
}
@article{JACOBS20101155,
title = {Extreme thinking in clinically depressed adolescents: Results from the Treatment for Adolescents with Depression Study (TADS)},
journal = {Behaviour Research and Therapy},
volume = {48},
number = {11},
pages = {1155-1159},
year = {2010},
issn = {0005-7967},
doi = {https://doi.org/10.1016/j.brat.2010.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S000579671000166X},
author = {Rachel H. Jacobs and Mark A. Reinecke and Jackie K. Gollan and Neil Jordan and Susan G. Silva and John S. March},
keywords = {Major depressive disorder, Adolescents, Recovery, Cognitive therapy},
abstract = {The purpose of this report is to examine relations between extreme thinking, as measured by the Dysfunctional Attitudes Scale, and the maintenance of gains among adolescents who participated in the Treatment for Adolescents with Depression Study (TADS). We examine extreme thinking among 327 adolescents (mean age=14.56, 57% female, 75% White) who received cognitive behavior therapy (CBT), fluoxetine (FLX), or a combination of CBT and FLX (COMB). Among those who met remission status on the Children’s Depression Rating Scale – Revised (CDRS-R≤28; 56 at week 12, 79 at week 18) extreme thinking did not predict failure to maintain remission. This is in contrast to findings with depressed adults. Treatment influenced level of extreme thinking, and this appeared to be driven by greater endorsement of positively valenced beliefs as opposed to a decrease in negatively valenced beliefs. Developmental or investigation characteristics may account for the discrepancy in findings.}
}
@article{TAURO2023130064,
title = {Thinking inside the box: Investigating peak storm response in a simplified outdoor slope setup},
journal = {Journal of Hydrology},
volume = {625},
pages = {130064},
year = {2023},
issn = {0022-1694},
doi = {https://doi.org/10.1016/j.jhydrol.2023.130064},
url = {https://www.sciencedirect.com/science/article/pii/S0022169423010065},
author = {Flavia Tauro and Andrea Petroselli and Salvatore Grimaldi},
keywords = {Peak runoff, Peak rainfall, Hillslope, Storm response, Soil moisture, Hydrological response},
abstract = {Hillslopes are the fundamental building blocks of catchments, however, fully disentangling their hydrological response remains an outstanding challenge. In natural settings, hillslope hydrology is challenged by the interplay of several factors, such as, heterogeneous morphology, vegetation, and complex soils. Herein, we attempt to clarify the mechanisms that control the rainfall-runoff relationship by investigating the response of an artificial outdoor slope setup with uniform geometry, soil properties, topography, and in the absence of vegetation located in a Mediterranean climate. Based on the analysis of more than 100 storms across six consecutive hydrological years, our results demonstrate that either pre-event soil water content or rainfall conditions alone are not sufficient to explain the slope response. Seasonality played a major role through soil moisture conditions, and pre-event soil moisture, peak rainfall intensity and rainfall duration influenced the slope runoff response. Observations suggest that in fall and winter subsurface flow was the prevalent runoff mechanism, while infiltration excess overland flow mostly occurred in the dry season. Our findings show that continuous measurement of runoff could be beneficial to understand the peak rainfall-peak runoff relationship.}
}
@incollection{SCHULZ2012269,
title = {Chapter Ten - Finding New Facts; Thinking New Thoughts},
editor = {Fei Xu and Tamar Kushnir},
series = {Advances in Child Development and Behavior},
publisher = {JAI},
volume = {43},
pages = {269-294},
year = {2012},
booktitle = {Rational Constructivism in Cognitive Development},
issn = {0065-2407},
doi = {https://doi.org/10.1016/B978-0-12-397919-3.00010-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780123979193000101},
author = {Laura Schulz},
keywords = {Active learning, Children, Computational models, Constructivism, Exploration, Hierarchical bayesian inference, Hypothesis generation, Imagination, Search},
abstract = {The idea of the child as an active learner is one of Piaget's enduring legacies. In this chapter, I discuss the ways in which contemporary computational models of learning do, and do not, address learning as an active, child-driven process. In Part 1, I discuss the problem of search and exploration. In Part 2, I discuss the (harder and more interesting) problem of hypothesis generation. I conclude by proposing some possible new directions for research.}
}
@article{GROSSI2023104437,
title = {Cultural, creative, and complex: A computational foundation of culture-driven urban governance},
journal = {Cities},
volume = {140},
pages = {104437},
year = {2023},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2023.104437},
url = {https://www.sciencedirect.com/science/article/pii/S0264275123002494},
author = {Enzo Grossi and Pier Luigi Sacco and Giorgio Tavano Blessi},
keywords = {Cultural and creative cities, Minimum Spanning Tree (MST), Cultural and Creative Cities Monitor (CCCM), Urban governance, Complexity},
abstract = {Culture and creative production have an important but somewhat elusive role in urban development. None of the many conceptual paradigms that have been proposed so far to explain it has turned out entirely satisfactory. We argue that the main reason behind this failure is the implicit linear thinking that informs all these approaches: namely, the idea that a few, major drivers explain urban development through a direct, clearly readable systemic impact. Cities are complex socio-environmental systems whose functioning depends on the concurrent interaction of many different factors which cannot be reduced to the action of a few, simple causal forces. Failing to understand such complexity easily leads to dysfunctional urban governance approaches. In this paper, we analyze a database of 144 European cities as described by 58 variables belonging to different domains, as designed by a preliminary stage of the Cultural and Creative City Monitor (CCCM). Our analysis builds on innovative machine learning techniques (PST) and on the Minimum Spanning Tree (MST) representation to map the structural interdependencies between the cultural and non-cultural sectors in cities with a strong cultural policy orientation. This toolbox carries considerable potential for precision cultural policies and data-driven urban governance strategies of the future.}
}
@article{CHU2024628,
title = {In praise of folly: flexible goals and human cognition},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {7},
pages = {628-642},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.03.006},
url = {https://www.sciencedirect.com/science/article/pii/S1364661324000597},
author = {Junyi Chu and Joshua B. Tenenbaum and Laura E. Schulz},
keywords = {goals, exploration, motivation, play, children, learning},
abstract = {Humans often pursue idiosyncratic goals that appear remote from functional ends, including information gain. We suggest that this is valuable because goals (even prima facie foolish or unachievable ones) contain structured information that scaffolds thinking and planning. By evaluating hypotheses and plans with respect to their goals, humans can discover new ideas that go beyond prior knowledge and observable evidence. These hypotheses and plans can be transmitted independently of their original motivations, adapted across generations, and serve as an engine of cultural evolution. Here, we review recent empirical and computational research underlying goal generation and planning and discuss the ways that the flexibility of our motivational system supports cognitive gains for both individuals and societies.}
}
@article{STOREY2025114368,
title = {Digitalization of the natural sciences: Design science research and computational science},
journal = {Decision Support Systems},
volume = {189},
pages = {114368},
year = {2025},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2024.114368},
url = {https://www.sciencedirect.com/science/article/pii/S016792362400201X},
author = {Veda C. Storey and Richard L. Baskerville},
keywords = {Natural science, Computational science, Digital science, Design science research, Sciences of the artificial, Research , Digital artifact, Digital exhaust artifact},
abstract = {In the natural sciences, many research activities now require the support of digital artifacts. This digitalization of science has led to the need to develop essential, specialized, devices and software. Computational science is a branch of science that especially requires such artifacts. This research examines computational science to identify its challenges and successes in developing and applying digital artifacts as it moves to digital science. We propose that it might be possible and helpful to support digital artifact creation by applying results from research in design science. We are especially motivated by the types of problems encountered in computational science and how they might be supported by design science research methods and evaluation approaches to develop and assess artifacts for important, and complex, real-world problems. In a complementary manner, computational science could provide an area of inquiry for extending design science research into the natural sciences.}
}
@article{HAUSER2024100439,
title = {Morphological computation—Past, present and future},
journal = {Device},
volume = {2},
number = {9},
pages = {100439},
year = {2024},
issn = {2666-9986},
doi = {https://doi.org/10.1016/j.device.2024.100439},
url = {https://www.sciencedirect.com/science/article/pii/S2666998624002825},
author = {Helmut Hauser and Josie Hughes},
abstract = {Morphological computation is a design approach used in robotics that proposes the exploitation of morphological features in order to build intelligent robotic systems and improve their performance. This approach is inspired by observations of biological systems, which all rely heavily on their body morphologies. Taking into account the material properties and the corresponding dynamics of the physical body of a robot, morphological computation aims to improve sensing, control, and learning.}
}
@article{SHU2021100961,
title = {RETRACTED: Influence of piano playing on logical thinking formation of future musicians},
journal = {Thinking Skills and Creativity},
volume = {42},
pages = {100961},
year = {2021},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2021.100961},
url = {https://www.sciencedirect.com/science/article/pii/S1871187121001760},
author = {Ying Shu},
abstract = {This article has been retracted: please see Elsevier Policy on Article Withdrawal (https://www.elsevier.com/about/our-business/policies/article-withdrawal). This article has been retracted at the request of the Editors-in-Chief. After a thorough investigation, the Editors have concluded that the acceptance of this article was partly based upon the positive advice of one illegitimate reviewer report. The report was submitted from an email account which was provided to the journal as a suggested reviewer during the submission of the article. Although purportedly a real reviewer account, the Editors have concluded that this was not of an appropriate, independent reviewer. This manipulation of the peer-review process represents a clear violation of the fundamentals of peer review, our publishing policies, and publishing ethics standards. Apologies are offered to the reviewer whose identity was assumed and to the readers of the journal that this deception was not detected during the submission process.}
}
@article{LACHNEY2023100591,
title = {From endpoints to trading zones: Multi-directional exchange for computational empowerment in computer science education},
journal = {International Journal of Child-Computer Interaction},
volume = {37},
pages = {100591},
year = {2023},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2023.100591},
url = {https://www.sciencedirect.com/science/article/pii/S2212868923000284},
author = {Michael Lachney and Aman Yadav},
keywords = {Computational empowerment, Trading zones, Computer science education, Co-design, Physical computing, Visual programming},
abstract = {In this paper we build on a conceptual framing of computational empowerment that seeks to provide alternative endpoints for computer science (CS) education beyond degree attainment and job placement. But, as opposed to a teleological framing that prioritizes ends, we propose using the metaphor of trading zones to construct a framing for computational empowerment that is based on collaborative multi-directional exchanges of resources and knowledge between people with different expertise. This leaves the co-design and implementation of CS education open to emergent directions and possibilities. Using a descriptive case study methodology, we detail trading zones in two different co-design projects that sought to situate CS education in relationship to cultural contexts through multi-directional exchanges of resources and knowledge: (1) a co-design project in a youth boxing gym with coaches, mentors, and staff; (2) a co-design project in a high school barbering program with a barbering instructor and barbering students. Our findings show that the metaphor is useful for the concept of computational empowerment in ways that are reflexive and interventionist.}
}
@article{WERNLI2023102096,
title = {Fostering interdisciplinary collaboration in computational diplomacy: A multi-layered network approach to improve our understanding of institutional complexity and effective governance design},
journal = {Journal of Computational Science},
volume = {72},
pages = {102096},
year = {2023},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2023.102096},
url = {https://www.sciencedirect.com/science/article/pii/S1877750323001564},
author = {Didier Wernli},
keywords = {Institutional complexity, Computational science, Data science, Multilateral diplomacy, Governance, Complex adaptive systems, Multi-layered network, United Nations, International organizations},
abstract = {While the study of global governance is moving from a focus on component-dominated to interaction-dominated systems, the present paper reviews development in governance theories from a complexity perspective and discuss how governance systems can be represented in terms of multi-layered networks. Such representation is useful to foster interdisciplinary collaborations between researchers working in global governance/international relations and data science/computational science. The combination of a data-driven approach with computational modelling paves the way to both contribute to a more fundamental understanding of how multilateral governance systems work and to address some important contemporary questions about institutional complexity and the effectiveness of governance design.}
}
@article{LEISCHOW2008S196,
title = {Systems Thinking to Improve the Public's Health},
journal = {American Journal of Preventive Medicine},
volume = {35},
number = {2, Supplement },
pages = {S196-S203},
year = {2008},
note = {The Science of Team Science},
issn = {0749-3797},
doi = {https://doi.org/10.1016/j.amepre.2008.05.014},
url = {https://www.sciencedirect.com/science/article/pii/S074937970800425X},
author = {Scott J. Leischow and Allan Best and William M. Trochim and Pamela I. Clark and Richard S. Gallagher and Stephen E. Marcus and Eva Matthews},
abstract = {Abstract
Improving population health requires understanding and changing societal structures and functions, but countervailing forces sometimes undermine those changes, thus reflecting the adaptive complexity inherent in public health systems. The purpose of this paper is to propose systems thinking as a conceptual rubric for the practice of team science in public health, and transdisciplinary, translational research as a catalyst for promoting the functional efficiency of science. The paper lays a foundation for the conceptual understanding of systems thinking and transdisciplinary research, and will provide illustrative examples within and beyond public health. A set of recommendations for a systems-centric approach to translational science will be presented.}
}
@article{VALLET2020102513,
title = {Tangible futures: Combining scenario thinking and personas - A pilot study on urban mobility},
journal = {Futures},
volume = {117},
pages = {102513},
year = {2020},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2020.102513},
url = {https://www.sciencedirect.com/science/article/pii/S0016328720300033},
author = {Flore Vallet and Jakob Puchinger and Alexandra Millonig and Guillaume Lamé and Isabelle Nicolaï},
keywords = {Mobility, Persona, Traveler, Scenario planning},
abstract = {Scenario planning methods tend to work at an aggregate level and to consider homogeneous populations, thus levelling the variable effects of future developments on different social groups. Decision-making based on such scenarios bears the risk of missing undesired impacts on specific groups of people, which may cause social tensions or require costly countermeasures. New approaches are needed to provide a better basis for socially responsible planning by making clearer the complex social impacts of future scenarios. In marketing and user-centered design, persona models are developed to represent typologies of users to cover a broad range of needs and requirements. We propose a systematic method, called the Scenario Personarrative method, for combining scenario thinking and personas into a structured but nonetheless flexible process, which allows generating fine-grained individualized narratives. We describe a pilot application in a case study on urban mobility. This pilot used existing scenarios and focused on a two-hour workshop where twelve experts created personas and the associated narratives across three scenarios of urban mobility in 2030. This pilot shows the applicability of the method for making potential effects on different social groups more tangible. We propose ways forward for further evaluation of the proposed methodology.}
}
@article{GOODCHILD20113,
title = {Spatial Thinking and the GIS User Interface},
journal = {Procedia - Social and Behavioral Sciences},
volume = {21},
pages = {3-9},
year = {2011},
note = {International Conference: Spatial Thinking and Geographic Information Sciences 2011},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2011.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S1877042811013255},
author = {Michael F. Goodchild},
keywords = {Spatial thinking, Geographic information system, User interface, Spatial concepts ;},
abstract = {Geographic information science can be defined as the study of the fundamental issues of geographic information, and is often motivated by the need to improve geographic information technologies. One such issue concerns the design of the user interface, and the relationship between the tasks performed by the technologies on the one hand, and the concepts that humans use in thinking about those tasks on the other. Nowhere is this issue more important than in the design of GIS user interfaces and functionality. Recent efforts have led to a comprehensive understanding of the concepts of spatial thinking, and of how these concepts might form the basis for a much-improved functionality and user interface. The presentation summarizes those efforts, and points to a future in which GIS will be much easier to teach, master, and use.}
}
@article{MARGITTAI2016131,
title = {Exogenous cortisol causes a shift from deliberative to intuitive thinking},
journal = {Psychoneuroendocrinology},
volume = {64},
pages = {131-135},
year = {2016},
issn = {0306-4530},
doi = {https://doi.org/10.1016/j.psyneuen.2015.11.018},
url = {https://www.sciencedirect.com/science/article/pii/S0306453015300202},
author = {Zsofia Margittai and Gideon Nave and Tina Strombach and Marijn {van Wingerden} and Lars Schwabe and Tobias Kalenscher},
keywords = {Cortisol, CRT, Stress, Cognitive reflection, Intuitive, Deliberate, Decision biases},
abstract = {People often rely on intuitive judgments at the expense of deliberate reasoning, but what determines the dominance of intuition over deliberation is not well understood. Here, we employed a psychopharmacological approach to unravel the role of two major endocrine stress mediators, cortisol and noradrenaline, in cognitive reasoning. Healthy participants received placebo, cortisol (hydrocortisone) and/or yohimbine, a drug that increases noradrenergic stimulation, before performing the cognitive reflection test (CRT). We found that cortisol impaired performance in the CRT by biasing responses toward intuitive, but incorrect answers. Elevated stimulation of the noradrenergic system, however, had no effect. We interpret our results in the context of the dual systems theory of judgment and decision making. We propose that cortisol causes a shift from deliberate, reflective cognition toward automatic, reflexive information processing.}
}

@article{BATTY20174,
title = {Thinking organic, acting civic: The paradox of planning for Cities in Evolution},
journal = {Landscape and Urban Planning},
volume = {166},
pages = {4-14},
year = {2017},
note = {Special Issue: Planning living cities: Patrick Geddes’ legacy in the new millennium},
issn = {0169-2046},
doi = {https://doi.org/10.1016/j.landurbplan.2016.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0169204616301001},
author = {Michael Batty and Stephen Marshall},
keywords = {Evolution, Darwinism, Organic growth, Top-down planning, Bottom-up action, Complexity sciences},
abstract = {Patrick Geddes articulated the growth and design of cities in the early years of the town planning movement in Britain using biological principles of which Darwin’s (1859) theory of evolution was central. His ideas about social evolution, the design of local communities, and his repeated calls for comprehensive understanding through regional survey and plan laid the groundwork for much practical planning in the mid 20th century, both with respect to an embryonic theory of cities and the practice of planning. But Geddes had a much wider agenda that town planning per se. He sought after a philosophy of life that went well beyond Darwinism verging almost on the spiritual at times. Yet his personal approach and the limits he imposed on his formal thinking meant that he was never able to establish his big picture in a way that later generations could easily grasp and build upon. He left us with enticing ideas, evocative phrases, and a practical philosophy of doing planning and building communities that has indeed survived as something more than a footnote in history. In this essay, we identify the key paradox of modern planning which seeks to intervene in systems that have enormous complexity, growing and evolving rather than being designed in any top-down fashion. We illustrate this paradox through Geddes’ own career and life in which this tension between bottom up and top down was always to the forefront. We then sketch his influence on practicing planners and key intellectuals of the mid to late 20th century—Abercrombie and Mumford, Jacobs and Alexander. We bring this history of Geddes’ influence up to contemporary times when the complexity sciences with all their focus on evolving systems, now permeate our thinking, suggesting various ways in which we might examine the history of the planning in the last 100 years in a new light through the lens of Geddes’ arguments and principles}
}
@incollection{WARE2013375,
title = {Chapter Eleven - Visual Thinking Processes},
editor = {Colin Ware},
booktitle = {Information Visualization (Third Edition)},
publisher = {Morgan Kaufmann},
edition = {Third Edition},
address = {Boston},
pages = {375-423},
year = {2013},
series = {Interactive Technologies},
isbn = {978-0-12-381464-7},
doi = {https://doi.org/10.1016/B978-0-12-381464-7.00011-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780123814647000119},
author = {Colin Ware}
}
@article{ASTLE2023726,
title = {Toward computational neuroconstructivism: a framework for developmental systems neuroscience},
journal = {Trends in Cognitive Sciences},
volume = {27},
number = {8},
pages = {726-744},
year = {2023},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2023.04.009},
url = {https://www.sciencedirect.com/science/article/pii/S1364661323000992},
author = {Duncan E. Astle and Mark H. Johnson and Danyal Akarca},
keywords = {development, systems neuroscience, computational models, network science, connectomics},
abstract = {Brain development is underpinned by complex interactions between neural assemblies, driving structural and functional change. This neuroconstructivism (the notion that neural functions are shaped by these interactions) is core to some developmental theories. However, due to their complexity, understanding underlying developmental mechanisms is challenging. Elsewhere in neurobiology, a computational revolution has shown that mathematical models of hidden biological mechanisms can bridge observations with theory building. Can we build a similar computational framework yielding mechanistic insights for brain development? Here, we outline the conceptual and technical challenges of addressing this theory gap, and demonstrate that there is great potential in specifying brain development as mathematically defined processes operating within physical constraints. We provide examples, alongside broader ingredients needed, as the field explores computational explanations of system-wide development.}
}
@article{LI2024117366,
title = {Debates over the role of Traditional Chinese Medicine on COVID-19: A computational comparison between professionals and laypersons in Chinese online knowledge community},
journal = {Social Science & Medicine},
volume = {361},
pages = {117366},
year = {2024},
issn = {0277-9536},
doi = {https://doi.org/10.1016/j.socscimed.2024.117366},
url = {https://www.sciencedirect.com/science/article/pii/S0277953624008207},
author = {Jinhui Li and Wen Shi},
keywords = {Scientific debate, COVID-19, Agenda setting, Zhihu, Structural topic modeling},
abstract = {Leveraging a large collection of textual data (N = 21,539) from a Chinese online community, we employed structural topic modeling to investigate the thematic disparities between professionals and laypersons, regarding the effectiveness of Traditional Chinese Medicine (TCM) on COVID-19. Findings reveal that laypersons are the dominant communicators in terms of discussion volume, who often focus on relevant news events, societal or political aspects of TCM. In contrast, professionals keep concentrating on issues related to medical expertise, and do not shift attentions as frequent as laypersons. Despite the dominant influence of professionals on laypersons’ agenda, two-way agenda interactions identified confirm that lay public is empowered to negotiate with elite professionals under certain topics. Our results provide novel insights into the dynamic nature of attentions, behaviors, and relations among prominent communication actors, and encourage future research to examine the individual-level and societal-level impacts of these constructs in the emerging online media landscape.}
}
@article{GAO2025100776,
title = {Method towards collaborative cloud and edge computing via RBC for joint communication and computation resource allocation},
journal = {Journal of Industrial Information Integration},
volume = {44},
pages = {100776},
year = {2025},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2025.100776},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X25000019},
author = {Ruiling Gao and Wenzhong Zhang and Wenyi Mao and Jinjing Tan and Jin Zhang and Haiyun Huang and Wen'an Tan and Feiyue Huang},
keywords = {Cloud and edge computing, Intelligent manufacturing systems, Offloading Strategy, RBC, Load Balancing},
abstract = {With the extensive adoption of cloud and edge computing in intelligent manufacturing systems driven by the Industrial Internet of Things (IIoT) and Artificial Intelligence, enhancing the efficiency of cloud-edge collaboration under constrained communication and computational resources has emerged as a prominent research focus. We develop the GRALB model, which is based on Role-Based Collaboration (RBC) in cooperative services, to comprehensively manage the offloading strategy of terminal user tasks between edge nodes and the cloud to solve the joint communication and computing resource allocation problem in intelligent manufacturing systems. First, we jointly model the end-to-end latency and energy consumption based on the physical scenario of cloud-edge collaboration. Then, we extend the GRA model based on E-CARGO and propose the GRALB model with load balancing, which formally models the original joint communication and computing resource allocation problem as an equivalent cooperative service model and provides a proof of algorithm convergence. Finally, we design an x-ILP solution to support the verification and integrated application of the proposed model. Simulation results further confirm our theoretical analysis and show that the proposed collaborative cloud and edge computing solution significantly improves the overall system performance.}
}
@article{MITCHELL20061194,
title = {Complex systems: Network thinking},
journal = {Artificial Intelligence},
volume = {170},
number = {18},
pages = {1194-1212},
year = {2006},
note = {Special Review Issue},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2006.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S000437020600083X},
author = {Melanie Mitchell},
keywords = {Complex systems, Networks, Small-world networks, Scale-free networks, Cellular automata, Biologically inspired AI, Information processing},
abstract = {In this article, I discuss some recent ideas in complex systems on the topic of networks, contained in or inspired by three recent complex systems books. The general science of networks is the subject of Albert-Lazlo Barabási's Linked [A.-L. Barabási, Linked: The New Science of Networks, Perseus, New York, 2002] and Duncan Watts' Six Degrees [D. Watts, Six Degrees: The Science of a Connected Age, Gardner's Books, New York, 2003]. Commonalities among complex biological networks, e.g., immune systems, social insects, and cellular metabolism, and their relation to intelligence in computational systems are explored in the proceedings of a interdisciplinary conference on “Distributed Autonomous Systems” [L.A. Segel, I.R. Cohen (Eds.), Design Principles for the Immune System and Other Distributed Autonomous Systems, Oxford University Press, New York, 2001]. The ideas discussed in the third book have led to me to propose four general principles of adaptive information processing in decentralized systems. These principles, and the relevance of “network thinking” for artificial intelligence (and vice versa), are the subject of the last two sections of the article.}
}
@article{COTTAM2022104635,
title = {Computation in biological systems as a quantum mechanical simulation},
journal = {Biosystems},
volume = {214},
pages = {104635},
year = {2022},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2022.104635},
url = {https://www.sciencedirect.com/science/article/pii/S0303264722000272},
author = {Ron Cottam and Roger Vounckx},
keywords = {Computation, Quantum mechanics, Classical mechanics, Quantum mechanical simulation, Evolution},
abstract = {Our initial premise is that computation as we know it is formally derived from our bodies' internal processing, via our neural processors. Going backwards in time, our bodies' internal processing is in turn derived from wider Nature's own style of processing, which in turn is a rendition of the Universe's processing following the Big Bang. Computation is described as consisting of two intimately connected parts: comparative processing and conclusive processing. Our examination of post-Big Bang processing, biological processing, neural processing and human thinking supports our initial premise and the conclusion that computation is the motor for evolutionary emergence across the entire timescale of the Universe.}
}
@article{MAVROMATIDIS2025105404,
title = {Constructal thermodynamics and its semantic ontology in autopoietic, digital, and computational architectural and urban space open systems},
journal = {BioSystems},
volume = {249},
pages = {105404},
year = {2025},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2025.105404},
url = {https://www.sciencedirect.com/science/article/pii/S0303264725000140},
author = {Lazaros Mavromatidis},
keywords = {Complexity, constructal law, Exergy, Energy, Subject, Predicate, Gouy-Stodola theorem, Entropy, Heterotopia},
abstract = {This paper explores the intersections of constructal thermodynamics, and its semantic ontology within the context of autopoietic, digital and computational design in protocell inspired numerical architectural and urban narratives that are examined here as open systems. Constructal law is the thermodynamic theory based on the analysis of fluxes across the boundaries of an open system. Protocells, as dynamic, autopoietic and adaptive open finite size systems, serve in this paper as a compelling metaphor and design model for responsive and sustainable manmade architectural and urban environments. The ability of protocells to harness energy, minimize entropy, and adapt to environmental changes mirrors the principles of constructal thermodynamics, which govern the flow and distribution of resources in complex self-organizing information open systems in nature. By applying these principles to digital architecture, this study investigates how relational dynamics between spaces, materials, and functions can create adaptive designs that “go with the flow” of ecological and cultural systems. The research demonstrates using the Gouy-Stodola theorem as a variational principle, how protocell-inspired processes facilitate exergy-efficient designs, minimizing waste while maximizing resilience and flexibility. The present paper argues -through an applied case study- for a paradigm where protocell digital architecture serves not only as an ecological and material model but mainly as a spatial narrative driver, blending constructal and digital tools with cultural mythos. Finally, this paper exploring simultaneously the semantic complexity and ontology of such systems, in turn, connects these constructal driven digital designs to broader poly-narratives, embedding cultural, symbolic, philosophical and functional predicates into architectural forms.}
}
@incollection{MARTINGAMBOA2021295,
title = {Chapter 16 - Coupled life cycle thinking and data envelopment analysis for quantitative sustainability improvement},
editor = {Jingzheng Ren},
booktitle = {Methods in Sustainability Science},
publisher = {Elsevier},
pages = {295-320},
year = {2021},
isbn = {978-0-12-823987-2},
doi = {https://doi.org/10.1016/B978-0-12-823987-2.00003-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128239872000039},
author = {Mario Martín-Gamboa and Diego Iribarren},
keywords = {Data Envelopment Analysis, Multicriteria Decision Analysis, Life Cycle Assessment, Sustainability Assessment},
abstract = {This chapter addresses the joint use of Data Envelopment Analysis (DEA) and Life Cycle Assessment (LCA) as a source of synergistic frameworks for quantitative sustainability assessment and benchmarking of multiple similar entities. In addition to current progress in the growing field of research in (environmental) LCA + DEA, novel approaches further integrating social life cycle indicators are proposed. This enhanced sustainability scope is expected to further promote the combined use of life cycle approaches and DEA when assessing and benchmarking a large number of resembling entities.}
}
@article{LARKINS2010913,
title = {Introductory computational science using MATLAB and image processing},
journal = {Procedia Computer Science},
volume = {1},
number = {1},
pages = {913-919},
year = {2010},
note = {ICCS 2010},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2010.04.100},
url = {https://www.sciencedirect.com/science/article/pii/S1877050910001018},
author = {D. Brian Larkins and William Harvey},
abstract = {We describe a new course designed to introduce engineering students to computational thinking. One of the most significant challenges in teaching an introductory-level applied computing course is that students are not expected to have substantial math and science experience. To address this, we have developed exercises which use edge detection and basic image processing to motivate the use of programming MATLAB in a non-trivial scientific application. MATLAB is a popular high-level programming language and environment which supports a wide range of computational science applications. MATLAB has strong support for operating on image data, which allows us to balance solving practical engineering problems with basic core concepts of computer science such as functional abstraction, conditional execution, and iteration.}
}
@article{ATANCE2001533,
title = {Episodic future thinking},
journal = {Trends in Cognitive Sciences},
volume = {5},
number = {12},
pages = {533-539},
year = {2001},
issn = {1364-6613},
doi = {https://doi.org/10.1016/S1364-6613(00)01804-0},
url = {https://www.sciencedirect.com/science/article/pii/S1364661300018040},
author = {Cristina M. Atance and Daniela K. O'Neill},
keywords = {episodic future thinking, planning, future orientation, self, time, episodic memory, semantic memory},
abstract = {Thinking about the future is an integral component of human cognition – one that has been claimed to distinguish us from other species. Building on the construct of episodic memory, we introduce the concept of ‘episodic future thinking’: a projection of the self into the future to pre-experience an event. We argue that episodic future thinking has explanatory value when considering recent work in many areas of psychology: cognitive, social and personality, developmental, clinical and neuropsychology. Episodic future thinking can serve as a unifying concept, connecting aspects of diverse research findings and identifying key questions requiring further reflection and study.}
}
@article{GOLDSCHMIDT2017107,
title = {Design Thinking: A Method or a Gateway into Design Cognition?},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {3},
number = {2},
pages = {107-112},
year = {2017},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2017.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S2405872617301235},
author = {Gabriela Goldschmidt}
}
@article{CRUZ2024111005,
title = {Nonconvexity and computational effort in the problem of Hydro-Power spillage policy assessment},
journal = {Electric Power Systems Research},
volume = {237},
pages = {111005},
year = {2024},
issn = {0378-7796},
doi = {https://doi.org/10.1016/j.epsr.2024.111005},
url = {https://www.sciencedirect.com/science/article/pii/S0378779624008903},
author = {Eric Augusto Melchor Cruz and David Sebastian Baltazar and Mohamed Badaoui},
keywords = {Generation function, Hydro-Power Plant, Nonconvex, Spillage, Assessment},
abstract = {This paper aims to assess the spillage policies in the Day-Ahead Hydro-Power Plant operation. For this purpose, a combination technique is proposed to prevent erroneous spillage decisions. Given that the developed mathematical modeling lacks the convexity property, we examine the multiple solutions obtained from the Hydro-Power production optimization subject to different power output formulations. In addition, a nonlinear approach to consider friction losses in the modeling is introduced. The modeling is described by Mixed-Integer Linear (MILP) and Integer Nonlinear (MINLP) Programming models. The optimal solutions are provided by Outer Approximation (OA), Branch-and-Bound (BB), and Interior Point algorithms. The simulations show that the water is managed distinctly depending on the optimizer and solution algorithms. Finally, the findings of the spillage policy obtained by the Mixed-Integer Nonlinear model under the cubic function for power generation encourage and indicate its adequacy for a more realistic operation and management of the Mexican Hydro-Power Plant water resources.}
}
@article{HUANG201244,
title = {Protocol analysis of designers using an interactive evolutionary computation},
journal = {Frontiers of Architectural Research},
volume = {1},
number = {1},
pages = {44-50},
year = {2012},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2012.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S2095263512000040},
author = {Weixin Huang and Daisuke Matsushita and Junzo Munemoto},
keywords = {Interior color, Problem-solving behavior, Protocol analysis, Interactive evolutionary computation (IEC)},
abstract = {This paper explores the problem-solving behavior of people in design activities through a protocol analysis of verbal reports on the interior work design process simulated by an interactive evolutionary computation (IEC). The protocol analysis method was used to explore the ways of thinking of the participants throughout the process. The analysis reveals that different parts of the interior scene have different effects on the evaluations, and people tend to use the same evaluation criteria continuously on several images. This kind of behavior is consistent with that of professional designers in past studies and is revealed applicable to non-professionals in the current research.}
}
@article{BECK2011190,
title = {Supporting children’s counterfactual thinking with alternative modes of responding},
journal = {Journal of Experimental Child Psychology},
volume = {108},
number = {1},
pages = {190-202},
year = {2011},
issn = {0022-0965},
doi = {https://doi.org/10.1016/j.jecp.2010.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S0022096510001487},
author = {Sarah R. Beck and Daniel J. Carroll and Victoria E.A. Brunsdon and Charlotte K. Gryg},
keywords = {Counterfactual, Executive function, Inhibition, Imagination, Reasoning, Prepotent responses},
abstract = {To speculate about counterfactual worlds, children need to ignore what they know to be true about the real world. Prior studies yielding individual differences data suggested that counterfactual thinking may be related to overcoming prepotent responses. In two experiments, we manipulated how 3- to 5-year-olds responded to counterfactual conditional and syllogism tasks. In Experiment 1 (N=39), children’s performance improved on both conditional and syllogism tasks when they responded with an arrow rather than pointing with a finger. In Experiment 2 (N=42), 3- and 4-year-olds benefited from both an arrow manipulation and, separately, the introduction of a delay before responding. We suggest that both manipulations help children to overcome an impulsive prepotent response to counterfactual questions arising from a default assumption that information about the past is true.}
}
@article{SAXENA2023113238,
title = {Thinking green with 2-D and 3-D MXenes: Environment friendly synthesis and industrial scale applications and global impact},
journal = {Renewable and Sustainable Energy Reviews},
volume = {178},
pages = {113238},
year = {2023},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2023.113238},
url = {https://www.sciencedirect.com/science/article/pii/S1364032123000941},
author = {Shatakshi Saxena and Michael Johnson and Fuhar Dixit and Karl Zimmermann and Shreya Chaudhuri and Fiyanshu Kaka and Balasubramanian Kandasubramanian},
keywords = {MXene nanocomposites, Green synthesis, Defect engineering, Ionic liquid, Supercapacitors, Machine learning, Economic impact},
abstract = {MXenes are currently a research hotspot in the field of 2D materials, hinting to revolutionize material technology. Their layered architecture allows for molecular intercalation, defect engineering, and surface band gap functionalization, with applications as diverse as energy storage and drinking water desalination. Its structural and functional integrity has prompted the scientific community to investigate novel compositions in an effort to leverage electrochemical activity, mechanical robustness, flexibility and environmental stability. However, the current synthesis routes present a bottleneck in proposing MXenes as a sustainable material for the future. Therefore, by expanding the reach of synthetic chemistry towards efficient strategies for green production, we present the first comprehensive introspection of the use of green solvents and their impact on material properties during MXene synthesis. This review is an attempt to quantify the intriguing characteristics of MXene nanocomposites by embracing design tools like the ‘iceberg model’. To further evaluate the performance of MXenes fabricated using green strategies (such as eutectic etching) we have made an attempt to critically compare them with conventional MXenes by examining surface characteristics, electrochemical analysis, charge transfer mechanisms etc. Conclusively, we aim to instigate concern about the environmental impact of MXene synthesis and instil a multidisciplinary approach to tailor environmentally benign, scalable and efficient MXene derivatives for commercial energy applications. The review provides an immersive account linking UN sustainable development goals with the industrial outlook of green MXenes, it highlights their impact on climate change, potential to build technically advanced economies, low cost production and range of applications.}
}
@article{LLOYD2017A1,
title = {From Design Methods to Future-Focused Thinking: 50 years of design research},
journal = {Design Studies},
volume = {48},
pages = {A1-A8},
year = {2017},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2016.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X1630093X},
author = {Peter Lloyd},
abstract = {The 50th anniversary of the founding of the Design Research Society fell in 2016, and the biennial DRS conference for 2016 became a special 50th anniversary conference, which took place in Brighton, UK, last June.}
}
@article{FLY2017S105,
title = {Where Did They Go Wrong? Identifying Student Strategies Used in Analytic Thinking, Evaluating Data, and Problem Solving},
journal = {Journal of Nutrition Education and Behavior},
volume = {49},
number = {7, Supplement 1},
pages = {S105},
year = {2017},
note = {SNEB 2017 Annual Conference Proceedings},
issn = {1499-4046},
doi = {https://doi.org/10.1016/j.jneb.2017.05.125},
url = {https://www.sciencedirect.com/science/article/pii/S1499404617303913},
author = {Alyce Fly and Krisha Thiagarajah and Lisa Kurz}
}
@article{ASADZADEH2024100694,
title = {Computational and experimental study of AC measurements performed by a double-nanohole plasmonic nanopore sensor on 20 nm silica nanoparticles},
journal = {Sensing and Bio-Sensing Research},
volume = {46},
pages = {100694},
year = {2024},
issn = {2214-1804},
doi = {https://doi.org/10.1016/j.sbsr.2024.100694},
url = {https://www.sciencedirect.com/science/article/pii/S221418042400076X},
author = {Homayoun Asadzadeh and Scott Renkes and MinJun Kim and George Alexandrakis},
keywords = {Solid-state nanopores, Double nanohole, Plasmonic, Optical trapping, Conductance, AC, Phase shift, Computational model, COMSOL},
abstract = {A novel method of AC sensing is presented that uses a double nanohole (DNH) nanoaperture atop a solid-state nanopore (ssNP) to trap analytes and measure their optical and electrical properties. In this method analytes are propelled by an external applied voltage towards the sensor until they are trapped at the DNH-ssNP interface via a self-induced back action (SIBA) plasmonic force. We have previously named this method SIBA Actuated Nanopore Electrophoresis (SANE) sensing and have shown its ability to perform concurrent optical and DC electrical measurements. Here, we extend this method to AC sensing of 20 nm SiO2 (silica) nanoparticles, using voltage modulation over a wide range of frequencies applied on top of a baseline DC bias. The sensor was constructed using two-beam GFIS Focused Ion Beam (FIB) lithography, incorporating Ne FIB to mill the DNH and He FIB to drill a central 30 nm ssNP. We utilized COMSOL Multiphysics simulations to explore the multi-frequency AC current conductance properties of the silica nanoparticles trapped at the SANE sensor. These simulations computed conductance changes and phase shifts induced by the presence of the nanoparticle over an AC frequency range of 20 Hz to 100 kHz. Experimental measurements confirmed the trends seen in the computational data. Additional computational studies were then performed to dissect the underlying mechanisms driving the observed AC measurements. Looking forward, we aim to adapt this technology for probing therapeutic nanoparticles non-invasively, offering a promising tool for enhancing quality control of nanoparticle-mediated drug and gene delivery systems.}
}
@article{BLEILDESOUZA2012112,
title = {Contrasting paradigms of design thinking: The building thermal simulation tool user vs. the building designer},
journal = {Automation in Construction},
volume = {22},
pages = {112-122},
year = {2012},
note = {Planning Future Cities-Selected papers from the 2010 eCAADe Conference},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2011.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S0926580511001695},
author = {Clarice {Bleil de Souza}},
keywords = {Thermal simulation, Paradigms of design thinking, Role of simulation in design, Integration of simulation in design, Criticising integrated simulation},
abstract = {This paper contrasts two different paradigms of design thinking: the one of the dynamic thermal simulation tool users with the one of the building designer. It shows that, in theory, the two paradigms seem to be incommensurable but complementary due to differences in knowledge and praxis between the two professions. The author discusses these differences side-by-side based on a review of the design science literature together with an analysis of the basic structure and knowledge involved in existing thermal simulation tools. This discussion aims to unfold a set of insights into the type of approach needed to move this research area further. It highlights the modus operandi of the building designer rather than focusing on collaborative efforts and sets up the backgrounds for designers to learn relevant concepts of building physics in an environment in which they can experiment with these concepts as ‘craftsmen’.}
}
@article{JOHNSONRESTREPO2020101088,
title = {A computational science approach to understanding human conflict},
journal = {Journal of Computational Science},
volume = {46},
pages = {101088},
year = {2020},
note = {20 years of computational science},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2020.101088},
url = {https://www.sciencedirect.com/science/article/pii/S1877750319313456},
author = {D. Dylan {Johnson Restrepo} and Michael Spagat and Stijn {van Weezel} and Minzhang Zheng and Neil F. Johnson},
keywords = {Human conflict, Power laws, Generative models, Computational approaches, Agent-based models},
abstract = {We discuss how computational data science and agent-based modeling, are shedding new light on the age-old issue of human conflict. While social science approaches focus on individual cases, the recent proliferation of empirical data and complex systems thinking has opened up a computational approach based on identifying common statistical patterns and building generative but minimal agent-based models. We discuss a reconciliation for various disparate claims and results in the literature that stand in the way of a unified description and understanding of human wars and conflicts. We also discuss the unified interpretation of the origin of these power-law deviations in terms of dynamical processes. These findings show that a unified computational science framework can be used to understand and quantitatively describe collective human conflict.}
}
@article{ZHANG2002445,
title = {Measuring thinking styles in addition to measuring personality traits?},
journal = {Personality and Individual Differences},
volume = {33},
number = {3},
pages = {445-458},
year = {2002},
issn = {0191-8869},
doi = {https://doi.org/10.1016/S0191-8869(01)00166-0},
url = {https://www.sciencedirect.com/science/article/pii/S0191886901001660},
author = {Li-fang Zhang},
keywords = {Thinking styles, Personality traits, Measurement},
abstract = {This paper intends to join the long-standing debate regarding thinking styles and personality traits—should thinking styles be measured in addition to the measurement of personality traits? The means to achieve this goal was to provide empirical evidence as well as to review other studies in the literature. The Thinking Styles Inventory and the NEO Five-Factor Inventory were administered to 267 (67 male and 200 female) students from a large research university in Beijing, People's Republic of China. Results showed that thinking styles and personality traits statistically overlap. However, this overlap is limited. Two major arguments are made. First, thinking styles make a unique contribution to the understanding of human individual differences. Second, the necessity for measuring thinking styles apart from measuring personality traits depends on who uses the inventories and for what purposes.}
}
@article{SCHAPER2023100617,
title = {Computational Empowerment and children: Expanding empowerment, agency and participation in computation},
journal = {International Journal of Child-Computer Interaction},
volume = {38},
pages = {100617},
year = {2023},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2023.100617},
url = {https://www.sciencedirect.com/science/article/pii/S2212868923000545},
author = {Marie-Monique Schaper and Rachel Charlotte Smith and Ole Sejer Iversen and Christopher Frauenberger and Netta Iivari and Anja Zeising and Mike Tissenbaum and Elizabeth Marie Bonsignore and Jason Yip}
}
@article{STUSSI2024105676,
title = {Computational analysis, appraised concern-relevance, and the amygdala: The algorithmic value of appraisal processes in emotion},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {161},
pages = {105676},
year = {2024},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2024.105676},
url = {https://www.sciencedirect.com/science/article/pii/S0149763424001453},
author = {Yoann Stussi and David Sander},
keywords = {Emotion, Appraisal, Concerns, Learning, Computational approach, Algorithm, Amygdala}
}
@article{BULLEY201753,
title = {Thinking about threats: Memory and prospection in human threat management},
journal = {Consciousness and Cognition},
volume = {49},
pages = {53-69},
year = {2017},
issn = {1053-8100},
doi = {https://doi.org/10.1016/j.concog.2017.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S1053810017300326},
author = {Adam Bulley and Julie D. Henry and Thomas Suddendorf},
keywords = {Episodic foresight, Episodic memory, Semantic memory, Mental time travel, Threat detection, Anxiety, Worry, Evolution, Evolutionary psychology, Counterfactual thinking},
abstract = {Humans have evolved mechanisms for the detection and management of possible threats in order to abate their negative consequences for fitness. Internally generated (‘detached’) cognition may have evolved in part because of its contributions to this broad function, but important questions remain about its role in threat management. In this article, we therefore present a taxonomy of threat-related internally generated cognition comprising episodic and semantic formats of memory and prospection. We address the proximate mechanisms of each of the capacities in this taxonomy, and discuss their respective contributions to adaptive threat management in humans. For instance, mental time travel empowers people to contemplate and learn from threats experienced long ago, as well as to plan for dangers that might arise in the distant future. However, despite their functional benefits, these thought processes are also central to contemporary anxiety disorders and may be a potent source of distress.}
}
@article{ZHANG2021100947,
title = {RETRACTED: Creative thinking and musical collaboration: Promoting online learning groups for aspiring musicians},
journal = {Thinking Skills and Creativity},
volume = {42},
pages = {100947},
year = {2021},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2021.100947},
url = {https://www.sciencedirect.com/science/article/pii/S1871187121001620},
author = {Meng Zhang and Minjian Guo and Banghan Xiao},
abstract = {This article has been retracted: please see Elsevier Policy on Article Withdrawal (https://www.elsevier.com/about/our-business/policies/article-withdrawal). This article has been retracted at the request of the Editors-in-Chief. After a thorough investigation, the Editors have concluded that the acceptance of this article was partly based upon the positive advice of one illegitimate reviewer report. The report was submitted from an email account which was provided to the journal as a suggested reviewer during the submission of the article. Although purportedly a real reviewer account, the Editors have concluded that this was not of an appropriate, independent reviewer. This manipulation of the peer-review process represents a clear violation of the fundamentals of peer review, our publishing policies, and publishing ethics standards. Apologies are offered to the reviewer whose identity was assumed and to the readers of the journal that this deception was not detected during the submission process.}
}
@article{MCDONALD202239,
title = {Undergraduate structural biology education: A shift from users to developers of computation and simulation tools},
journal = {Current Opinion in Structural Biology},
volume = {72},
pages = {39-45},
year = {2022},
issn = {0959-440X},
doi = {https://doi.org/10.1016/j.sbi.2021.07.012},
url = {https://www.sciencedirect.com/science/article/pii/S0959440X21001202},
author = {Ashley Ringer McDonald and Rebecca Roberts and Julia R. Koeppe and Bonnie L. Hall},
abstract = {The use of theory and simulation in undergraduate education in biochemistry, molecular biology, and structural biology is now common, but the skills students need and the curriculum instructors have to train their students are evolving. The global pandemic and the immediate switch to remote instruction forced instructors to reconsider how they can use computation to teach concepts previously approached with other instructional methods. In this review, we survey some of the curricula, materials, and resources for instructors who want to include theory, simulation, and computation in the undergraduate curriculum. There has been a notable progression from teaching students to use discipline-specific computational tools to developing interactive computational tools that promote active learning to having students write code themselves, such that they view computation as another tool for solving problems. We are moving toward a future where computational skills, including programming, data analysis, visualization, and simulation, will no longer be considered an optional bonus for students but a required skill for the 21st century STEM (Science, Technology, Engineering, and Mathematics) workforce; therefore, all physical and life science students should learn to program in the undergraduate curriculum.}
}
@article{MILZ2016643,
title = {The functional significance of EEG microstates—Associations with modalities of thinking},
journal = {NeuroImage},
volume = {125},
pages = {643-656},
year = {2016},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2015.08.023},
url = {https://www.sciencedirect.com/science/article/pii/S105381191500734X},
author = {P. Milz and P.L. Faber and D. Lehmann and T. Koenig and K. Kochi and R.D. Pascual-Marqui},
keywords = {Cognitive style, eLORETA, Object, Spatial, Verbal, Visual},
abstract = {The momentary, global functional state of the brain is reflected by its electric field configuration. Cluster analytical approaches consistently extracted four head-surface brain electric field configurations that optimally explain the variance of their changes across time in spontaneous EEG recordings. These four configurations are referred to as EEG microstate classes A, B, C, and D and have been associated with verbal/phonological, visual, subjective interoceptive–autonomic processing, and attention reorientation, respectively. The present study tested these associations via an intra-individual and inter-individual analysis approach. The intra-individual approach tested the effect of task-induced increased modality-specific processing on EEG microstate parameters. The inter-individual approach tested the effect of personal modality-specific parameters on EEG microstate parameters. We obtained multichannel EEG from 61 healthy, right-handed, male students during four eyes-closed conditions: object-visualization, spatial-visualization, verbalization (6 runs each), and resting (7 runs). After each run, we assessed participants' degrees of object-visual, spatial-visual, and verbal thinking using subjective reports. Before and after the recording, we assessed modality-specific cognitive abilities and styles using nine cognitive tests and two questionnaires. The EEG of all participants, conditions, and runs was clustered into four classes of EEG microstates (A, B, C, and D). RMANOVAs, ANOVAs and post-hoc paired t-tests compared microstate parameters between conditions. TANOVAs compared microstate class topographies between conditions. Differences were localized using eLORETA. Pearson correlations assessed interrelationships between personal modality-specific parameters and EEG microstate parameters during no-task resting. As hypothesized, verbal as opposed to visual conditions consistently affected the duration, occurrence, and coverage of microstate classes A and B. Contrary to associations suggested by previous reports, parameters were increased for class A during visualization, and class B during verbalization. In line with previous reports, microstate D parameters were increased during no-task resting compared to the three internal, goal-directed tasks. Topographic differences between conditions included particular sub-regions of components of the metabolic default mode network. Modality-specific personal parameters did not consistently correlate with microstate parameters except verbal cognitive style which correlated negatively with microstate class A duration and positively with class C occurrence. This is the first study that aimed to induce EEG microstate class parameter changes based on their hypothesized functional significance. Beyond the associations of microstate classes A and B with visual and verbal processing, respectively, our results suggest that a finely-tuned interplay between all four EEG microstate classes is necessary for the continuous formation of visual and verbal thoughts. Our results point to the possibility that the EEG microstate classes may represent the head-surface measured activity of intra-cortical sources primarily exhibiting inhibitory functions. However, additional studies are needed to verify and elaborate on this hypothesis.}
}
@incollection{MISHRA2025167,
title = {Chapter 5-1 - Role of computational biology in the diagnosis of neurodegenerative disorders},
editor = {Babita Pandey and Suman Lata Tripathi and Valentina {Emilia Balas} and Devendra Kumar Pandey and Mufti Mahmud},
booktitle = {Computational Intelligence for Genomics Data},
publisher = {Academic Press},
pages = {167-179},
year = {2025},
series = {Advances in Biomedical Informatics},
isbn = {978-0-443-30080-6},
doi = {https://doi.org/10.1016/B978-0-443-30080-6.00004-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443300806000043},
author = {Ashish Mishra and Sanjeev Kumar Sahu and Sunil Mistry},
keywords = {Computational biology, neurodegenerative disorders, diagnosis, artificial intelligence},
abstract = {Neurodegenerative disorders present a significant challenge in modern healthcare due to their complex and diverse manifestations. The beginning of computational intelligence has revolutionized the diagnostic landscape, offering promising ways for early and accurate detection of these debilitating conditions. Machine learning algorithms, a subset of computational intelligence, have emerged as powerful tools for analyzing extensive datasets comprising genetic, imaging, and clinical information. Furthermore, computational intelligence facilitates the integration of multimodal data, integrating information from genetic profiles, brain imaging (MRI, PET scans), and clinical assessments. This consolidative approach enables a comprehensive understanding of disease progression and aids in the development of predictive models for early medical assessment and prediction of the outcome. Moreover, the utilization of computational intelligence in neuroimaging analysis has shown remarkable potential. Advanced image processing techniques coupled with machine learning algorithms enable the detection of structural and functional abnormalities in the brain, often serving as precursors to neurodegenerative disorders. This chapter explores the key role of computational intelligence in enhancing the diagnosis of neurodegenerative disorders, such as Alzheimer, Parkinson, etc. In conclusion, computational intelligence offers a transformative framework for advancing the diagnosis of neurodegenerative disorders. Embracing and refining these computational tools will undoubtedly overlay the way for more effective interventions and personalized medicine in the fight against these challenging conditions.}
}
@article{GUILLENGOSALBEZ2019170,
title = {Process systems engineering thinking and tools applied to sustainability problems: current landscape and future opportunities},
journal = {Current Opinion in Chemical Engineering},
volume = {26},
pages = {170-179},
year = {2019},
note = {Energy, Environment & Sustainability: Sustainability Modeling ● Reaction engineering and catalysis: Green Reaction Engineering},
issn = {2211-3398},
doi = {https://doi.org/10.1016/j.coche.2019.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S2211339819300541},
author = {Gonzalo Guillén-Gosálbez and Fengqi You and Ángel Galán-Martín and Carlos Pozo and Ignacio E. Grossmann},
abstract = {In this work we provide a perspective on Process Systems Engineering (PSE) in the context of sustainability, reviewing the main tools available and describing major applications in sustainability problems spanning multiple scales, from molecules, through chemical plants, and finally the enterprise and macroeconomic levels. After highlighting the potential role of PSE in meeting the UN Sustainable Development Goals, we discuss future research directions, focusing on major modelling and algorithmic challenges along with the trend to explore new application domains beyond chemical engineering while still revisiting problems within the core discipline.}
}
@incollection{WHITNEY2013231,
title = {Chapter 6 - Thinking . . . Machines},
editor = {Hunter Whitney},
booktitle = {Data Insights},
publisher = {Morgan Kaufmann},
pages = {231-263},
year = {2013},
isbn = {978-0-12-387793-2},
doi = {https://doi.org/10.1016/B978-0-12-387793-2.00006-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780123877932000061},
author = {Hunter Whitney}
}
@article{LAMB2014116,
title = {A computational modeling of student cognitive processes in science education},
journal = {Computers & Education},
volume = {79},
pages = {116-125},
year = {2014},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2014.07.014},
url = {https://www.sciencedirect.com/science/article/pii/S0360131514001651},
author = {Richard L. Lamb and David B. Vallett and Tariq Akmal and Kathryn Baldwin},
keywords = {Computational modeling, Cognitive processing, Science education, Critical reasoning, Serious educational games},
abstract = {The purpose of this paper is to explain and document the creation of a computational model in the form of an Artificial Neural Network (ANN) capable of simulating student cognition. Specifically, the model simulates students' cognition as they complete activities within a science classroom. This study also seeks to examine the effects, as evidenced in the ANN, of an intervention designed to develop increased levels of critical thinking related to science skills. This model is based on the identification of cognitive attributes and integration of two advanced measurement frameworks: cognitive diagnostics and Item Response Theory. Both frameworks examine student response patterns, providing initial inputs for the ANN portion of the model. Once initial task response patterns are identified, they are parameterized and presented to the ANN. The ANN within this study is the foundational component of a computational model based upon the interaction of multiple, connected, adaptive processing elements know as cognitive attributes. These cognitive attributes process student responses to cognitive tasks within science tasks. Using the Student Task and Cognition Model (STAC-M), the study authors simulated a cognitive training intervention using a randomized control trial design of 100,000 students. Results of the simulation suggest that it is possible to increase levels of student success using a targeted cognitive attribute approach and that computational modeling provides a means to test educational theory for future education research. The paper also discusses limitations of the use of this computational model within education and the possible future directions for educators and researchers.}
}
@article{OBRIEN2002313,
title = {Radical connectionism: thinking with (not in) language},
journal = {Language & Communication},
volume = {22},
number = {3},
pages = {313-329},
year = {2002},
issn = {0271-5309},
doi = {https://doi.org/10.1016/S0271-5309(02)00010-1},
url = {https://www.sciencedirect.com/science/article/pii/S0271530902000101},
author = {Gerard O'Brien and Jon Opie},
keywords = {Analog, Computation, Connectionism, Representation, Resemblance, Thought},
abstract = {In this paper we defend a position we call radical connectionism. Radical connectionism claims that cognition never implicates an internal symbolic medium, not even when natural language plays a part in our thought processes. On the face of it, such a position renders the human capacity for abstract thought quite mysterious. However, we argue that connectionism is committed to an analog conception of neural computation, and that representation of the abstract is no more problematic for a system of analog vehicles than for a symbol system. Natural language is therefore not required as a representational medium for abstract thought. Since natural language is arguably not a representational medium at all, but a conventionally governed scheme of communicative signals, we suggest that the role of internalised (i.e. self-directed) language is best conceived in terms of the coordination and control of cognitive activities within the brain.}
}
@incollection{WARE2021393,
title = {Chapter Eleven - Thinking With Visualizations},
editor = {Colin Ware},
booktitle = {Information Visualization (Fourth Edition)},
publisher = {Morgan Kaufmann},
edition = {Fourth Edition},
pages = {393-424},
year = {2021},
series = {Interactive Technologies},
isbn = {978-0-12-812875-6},
doi = {https://doi.org/10.1016/B978-0-12-812875-6.00011-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128128756000116},
author = {Colin Ware},
keywords = {Change blindness, Cognitive system, Computational data mappings, Degree-of-relevance highlighting, Design sketching, Epistemic actions, Generalized fisheye views, Intrasaccadic scanning loop, Knowledge transfer, Mental imagery, Mental images, Multidimensional dynamic queries, Pattern perception, Pattern-finding loop, Scatterplots, Spatial information, Visual cognitive system components, Visual queries, Visual thinking algorithms, Visual working memory capacity},
abstract = {This chapter begins by outlining the cognitive system involved in thinking with visualizations. These are processes that occur partly in a computer and partly in the visual brain of the user. The output of the computer is a series of visual images that are processed through the visual system of the user. The output of the user is a set of epistemic actions, such as clicking on an object or moving a slider, which result in the visualization being modified in some way by the computer. The applications discussed include problem solving with visualization, design of interactive systems, and creativity.}
}
@article{MONTEIROJUNIOR2020109894,
title = {COVID-19: Thinking about further mental and neurological disorders},
journal = {Medical Hypotheses},
volume = {143},
pages = {109894},
year = {2020},
issn = {0306-9877},
doi = {https://doi.org/10.1016/j.mehy.2020.109894},
url = {https://www.sciencedirect.com/science/article/pii/S030698772031046X},
author = {Renato Sobral Monteiro-Junior}
}
@article{RAOELISON2020104381,
title = {The smart intuitor: Cognitive capacity predicts intuitive rather than deliberate thinking},
journal = {Cognition},
volume = {204},
pages = {104381},
year = {2020},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2020.104381},
url = {https://www.sciencedirect.com/science/article/pii/S0010027720302006},
author = {Matthieu Raoelison and Valerie A. Thompson and Wim {De Neys}},
keywords = {Reasoning, Decision-making, Cognitive capacity, Dual process theory, Heuristics & Biases},
abstract = {Cognitive capacity is commonly assumed to predict performance in classic reasoning tasks because people higher in cognitive capacity are believed to be better at deliberately correcting biasing erroneous intuitions. However, recent findings suggest that there can also be a positive correlation between cognitive capacity and correct intuitive thinking. Here we present results from 2 studies that directly contrasted whether cognitive capacity is more predictive of having correct intuitions or successful deliberate correction of an incorrect intuition. We used a two-response paradigm in which people were required to give a fast intuitive response under time pressure and cognitive load and afterwards were given the time to deliberate. We used a direction-of change analysis to check whether correct responses were generated intuitively or whether they resulted from deliberate correction (i.e., an initial incorrect-to-correct final response change). Results showed that although cognitive capacity was associated with the correction tendency (overall r = 0.22) it primarily predicted correct intuitive responding (overall r = 0.44). These findings force us to rethink the nature of sound reasoning and the role of cognitive capacity in reasoning. Rather than being good at deliberately correcting erroneous intuitions, smart reasoners simply seem to have more accurate intuitions.}
}
@incollection{DING202319,
title = {Mathematics in STEM education},
editor = {Robert J Tierney and Fazal Rizvi and Kadriye Ercikan},
booktitle = {International Encyclopedia of Education (Fourth Edition)},
publisher = {Elsevier},
edition = {Fourth Edition},
address = {Oxford},
pages = {19-27},
year = {2023},
isbn = {978-0-12-818629-9},
doi = {https://doi.org/10.1016/B978-0-12-818630-5.13035-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128186305130350},
author = {Meixia Ding and Jinfa Cai},
keywords = {Computational thinking, Content, Explicit, Integration, K–12, Language tool, Mathematics, Process, Mathematical reasoning, STEM, Thinking tool},
abstract = {In this article, we discuss how mathematics can play a role in STEM activities in K–12 classrooms. From the perspective of content, we argue that mathematics serves as a language tool to help represent/model STEM activities and explain/interpret identified solutions. From the perspective of process, we argue that mathematics serves as a thinking tool because mathematical reasoning is at the core of problem solving. In addition, computational thinking is a critical skill for solving problems in complex systems. We conclude our study with three suggestions that help make mathematics more explicit in K–12 STEM classrooms.}
}
@article{BOSSAERTS2024100906,
title = {Resource allocation, computational complexity, and market design},
journal = {Journal of Behavioral and Experimental Finance},
volume = {42},
pages = {100906},
year = {2024},
issn = {2214-6350},
doi = {https://doi.org/10.1016/j.jbef.2024.100906},
url = {https://www.sciencedirect.com/science/article/pii/S2214635024000212},
author = {Peter Bossaerts and Elizabeth Bowman and Felix Fattinger and Harvey Huang and Michelle Lee and Carsten Murawski and Anirudh Suthakar and Shireen Tang and Nitin Yadav},
keywords = {Computational complexity, Knapsack problem, Resource allocation, Market design, Securities design, Oracles, Complete markets, Noisy rational expectations},
abstract = {With three experiments, we study the design of financial markets to help spread knowledge about solutions to the 0-1 Knapsack Problem (KP), a combinatorial resource allocation problem. To solve the KP, substantial cognitive effort is required; random sampling is ineffective and humans rarely resort to it. The theory of computational complexity motivates our experiment designs. Complete markets generate noisy prices and knowledge spreads poorly. Instead, one carefully chosen security per problem instance causes accurate pricing and effective knowledge dissemination. This contrasts with information aggregation experiments. There, values depend on solutions to probabilistic problems, which can be solved by random drawing.}
}
@article{WEBER2014679,
title = {Does “thinking about thinking” interfere with memory? An experimental memory study in obsessive–compulsive disorder},
journal = {Journal of Anxiety Disorders},
volume = {28},
number = {7},
pages = {679-686},
year = {2014},
issn = {0887-6185},
doi = {https://doi.org/10.1016/j.janxdis.2014.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S0887618514001029},
author = {Friederike Weber and Walter Hauke and Ina Jahn and Katarina Stengler and Hubertus Himmerich and Michael Zaudig and Cornelia Exner},
keywords = {Obsessive–compulsive disorder, Verbal memory, Cognitive self-consciousness, Proactive interference},
abstract = {Neuropsychological assessments of participants with obsessive–compulsive disorder (OCD) indicate impaired verbal memory if to be remembered material has to be organized. People with OCD also tend to focus their attention on their thoughts (heightened cognitive self-consciousness). We tested the hypothesis that cognitive self-consciousness causes verbal memory deficits by provoking a division of attention between study task and thoughts. Thirty-six participants with OCD, 36 matched healthy controls and 36 participants with major depressive disorder (MDD) learned under proactive interference in three study conditions: single-task condition, condition with heightened cognitive self-consciousness and condition with an external secondary task. Memory was impaired in the cognitive self-consciousness condition compared to both other conditions. Independent of condition, participants with OCD showed a reduced memory performance compared to healthy controls, but did not differ from participants with MDD. Our results are in line with the hypothesis that cognitive self-consciousness causes memory impairment.}
}
@article{SCURO2024105450,
title = {Coupled computational fluid dynamics and computational thermodynamics simulations for fission product retention and release: A molten salt fast reactor application},
journal = {Progress in Nuclear Energy},
volume = {177},
pages = {105450},
year = {2024},
issn = {0149-1970},
doi = {https://doi.org/10.1016/j.pnucene.2024.105450},
url = {https://www.sciencedirect.com/science/article/pii/S0149197024004001},
author = {N.L. Scuro and O. Beneš and S. Lorenzi and M. Krstovic and J. Krepel and M.H.A. Piro},
keywords = {Computational fluid dynamics, Computational thermodynamics, Multiphysics, Molten salt fast reactor, Fission products, JRCMDS},
abstract = {This study presents a computational capability for fission product retention and release in two-phase, multi-species systems representing Molten Salt Reactors (MSR) with coupled thermal-hydraulics and fuel coolant chemical behaviours. This is demonstrated through four simulated cases centred on the proposed Molten Salt Fast Reactor (MSFR). This is achieved by two-way coupling the Computational Fluid Dynamics (CFD) code OpenFOAM and the Computational Thermodynamics (CT) code Thermochimica, using the Joint Research Centre Molten Salt Database (JRCMSD). Local chemical equilibrium is assumed, implying that chemical kinetics are predominantly governed by mass transport. Four simulations address normal operating conditions, exploring: (i) dilution of fission products injected within the molten salt coolant, (ii) molten salt coolant evaporation rate, (iii) release of radioactive gaseous species, (iv) shifts in the UF4/UF3 ratio, and (v) comparison of vapour pressures of gaseous species. The influence of temperature-dependent viscosity on retaining fission products, compared to consistent values, is also discussed. The feasibility of integrating CFD with Thermochimica showed promising results, broadening insights into multiphysics systems and setting the stage for its application in more intricate scenarios.}
}
@article{LI2022100980,
title = {RETRACTED: Studying creativity and critical thinking skills at university and students' future income},
journal = {Thinking Skills and Creativity},
volume = {43},
pages = {100980},
year = {2022},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2021.100980},
url = {https://www.sciencedirect.com/science/article/pii/S1871187121001954},
author = {Weijuan Li},
abstract = {This article has been retracted: please see Elsevier Policy on Article Withdrawal (https://www.elsevier.com/about/our-business/policies/article-withdrawal). This article has been retracted at the request of the Editors-in-Chief. After a thorough investigation, the Editors have concluded that the acceptance of this article was partly based upon the positive advice of one illegitimate reviewer report. The report was submitted from an email account which was provided to the journal as a suggested reviewer during the submission of the article. Although purportedly a real reviewer account, the Editors have concluded that this was not of an appropriate, independent reviewer. This manipulation of the peer-review process represents a clear violation of the fundamentals of peer review, our publishing policies, and publishing ethics standards. Apologies are offered to the reviewer whose identity was assumed and to the readers of the journal that this deception was not detected during the submission process.}
}
@article{HOBSON2016411,
title = {Network Thinking in Animal Social Behavior},
journal = {Trends in Ecology & Evolution},
volume = {31},
number = {6},
pages = {411-412},
year = {2016},
issn = {0169-5347},
doi = {https://doi.org/10.1016/j.tree.2016.02.018},
url = {https://www.sciencedirect.com/science/article/pii/S016953471600063X},
author = {Elizabeth A. Hobson}
}
@article{QFIASCO201836,
journal = {Artificial Intelligence},
volume = {260},
pages = {36-41},
year = {2018},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2018.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0004370218301528},
author = {Flash qFiasco}
}
@article{ARANTES2023515,
title = {Rescripting creativity after automation: situating the simulacrum to interpret the queerness of computational creativity},
journal = {Qualitative Research Journal},
volume = {23},
number = {5},
pages = {515-528},
year = {2023},
issn = {1443-9883},
doi = {https://doi.org/10.1108/QRJ-01-2023-0012},
url = {https://www.sciencedirect.com/science/article/pii/S144398832300036X},
author = {Janine Aldous Arantes and Mark Vicars},
keywords = {Automation, Creativity, Simulacrum, Technology, Post qualitative},
abstract = {Purpose
The purpose of this paper is to examine how automation in the ever-changing technological landscape is increasing integrated into, and has become a significant presence in, our personal lives.
Design/methodology/approach
Through post qualitative inquiry, the authors provide a contemplation of automation and its effect on creativity, as a contemporary expression of dis/locations, the simulacrum, performative work and a toxic digital presence in socio-cultural-technical spaces.
Findings
The authors discuss how we behave, contribute, explore, interact and communicate within and across automated digital platforms, has salience for understanding and questioning the ways that dominant discourses in the contemporary construction and enactment of subjectivity, creativity and agency are being modulated by the machine.
Originality/value
This paper offers a nuanced consideration of creativity, by considering the way creativity is being performed and situated within the effects of automation and its role in dis/locations, performative work and its potential as a the simulacrum in socio-cultural-technical spaces.}
}
@article{REGIER2019235,
title = {Choice certainty and deliberative thinking in discrete choice experiments. A theoretical and empirical investigation},
journal = {Journal of Economic Behavior & Organization},
volume = {164},
pages = {235-255},
year = {2019},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2019.05.031},
url = {https://www.sciencedirect.com/science/article/pii/S0167268119301830},
author = {Dean A. Regier and Jonathan Sicsic and Verity Watson},
keywords = {Choice certainty, Discrete choice experiments, Hypothetical bias, Information processing, Stated preferences, Survey engagement},
abstract = {Resource allocation decisions require information about individuals' preferences for goods and services. Survey based stated preference methods, such as discrete choice experiments (DCEs), are used to elicit preferences for non-market goods. A critique of stated preference research is that respondents to hypothetical surveys may not provide careful and thoughtful responses that reveal rational preferences. Choice certainty has been used to measure survey respondents' task engagement. Researchers assume that respondents who are certain about their choices provide deliberative responses. In the case of DCE, we argue that the variability of choice certainty is also important. We present a novel framework to identify thoughtful / deliberative respondents. The framework combines respondents’ certainty with their variability in certainty across a set of choice tasks. We test our framework empirically using data from two case studies. We find respondents with higher mean certainty and variability (i) seldom use decision heuristics, (ii) are more likely to have monotonic preferences, (iii) have longer response times, (iv) make choices that have higher interval validity, and (v) have higher choice consistency. We discuss the relevance of alternative ex-post calibration strategies with a view to improve the precision and accuracy of DCE-based welfare estimates.}
}
@article{LISSACK2019231,
title = {Understanding Is a Design Problem: Cognizing from a Designerly Thinking Perspective. Part 1},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {5},
number = {3},
pages = {231-246},
year = {2019},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2019.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S2405872619300589},
author = {Michael Lissack},
keywords = {Design, Cognition, Understanding, Representation, Narrative, Cybernetics},
abstract = {Understanding and cognition are traditionally viewed as philosophical and scientific issues where there is little room for contribution from the design community. This article proposes a radically different approach based on the observation that we live in a world that is more complex than our minds/brains possess the ability to process in its entirety. Our limited equipment forces us to deal with only selected aspects of any given piece of that complex world at each instant. Selection—be it conscious or unconscious—involves agency and choice. Design and design thinking scholars have much to say about how agency and choice can be impacted by still other choices—context, symbols, movement, audience, and so on. Suppose cognition and meaning making were re-cast as design processes? This would highlight the role played by cybernetics—the science of how we learn how to steer—in shaping how we cognitively deal with the world. Together design and cybernetics have much to offer the cognitive sciences.}
}
@article{KANGAS2004101,
title = {The role of passive electrical analogs in H.T. Odum’s systems thinking},
journal = {Ecological Modelling},
volume = {178},
number = {1},
pages = {101-106},
year = {2004},
note = {Through the MACROSCOPE: the legacy of H.T. Odum},
issn = {0304-3800},
doi = {https://doi.org/10.1016/j.ecolmodel.2003.12.019},
url = {https://www.sciencedirect.com/science/article/pii/S0304380003005313},
author = {Patrick Kangas}
}
@incollection{KUPPUCHAMY20251,
title = {Chapter 1 - Journey of computational intelligence in sustainable computing and optimization techniques: An introduction},
editor = {Balamurugan Balusamy and Vinayakumar Ravi and Rajesh Kumar Dhanaraj and Sudha Senthilkumar and Brindha K.},
booktitle = {Computational Intelligence in Sustainable Computing and Optimization},
publisher = {Morgan Kaufmann},
pages = {1-51},
year = {2025},
isbn = {978-0-443-23724-9},
doi = {https://doi.org/10.1016/B978-0-443-23724-9.00001-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443237249000013},
author = {Sampath Kumar Kuppuchamy and S. Srinivasan and Ganesh Dhandapani and S. Nagaraj and Jeya A. Celin and Muthuvel Subramanian},
keywords = {Artificial neural networks, Computational intelligence, Evolutionary computation, Green computing, Optimization techniques, Sustainable computing},
abstract = {Presently, computational intelligence plays a major role in the areas of artificial intelligence–based neural network, fuzzy network and natural language processing, diligence-based games cognitive developmental computing, genetic algorithm, deep and machine learning, evolutionary computing under sustainable computing, and optimization methods. Several uncertainties raised in multivariant complexity for mathematical-based computational reasoning cannot be converted in machine language, which can be understood by computer. But the computational intelligence gives various solutions for many issues in real-world problems. The uncertainty fuzziness issues could be solved through computational artificial intelligence–based neural networks, which understand the real world as well as experimental facts through biological and evolutionary computing and machine learning with probabilistic methods. Swarm-based artificial intelligence and intelligent robotic immune systems is also an integral part of computational intelligence in sustainable computing. Presently, computational-based intelligence-based various fuzzy logic concepts has been enforced through fuzzifier and de-fuzzifier with assistance of crisp sets in automated control-based aerospace engineering, cooperative business with suitable logical decision-making, highly productive-based industrial engineering process, efficient automotive traffic control, and other real-time environment. Computational intelligence enforced the fuzzy semantics with mathematics ideas are implemented in advanced trading models, which assist the data analysts to make computerized automated artificial intelligence–based machine learning buy and sell signals. To sustain the artificial-intelligence applications by various categories of different types of artificial intelligence neural network like forward, convolutional, modular, and radial basis. Computational intelligence involved evolutionary intelligence techniques and algorithm enforce a collection of families of population-based experimental and error issues with solvers using a metaheuristic algorithm. Evolutionary intelligence algorithms invoke biological neural network operations such as computational reproduction, automated mutation, neural network-based natural selection, and evaluation of fitness in real entities. Computational intelligence in sustainable computing enforces artificial intelligence evolutionary computational system includes finite deterministic automata, a simplification of computerized-Turing machines, context-free-grammars enable to inspect the features of biological-based artificial intelligence neural network. Swarm intelligence applies swarm robotics, which govern and implement swarm principles and rules to automated robots through set artificial intelligence–based algorithms, which solved weather forecasting issues. Swarm robotics with genetically revised organisms applied in synthetic cooperative artificial intelligence, natural systems such as hawks hunting, bacterial growth. Artificial intelligence immune systems are one of the computational intelligence in sustainable computing, which adopts theoretically and practical based immunological and biology concepts and its functions, ideologies, and methods, which has been implemented in a fertile ground for encouragement and DNA computing. Sustainable computing makes use of well-organized physical equipment's and logical program, the dropping of electronic waste, the execution of supportable practices in management data center operations, and also reduced the negative impact on the environment caused by the fast growth of knowledge and increasing demand for computing power. Computational sustainable artificial-intelligence applied in social, environmental, and technological resources for the upcoming well-being of various civilizations through different from computer science, mathematics, and various fields. Optimization techniques are a controlling combination of methods and tools for solving complex real-world problems in different areas of optimization like linear programming optimization, intelligent-based meta-heuristics, nature-inspired optimization and applications. Optimizing the software can be achieved through virtualization, terminal servers and allocating resources strategically. Applications of computational intelligence in sustainable computing and optimization techniques are intelligent transportation systems, electrical grid, efficient power management, material recycling, cloud, edge, and parallel computing, telecommuting, real-life applications of optimization like data structure-based analysis of algorithmic optimized roaming salesman problem, financial markets, data clustering and mining, wireless sensor networks, chemical manufacturing, and so on. Finally, optimization achieved the following benefits such as improved efficiency, cost savings, improved quality, improved sustainability, and so on.}
}
@article{LAURENT2022101667,
title = {Impact of programming on primary mathematics learning},
journal = {Learning and Instruction},
volume = {82},
pages = {101667},
year = {2022},
issn = {0959-4752},
doi = {https://doi.org/10.1016/j.learninstruc.2022.101667},
url = {https://www.sciencedirect.com/science/article/pii/S0959475222000883},
author = {Manon Laurent and Rosamaria Crisci and Pascal Bressoux and Hamid Chaachoua and Cécile Nurra and Erica {de Vries} and Pierre Tchounikine},
keywords = {Computational thinking, Programming activity, Mathematics learning, Primary school, Randomized trial, Learning transfer},
abstract = {The aim of this study is to investigate whether a programming activity might serve as a learning vehicle for mathematics acquisition in grades four and five. For this purpose, the effects of a programming activity, an essential component of computational thinking, were evaluated on learning outcomes of three mathematical notions: Euclidean division (N = 1,880), additive decomposition (N = 1,763) and fractions (N = 644). Classes were randomly assigned to the programming (with Scratch) and control conditions. Multilevel analyses indicate negative effects (effect size range −0.16 to −0.21) of the programming condition for the three mathematical notions. A potential explanation of these results is the difficulties in the transfer of learning from programming to mathematics.}
}
@article{TUSHAR2020117141,
title = {Exploiting design thinking to improve energy efficiency of buildings},
journal = {Energy},
volume = {197},
pages = {117141},
year = {2020},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2020.117141},
url = {https://www.sciencedirect.com/science/article/pii/S0360544220302486},
author = {Wayes Tushar and Lan Lan and Chathura Withanage and Hui En Karen Sng and Chau Yuen and Kristin L. Wood and Tapan Kumar Saha},
keywords = {Design thinking, design innovation, building, energy conservation, smart energy management},
abstract = {This paper studies an interdisciplinary approach for improving building energy efficiency. In particular, the proposed approach integrates design innovation (DI) techniques, existing energy audit methods (EAM), and data-driven & engineering modeling techniques (DET) in the process of sustainable smart energy system design. From this perspective, DI methods are extended and modified to suit the content of sustainable smart energy system design and a DI 4D (Discover, Define, Develop and Deliver) framework is introduced to guide the design process. The motivation behind and the implementation procedure of each of the DI phases is explained separately, and the process of integrating DI methods, EAM and DET in developing a sustainable smart energy system is demonstrated. The proposed approach is deployed within the campus of a tertiary education institution to show its effectiveness in designing a smart sustainable energy system.}
}
@article{LAMBERT202132,
title = {From creative thinking to scientific principles in clinical practice},
journal = {Injury},
volume = {52},
number = {1},
pages = {32-36},
year = {2021},
note = {In Tribute To Professor Dr med Stephan Perren},
issn = {0020-1383},
doi = {https://doi.org/10.1016/j.injury.2020.09.036},
url = {https://www.sciencedirect.com/science/article/pii/S0020138320307397},
author = {Simon Lambert and Dominic Mischler and Markus Windolf and Pietro Regazzoni and Alberto Fernandez Dell'Oca and Boyko Gueorguiev and Peter Varga},
keywords = {Stephan Perren, AO Foundation, Strain theory, Education, Surgical skills, ICUC, OSAPP},
abstract = {Stephan Perren's contributions to the understanding and application of the principles of bone pathobiology, healing, and fracture fixation to clinical care remain as a lasting legacy of a great creative mind. Less well appreciated perhaps were his important contributions to the dissemination and practical application of those principles through the use of technology as applied to the learning environment. This paper describes and pays tribute to a series of initiatives in which Perren was a leading mentor and collaborator in the development of methods and instruments through which the principles of bone mechano-pathobiology could be translated through active learning environments into the practical world of clinical musculoskeletal traumatology.}
}
@article{WARREN2006208,
title = {Investigating functional thinking in the elementary classroom: Foundations of early algebraic reasoning},
journal = {The Journal of Mathematical Behavior},
volume = {25},
number = {3},
pages = {208-223},
year = {2006},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2006.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S0732312306000356},
author = {Elizabeth A. Warren and Tom J. Cooper and Janeen T. Lamb},
keywords = {Mathematics, Learning, Elementary, Algebra, Function},
abstract = {This paper examines the development of student functional thinking during a teaching experiment that was conducted in two classrooms with a total of 45 children whose average age was nine years and six months. The teaching comprised four lessons taught by a researcher, with a second researcher and classroom teacher acting as participant observers. These lessons were designed to enable students to build mental representations in order to explore the use of function tables by focusing on the relationship between input and output numbers with the intention of extracting the algebraic nature of the arithmetic involved. All lessons were videotaped. The results indicate that elementary students are not only capable of developing functional thinking but also of communicating their thinking both verbally and symbolically.}
}
@article{GUO2021100952,
title = {RETRACTED: Steal like an artist: Connection between critical thinking and creativity of a future musician in a digital environment},
journal = {Thinking Skills and Creativity},
volume = {42},
pages = {100952},
year = {2021},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2021.100952},
url = {https://www.sciencedirect.com/science/article/pii/S187118712100167X},
author = {Minjian Guo and Meng Zhang and Xue rui Li},
abstract = {This article has been retracted: please see Elsevier Policy on Article Withdrawal (https://www.elsevier.com/about/our-business/policies/article-withdrawal). This article has been retracted at the request of the Editors-in-Chief. After a thorough investigation, the Editors have concluded that the acceptance of this article was partly based upon the positive advice of one illegitimate reviewer report. The report was submitted from an email account which was provided to the journal as a suggested reviewer during the submission of the article. Although purportedly a real reviewer account, the Editors have concluded that this was not of an appropriate, independent reviewer. This manipulation of the peer-review process represents a clear violation of the fundamentals of peer review, our publishing policies, and publishing ethics standards. Apologies are offered to the reviewer whose identity was assumed and to the readers of the journal that this deception was not detected during the submission process.}
}
@article{DUMAS20181,
title = {Relational reasoning and divergent thinking: An examination of the threshold hypothesis with quantile regression},
journal = {Contemporary Educational Psychology},
volume = {53},
pages = {1-14},
year = {2018},
issn = {0361-476X},
doi = {https://doi.org/10.1016/j.cedpsych.2018.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S0361476X17304526},
author = {Denis Dumas},
abstract = {Relational reasoning (RR) and divergent thinking (DT) are two critical antecedents of creative problem solving, but the relation between them is not currently well understood psychologically, limiting efforts to support these constructs through education. The threshold hypothesis (TH) is currently the dominant explanation for the relation between RR and DT, and posits that RR fundamentally supports DT, but only up to a point. In this study, quantile regression was used to test the TH among RR and two separate dimensions of DT: originality and fluency. Results generally supported the TH in regards to originality, with RR being significantly positively related to originality, but only in students at or below the median of the originality distribution. However, the TH was not upheld for fluency, which was only significantly predicted by RR at the top (i.e. 9th decile) of the fluency distribution. In general, results suggest that direct instructional intervention of RR strategies may be most supportive of creativity for those students who are simultaneously highly fluent but low-original thinkers.}
}
@article{ZHANG2001883,
title = {Thinking styles and personality types revisited},
journal = {Personality and Individual Differences},
volume = {31},
number = {6},
pages = {883-894},
year = {2001},
issn = {0191-8869},
doi = {https://doi.org/10.1016/S0191-8869(00)00189-6},
url = {https://www.sciencedirect.com/science/article/pii/S0191886900001896},
author = {Li-fang Zhang},
keywords = {Thinking styles, Personality types},
abstract = {This study was designed to test the efficacy of the Short-Version Self-Directed Search (SVSDS) as well as to further investigate the relationships between thinking styles and personality types. Seven hundred and eighty-nine students (average 20 years) from two research-oriented universities from mainland China responded to the Thinking Styles Inventory and the SVSDS. Two major findings are: (1) the SVSDS is composed of six scales with good internal consistency, each assessing one of Holland’s six personality types; factor analysis yielded a two-factor solution, with one factor being characterized by people who like to work with things and data, and the other being dominated by people who like to work with people and ideas; and (2) thinking styles and personality types are related in predictable ways. Implications of these findings for test users, including teachers and counselors, are discussed.}
}
@article{CALVARESI2025100577,
title = {Computational persuasion technologies, explainability, and ethical-legal implications: A systematic literature review},
journal = {Computers in Human Behavior Reports},
volume = {17},
pages = {100577},
year = {2025},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2024.100577},
url = {https://www.sciencedirect.com/science/article/pii/S2451958824002100},
author = {Davide Calvaresi and Rachele Carli and Simona Tiribelli and Berk Buzcu and Reyhan Aydogan and Andrea {Di Vincenzo} and Yazan Mualla and Michael Schumacher and Jean-Paul Calbimonte},
keywords = {Computational persuasion, eHealth, Behavior change, Ethics, Legal implications, Systematic literature review},
abstract = {This paper conducts a systematic literature review (SLR) to evaluate the effectiveness of computational persuasion technology (CPT) in the eHealth domain. Over the past fifteen years, CPT has been used in various scenarios, from promoting healthy diets to supporting chronic disease management. Despite the proliferation of intelligent systems and Web-based applications, the ethical and legal nuances of these technologies have become increasingly significant. The review follows a structured methodology, assessing 92 primary studies through sixteen research questions covering demographics, application scenarios, user requirements, objectives, functionalities, technologies, advantages, limitations, proposed solutions, ethical and legal implications, and the role of explainable AI (XAI). The findings indicate that while CPT holds promise in inducing behavioral change, many prototypes remain untested on a large scale (60% of surveyed studies only developed at a conceptual level), and long-term effectiveness is still uncertain (36% report attaining their goals, but none focuses on long-term assessment). The study highlights the need for more comparative analyses of persuasion models and tailored approaches to meet diverse user needs. Ethical and legal concerns, such as patient consent, data privacy, and potential for users’ manipulation, are under-explored and require deeper investigation. The paper recommends a bottom-up regulatory approach to create more effective and flexible ethical and legal guidelines for CPT applications. In conclusion, significant advancements have been made in CPT for eHealth, but ongoing research is essential to address current limitations, enhance user acceptability and adherence, and ensure ethical and legal soundness.}
}
@article{BHUTTO2024101003,
title = {Electro-positive thinking: Catalytic dinitrogen reduction using electropositive metals},
journal = {Chem Catalysis},
volume = {4},
number = {5},
pages = {101003},
year = {2024},
issn = {2667-1093},
doi = {https://doi.org/10.1016/j.checat.2024.101003},
url = {https://www.sciencedirect.com/science/article/pii/S2667109324001520},
author = {Samuel M. Bhutto and Louise A. Berben},
abstract = {In this issue of Chem Catalysis, Arnold and co-workers describe Lewis acidic f- and d-block metal complexes that are catalysts for the conversion of N2 into secondary and tertiary amines. The origins of the remarkable selectivity and tunability of product formation are discussed in relation to molecular structure.}
}
@article{FLACH2017612,
title = {Supporting productive thinking: The semiotic context for Cognitive Systems Engineering (CSE)},
journal = {Applied Ergonomics},
volume = {59},
pages = {612-624},
year = {2017},
note = {The Legacy of Jens Rasmussen},
issn = {0003-6870},
doi = {https://doi.org/10.1016/j.apergo.2015.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0003687015300739},
author = {John Flach},
keywords = {Cognitive Systems Engineering, Abstraction Hierarchy, Work domain analysis, Decision Ladder, Skills-Rules-Knowledge Model, Ecological Interface Design, Proactive Risk Management},
abstract = {The central thesis of this paper is that Rasmussen framed his approach to Cognitive Systems Engineering from the perspective of a Triadic Semiotic Model. This frame became the context for integrating multiple intellectual threads including Control Theory, Information Theory, Ecological Psychology, and Gestalt Psychology into a coherent theoretical framework. The case is made that the triadic semiotic framework is essential for a complete appreciation of the constructs that were central to Rasmussen's approach: Abstraction Hierarchy, Skill-Rules-Knowledge Model, Ecological Interface Design, and Proactive Risk Management.}
}
@incollection{ROESE20171,
title = {Chapter One - The Functional Theory of Counterfactual Thinking: New Evidence, New Challenges, New Insights},
editor = {James M. Olson},
series = {Advances in Experimental Social Psychology},
publisher = {Academic Press},
volume = {56},
pages = {1-79},
year = {2017},
issn = {0065-2601},
doi = {https://doi.org/10.1016/bs.aesp.2017.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S0065260117300187},
author = {Neal J. Roese and Kai Epstude},
keywords = {Counterfactual, Regret, Mental simulation, Goal, Regulatory, Episodic, Self-regulation, Affect, Emotion, Attribution, Orbitofrontal, Nucleus accumbens, Insula, Functional theory, Mental models},
abstract = {Thinking about what might have been—counterfactual thinking—is a common feature of the mental landscape. Key questions about counterfactual thinking center on why and how they occur and what downstream cognitive and behavioral outcomes they engender. The functional theory of counterfactual thinking aims to answer these and other questions by drawing connections to goal cognition and by specifying distinct functions that counterfactuals may serve, including preparing for goal pursuit and regulating affect. Since the publication of our last theoretical statement (Epstude & Roese, 2008), numerous lines of empirical evidence support, or are rendered more readily understandable, when glimpsed through the lens of the functional theory. However, other lines of evidence have called into question the very basis of the theory. We integrate a broad range of findings spanning several psychological disciplines so as to present an updated version of the functional theory. We integrate findings from social psychology, cognitive neuroscience, developmental psychology, clinical psychology, and health psychology that support the claim that episodic counterfactual thoughts are geared mainly toward preparation and goal striving and are generally beneficial for individuals. Counterfactuals may influence behavior via either a content-specific pathway (in which the counterfactual insight informs behavior change) or a content-neutral pathway (in which the negative affect from the counterfactual motivates generic behavior change). Challenges to the functional theory of counterfactual thinking center on whether counterfactuals typically cohere to a structural form amenable to goal striving and whether behavioral consequences are mainly dysfunctional rather than functional. Integrating both supporting and challenging evidence, we offer a new theoretical synthesis intended to clarify the literature and guide future research in multiple disciplines of psychology.}
}
@article{HAO2017237,
title = {A function-based computational method for design concept evaluation},
journal = {Advanced Engineering Informatics},
volume = {32},
pages = {237-247},
year = {2017},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2017.03.002},
url = {https://www.sciencedirect.com/science/article/pii/S1474034616303664},
author = {Jia Hao and Qiangfu Zhao and Yan Yan},
keywords = {Concept generation, Evaluation metrics, Function basis, Word-embedding},
abstract = {Concept generation is an indispensable step of innovation design. However, the limited knowledge and design thinking fixation of designers often impede the generation of novel design concepts. Computational tools can be a necessary supplement for designers. They can generate a big number of design concepts based on an existing knowledge base. For filtering these design concepts, this work presents a computational measurement of novelty, feasibility and diversity based on 500,000 granted patents. First, about 1700 functional terms (terminologies) are mapped to high dimensional vectors (100 dimensional space) by word embedding technique. The resulted database is knowledge base-I (KB-I). Then, we adopt circular convolution to convert patents into high dimensional vectors. The resulted database is KB-II. Based on the two knowledge bases, the computational definitions of novelty, feasibility and diversity are developed. We conduct six experiments based on KB-II, a random dataset and a real product dataset, and the results show that these metrics can be used to roughly filter a big number of design concepts, and then expert-based method can be further used. This work provides a computational framework for measuring the novelty, feasibility and diversity of design concept.}
}
@article{CARNEY2014200,
title = {Using computational modeling to assess the impact of clinical decision support on cancer screening improvement strategies within the community health centers},
journal = {Journal of Biomedical Informatics},
volume = {51},
pages = {200-209},
year = {2014},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2014.05.012},
url = {https://www.sciencedirect.com/science/article/pii/S1532046414001361},
author = {Timothy Jay Carney and Geoffrey P. Morgan and Josette Jones and Anna M. McDaniel and Michael Weaver and Bryan Weiner and David A. Haggstrom},
keywords = {Computational, Simulation, Modeling, Community health center, Systems-thinking, Cancer screening},
abstract = {Our conceptual model demonstrates our goal to investigate the impact of clinical decision support (CDS) utilization on cancer screening improvement strategies in the community health care (CHC) setting. We employed a dual modeling technique using both statistical and computational modeling to evaluate impact. Our statistical model used the Spearman’s Rho test to evaluate the strength of relationship between our proximal outcome measures (CDS utilization) against our distal outcome measure (provider self-reported cancer screening improvement). Our computational model relied on network evolution theory and made use of a tool called Construct-TM to model the use of CDS measured by the rate of organizational learning. We employed the use of previously collected survey data from community health centers Cancer Health Disparities Collaborative (HDCC). Our intent is to demonstrate the added valued gained by using a computational modeling tool in conjunction with a statistical analysis when evaluating the impact a health information technology, in the form of CDS, on health care quality process outcomes such as facility-level screening improvement. Significant simulated disparities in organizational learning over time were observed between community health centers beginning the simulation with high and low clinical decision support capability.}
}
@article{WANG2025128735,
title = {Answering, Fast and Slow: Strategy enhancement of visual understanding guided by causality},
journal = {Neurocomputing},
volume = {613},
pages = {128735},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.128735},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224015066},
author = {Chao Wang and Zihao Wang and Yang Zhou},
keywords = {Causal inference, Explainable, Intuitive thinking, Prior knowledge, Visual question answering},
abstract = {In his classic book Thinking, Fast and Slow (Daniel, 2017), Kahneman points out that human thinking can be categorized into two main modes of thinking: a system that displays intuition and emotion (i.e., System 1), and a system that is more planned and relies more on logic, defined as System 2. This idea explains both rational and irrational motivations. In this paper, we revisit visual comprehension tasks based on this idea. At the theoretical level, we focus on the relationship between intuitive thinking, prior knowledge, and environmental information, and build a causal graph between the three. Further, inspired by the constructed causal graph, an intuitive optimization strategy with clear interpretability is proposed. In the validation session, we provide conclusions consistent with the theoretical analyses through extensive experiments on public datasets based on a visual quizzing task. Excitingly, our scheme demonstrates strong competitiveness in terms of generalizability without adding new technologies.}
}
@incollection{DUNN2023461,
title = {17 - Thinking in systems: sustainable design of nano-enabled agriculture informed by life cycle assessment},
editor = {Peng Zhang and Iseult Lynch and Jason C. White and Richard D. Handy},
booktitle = {Nano-Enabled Sustainable and Precision Agriculture},
publisher = {Academic Press},
pages = {461-491},
year = {2023},
isbn = {978-0-323-91233-4},
doi = {https://doi.org/10.1016/B978-0-323-91233-4.00019-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780323912334000193},
author = {Patrick J. Dunn and Leila Pourzahedi and Thomas L. Theis and Leanne M. Gilbertson},
keywords = {Agriculture, food, environment, life cycle assessment, trade-off, production},
abstract = {Food systems are among the most complex systems devised by humankind with multiple stages involved in the production, marketing, and distribution, as well as the preparation and consumption of food.}
}
@article{BARRIOSHERNANDEZ2006309,
title = {Thinking parametric design: introducing parametric Gaudi},
journal = {Design Studies},
volume = {27},
number = {3},
pages = {309-324},
year = {2006},
note = {Digital Design},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2005.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X05000876},
author = {Carlos Roberto {Barrios Hernandez}},
keywords = {case study, computational model(s), design model(s), parametric modeling, parametric design},
abstract = {This paper presents an innovative methodology for parametric design called Design Procedures (DP) and shows how it is applied to the columns of the Expiatory Temple of the Sagrada Familia. Design Procedures are actions that generate parametric models where geometrical components are consider as variables. A brief introduction on parametric design is followed by illustrated explanations of the traditional forms of parametric models. Design Procedures is presented as an alternative to overcome the topological and geometrical limitations of traditional parametric models. The DP is able to generate all original designs by Gaudi plus an infinite number of new designs.}
}
@article{PAGANI2009382,
title = {Roadmapping 3G mobile TV: Strategic thinking and scenario planning through repeated cross-impact handling},
journal = {Technological Forecasting and Social Change},
volume = {76},
number = {3},
pages = {382-395},
year = {2009},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2008.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S0040162508001303},
author = {Margherita Pagani},
keywords = {Scenario planning, Mobile TV, Strategic thinking, 3G wireless, Impact factor analysis},
abstract = {In order to deal with growing uncertainties emerging in the 3G wireless industry and to preserve their competitiveness, managers involved in the wireless value network should identify future success very early and develop their strategic planning on time. This study, based on a Scenario Evaluation and Analysis through Repeated Cross impact Handling, allows the generation of both qualitative and quantitative scenarios and can be used as an operative planning tool. The dynamic forces driving the scenario are based on the main principles of system thinking and multiple features. The probabilistic data have been elicited with the help of 40 executives in USA and Europe working for companies in the different phases of the wireless value chain. Findings allow to identify basic trends and uncertainties useful to develop corporate or business strategies.}
}
@article{LISSACK2019327,
title = {Understanding Is a Design Problem: Cognizing from a Designerly Thinking Perspective. Part 2},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {5},
number = {4},
pages = {327-342},
year = {2019},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2019.11.019},
url = {https://www.sciencedirect.com/science/article/pii/S2405872619300929},
author = {Michael Lissack},
keywords = {Design, Cognition, Understanding, Representation, Narrative, Cybernetics},
abstract = {Understanding and cognition are traditionally viewed as philosophical and scientific issues where there is little room for contribution from the design community. This article proposes a radically different approach based on the observation that we live in a world that is more complex than our minds/brains possess the ability to process in its entirety. Our limited equipment forces us to deal with only selected aspects of any given piece of that complex world at each instant. Selection—be it conscious or unconscious—involves agency and choice. Design and design thinking scholars have much to say about how agency and choice can be impacted by still other choices—context, symbols, movement, audience, and so on. Suppose cognition and meaning making were re-cast as design processes? This would highlight the role played by cybernetics—the science of how we learn how to steer—in shaping how we cognitively deal with the world. Together design and cybernetics have much to offer the cognitive sciences.}
}
@article{NAPPI2020156,
title = {The machine learning approach: Artificial intelligence is coming to support critical clinical thinking},
journal = {Journal of Nuclear Cardiology},
volume = {27},
number = {1},
pages = {156-158},
year = {2020},
issn = {1071-3581},
doi = {https://doi.org/10.1007/s12350-018-1344-2},
url = {https://www.sciencedirect.com/science/article/pii/S1071358123017543},
author = {Carmela Nappi and Alberto Cuocolo}
}
@article{POWERS2025117,
title = {A Computational Account of the Development and Evolution of Psychotic Symptoms},
journal = {Biological Psychiatry},
volume = {97},
number = {2},
pages = {117-127},
year = {2025},
note = {Brain Structural and Functional Connectivity in Psychosis: Relationship to Clinical Outcomes},
issn = {0006-3223},
doi = {https://doi.org/10.1016/j.biopsych.2024.08.026},
url = {https://www.sciencedirect.com/science/article/pii/S0006322324015841},
author = {Albert Powers and Phillip A. Angelos and Alexandria Bond and Emily Farina and Carolyn Fredericks and Jay Gandhi and Maximillian Greenwald and Gabriela Hernandez-Busot and Gabriel Hosein and Megan Kelley and Catalina Mourgues and William Palmer and Julia Rodriguez-Sanchez and Rashina Seabury and Silmilly Toribio and Raina Vin and Jeremy Weleff and Scott Woods and David Benrimoh},
keywords = {Computational psychiatry, Hallucinations, Nosology, Perception, Psychosis},
abstract = {The mechanisms of psychotic symptoms such as hallucinations and delusions are often investigated in fully formed illness, well after symptoms emerge. These investigations have yielded key insights but are not well positioned to reveal the dynamic forces underlying symptom formation itself. Understanding symptom development over time would allow us to identify steps in the pathophysiological process leading to psychosis, shifting the focus of psychiatric intervention from symptom alleviation to prevention. We propose a model for understanding the emergence of psychotic symptoms within the context of an adaptive, developing neural system. We make the case for a pathophysiological process that begins with cortical hyperexcitability and bottom-up noise transmission, which engenders inappropriate belief formation via aberrant prediction error signaling. We argue that this bottom-up noise drives learning about the (im)precision of new incoming sensory information because of diminished signal-to-noise ratio, causing a compensatory relative overreliance on prior beliefs. This overreliance on priors predisposes to hallucinations and covaries with hallucination severity. An overreliance on priors may also lead to increased conviction in the beliefs generated by bottom-up noise and drive movement toward conversion to psychosis. We identify predictions of our model at each stage, examine evidence to support or refute those predictions, and propose experiments that could falsify or help select between alternative elements of the overall model. Nesting computational abnormalities within longitudinal development allows us to account for hidden dynamics among the mechanisms driving symptom formation and to view established symptoms as a point of equilibrium among competing biological forces.}
}
@article{SORIANO2017443,
title = {Thinking, fast and slow: highlights from the 2016 BJA seminar on anaesthetic neurotoxicity and neuroplasticity},
journal = {British Journal of Anaesthesia},
volume = {119},
number = {3},
pages = {443-447},
year = {2017},
issn = {0007-0912},
doi = {https://doi.org/10.1093/bja/aex238},
url = {https://www.sciencedirect.com/science/article/pii/S0007091217537575},
author = {S.G. Soriano and L. Vutskits and V. Jevtovic-Todorovic and H.C. Hemmings}
}
@incollection{BRUCKLACHER2025657,
title = {Predictive processing in neuroscience, computational modeling and psychology},
editor = {Jordan Henry Grafman},
booktitle = {Encyclopedia of the Human Brain (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {657-679},
year = {2025},
isbn = {978-0-12-820481-8},
doi = {https://doi.org/10.1016/B978-0-12-820480-1.00201-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128204801002011},
author = {Matthias Brucklacher and Kwangjun Lee and Giulia Moreni and Jorge F. Mejías and Sander M. Bohté and Cyriel M.A. Pennartz},
keywords = {Active inference, Bayesian inference, Cortex, Consciousness, Credit assignment, Inference learning, Imagery, Inverse problem, Multimodal integration, Neurorepresentationalism, Perception, Prediction error, Predictive coding, Representation learning, Unsupervised learning},
abstract = {Over the past decades, predictive processing has emerged as a powerful theoretical framework that holds promise for explaining a wide range of phenomena, including perception and imagery but also sensorimotor control and consciousness. Here we focus on the question if and how predictive processing may be implemented in the mammalian and human brain, and what its scope of perceptual and cognitive functions is. We review basic and advanced computational models of predictive processing, expanding the range of computational, cognitive and sensorimotor capacities and enhancing their biological plausibility. Based on empirical evidence, major steps will need to be taken to flesh out how predictive processing may be precisely implemented in the brain, but the overall framework holds great potential as an explanatory framework in the neurosciences and psychology, strongly linking to Artificial Intelligence.}
}
@article{CSISZAR2020106530,
title = {How to implement MCDM tools and continuous logic into neural computation?: Towards better interpretability of neural networks},
journal = {Knowledge-Based Systems},
volume = {210},
pages = {106530},
year = {2020},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2020.106530},
url = {https://www.sciencedirect.com/science/article/pii/S0950705120306596},
author = {Orsolya Csiszár and Gábor Csiszár and József Dombi},
keywords = {Multi-criteria decision-making, Preference modeling, Outranking methods, Fuzzy systems, Continuous logic, Nilpotent logical systems, Neural networks},
abstract = {The theories of multi-criteria decision-making (MCDM) and fuzzy logic both aim to model human thinking. In MCDM, aggregation processes and preference modeling play the central role. This paper suggests a consistent framework for modeling human thinking by using the tools of both fields: fuzzy logical operators as well as aggregation and preference operators. In this framework, aggregation, preference, and the logical operators are described by the same unary generator function. Similarly to the implication being defined as a composition of the disjunction and the negation operator, preference operators were introduced as a composition of the aggregative operator and the negation operator. After a profound examination of the main properties of the preference operator, our main goal is the implementation into neural networks. We show how preference can be modeled by a perceptron, and illustrate the results in practical neural applications.}
}
@article{CRISTIANINI201639,
title = {A different way of thinking},
journal = {New Scientist},
volume = {232},
number = {3101},
pages = {39-43},
year = {2016},
issn = {0262-4079},
doi = {https://doi.org/10.1016/S0262-4079(16)32190-X},
url = {https://www.sciencedirect.com/science/article/pii/S026240791632190X},
author = {Nello Cristianini},
abstract = {Artificial intelligences may not understand things like we do, but what they can achieve is still staggering, says Nello Cristianini}
}
@incollection{COWAN2017147,
title = {2.09 - Working Memory: The Information You Are Now Thinking of},
editor = {John H. Byrne},
booktitle = {Learning and Memory: A Comprehensive Reference (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {Oxford},
pages = {147-161},
year = {2017},
isbn = {978-0-12-805291-4},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.21040-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245210407},
author = {Nelson Cowan},
keywords = {Immediate memory, Memory capacity, Memory decay, Partial report, Recall, Recognition, Selective attention, Short-term memory, Working memory, Working memory capacity},
abstract = {Working memory is the limited information that we keep in mind and use to carry out thinking. This chapter explains the early and modern history of investigation of working memory, current controversies regarding the nature of working memory, and practical applications of the concept. Working memory is important because its limits help define what one can or cannot comprehend. A better understanding of working memory should allow improvements in the diagnosis and treatment of various neural conditions. Thinking broadly, studying working memory and other general limitations of the cognitive system could produce more humble and accommodating styles of interaction with other people, as one keeps in mind one's own cognitive limitations.}
}
@article{POLLAROLO2024100637,
title = {Play with Coding Toys in Early Childhood Education and Care: Teachers’ Pedagogical Strategies, Views and Impact on Children's Development. A Systematic Literature Review},
journal = {Entertainment Computing},
volume = {50},
pages = {100637},
year = {2024},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2024.100637},
url = {https://www.sciencedirect.com/science/article/pii/S1875952124000053},
author = {Enrico Pollarolo and Sofia Papavlasopoulou and Francesca Granone and Elin Reikerås},
keywords = {Coding toys, Communication skills, Computational thinking, Early childhood education and care, Teachers’ pedagogical strategies, Problem-solving},
abstract = {This paper presents a systematic literature review that aims to portray an overview of pedagogical strategies that Early Childhood Education and Care (ECEC) teachers adopt to support children’s play with coding toys. In addition, the article synthesizes findings about teachers’ views in relation to the use of coding toys in ECEC and describes the outputs that the existing literature identifies as children’s development after play activities with coding toys. The systematic literature search was performed in accordance with the PRISMA-2020 statement, and the initial search across four databases (Eric, Scopus, Web of Science, and Academic Research Ultimate) for papers published between January 2010 and May 2022 yielded 2672 peer-reviewed articles. Following the first evaluation, the application of the inclusion and exclusion criteria resulted in a shortlist of 22 papers. The results show different strategies that the teachers can use during play activities with coding toys, assuming the roles of facilitators and mediators through collaborative work, allowing children to try and fail. Moreover, the results revealed that ECEC teachers largely hold positive and constructive attitudes towards the use of coding toys. Findings also highlight positive outcomes regarding children’s development across various cognitive and socio-emotional skills such as problem solving, computational thinking and communication. As an improvement, future studies should focus on identifying appropriate pedagogies that may be applied in tandem with the technology to maximise the pedagogical benefits for the children as well as adequate training for teachers.}
}
@article{VANHARANTA2010425,
title = {Intuitive managerial thinking; the use of mental simulations in the industrial marketing context},
journal = {Industrial Marketing Management},
volume = {39},
number = {3},
pages = {425-436},
year = {2010},
note = {Sense-Making and Management in Business Networks},
issn = {0019-8501},
doi = {https://doi.org/10.1016/j.indmarman.2007.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S0019850109000704},
author = {Markus Vanharanta and Geoff Easton},
keywords = {Mental simulation, Intuitive thinking, Industrial network, Cognition, Marketing, Story building, Naturalistic decision making, Recognition-primed decision making},
abstract = {In this paper, we introduce empirical evidence showing how mental simulation was used as a heuristic strategy in an industrial network context. The mental network simulations observed are consistent with the Recognition-Primed Decision (RPD) model, according to which intuitive thinking allows managerial experience to be translated into focal network action, without resorting to a “rational” or comparative decision strategy. We identify the main business significance of mental network simulations in terms of their utility to clarify ambiguous or only partially known focal network situations, to develop coherent focal net plans and tactics, and to mentally preview how specific focal net tactics/strategies are likely to play out in reality. In short, mental network simulations were observed as being useful in generating focal net action through cognitively meeting the complex environmental challenges in dynamic focal net interaction between companies.}
}
@article{CHEN200815606,
title = {A Project-Based Mechatronics Program to Reinforce Mechatronic Thinking – A Restructuring Experience from the University of Canterbury},
journal = {IFAC Proceedings Volumes},
volume = {41},
number = {2},
pages = {15606-15611},
year = {2008},
note = {17th IFAC World Congress},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20080706-5-KR-1001.02639},
url = {https://www.sciencedirect.com/science/article/pii/S1474667016415041},
author = {XiaoQi Chen and Paul Gaynor and Richard King and Geoff J Chase and Phil Bones and Peter Gough and Richard Duke},
abstract = {The approach taken during restructuring the Mechatronics Program at the University of Canterbury is described, along with challenges faced. The background of the University of Canterbury Mechatronics program is examined, as are the challenges of integrating the program within the Department of Mechanical Engineering and the Department of Electrical & Computer Engineering. The new Mechatronics program features integrative projects during each of three Professional Education years to reinforce students’ “mechatronic” thinking and hands-on abilities. The project-based course “Introduction to Mechatronics Design” features a series of application-oriented laboratory projects using a Programmable Logic Controller (PLC). The restructured program of balanced essential skills training coupled with focus streams of specialization may signal a paradigm shift in engineering education.}
}
@article{BAR20104,
title = {Wait for the Second Marshmallow? Future-Oriented Thinking and Delayed Reward Discounting in the Brain},
journal = {Neuron},
volume = {66},
number = {1},
pages = {4-5},
year = {2010},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2010.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0896627310002412},
author = {Moshe Bar},
abstract = {Humans tend to discount the value of delayed rewards. Peters and Büchel show in this issue of Neuron that the ability to appraise the value of such future rewards improves when future-oriented cognitive processes in the brain are recruited using personally relevant information. These results provide the platform for exciting new questions.}
}
@article{PRITCHARD2025107684,
title = {Formal definition and implementation of reproducibility tenets for computational workflows},
journal = {Future Generation Computer Systems},
volume = {166},
pages = {107684},
year = {2025},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2024.107684},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X24006484},
author = {Nicholas J. Pritchard and Andreas Wicenec},
keywords = {Scientific workflows, Scientific reproducibility, Workflow management systems},
abstract = {Computational workflow management systems power contemporary data-intensive sciences. The slowly resolving reproducibility crisis presents both a sobering warning and an opportunity to iterate on what science and data processing entails. The Square Kilometre Array (SKA), the world’s largest radio telescope, is among the most extensive scientific projects underway and presents grand scientific collaboration and data-processing challenges. In this work, we aim to improve the ability of workflow management systems to facilitate reproducible, high-quality science. This work presents a scale and system-agnostic computational workflow model and extends five well-known reproducibility concepts into seven well-defined tenets for this workflow model. Additionally, we present a method to construct workflow execution signatures using cryptographic primitives in amortized constant time. We combine these three concepts and provide a concrete implementation in Data Activated Flow Graph Engine (DALiuGE), a workflow management system for the SKA to embed specific provenance information into workflow signatures, demonstrating the possibility of facilitating automatic formal verification of scientific quality in amortized constant time. We validate our approach with a simple yet representative astronomical processing task: filtering a noisy signal with a lowpass filter using CPU and GPU methods. This example shows the practicality and efficacy of combining formal tenet definitions with a workflow signature generation mechanism. Our framework, spanning formal UML specification, principled provenance information collection based on reproducibility tenets, and finally, a concrete example implementation in DALiuGE illuminates otherwise obscure scientific discrepancies and similarities between principally identical workflow executions.}
}
@article{FANG2025103716,
title = {Functional connectivity profiles in remitted depression and their relation to ruminative thinking},
journal = {NeuroImage: Clinical},
volume = {45},
pages = {103716},
year = {2025},
issn = {2213-1582},
doi = {https://doi.org/10.1016/j.nicl.2024.103716},
url = {https://www.sciencedirect.com/science/article/pii/S2213158224001578},
author = {Zhuo Fang and Emma Lynn and Verner J. Knott and Natalia Jaworska},
keywords = {Remitted depression, Default mode network, Central executive network, Salience network, Hopeless rumination, Emotional processing},
abstract = {The triple network model suggests that dysfunction in three major brain networks – the default mode network (DMN), central executive network (CEN), and salience network (SN) – might contribute to cognitive impairments in various psychiatric disorders, including major depressive disorder (MDD). While hyperconnectivity in the DMN, hypoconnectivity in the CEN, and abnormal SN connectivity have been observed in acutely depressed patients, evidence for network alterations during remission is limited. Further, there are few studies examining connectivity in people in remission from MDD (rMDD) during emotional processing tasks, including during affective cognition (i.e., tasks that encompass affective processing in the context of cognitive processes, such as inhibition). To address these literature gaps, this study compared functional connectivity (FC) between resting and task conditions, specifically during the emotional Stroop (eStroop) task, as well as between rMDD and healthy volunteers (HVs), within and between nodes of the three networks. We also explored how FC relates to rumination in the rMDD group, given that rumination tends to persist in rMDD and involves affective and cognitive networks. We unexpectedly found greater FC during the task vs. rest condition within the DMN, and decreased FC during the task vs. rest conditions within the CEN and SN across the groups. Greater FC during the task vs. rest condition between DMN and SN nodes, as well as between CEN and SN nodes were also observed. These effects were more pronounced in the rMDD group as per our exploratory analyses. Additionally, the rMDD vs. HV group showed higher FC between DMN-CEN nodes, regardless of condition. Higher hopeless rumination scores were associated with decreased resting FC within the DMN, while higher active problem-solving scores were associated with increased task FC within the DMN in the rMDD group. These findings suggest that tasks engaging affective cognition processes influence FC within and among the three networks, with this effect more pronounced in the rMDD group. This might indicate potential protective and compensatory mechanisms in rMDD and expands our understanding of large-scale intrinsic network connectivity alterations during remission from depression. However, given the limited sample and the exploratory nature of some of our analyses, replication is necessary.}
}
@incollection{YIN2016273,
title = {Chapter 7 - Engineering Thinking and a New Generation of Steel Manufacturing Process},
editor = {Ruiyu Yin},
booktitle = {Theory and Methods of Metallurgical Process Integration},
publisher = {Academic Press},
pages = {273-306},
year = {2016},
isbn = {978-0-12-809568-3},
doi = {https://doi.org/10.1016/B978-0-12-809568-3.00017-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128095683000176},
author = {Ruiyu Yin},
keywords = {Holistic view, dynamic view, essence view, analysis and integration, virtuality and substantiality},
abstract = {Traditional thinking mode in Chinese culture chronically emphasizes the whole observation and thinking, namely holistic view, pays attention to observe and think problems based on the development, evolution of things, and analyzes problem as time(s) changes, namely the dynamic view. It also emphasizes to explore deeply and reveal the internal essence through the study and observe the imagery of a matter, namely the essence view. For the engineering methodology, the current book emphasizes the combination between reductionism and holism theory, between analysis and integration, and between virtuality and substantiality. The new generation of the steel manufacturing process is proposed based on the thinking mode above. The thinking mode above clarifies that thinking and studying a new generation of the steel manufacturing process should neither consider things as its standard nor tend to the specific application of individual technology. The general theoretical study of integrity, openness, hierarchy, dynamic character in the steel manufacturing process is more important. The old method of figurative observation should be turned to the physical nature investigation of dynamic running process. Based on the rational abstract, concept research, top level design, the dynamic tailored design study and dynamic operation rules, etc., are performed. Thus the concept, connotation, function, design method, and operation rules of a new generation of the steel manufacturing process are established.}
}
@article{QIAN2024105914,
title = {Ambivalence by design: A computational account of loopholes},
journal = {Cognition},
volume = {252},
pages = {105914},
year = {2024},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2024.105914},
url = {https://www.sciencedirect.com/science/article/pii/S0010027724002002},
author = {Peng Qian and Sophie Bridgers and Maya Taliaferro and Kiera Parece and Tomer D. Ullman},
keywords = {Communication, Social cognition, Utility, Bayesian model},
abstract = {Loopholes offer an opening. Rather than comply or directly refuse, people can subvert an intended request by an intentional misunderstanding. Such behaviors exploit ambiguity and under-specification in language. Using loopholes is commonplace and intuitive in everyday social interaction, both familiar and consequential. Loopholes are also of concern in the law, and increasingly in artificial intelligence. However, the computational and cognitive underpinnings of loopholes are not well understood. Here, we propose a utility-theoretic recursive social reasoning model that formalizes and accounts for loophole behavior. The model captures the decision process of a loophole-aware listener, who trades off their own utility with that of the speaker, and considers an expected social penalty for non-cooperative behavior. The social penalty is computed through the listener’s recursive reasoning about a virtual naive observer’s inference of a naive listener’s social intent. Our model captures qualitative patterns in previous data, and also generates new quantitative predictions consistent with novel studies (N = 265). We consider the broader implications of our model for other aspects of social reasoning, including plausible deniability and humor.}
}
@article{AZAR2008684,
title = {The effect of relative thinking on firm strategy and market outcomes: A location differentiation model with endogenous transportation costs},
journal = {Journal of Economic Psychology},
volume = {29},
number = {5},
pages = {684-697},
year = {2008},
note = {Affect, Motivation and Decision Making},
issn = {0167-4870},
doi = {https://doi.org/10.1016/j.joep.2007.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0167487007000475},
author = {Ofer H. Azar},
keywords = {Consumer psychology, Consumer attitudes and behavior, Marketing and advertising, Cognitive processes},
abstract = {Consumers often have to decide whether to make an effort and go to a remote store rather than a nearby one in order to obtain a lower price. Only the absolute price difference between the stores should be relevant in this case, but several experiments showed that people exhibit “relative thinking”: they are affected also by the relative savings (relative to the good’s price). This article analyzes the effects of this bias on firm strategy and market outcomes using a two-period game-theoretic model of location differentiation. Relative thinking causes consumers to make less effort to save a constant amount when they buy more expensive goods. In the location differentiation context this behavior can be modeled by consumers who behave as if their transportation costs are an increasing function of the good’s price. This gives firms an additional incentive to raise prices, in order to increase the perceived transportation costs of consumers, which consequently softens competition and allows higher profits. Therefore, the response of firms to relative thinking raises prices and profits and reduces consumer surplus, in both periods. Total welfare is unchanged in the first period, and in the second period it is either unchanged or reduced, depending on whether the objective or subjective transportation costs are used to compute welfare. The main results of the model (firms’ response to relative thinking increases prices and reduces consumer surplus) are likely to hold also in the context of search. The article also explains why “relative thinking” is a more appropriate term than “mental accounting” (which was often used before) to describe this behavior, and discusses why people might exhibit relative thinking.}
}
@article{BUCHLAK20201372,
title = {Ethical thinking machines in surgery and the requirement for clinical leadership},
journal = {The American Journal of Surgery},
volume = {220},
number = {5},
pages = {1372-1374},
year = {2020},
issn = {0002-9610},
doi = {https://doi.org/10.1016/j.amjsurg.2020.06.073},
url = {https://www.sciencedirect.com/science/article/pii/S000296102030427X},
author = {Quinlan D. Buchlak and Nazanin Esmaili and Jean-Christophe Leveque and Christine Bennett and Massimo Piccardi and Farrokh Farrokhi}
}
@article{TELLNES2024278,
title = {Implementing life cycle thinking and climate change indicators in small and medium size enterprises},
journal = {Sustainable Production and Consumption},
volume = {51},
pages = {278-291},
year = {2024},
issn = {2352-5509},
doi = {https://doi.org/10.1016/j.spc.2024.09.014},
url = {https://www.sciencedirect.com/science/article/pii/S2352550924002719},
author = {Lars Gunnar Furelid Tellnes and Asbjørn Olav Pedersen and Ramón Pamies and Bjørn Gitle Hauge and Anna-Lena Kjøniksen},
keywords = {Life cycle assessment (LCA), Business models (BM), Sustainable development goals (SDG) indicator 9.4.1, European sustainability reporting standard (ESRS), Small and medium sized enterprises (SME)},
abstract = {The policy for a low emission society requires that companies measure their impact from a life cycle perspective for both products and corporate reporting. This work presents new climate performance indicators to evaluate business models (BM) based on life cycle assessment (LCA) and benchmarked with statistics for Sustainable Development Goal indicator 9.4.1. The research was conducted by action case studies involving 20 small and medium sized enterprises (SMEs) from various sectors. The SMEs did not have previous experience with LCA. Therefore, a work process called “LCA á la carte” was designed to gradually increase details and effort. The results of simplified indicators on the manufacturing SMEs showed that the direct emissions to value added are lower than industry average. However, when upstream emissions and value added were included, the emission intensities are about industry average. The full life cycle climate indicators are presented for a boat production company that experiment with new BMs. Use phase electrification was found to be the most effective measure (60 % lower emission intensity), while material recycling and boat rental each reduced the emission intensity with about 30 %. However, a combination of these new BMs gives best results and could be needed to reach future benchmarks. This study suggests LCA for BM as a combination of a work process, actors' perspectives, and performance indicators. The results highlight that the scope of activities included in the performance indicators is crucial. New reporting standards such as the European Sustainable Development Standard (ESRS) should review the emission intensity indicators to ensure consistency between the scopes of activities included.}
}
@article{TAYLOR2010561,
title = {Using a Computer Programming Environment and an Interactive Whiteboard to Investigate Some Mathematical Thinking},
journal = {Procedia - Social and Behavioral Sciences},
volume = {8},
pages = {561-570},
year = {2010},
note = {International Conference on Mathematics Education Research 2010 (ICMER 2010)},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2010.12.078},
url = {https://www.sciencedirect.com/science/article/pii/S187704281002183X},
author = {Merilyn Taylor and Ann Harlow and Michael Forret},
keywords = {Elementary mathematics, Interactive whiteboard, Computer programming},
abstract = {Scratch is a free graphical programming language designed for children to create their own interactive games, animations, simulations and stories. Scratch provides a virtual space where children use some mathematics ideas in order to build their own animated artefacts. This paper reports on some preliminary findings from a research project where two elementary teachers in an urban New Zealand school introduced Scratch to nine and ten year old children in their classrooms. In each of the classrooms a small number of computers and an interactive whiteboard (IWB) were utilised. This paper uses a case study approach to describe how engagement with Scratch and independent use of the IWB enabled children to work collaboratively to solve design challenges. Initial results indicate that the Scratch program is engaging for children. It created an environment where the children were, by necessity, using problem-solving processes such as goal setting, and generating and testing of ideas. The interactive whiteboard afforded rich opportunities for children to collaborate and share their thinking. Some questions and implications for the learning and teaching of elementary school mathematics are explored at the conclusion of the paper.}
}
@article{SHARIATI201640,
title = {Model Predictive Control in two days: Educating a new way of thinking},
journal = {IFAC-PapersOnLine},
volume = {49},
number = {6},
pages = {40-45},
year = {2016},
note = {11th IFAC Symposium on Advances in Control Education ACE 2016},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2016.07.150},
url = {https://www.sciencedirect.com/science/article/pii/S240589631630355X},
author = {S. Shariati and D. Abel},
keywords = {Workshop, Model Predictive control, Process Control, Kalman Filter, Education, Tutorial},
abstract = {In this paper, a two-day workshop on Model Predictive Controllers (MPC) is developed and practiced. The goal is to introduce the concept of MPC in an easy and motivating fashion, so that at the end of the second day not only the students are familiar with the basics of the MPC, but also are capable of indipendently program, tune and observe the performance of the MPC for their various applications. The course is mainly designed for the students with basic control engineering background and elementary Matlab/Simulink experience.}
}
@article{CEDERMAN2023102112,
title = {Computational approaches to conflict research from modeling and data to computational diplomacy},
journal = {Journal of Computational Science},
volume = {72},
pages = {102112},
year = {2023},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2023.102112},
url = {https://www.sciencedirect.com/science/article/pii/S1877750323001722},
author = {Lars-Erik Cederman and Luc Girardin},
keywords = {Computational diplomacy, Agent-based modeling, Simulation, Conflict research},
abstract = {This paper offers an account of our own efforts to draw on computational methods to study conflict processes at the macro level. During a first phase, we relied on agent-based modeling in order to capture the complexity of system-level processes. This research yielded a number of publications, but less by way of influence on substantive research and policy making. Therefore, we decided to shift our main focus away from agent-based modeling to spatial computation, which allow for a more direct empirical validation of our results. This second phase of research includes the collection and integration of large amounts of spatiotemporally structured data, which we analyze with more conventional econometric tools. To advance the field of computational diplomacy, we recommend that future search combines agent-based modeling with rigorous empirical validation through the utilization of spatial computation.}
}
@article{GREENE2010230,
title = {Fostering historical knowledge and thinking skills using hypermedia learning environments: The role of self-regulated learning},
journal = {Computers & Education},
volume = {54},
number = {1},
pages = {230-243},
year = {2010},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2009.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0360131509002012},
author = {Jeffrey Alan Greene and Cheryl Mason Bolick and Jane Robertson},
keywords = {Teaching/learning strategies, Secondary education, Multimedia/hypermedia systems},
abstract = {In this study, we examined how high-school students utilized a hypermedia learning environment (HLE) to acquire declarative knowledge of a historical topic, as well as historical thinking skills. In particular, we were interested in whether self-regulated learning (SRL; Winne & Hadwin, 1998; Zimmerman, 2000) processing was related to the acquisition of declarative knowledge and historical thinking. We found that, using the HLE, participants did learn from pretest to posttest, and that they most often engaged in strategy use SRL processes. However, the frequency of participant use of planning SRL processes, not strategy use, was predictive of learning. This study has implications for how educators use HLEs to foster historical thinking skills, and suggests that scaffolding planning skills may facilitate students’ use of computers as cognitive and metacognitive tools for learning (Azevedo, 2005; Lajoie, 2000).}
}
@article{LASPIDOU2020137264,
title = {Systems thinking on the resource nexus: Modeling and visualisation tools to identify critical interlinkages for resilient and sustainable societies and institutions},
journal = {Science of The Total Environment},
volume = {717},
pages = {137264},
year = {2020},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2020.137264},
url = {https://www.sciencedirect.com/science/article/pii/S0048969720307749},
author = {Chrysi S. Laspidou and Nikolaos K. Mellios and Alexandra E. Spyropoulou and Dimitrios Th. Kofinas and Maria P. Papadopoulou},
keywords = {Resource nexus, Sustainability, System dynamics modeling, Water-energy-food-land-climate nexus, Advanced visualization tools, Nexus informatics},
abstract = {Achieving the UN Sustainable Development Goals depends on using resources efficiently, avoiding fragmentation in decision-making, recognising the trade-offs and synergies across sectors and adopting an integrated Nexus thinking among policymakers. Nexus Informatics develops the science of recognising and quantifying nexus interlinkages. Nexus-coherent solutions enhance the effect of policymaking in achieving adequate governance, leading to successful strategic vision and efficient resource management. In this article, we present the structure of a System Dynamics Model—the Nexus_SDM—that maps sector-specific data from major databases (e.g., EUROSTAT) and scenario models (e.g., E3ME-FTT OSeMOSYS and SWIM) for the national case study of Greece. Disaggregation algorithms are employed on annual national-scale data, turning them into detailed spatial and temporal datasets, by converting them to monthly values spread among all 14 River Basin Districts (RBDs). The Nexus_SDM calculates Nexus Interlinkage Factors and quantifies interlinkages among Water, Energy, Food, Built Environment, Natural Land and greenhouse gas (GHG) emissions. It simulates the nexus in the national case study of Greece as a holistic multi-sectoral system and provides insights into the vulnerability of resources to future socio-economic scenarios. It calculates the link between crop type/area, irrigation water and agricultural value, revealing which crops have the highest agricultural value with the least water and crop area. It demonstrates that fossil fuel power generation and use of oil for transportation are responsible for the most GHG emissions in most RBDs and presents projections for years 2030 and 2050. The analysis showcases that to move from a general nexus thinking to an operational nexus concept, it is important to focus on data availability and scale. Advanced Sankey and Chord diagrams are introduced to show distribution of resource use among RBDs and an innovative visualisation tool is developed, the Nexus Directional Chord plot, which reveals Nexus hotspots and strong interlinkages among sectors, facilitating stakeholder awareness.}
}
@article{SCHACHTER2016261,
title = {A critical review of Real Options thinking for valuing investment flexibility in Smart Grids and low carbon energy systems},
journal = {Renewable and Sustainable Energy Reviews},
volume = {56},
pages = {261-271},
year = {2016},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2015.11.071},
url = {https://www.sciencedirect.com/science/article/pii/S1364032115013386},
author = {J.A. Schachter and P. Mancarella},
keywords = {Real Options, Flexibility, Renewable energy, Energy systems investment, Low carbon technologies, Smart Grid},
abstract = {This paper aims at serving as a critical analysis of Real Options (RO) methodologies that have so far been applied to the flexible evaluation of smart grid developments and as a practical guide to understanding the benefits but more importantly the limitations of RO methodologies. Hence, future research could focus on developing more practical RO tools for application to the energy industry, thus making the utilization of powerful “real options thinking” for decision making under uncertainty more widespread. This is particularly important for applications in low carbon power and energy systems with increasing renewable and sustainable energy resources, given the different types of uncertainty they are facing in the transition towards a truly Smart Grid. In order to do so, and based on an extensive relevant literature review, the analogies with financial options are first presented, with various assumptions and their validity being clearly discussed in order to understand if, when, and how specific methods can be applied. It is then argued how option theory is in most cases not directly applicable to investment in energy systems but requires the consideration of their physical characteristics. The paper finally gives recommendations for building practical RO approaches to energy system (and potentially all engineering) project investments under uncertainty, regardless of the scale, time frame, or type of uncertainty involved.}
}
@article{TAKEUCHI2017258,
title = {Regional homogeneity, resting-state functional connectivity and amplitude of low frequency fluctuation associated with creativity measured by divergent thinking in a sex-specific manner},
journal = {NeuroImage},
volume = {152},
pages = {258-269},
year = {2017},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2017.02.079},
url = {https://www.sciencedirect.com/science/article/pii/S1053811917301891},
author = {Hikaru Takeuchi and Yasuyuki Taki and Rui Nouchi and Ryoichi Yokoyama and Yuka Kotozaki and Seishu Nakagawa and Atsushi Sekiguchi and Kunio Iizuka and Yuki Yamamoto and Sugiko Hanawa and Tsuyoshi Araki and Carlos {Makoto Miyauchi} and Takamitsu Shinada and Kohei Sakaki and Takayuki Nozawa and Shigeyuki Ikeda and Susumu Yokota and Magistro Daniele and Yuko Sassa and Ryuta Kawashima},
keywords = {Resting state, Regional coherence, Creativity, Divergent thinking, Anterior temporal lobe, Sex difference, Functional connectivity},
abstract = {Brain connectivity is traditionally thought to be important for creativity. Here we investigated the associations of creativity measured by divergent thinking (CMDT) with resting-state functional magnetic imaging (fMRI) measures and their sex differences. We examined these relationships in the brains of 1277 healthy young adults. Whole-brain analyses revealed a significant interaction between verbal CMDT and sex on (a) regional homogeneity within an area from the left anterior temporal lobe (b) on the resting state functional connectivity (RSFC) between the mPFC and the left inferior frontal gyrus and (c) on fractional amplitude of low frequency fluctuations (fALFF) in several distinct areas, including the precuneus and middle cingulate gyrus, left middle temporal gyrus, right middle frontal gyrus, and cerebellum. These interactions were mediated by positive correlations in females and negative correlations in males. These findings suggest that greater CMDT in females is reflected by (a) regional coherence (regional homogeneity) of brain areas responsible for representing and combining concepts as well as (b) the efficient functional connection (RSFC) between the key areas for the default state of cognitive activity and speech production, and (c) greater spontaneous neural activity (fALFF) during the resting of brain areas involved in frontal lobe functions, default cognitive activities, and language functions. Furthermore, these findings suggest that the associations between creativity and resting state brain connectivity patterns are different between males and females.}
}
@article{DESHPANDE2025100187,
title = {Computational intelligence in neuroinformatics: Technologies and data analytics},
journal = {Neuroscience Informatics},
volume = {5},
number = {1},
pages = {100187},
year = {2025},
issn = {2772-5286},
doi = {https://doi.org/10.1016/j.neuri.2025.100187},
url = {https://www.sciencedirect.com/science/article/pii/S2772528625000020},
author = {Anand Deshpande and Vania Vieira Estrela and Anitha Jude and Jude Hemanth}
}
@article{ZHOU2024102496,
title = {Computational strategic communication in a data-driven world},
journal = {Public Relations Review},
volume = {50},
number = {5},
pages = {102496},
year = {2024},
issn = {0363-8111},
doi = {https://doi.org/10.1016/j.pubrev.2024.102496},
url = {https://www.sciencedirect.com/science/article/pii/S0363811124000754},
author = {Alvin Zhou and Toni G.L.A. {van der Meer}}
}
@article{GIANNANTONI201462,
title = {The Relevance of Emerging Solutions for Thinking, Decision Making and Acting. The case of Smart Grids},
journal = {Ecological Modelling},
volume = {271},
pages = {62-71},
year = {2014},
note = {Environmental Accounting: Emergy, Systems Ecology and Ecological Modelling},
issn = {0304-3800},
doi = {https://doi.org/10.1016/j.ecolmodel.2013.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0304380013001907},
author = {Corrado Giannantoni},
keywords = {Emerging Solutions, Incipient Differential Calculus (IDC), Maximum Ordinality Principle, Intractable problems, Smart Grids},
abstract = {The paper presents a real novelty in Mathematical Modelling, which may have an enormous relevance in our way of Thinking, Decision Making and Acting. At the same time it would like to represent an explicit “Tribute” to Prof. Odum, because the original concept is already seminally present in his well-known Rules of Emergy Algebra. This novelty in Mathematical Modelling is represented by the so-called “Emerging Solutions”, which are radically different from solutions to traditional mathematical problems. This is because any traditional solution to an algebraic or differential problem is always represented by a formal expression that, when reintroduced into the initial formulation of the problem, reduces the latter to a perfect identity. Emerging Solutions, on the contrary, show an Ordinal Information content which is always much higher than the corresponding content pertaining to the initial formulation of the problem. Emerging Solutions, in fact, originate from any physical problem when this is modelled in accordance with the Maximum Ordinality Principle, and thus understood in Ordinal Terms. Such a property, which represents one of the most interesting aspects of the Maximum Ordinality Principle, then suggests we adopt a Generative way of Thinking when designing a new practical application. The same happens at the level of Will, that is at the level of Decision Making. Clearly, if we really want to take advantage of those “Emerging Exits” which arise from the physical behaviour of the system. Finally, at the level of Acting, if we are really interested in favouring any “emerging behaviour” of the system which is decisively capable to improve our design. For instance, to get the maximum intrinsic stability of the system, so as to prevent any possible disturbance that might significantly alter its expected behaviour. All these aspects will be illustrated through the case of Smart Grids, with particular reference to their large scale “intrinsic” instability and their recognized strong vulnerability to “cyber” attacks.}
}
@article{CAFIERO2023102056,
title = {Datafying diplomacy: How to enable the computational analysis and support of international negotiations},
journal = {Journal of Computational Science},
volume = {71},
pages = {102056},
year = {2023},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2023.102056},
url = {https://www.sciencedirect.com/science/article/pii/S1877750323001163},
author = {Florian Cafiero},
keywords = {Computational diplomacy, Open data, Digital humanities},
abstract = {Computational diplomacy, the application of digital and computational methods to the study and practice of international negotiations, presents unique challenges compared to most other fields in the computational humanities and social sciences. Among them are the necessity of responsiveness when handling crises, the need to anticipate and respond to adversarial behavior, or the need for secrecy in dealing with sensitive information. In this paper, we propose an agenda to address these challenges, and evaluate the feasibility of the various tasks that could be assigned to computational diplomacy. While most analysis tools seem almost ready to use, the availability and reliability of diplomacy-related data remains a major concern.}
}
@incollection{GUO202369,
title = {Chapter Three - Cascades in language acquisition: Re-thinking the linear model of development},
editor = {Catherine S. Tamis-Lemonda and Jeffrey J. Lockman},
series = {Advances in Child Development and Behavior},
publisher = {JAI},
volume = {64},
pages = {69-107},
year = {2023},
booktitle = {Developmental Cascades},
issn = {0065-2407},
doi = {https://doi.org/10.1016/bs.acdb.2022.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S0065240722000465},
author = {Laura X. Guo and Amy Pace and Lillian R. Masek and Roberta M. Golinkoff and Kathy Hirsh-Pasek},
keywords = {Developmental cascades, Child language development, Domain general, Domain specific, Bilingual development, Developmental language disorders},
abstract = {The first 5 years of life are characterized by incredible growth across domains of child development. Drawing from over 50 years of seminal research, this chapter contextualizes recent advances in language sciences through the lens of developmental cascades to explore complexities and connections in acquisition. Converging evidence—both classic and contemporary—points to the many ways in which advances in one learning system can pose significant and lasting impacts on the advances in other learning systems. This chapter reviews evidence in developmental literature from multiple domains and disciplines (i.e., cognitive, social, motor, bilingual language learning, and communication sciences and disorders) to examine the phenomenon of developmental cascades in language acquisition.}
}
@article{WOLFENGAGEN20229,
title = {Cognitive technology to capture deep computational concepts with combinators},
journal = {Cognitive Systems Research},
volume = {71},
pages = {9-23},
year = {2022},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2021.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S1389041721000747},
author = {Viacheslav Wolfengagen and Larisa Ismailova and Sergey Kosikov},
keywords = {Combinatory logic, Combinator-as-a-process, Information process, Applicative structure, Artificial computing, Natural computing},
abstract = {Computational activity is now recognized as a natural science, and computational and information processes have been discovered in the deep structures of many areas. Computations in the natural world were present long before the invention of computers, but a remarkable shift in understanding its fundamental nature occurs, in fact, before our eyes. The present moment, in fact, is a transition from the concept of computer science as an artificial science to the understanding that information processes are abundant in nature. Computing is recognized as a natural science that studies natural and artificial information processes. In everyday computing, operations are performed on the individual generators, with little attention paid to their internal structure. However, many common operations consist of more primitive constructions connected by a combination mode. The interaction of information processes and corresponding structures is carried out in an environment of “applicative interaction”, their applications to each other, and the study of the properties of this environment allows us to understand the nature of the computations. In the present work, the main attention is paid to elucidating the technological features of computations with individual generators, or objects. Their interaction is considered in an applicative environment, which allows us to elucidate the internal structure of ordinary operations, the knowledge of which allows us to understand their properties. The choice of initial constant generators, considered as generic ones and expressed by combinators, is discussed. These initial generators are used as the main “building blocks” that occur within the larger blocks of the applicative environment in interaction with each other. As a result of the interaction, constructions arise that give representative sets of ordinary operators and embedded computing systems.}
}
@article{CHERMITE2025122764,
title = {A novel hybrid approach combining Differentiated Creative Search with adaptive refinement for photovoltaic parameter extraction},
journal = {Renewable Energy},
volume = {245},
pages = {122764},
year = {2025},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2025.122764},
url = {https://www.sciencedirect.com/science/article/pii/S0960148125004264},
author = {Charaf Chermite and Moulay Rachid Douiri},
keywords = {Photovoltaic parameter extraction, Parameter identification, Hybrid optimization methods, Differentiated creative search (DCS), Newton-Raphson (NR) method, Metaheuristic algorithms},
abstract = {Accurate parameter extraction from Photovoltaic (PV) models using current-voltage (I-V) data is essential for optimizing and simulating photovoltaic systems. Despite the existence of various techniques, many face challenges in achieving a balance between precision, robustness, computational efficiency, and execution time. In this paper, we present a novel hybrid algorithm, Differentiated Creative Search combined with Newton-Raphson (DCS-NR), designed to improve the accuracy and efficiency of PV parameter extraction. DCS employs a dual-strategy mechanism that balances exploration and exploitation through divergent and convergent thinking, ensuring a comprehensive search for solutions. The Newton-Raphson method further refines the parameters optimized by DCS, minimizing the discrepancy between estimated and measured currents, and consequently improving power estimation. The proposed approach is evaluated on three distinct models: Single Diode Model (SDM), Double Diode Model (DDM), and PV Module Model (PMM). Among the different models tested, DCS-NR consistently delivers superior accuracy. For example, it achieves an RMSE of 7.75392 × E−04 for the RTC France SDM and 1.77454 × E−04 for the PVM 752 cell, outperforming ten state-of-the-art metaheuristic algorithms. Moreover, DCS-NR demonstrates remarkable computational efficiency, requiring only 0.830 s on average for the RTC France SDM, which is considerably faster than algorithms such as Flying Foxes Optimization (251.5 s). Furthermore, it proves highly effective in real-world conditions, under varying irradiance and constant temperature, as well as vice versa. The method consistently converges within approximately 100 iterations, showcasing rapid optimization capabilities. These findings highlight the potential of DCS-NR as a powerful and versatile tool for photovoltaic parameter extraction, capable of addressing diverse and challenging scenarios.}
}
@incollection{MAYER200115476,
title = {Teaching for Thinking},
editor = {Neil J. Smelser and Paul B. Baltes},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences},
publisher = {Pergamon},
address = {Oxford},
pages = {15476-15479},
year = {2001},
isbn = {978-0-08-043076-8},
doi = {https://doi.org/10.1016/B0-08-043076-7/02466-9},
url = {https://www.sciencedirect.com/science/article/pii/B0080430767024669},
author = {R.E. Mayer},
abstract = {Teaching for thinking refers to instruction intended to improve the effectiveness of people's thinking. A rationale for teaching for thinking is that students are expected to be effective thinkers but rarely are taught how to think. Teaching for thinking is intended to promote the ability to use what one has learned to solve new problems, which Wertheimer refers to as productive thinking. Teaching for thinking requires the consideration of four issues—what, how, where, and when to teach. Concerning what to teach, successful teaching for thinking focuses on helping students develop a collection of component skills for a particular cognitive task rather than on improving the mind in general. Concerning how to teach, successful teaching for thinking focuses on modeling the process of problem solving rather than solely drill and practice on getting the right answer. Concerning where to teach, successful teaching for thinking focuses on teaching within specific subject areas rather than in a content-independent course. Concerning when to teach, successful teaching for thinking includes teaching while students are novices rather than waiting until they have mastered all prerequisite basic skills.}
}
@article{ALBERT2002220,
title = {Relationships among bilingualism, critical thinking ability, and critical thinking disposition},
journal = {Journal of Professional Nursing},
volume = {18},
number = {4},
pages = {220-229},
year = {2002},
issn = {8755-7223},
doi = {https://doi.org/10.1053/jpnu.2002.127015},
url = {https://www.sciencedirect.com/science/article/pii/S8755722302000212},
author = {Raymond T. Albert and Rachel E. Albert and Jenny Radsma},
keywords = {Critical thinking, Critical thinking disposition, Bilingualism, Nursing, Baccalaureate},
abstract = {Evidence exists supporting relationships between bilingualism and many cognitive factors. Research, however, has not been conducted to specifically examine the relationships among bilingualism, critical thinking ability, and critical thinking disposition of baccalaureate nursing students. This cross-sectional study used a pooled, within-bilingual, correlational design to examine such relationships. Specific research questions posed were: (1) is there a statistically significant curvilinear relationship between bilingualism and critical thinking ability, (2) is there a statistically significant curvilinear relationship between bilingualism and critical thinking disposition, and (3) is there a statistically significant relationship between critical thinking disposition and critical thinking ability? A convenience sample of nursing students (N = 111) was administered a French language Cloze Test (C-Test), an English language C-Test, as well as the California Critical Thinking Skills Test, and the California Critical Thinking Disposition Inventory. Multiple regression analysis was used to test the hypotheses. Findings failed to provide sufficient evidence to support the existence of a relationship between either bilingualism and critical thinking ability, or between critical thinking disposition and critical thinking ability. However, there was sufficient evidence to support the existence of a curvilinear relationship between bilingualism and critical thinking disposition. Implications for nursing education are presented. J Prof Nurs 18:220-229, 2002. Copyright 2002, Elsevier Science (USA). All rights reserved.}
}

@article{STAVERT2023432,
title = {Unlocking the holy grail of sustainable and scalable mesoporous silica using computational modelling},
journal = {RSC Sustainability},
volume = {1},
number = {3},
pages = {432-438},
year = {2023},
issn = {2753-8125},
doi = {https://doi.org/10.1039/d3su00019b},
url = {https://www.sciencedirect.com/science/article/pii/S2753812523000952},
author = {Tom Stavert and Siddharth V. Patwardhan and Robert Pilling and Miguel Jorge},
abstract = {ABSTRACT
Bio-inspired methods offer a great alternative to design high-value mesoporous silica under more environmentally friendly conditions, allowing for an economical and sustainable scale-up. However, the synthesis of bio-inspired silica (BIS) is currently poorly understood, creating barriers to achieving products with comparable quality to traditional mesoporous silica. This perspective summarizes the key findings in the development of ordered mesoporous silica (OMS) and BIS synthesis, highlighting in particular the challenges faced in the development of scalable processing routes for these materials. Recent successes in improving mechanistic understanding of these syntheses using computational modelling are then presented, followed by suggestions as to how modelling may be used for predictive design of BIS with desired quality attributes. A multi-scale computational model, utilizing a combination of both ‘top-down’ and ‘bottom-up’ approaches, is argued to be critical for achieving a unified description of both BIS and OMS synthesis, allowing the potential of these materials to be fully realised.}
}
@article{DU2023108546,
title = {OSSCAR, an open platform for collaborative development of computational tools for education in science},
journal = {Computer Physics Communications},
volume = {282},
pages = {108546},
year = {2023},
issn = {0010-4655},
doi = {https://doi.org/10.1016/j.cpc.2022.108546},
url = {https://www.sciencedirect.com/science/article/pii/S001046552200265X},
author = {Dou Du and Taylor J. Baird and Sara Bonella and Giovanni Pizzi},
keywords = {Jupyter, Notebooks, Computational physics, Computational chemistry, Computational materials science, Education},
abstract = {In this paper we present the Open Software Services for Classrooms and Research (OSSCAR) platform. OSSCAR provides an open collaborative environment to develop and access educational resources in the form of web applications, for which various deployment methods are discussed and compared. To minimize efforts in the creation and use of new educational material, OSSCAR combines software tools that have emerged as standards with custom domain-specific ones. The technical solutions adopted to create and distribute content are described and motivated on the basis of reliability, sustainability, ease of uptake and use. Examples from courses in the domains of physics, chemistry, and materials science are shown to demonstrate the style and level of interactivity of typical applications. The tools presented are easy to use, and create a uniform and open environment exploitable by a large community of teachers, students, and researchers with the goal of facilitating learning and avoiding, when possible, duplication of efforts in creating teaching material. Contributions to expand the educational content of the OSSCAR project are welcome.
Program summary
Program Title: OSSCAR Interactive Notebooks for Quantum Mechanics and Computational Materials Science CPC Library link to program files: https://doi.org/10.17632/26py5zz9f8.1 Developer's repository link: https://github.com/osscar-org/quantum-mechanics Licensing provisions: MIT Programming language: Python Nature of problem: Among others, computational courses (e.g. on quantum mechanics) can benefit from advanced interactive visualizations of the content. However, on the one hand it might be complicated for teachers to develop such interactive content; on the other hand, students need to be able to access very quickly and efficiently the content, reducing the time needed to install libraries and dependencies that might differ between courses. Solution method: Here, we developed interactive web applications to complement teaching and encourage computational thinking for courses in computational physics, chemistry and materials science, using Jupyter notebooks and their rendering as interactive web applications. The latter is powered by a combination of Voila, to hide code and convert notebooks into live web applications, and (existing or custom) Jupyter widgets to enable interactiveness. The code is ready to be deployed via a number of open approaches.}
}
@article{GOBL2023100604,
title = {Situating computational empowerment in formal education: A multi-perspective view},
journal = {International Journal of Child-Computer Interaction},
volume = {38},
pages = {100604},
year = {2023},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2023.100604},
url = {https://www.sciencedirect.com/science/article/pii/S2212868923000417},
author = {Barbara Göbl and Elisabeth Anna Guenther and Fares Kayali and Christopher Frauenberger},
keywords = {Computational empowerment, Digital competences, Digital literacy, Empowerment, Participatory design},
abstract = {Digital literacy and respective education are of growing interest in our increasingly digitalized world. Recent works stress the importance of aiming beyond the acquisition of corresponding technical competences and call for fostering children’s empowerment and participation in digitalization. Computational Empowerment (CE) pursues that goal through a creative and reflexive participatory design approach. However, remaining conceptual vagueness with regard to what CE entails may hinder its implementation in formal education. This paper addresses this gap, with the aim to demonstrate what is needed to advance CE’s position in this context. To this end, we elaborate on our understanding of CE’s vision, approach and impact. We then examine CE in the context of formal education, and contrast it with selected contemporary educational theory and practice. Specifically, we position CE in relation to an established learning framework (Bloom’s revised taxonomy), educational policy (DigComp) and practices in the classroom. This is complemented by an analysis of four different projects: we present lessons learned in the context of pedagogical interventions and take a closer look at the accompanying empowerment processes. As a result, this paper provides a foundation to make CE’s ideas more tangible and, thus, actionable, for researchers, policy makers and educators.}
}
@article{MARMION201345,
title = {The Drosophila BMPRII, wishful thinking, is required for eggshell patterning},
journal = {Developmental Biology},
volume = {375},
number = {1},
pages = {45-53},
year = {2013},
issn = {0012-1606},
doi = {https://doi.org/10.1016/j.ydbio.2012.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S001216061200677X},
author = {Robert A. Marmion and Milica Jevtic and Alexander Springhorn and George Pyrowolakis and Nir Yakoby},
keywords = {Tissue patterning, Oogenesis, TGF-beta signaling},
abstract = {The Drosophila eggshell is an elaborate structure that is derived from a monolayer of follicular epithelium surrounding the developing oocyte within the female ovary. The bone morphogenetic protein (BMP) signaling pathway is essential for controlling the patterning and morphogenesis of the eggshell. During oogenesis, the roles of patterning and morphogenesis by the BMP type I receptor thickveins (tkv) have been studied extensively. However, signaling through this pathway requires both type I and II receptors, and the latter has yet to be established in oogenesis. We focus on wishful thinking (wit), the Drosophila homolog to the mammalian BMP type II receptor, BMPRII. We found that wit is expressed dynamically in the FCs of D. melanogaster in an evolutionary conserved pattern. The expression patterns are highly correlated with the dynamics of the BMP signaling, which is consistent with our finding that wit is a target of BMP signaling. Furthermore, we established that WIT is necessary for BMP signaling, and loss of WIT is associated with cell autonomous loss of BMP responses. Of importance, we demonstrated that perturbations in WIT led to changes in eggshell morphologies in domains that are patterned by BMP signaling. Previous studies have shown a role for WIT in BMP signaling during neurogenesis; however, our results reveal a role for WIT in epithelial cells' development.}
}
@incollection{ALLAHVIRANLOO2024407,
title = {Chapter 23 - Computations with words},
editor = {Tofigh Allahviranloo and Witold Pedrycz and Amir Seyyedabbasi},
booktitle = {Decision-Making Models},
publisher = {Academic Press},
pages = {407-415},
year = {2024},
series = {Uncertainty, Computational Techniques, and Decision Intelligence},
isbn = {978-0-443-16147-6},
doi = {https://doi.org/10.1016/B978-0-443-16147-6.00012-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780443161476000128},
author = {Tofigh Allahviranloo},
keywords = {Computation, Fuzzy, Application},
abstract = {In fact, computing with words is a method in which the objects are words, and the computations are propositions extracted from ordinary conversation. For example, small, large, far, and heavy, not very likely, the price of gas in Iran is low and increasing a lot. Computing with words is inspired by the remarkable ability of humans to perform various types of physical and mental activities without any measurement or calculation. Familiar examples of these activities are parking a car, driving in heavy traffic, riding a bicycle, understanding speech, etc.}
}
@article{IIVARI2023100600,
title = {Computational empowerment of children: Design research on empowering and impactful designs by children},
journal = {International Journal of Child-Computer Interaction},
volume = {37},
pages = {100600},
year = {2023},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2023.100600},
url = {https://www.sciencedirect.com/science/article/pii/S2212868923000375},
author = {Netta Iivari and Leena Ventä-Olkkonen and Heidi Hartikainen and Sumita Sharma and Essi Lehto and Jenni Holappa and Tonja Molin-Juustila},
keywords = {Children, Empowerment, Impact, Critical design, Critical making, Bullying, Design research},
abstract = {Prioritizing children’s empowerment in and through design has been on the agenda of child–computer interaction (CCI) research for a long time. Recently, the notion of the computational empowerment of children has received attention. However, there are still open issues in our understanding and advocacy of it. A related development is the recent interest in the longer-term impacts of our work. Fast and furious participation of children in design sessions is considered inadequate. We should advocate for longer-term trajectories and possibilities for children to make changes that will influence our world. However, the literature is limited in addressing longer-term impacts. This study taps into these two research gaps and showcases how we have addressed the computational empowerment of children in a project tackling bullying at school through critical design and making. In this paper, we examine in detail the children’s designs and their trajectories from the viewpoint of empowerment and impact: whether and how these children’s designs show potential for the empowerment of those bullied and whether and how their designs have had an impact in the realm of digital technology development. Our study has interesting conceptual and methodological implications for CCI research and practice on the computational empowerment of children and on our design research practice.}
}
@article{MAMMINO2022100743,
title = {Computational chemistry and green chemistry: Familiarizing chemistry students with the modes and benefits of promising synergies},
journal = {Sustainable Chemistry and Pharmacy},
volume = {29},
pages = {100743},
year = {2022},
issn = {2352-5541},
doi = {https://doi.org/10.1016/j.scp.2022.100743},
url = {https://www.sciencedirect.com/science/article/pii/S2352554122001474},
author = {Liliana Mammino},
keywords = {Computational modelling of molecules, Cross-area synergies for green chemistry, Green chemistry education, Molecular design for green chemistry, Student-friendly introduction to the bases of molecular studies},
abstract = {Because of its nature as the science of substances, chemistry is bound to play major roles in the pursuit of sustainable development. Green chemistry outlines the framework of this role and its 12 principles express objectives simultaneously constituting implementation guidelines. Tackling the challenges posed by the pursuit of sustainability is likely to become an increasingly permeating component of chemists' professional activities, and future chemists need to be adequately prepared for it. The principles of green chemistry entail the design of substances and processes that are inherently benign to human health and to the environment (benign-by-design concept). Computational chemistry constitutes a major resource for the design of molecules having desired properties. However, students’ exposure to the potentialities and practices of this type of cross-area synergies remains largely inadequate. The paper discusses the importance of adequate exposure and outlines possible routes to facilitate it in a student-friendly and constructive way.}
}
@article{CAI2002401,
title = {Generalized and generative thinking in US and Chinese students’ mathematical problem solving and problem posing},
journal = {The Journal of Mathematical Behavior},
volume = {21},
number = {4},
pages = {401-421},
year = {2002},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(02)00142-6},
url = {https://www.sciencedirect.com/science/article/pii/S0732312302001426},
author = {Jinfa Cai and Stephen Hwang},
keywords = {Generalized thinking, Generative thinking, Problem solving, Problem posing, Cross-national study},
abstract = {This study examined US and Chinese 6th grade students’ generalization skills in solving pattern-based problems, their generative thinking in problem posing, and the relationships between students’ performance on problem solving and problem posing tasks. Across the problem solving tasks, Chinese students had higher success rates than US students. The disparities appear to be related to students’ use of differing strategies. Chinese students tend to choose abstract strategies and symbolic representations while US students favor concrete strategies and drawing representations. If the analysis is limited to those students who used concrete strategies, the success rates between the two samples become almost identical. With regard to problem posing, the US and Chinese samples both produce problems of various types, though the types occur in differing sequences. Finally, this study revealed differential relationships between problem posing and problem solving for US and Chinese students. There was a much stronger link between problem solving and problem posing for the Chinese sample than there was for the US sample.}
}
@article{WORKMAN200213,
title = {The state of multivariate thinking for scientists in industry: 1980–2000},
journal = {Chemometrics and Intelligent Laboratory Systems},
volume = {60},
number = {1},
pages = {13-23},
year = {2002},
note = {Fourth International Conference on Environ metrics and Chemometrics held in Las Vegas, NV, USA, 18-20 September 2000},
issn = {0169-7439},
doi = {https://doi.org/10.1016/S0169-7439(01)00182-4},
url = {https://www.sciencedirect.com/science/article/pii/S0169743901001824},
author = {Jerry Workman},
keywords = {Multivariate thinking, Spectrometer calibration, Spectroscopy-based measurements},
abstract = {Chemometrics has enjoyed tremendous success in the areas related to calibration of spectrometers and spectroscopy-based measurements. These chemometric-based spectrometers have been widely applied for process monitoring and quality assurance. However, chemometrics has the potential to revolutionize the very intellectual roots of problem solving. Are there barriers to a more rapid proliferation of chemometric-based thinking, particularly in industry? What are the potential effects of chemometrics technology and the New Network Economy (NNE) working in concert? Who will be the winners in the race for faster, better, cheaper systems and products? These questions are reviewed in terms of the principles of the NNE and in the promise of chemometrics for industry. What then is the state of multivariate thinking in industry? Several powerful principles are derived from an evaluation of the NNE and chemometrics which could allow chemometrics to proliferate much more rapidly as a key general problem-solving tool.}
}
@article{KOSTERHALE201465,
title = {Thinking about seeing: Perceptual sources of knowledge are encoded in the theory of mind brain regions of sighted and blind adults},
journal = {Cognition},
volume = {133},
number = {1},
pages = {65-78},
year = {2014},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2014.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S0010027714000675},
author = {Jorie Koster-Hale and Marina Bedny and Rebecca Saxe},
keywords = {Blindness, Theory of mind, Experience, Representation, fMRI, Multivoxel pattern analysis (MVPA)},
abstract = {Blind people’s inferences about how other people see provide a window into fundamental questions about the human capacity to think about one another’s thoughts. By working with blind individuals, we can ask both what kinds of representations people form about others’ minds, and how much these representations depend on the observer having had similar mental states themselves. Thinking about others’ mental states depends on a specific group of brain regions, including the right temporo-parietal junction (RTPJ). We investigated the representations of others’ mental states in these brain regions, using multivoxel pattern analyses (MVPA). We found that, first, in the RTPJ of sighted adults, the pattern of neural response distinguished the source of the mental state (did the protagonist see or hear something?) but not the valence (did the protagonist feel good or bad?). Second, these neural representations were preserved in congenitally blind adults. These results suggest that the temporo-parietal junction contains explicit, abstract representations of features of others’ mental states, including the perceptual source. The persistence of these representations in congenitally blind adults, who have no first-person experience with sight, provides evidence that these representations emerge even in the absence of relevant first-person perceptual experiences.}
}
@article{YANG2025101808,
title = {Cross-domain analogical reasoning ability links functional connectome to creativity},
journal = {Thinking Skills and Creativity},
pages = {101808},
year = {2025},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2025.101808},
url = {https://www.sciencedirect.com/science/article/pii/S1871187125000574},
author = {Lin Yang and Rongcan Zeng and Xueyang Wang and Jing Chen and Jing Gu and Jiaxin Fan and Jiang Qiu and GuiKang Cao},
keywords = {cross-domain analogical reasoning, creativity, CPM, natural language processing},
abstract = {ABSTRACT
Cross-domain analogical reasoning (CAR) is a potent cognitive tool that links seemingly unrelated knowledge domains, fostering creative thinking by identifying similarities across different fields. This study aimed to identify functional connectomes encoding individual variations in CAR abilities and assess the role in creativity. Participants included 69 typical university students who underwent resting-state brain MRI scans and behavioral tests. These tests assessed CAR and within-domain analogical reasoning (WAR) abilities using verbal analogy tasks in the A:B::C:D format and measured individual creativity levels using the Alternative Uses Test (AUT). We employed a connectome-based predictive modeling (CPM) approach, utilizing the Power264 brain atlas to identify functional connectomes supporting CAR abilities. The CPM analysis indicated that the positive network model could reliably predict individual CAR scores. Functional anatomy and lesion analysis revealed that functional connectivity was broadly distributed across the brain. However, the default mode network, along with specific internetwork connections—such as between the salience and sensory/somatomotor mouth networks, and between the fronto-parietal task control and cingulo-opercular task control networks—showed preferential involvement. Moreover, mediation analysis suggested that CAR mediates the impact of brain functional connectomes on creativity. Our research provides evidence for functional neural markers of CAR and reveals a potential neuropsychological pathway for predicting creativity, whereby brain functional connectomes support creativity through CAR.}
}
@article{JOHNSON2025101757,
title = {Shifting pedagogically: Incorporating the social, cultural, and emotional dimensions of student learning to develop STEM-identities in computer science},
journal = {Journal of Applied Developmental Psychology},
volume = {97},
pages = {101757},
year = {2025},
issn = {0193-3973},
doi = {https://doi.org/10.1016/j.appdev.2025.101757},
url = {https://www.sciencedirect.com/science/article/pii/S0193397325000048},
author = {Stanley L. Johnson and Joseph P. Bishop and Kirk D. Rogers},
keywords = {Stem-identity development, Social and emotional learning, Learning sciences, Pedagogy, Computational thinking, Educational equity},
abstract = {Through qualitative inquiry of a 9th-grade computer science (CS) classroom, this paper examines how teachers' pedagogical approaches can help prioritize the social and emotional dimensions of student learning to foster STEM identity and development. Findings from an ethnographic study of the delivery of the Exploring Computer Science curriculum in a high school setting of majority of students of color, and low-income youth identify five high-leverage instructional strategies. These strategies include 1) teacher mindsets towards specific subject areas like computer science; 2) creating conditions for affirming students culturally; 3) intentionally prioritizing student autonomy for social and emotional development; 4) co-constructing knowledge to increase student engagement; and 5) helping students create their own STEM identity by exposing them to STEM professionals of similar racial and cultural characteristics as students. Collectively, these practices offer critical windows into how educators can act as intermediaries in helping students see themselves in the CS field and STEM/CS career pathways. Findings from this study can inform strategies for teacher education and policy efforts seeking to close learning gaps for historically marginalized groups and to improve racial and gender diversity in opportunities for growing STEM fields.}
}
@article{CZAKON202399,
title = {Re-thinking strategic myopia: A necessary condition analysis of heuristic and firm's performance},
journal = {Industrial Marketing Management},
volume = {115},
pages = {99-109},
year = {2023},
issn = {0019-8501},
doi = {https://doi.org/10.1016/j.indmarman.2023.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S0019850123001864},
author = {Wojciech Czakon and Patrycja Klimas and Arkadiusz Kawa},
keywords = {Myopia, Managers, Heuristic, Performance, NCA},
abstract = {At times of fast paced technology progress and global disruptions strategic myopia can be particularly harmful to firms. A narrow view of actors, events and tendencies is a firm's environment, combined with short-term preferences is widely recognized in the literature as leading to belated or inadequate responses to challenges. Manager's myopia is typically portrayed as a systematic bias, inducing underperformance. However, empirical evidence is more than nuanced in this respect. In this study, we view strategic myopia as an effective heuristic triggered in uncertain environments and specific task conditions. We use the necessary condition analysis (NCA) to examine the association between strategic myopia and firm performance through a necessity logic lens. This innovative method provides insights into the relationship between low levels of strategic myopia dimensions and firm performance in both the short- and long term. We measure strategic myopia and firm performance as multidimensional constructs on a representative sample of 658 Polish managers. Our results challenge the conventional wisdom that low strategic myopia is necessary for high performance. We highlight the nuanced role of myopia across its dimensions (i.e., competitive, cooperative, temporal, and learning) and shed light on its implications for both short- and long-term performance.}
}
@article{GOLDSCHMIDT1994158,
title = {On visual design thinking: the vis kids of architecture},
journal = {Design Studies},
volume = {15},
number = {2},
pages = {158-174},
year = {1994},
issn = {0142-694X},
doi = {https://doi.org/10.1016/0142-694X(94)90022-1},
url = {https://www.sciencedirect.com/science/article/pii/0142694X94900221},
author = {Gabriela Goldschmidt},
keywords = {visual thinking, designing, imagery, sketching, architecture},
abstract = {Designers invariably use imagery to generate new form combinations which they represent through sketching. But they also do the reverse: they sketch to generate images of forms in their minds. Common belief regards such activity as non-rational. In contrast, we assert that interactive imagery through sketching is a rational mode of reasoning, characterized by systematic exchanges between conceptual and figural arguments. Cognitive science, strongly dominated by a linguistic paradigm, has yet to recognize the paramount role of visual reasoning in many instances of problem solving; and in design tool-making, computational and otherwise, we must learn to optimize rather than bypass intuitive visuality.}
}
@article{PICKLO2024112790,
title = {Denoising Particle-In-Cell data via Smoothness-Increasing Accuracy-Conserving filters with application to Bohm speed computation},
journal = {Journal of Computational Physics},
volume = {502},
pages = {112790},
year = {2024},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2024.112790},
url = {https://www.sciencedirect.com/science/article/pii/S0021999124000391},
author = {Matthew J. Picklo and Qi Tang and Yanzeng Zhang and Jennifer K. Ryan and Xian-Zhu Tang},
keywords = {Particle-In-Cell, SIAC filters, Denoising},
abstract = {The simulation of plasma physics is computationally expensive because the underlying physical system is of high dimensions, requiring three spatial dimensions and three velocity dimensions. One popular numerical approach is Particle-In-Cell (PIC) methods owing to its ease of implementation and favorable scalability in high-dimensional problems. An unfortunate drawback of the method is the introduction of statistical noise resulting from the use of finitely many particles. In this paper we examine the application of the Smoothness-Increasing Accuracy-Conserving (SIAC) family of convolution kernel filters as denoisers for moment data arising from PIC simulations. We show that SIAC filtering is a promising tool to denoise PIC data in the physical space as well as capture the appropriate scales in the Fourier space. Furthermore, we demonstrate how the application of the SIAC technique reduces the amount of information necessary in the computation of quantities of interest in plasma physics such as the Bohm speed.}
}
@article{LIU2024117403,
title = {Towards quantum computational mechanics},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {432},
pages = {117403},
year = {2024},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2024.117403},
url = {https://www.sciencedirect.com/science/article/pii/S0045782524006583},
author = {Burigede Liu and Michael Ortiz and Fehmi Cirak},
keywords = {Quantum computing, Multiscale analysis, Quantum Fourier transform, Quantum polynomial encoding, Gate-based quantum computing},
abstract = {The advent of quantum computers, operating on entirely different physical principles and abstractions from those of classical digital computers, sets forth a new computing paradigm that can potentially result in game-changing efficiencies and computational performance. Specifically, the ability to simultaneously evolve the state of an entire quantum system leads to quantum parallelism and interference. Despite these prospects, opportunities to bring quantum computing to bear on problems of computational mechanics remain largely unexplored. In this work, we demonstrate how quantum computing can indeed be used to solve representative volume element (RVE) problems in computational homogenisation with polylogarithmic complexity of O((logN)c), compared to O(Nc) in classical computing. Thus, our quantum RVE solver attains exponential acceleration with respect to classical solvers, bringing concurrent multiscale computing closer to practicality. The proposed quantum RVE solver combines conventional algorithms such as a fixed-point iteration for a homogeneous reference material and the Fast Fourier Transform (FFT). However, the quantum computing reformulation of these algorithms requires a fundamental paradigm shift and a complete rethinking and overhaul of the classical implementation. We employ or develop several techniques, including the Quantum Fourier Transform (QFT), quantum encoding of polynomials, classical piecewise Chebyshev approximation of functions and an auxiliary algorithm for implementing the fixed-point iteration and show that, indeed, an efficient implementation of RVE solvers on quantum computers is possible. We additionally provide theoretical proofs and numerical evidence confirming the anticipated O(logN)c complexity of the proposed solver.}
}
@article{LOWALEKAR201789,
title = {Revolutionizing blood bank inventory management using the TOC thinking process: An Indian case study},
journal = {International Journal of Production Economics},
volume = {186},
pages = {89-122},
year = {2017},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2017.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0925527317300336},
author = {Harshal Lowalekar and R. Raghavendra Ravi},
keywords = {Inventory management, Blood banks, Theory of Constraints (TOC), Thinking Process},
abstract = {The purpose of this research is to demonstrate an application of TOC's thinking process (TP) in a blood bank environment. We take an example of a real-life blood bank which is struggling with the problems of high shortage and wastage of blood products, large inventory levels, poor and erratic blood collection, limited product variety, high error rate, high turnover of technicians, high operating expenses and low revenue levels. We show using the TOC approach how these seemingly unrelated problems faced by the bank are in fact highly inter-related and how they all originate from a single root-cause. A current reality tree (CRT) is used to identify the root cause responsible for all the major blood bank problems. A conflict resolution diagram (CRD) is constructed to identify the core-conflict(s) responsible for the blood bank's poor performance. A simple yet powerful solution is generated for the given bank by breaking the core-conflict resulting from a paradigm constraint in blood banking. A future reality tree (FRT) is then constructed to show how the TOC approach will help the blood bank in lowering its shortage and wastage levels in spite of collecting lesser number of units in blood donation camps. The bank will be able to significantly cut down its inventories and can issue fresher units to the patients. Blood bank's revenue levels will increase while its operating expense will decrease due to the TOC approach. The error rate as well as the turnover of technicians in the blood bank laboratory will also reduce considerably. A simulation model shows that the proposed TOC solution will reduce the annual shortage of red blood cells by 66% and platelets by 82% at the bank. Similarly, the wastage of red blood cells will decrease by 93%, plasma by 99% and platelets by 98%. The average inventory level of the red blood cells will drop by 41%, plasma by 95% and platelets by 10%. The major contribution of this research is to show that TP tools can be extremely powerful in constructing win-win solutions for complex systems like blood banks by addressing their major problems in an integrated fashion. The TOC approach reveals how one widely-held belief in the blood banking world is the main reason behind the blood banks' poor state of affairs. The solutions presented in this research should be readily applicable to other blood banks which are struggling to improve their operational and financial performance.}
}
@article{MENG2025105053,
title = {Time-variant response computation of flexible multibody systems with imprecise random fields},
journal = {International Journal of Non-Linear Mechanics},
volume = {173},
pages = {105053},
year = {2025},
issn = {0020-7462},
doi = {https://doi.org/10.1016/j.ijnonlinmec.2025.105053},
url = {https://www.sciencedirect.com/science/article/pii/S0020746225000411},
author = {Jingwei Meng and Yanfei Jin},
keywords = {Hybrid uncertain analysis, Flexible multibody systems, Imprecise random fields, Interval parameters, Polynomial chaos-Legendre metamodel},
abstract = {This paper proposes a new uncertain modelling and analysis method for flexible multibody systems with imprecise random field uncertainties. The standard random field is expanded to the imprecise random field model containing the behavior of imprecise randomness with bounded statistical moments more appropriately for real engineering problems. The imprecise random field is further discretized to independent standard Gaussian random variables by using the Karhunen-Loève expansion method. The flexible multibody system is modeled by using a unified mesh of the absolute node coordinate formula. Mathematical expressions and solution procedure based on the Polynomial chaos-Legendre metamodel are developed to solve the dynamic equations of systems involving imprecise random field. Two types of evaluation indexes are effectively established by constructing the second layer polynomial chaos expansion, namely interval mean value, interval variance, mean of the upper bound, variance of the lower bound. Finally, the effectiveness of the presented method is illustrated by two numerical examples of flexible multibody systems. Especially, for complicated multibody systems, it is necessary to calculate two uncertainty evaluation indexes to study the complete dynamic behavior.}
}
@article{BAGO2018483,
title = {Fast and slow thinking: Electrophysiological evidence for early conflict sensitivity},
journal = {Neuropsychologia},
volume = {117},
pages = {483-490},
year = {2018},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2018.07.017},
url = {https://www.sciencedirect.com/science/article/pii/S0028393218303440},
author = {Bence Bago and Darren Frey and Julie Vidal and Olivier Houdé and Gregoire Borst and Wim {De Neys}},
keywords = {EEG, Dual process theory},
abstract = {Popular dual process models have characterized reasoning as an interplay between fast, intuitive (System 1) and slow, deliberate (System 2) processes, but the precise nature of the interaction between the two systems is much debated. Here we relied on the temporal resolution of electroencephalogram (EEG) recordings to decide between different models. We adopted base-rate problems in which an intuitively cued stereotypical response was either congruent or incongruent with the correct response that was cued by the base-rates. Results showed that solving problems in which the base-rates and stereotypical description cued conflicting responses resulted in an increased centro-parietal N2 and frontal P3. This early conflict sensitivity suggests that the critical base-rates can be processed fast without slow and deliberate System 2 reflection. Findings validate prior EEG work and support recent hybrid dual process models in which the fast System 1 is processing both heuristic belief-based responses (e.g., stereotypes) and elementary logico-mathematical principles (e.g., base-rates).}
}
@article{FRADKIN2023S122,
title = {71. A Transdiagnostic Investigation of the Computational Mechanisms of Formal Thought Disorder},
journal = {Biological Psychiatry},
volume = {93},
number = {9, Supplement },
pages = {S122-S123},
year = {2023},
note = {Abstract Supplement},
issn = {0006-3223},
doi = {https://doi.org/10.1016/j.biopsych.2023.02.311},
url = {https://www.sciencedirect.com/science/article/pii/S0006322323003852},
author = {Isaac Fradkin and Rick Adams and Noam Siegelman and Rani Moran and Raymond Dolan}
}
@article{WU20112788,
title = {Myth of ecological architecture designs: Comparison between design concept and computational analysis results of natural-ventilation for Tjibaou Cultural Center in New Caledonia},
journal = {Energy and Buildings},
volume = {43},
number = {10},
pages = {2788-2797},
year = {2011},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2011.06.035},
url = {https://www.sciencedirect.com/science/article/pii/S0378778811002842},
author = {Yu-Chou Wu and An-Shik Yang and Li-Yu Tseng and Chin-Lung Liu},
keywords = {Ecological architecture, Wind-driven ventilation design, Tjibaou Cultural Center, Computational Fluid Dynamics},
abstract = {The Jean-Marie Tjibaou Cultural Center, designed by Renzo Piano, a world renown Italian architect and a recipient of the Pritzker Architecture Prize, was described as a piece of “Ecological Architecture” in New Caledonia. This building is recognized by its sustainable ventilation design concept that implements the unique ten shell-like structures for aeration enhancement. This paper presents an approach using the computational fluid dynamics (CFD)-based simulations to compare the numerical predictions with the original architectural insight for a verification of the architect's thinking in his realization of the design purpose. In the analysis, we consider the incompressible isothermal turbulent airflow to examine the interaction of the flow with the building for a better understanding of the wind-driven self-sustaining ventilation mechanism. We also propose a modified model via enlarging the aeration opening with the least blockages along the wind pathway. The simulated results indicate that the improved design substantially enhances the air-intake effectiveness and realizes a satisfactory pressure balance for the Tjibaou Cultural Center.}
}
@article{BROWNING2023104031,
title = {Language, common sense, and the Winograd schema challenge},
journal = {Artificial Intelligence},
volume = {325},
pages = {104031},
year = {2023},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2023.104031},
url = {https://www.sciencedirect.com/science/article/pii/S0004370223001777},
author = {Jacob Browning and Yann LeCun},
keywords = {Winograd schema challenge, Artificial intelligence, Common-sense, Disambiguation, Symbolic AI, Large language models},
abstract = {Since the 1950s, philosophers and AI researchers have held that disambiguating natural language sentences depended on common sense. In 2012, the Winograd Schema Challenge was established to evaluate the common-sense reasoning abilities of a machine by testing its ability to disambiguate sentences. The designers argued only a system capable of “thinking in the full-bodied sense” would be able to pass the test. However, by 2023, the original authors concede the test has been soundly defeated by large language models which still seem to lack common sense of full-bodied thinking. In this paper, we argue that disambiguating sentences only seemed like a good test of common-sense based on a certain picture of the relationship between linguistic comprehension and semantic knowledge—one typically associated with the early computational theory of mind and Symbolic AI. If this picture is rejected, as it is by most LLM researchers, then disambiguation ceases to look like a comprehensive test of common-sense and instead appear only to test linguistic competence. The upshot is that any linguistic test, not just disambiguation, is unlikely to tell us much about common sense or genuine intelligence.}
}
@article{BIANCIARDI201787,
title = {Biomimicry thinking: methodological improvements and practical implementation},
journal = {Bioinspired, Biomimetic and Nanobiomaterials},
volume = {6},
number = {2},
pages = {87-101},
year = {2017},
issn = {2045-9866},
doi = {https://doi.org/10.1680/jbibn.16.00007},
url = {https://www.sciencedirect.com/science/article/pii/S2045986617000111},
author = {Alessandro Bianciardi and Caterina Credi and Marinella Levi and Francesco Rosa and Alessandro Zecca},
keywords = {bioinspired, low-dimensional structures, oleophobic},
abstract = {The importance of oilwater separation processes is rapidly increasing in the modern industry. This family of processes, in fact, is of fundamental importance in solving problems in several industrial sectors, among which, for instance, are the management of oil spills, accidental industrial waste water dispersions, water treatment industry, engine fuel filtration and oil sand tailing technology. This paper, firstly, presents and discusses a biologically inspired design approach, based on biomimicry thinking (BT). Besides integrating linguistic tools and brainstorming within the BT approach, the importance of a stricter integration with the engineering context is also discussed. Secondly, the paper presents a practical application of this approach: design an innovative and sustainable oilwater separation device. In particular, the application of the proposed approach allowed identifying a bioinspired solution capable to improve the process performances in a device based on a known strategy. More in detail, the adopted bioinspired solution consists of a superoleophobic surface that mimics the microstructure of the filefish scale surface and eases the oilwater separation process by hindering oil drops deposition on some surfaces. The cost and resource effectiveness of the practical realisation of this surface greatly benefited by the latest advancements in the additive manufacturing field.}
}
@article{KOVALCHUK2024102379,
title = {Computation at the Cutting Edge of Science},
journal = {Journal of Computational Science},
volume = {81},
pages = {102379},
year = {2024},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2024.102379},
url = {https://www.sciencedirect.com/science/article/pii/S1877750324001728},
author = {Sergey V. Kovalchuk and Clélia {de Mulatier} and Valeria V. Krzhizhanovskaya and Jiří Mikyška and Maciej Paszyński and Jack Dongarra and Peter M.A. Sloot}
}
@article{AZIZ2013679,
title = {Applying lean thinking in construction and performance improvement},
journal = {Alexandria Engineering Journal},
volume = {52},
number = {4},
pages = {679-695},
year = {2013},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2013.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S111001681300046X},
author = {Remon Fayek Aziz and Sherif Mohamed Hafez},
keywords = {Lean production, Lean thinking, Lean construction, Construction industry, Performance and, Improvement theories},
abstract = {The productivity of the construction industry worldwide has been declining over the past 40years. One approach for improving the situation is using lean construction. Lean construction results from the application of a new form of production management to construction. Essential features of lean construction include a clear set of objectives for the delivery process, aimed at maximizing performance for the customer at the project level, concurrent design, construction, and the application of project control throughout the life cycle of the project from design to delivery. An increasing number of construction academics and professionals have been storming the ramparts of conventional construction management in an effort to deliver better value to owners while making real profits. As a result, lean-based tools have emerged and have been successfully applied to simple and complex construction projects. In general, lean construction projects are easier to manage, safer, completed sooner, and cost less and are of better quality. Significant research remains to complete the translation to construction of lean thinking in Egypt. This research will discuss principles, methods, and implementation phases of lean construction showing the waste in construction and how it could be minimized. The Last Planner System technique, which is an important application of the lean construction concepts and methodologies and is more prevalent, proved that it could enhance the construction management practices in various aspects. Also, it is intended to develop methodology for process evaluation and define areas for improvement based on lean approach principles.}
}
@incollection{PARASHAR2024275,
title = {Chapter ten - Computational techniques for sustainable green procurement and production},
editor = {Sanjoy Kumar Paul and Sandeep Kautish},
booktitle = {Computational Intelligence Techniques for Sustainable Supply Chain Management},
publisher = {Academic Press},
pages = {275-300},
year = {2024},
series = {Uncertainty, Computational Techniques, and Decision Intelligence},
isbn = {978-0-443-18464-2},
doi = {https://doi.org/10.1016/B978-0-443-18464-2.00004-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780443184642000042},
author = {Bhakti Parashar and Sandeep Kautish and Amrita Chaurasia},
keywords = {Computational techniques, computing, green procurement, procurement},
abstract = {Computational techniques are used to generate, solve, analyze, explain, or manage any simple or complex task. The use of environmentally responsible techniques to meet demand for resources, commodities, utilities, and services is known as green procurement. Computational technique in green procurement and production is one of the components of sustainable procurement, along with a commitment to social responsibility and good corporate behavior. Some solutions for this kind of issue are low-maintenance, energy-efficient, and long-lasting. Several experts and researchers provided their findings on the environmental impact of ICT with the use of computational techniques. Also, the importance of energy-efficient information technology for environmentally conscious and feasible information technology is a hot topic because a computer faces environmental challenges at every stage of its life, from development to use to disposal. Due to changing environmental conditions, corporations have prioritized carbon emissions in procurement and transportation, which have the highest carbon impact. To encourage potential suppliers to adopt environmentally friendly practices, green criteria should be introduced into public procurement. Environmentally friendly corporate practices and environmental conservation are considered significant tools through public procurement. Techniques for green procurement and production procedures have recently been correlated with the concept of computational techniques of green procurement and production, owing to the increased emphasis on the concept of computational approaches. For eco-friendly procurement and production operations, computational approaches are inculcated and presented in the same way that they are for green procurement and manufacturing. From this perspective, this chapter presents a methodology for merging computational techniques into green procurement and production in public procurement in the form of green computing.}
}
@article{ZHANG2015201,
title = {Thinking of data protection law's subject matter as a complex adaptive system: A heuristic display},
journal = {Computer Law & Security Review},
volume = {31},
number = {2},
pages = {201-220},
year = {2015},
issn = {0267-3649},
doi = {https://doi.org/10.1016/j.clsr.2015.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S0267364915000084},
author = {Kunbei Zhang and Aernout H.J. Schmidt},
keywords = {Data protection law, Complex adaptive system, Dynamics of innovation, Self-organization, Emergence},
abstract = {According to both whistle blowers and public reports, some commercial and governmental practices concerning personal data do not even appear to notice the law as a regulatory force. We are not satisfied by what mainstream legal scholarship has on offer in this context. Positivists consider the issue outside their domain. Realists (including their critical branch) focus on the behavior of legal institutions, ignoring many of the diverse institutions that have regulatory force. We need an additional, complementary perspective to help us, legal scholars, earn and hold serious positions in the diverse disciplinary teams that we need to participate in, in order to adequately investigate (and inform on) persistent problems concerning personal-data protection as faced by legislators. In this article we investigate whether the subject matter of data protection law, identified as Personal Data Community (hereinafter PDC), can be treated as a complex adaptive system (hereinafter CAS). This proposition is premised on the argument that the PDC exhibits key traits of CAS, including systemic, dynamic and complex characteristics. And we further show how complexity theory can help legal scholarship (without losing its identity) to join and add value to diverse disciplinary research and advisory teams. In this article, we aim for a stepping-stone (establishing that data protection law addresses a complex adaptive system with all of its corollaries), rather than for final solutions.}
}
@article{LU2023100154,
title = {Developing a weather prediction project-based machine learning course in facilitating AI learning among high school students},
journal = {Computers and Education: Artificial Intelligence},
volume = {5},
pages = {100154},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100154},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000334},
author = {Wen-Yen Lu and Szu-Chun Fan},
keywords = {Artificial intelligence, Machine learning, Computational thinking, Secondary education},
abstract = {The rapid growth of artificial intelligence (AI) technology has changed lifestyles, work patterns, and educational approaches. However, courses that can guide students through the practical applications of AI technology are still scarce in K-12 education. This study aimed to develop a project-based machine learning (ML) course for the implementation of AI technology. The core idea of this course, which focused on the supervised learning of AI ML technology, was designed based on the project of weather prediction. Furthermore, data collection and status display were realized using various hardware devices such as Arduino and sensors, whereas ML algorithms were implemented in Python programming language. A total of 68 eleventh-grade senior high school students from a public school in Southern Taiwan participated in this study. The main variables included understanding AI concepts, computational thinking (CT), and learning attitude. Data were analyzed using quantitative statistics, including descriptive statistics, t-test, and analysis of covariance, supplemented with qualitative data. Based on the findings, the following conclusions were drawn: (1) the proposed course on the implementation of ML helps students understand the basic concepts of AI; (2) students demonstrate a significant improvement in CT skills after attending this course; (3) although the students’ attitude toward learning AI shows no significant change after attending this course, their overall view for it is positive; (4) contrary to their learning attitude, the CT skills among the students with different capabilities of learning AI are significantly dissimilar. Overall, the machine-learning implementation course developed in this study can serve as a reference for promoting AI education in the future. However, considering learners’ prior knowledge in programming, setting up appropriate learning scaffolding for them, and providing them with more examples of the applications of AI in real-life scenarios is still necessary when conducting the course for improving the students’ attitude toward AI.}
}
@article{FLEMING2024896,
title = {Quality space computations for consciousness},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {10},
pages = {896-906},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S1364661324001657},
author = {Stephen M. Fleming and Nicholas Shea},
keywords = {consciousness, sensory states, quality space, similarity, neural representation},
abstract = {The quality space hypothesis about conscious experience proposes that conscious sensory states are experienced in relation to other possible sensory states. For instance, the colour red is experienced as being more like orange, and less like green or blue. Recent empirical findings suggest that subjective similarity space can be explained in terms of similarities in neural activation patterns. Here, we consider how localist, workspace, and higher-order theories of consciousness can accommodate claims about the qualitative character of experience and functionally support a quality space. We review existing empirical evidence for each of these positions, and highlight novel experimental tools, such as altering local activation spaces via brain stimulation or behavioural training, that can distinguish these accounts.}
}
@article{KAVGA2023102837,
title = {Design and simulation of a greenhouse in a computational environment (ANSYS/FLUENT) and an automatic control system in a LABVIEW environment},
journal = {Simulation Modelling Practice and Theory},
volume = {129},
pages = {102837},
year = {2023},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2023.102837},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X23001144},
author = {Angeliki Kavga and Vasileios Thomopoulos and Evangelos Pischinas and Dimitris Tsipianitis and Pantelis Nikolakopoulos},
keywords = {Greenhouses, Digital twin, Control, Arduino, Fuzzy logic},
abstract = {Greenhouses have been used to increase agricultural production. With the development of technology, they can now be automated. Many studies have been done on the automatic control of their microclimate, from intelligent control systems to Computational Fluid Dynamics (CFD) analyses, with the main purpose of optimal control of the microclimate and at the same time saving energy. This research concerns the process of modeling, design, and simulation of an automatic control system in greenhouses. More specifically, a virtual greenhouse (digital twin) is designed, and in it, the natural phenomena that take place in a real greenhouse are simulated. The program used for the simulations is Ansys FLUENT, suitable for CFD analyses. A branch of artificial intelligence, fuzzy logic, which is a method of replicating human thinking was utilized. To find the optimal control system, four fuzzy controllers were tested, and the optimal control system that the simulations indicated was implemented on an Arduino board using the LabVIEW program. The control was done at the temperature inside the greenhouse, with real weather data from a real greenhouse.}
}
@article{BICER2024101652,
title = {Exploring creativity in mathematics assessment: An analysis of standardized tests},
journal = {Thinking Skills and Creativity},
volume = {54},
pages = {101652},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101652},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124001901},
author = {Ali Bicer and Tugce Aldemir and Geoff Krall and Fay Quiroz and Scott Chamberlin and Jana L. Nelson and Yujin Lee and Hyunkyung Kwon},
keywords = {Mathematical creativity, Assessment for creativity, Creativity-directed tasks},
abstract = {This paper aims to investigate whether US standardized tests provide opportunities for students to demonstrate their creative thinking abilities through the inclusion of creativity-directed problems in their mathematics assessments. Our results indicated that two commonly used standardized national tests (i.e., PARCC and SBAC) do offer students some opportunities to exhibit their creative thinking skills by incorporating creativity-directed problems (e.g., multiple solution tasks) in their assessments. However, not all creativity-directed tasks are present at every grade level. The findings of this paper are significant not only because they reveal the potential of these tests to include creativity-directed tasks but also because they underscore the importance of assessment materials in fostering students’ creative thinking skills in mathematics, as assessments significantly influence teachers’ instructional practices and curriculum materials.}
}
@article{DENEYS20081248,
title = {Conflict monitoring in dual process theories of thinking},
journal = {Cognition},
volume = {106},
number = {3},
pages = {1248-1299},
year = {2008},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2007.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0010027707001576},
author = {Wim {De Neys} and Tamara Glumicic},
keywords = {Reasoning, Decision making, Heuristics and biases, Conflict monitoring, Dual process theories},
abstract = {Popular dual process theories have characterized human thinking as an interplay between an intuitive-heuristic and demanding-analytic reasoning process. Although monitoring the output of the two systems for conflict is crucial to avoid decision making errors there are some widely different views on the efficiency of the process. Kahneman [Kahneman, D. (2002). Maps of bounded rationality: A perspective on intuitive judgement and choice. Nobel Prize Lecture. Retrieved January 11, 2006, from: http://nobelprize.org/nobel_prizes/economics/laureates/2002/kahnemann-lecture.pdf] and Evans [Evans, J. St. B. T. (1984). Heuristic and analytic processing in reasoning. British Journal of Psychology, 75, 451–468], for example, claim that the monitoring of the heuristic system is typically quite lax whereas others such as Sloman [Sloman, S. A. (1996). The empirical case for two systems of reasoning. Psychological Bulletin, 119, 3–22] and Epstein [Epstein, S. (1994). Integration of the cognitive and psychodynamic unconscious. American Psychologists, 49, 709–724] claim it is flawless and people typically experience a struggle between what they “know” and “feel” in case of a conflict. The present study contrasted these views. Participants solved classic base rate neglect problems while thinking aloud. In these problems a stereotypical description cues a response that conflicts with the response based on the analytic base rate information. Verbal protocols showed no direct evidence for an explicitly experienced conflict. As Kahneman and Evans predicted, participants hardly ever mentioned the base rates and seemed to base their judgment exclusively on heuristic reasoning. However, more implicit measures of conflict detection such as participants’ retrieval of the base rate information in an unannounced recall test, decision making latencies, and the tendency to review the base rates indicated that the base rates had been thoroughly processed. On control problems where base rates and description did not conflict this was not the case. Results suggest that whereas the popular characterization of conflict detection as an actively experienced struggle can be questioned there is nevertheless evidence for Sloman’s and Epstein’s basic claim about the flawless operation of the monitoring. Whenever the base rates and description disagree people will detect this conflict and consequently redirect attention towards a deeper processing of the base rates. Implications for the dual process framework and the rationality debate are discussed.}
}
@article{HELVACIOZACAR2023100560,
title = {Centering and decentering children in computing through joint activity at a computational science exhibit},
journal = {International Journal of Child-Computer Interaction},
volume = {35},
pages = {100560},
year = {2023},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2022.100560},
url = {https://www.sciencedirect.com/science/article/pii/S2212868922000782},
author = {Basak {Helvaci Ozacar} and Stephanie Hladik},
keywords = {Public computing, Joint activity, Science museums, Facilitation, Computer science education, Adult–child interactions},
abstract = {In this paper, we offer an investigation of the nuances of adult–child interactions at a computational science exhibit in a Canadian science museum. The theoretical lens of joint activity allows us to understand learning to code as a collaborative, intergenerational activity distributed between learners, educators, exhibit hardware, and the computer code itself. Specifically, we attend to the ways in which children can be centered at the computational science exhibit (moments in which their goals, histories, and desires are driving the exhibit’s interaction) by the actions of parents and museum facilitators or be decentered by them. Through qualitative analysis of video-recorded interactions of adults and children at the exhibit, we present categories of centering or decentering interactions while preserving the nuance and ambiguity involved in sociocultural contexts of learning. We also highlight two cases that illustrate the complexity and heterogeneity involved in facilitating a computational science exhibit. We close with a discussion and a call to eschew technocentric views of computing education that focus solely on device-level engagement and instead attend to the complex human–human interactions involved in computing education.}
}
@article{TURNER2018782,
title = {Enterprise Thinking for Self-aware Systems},
journal = {IFAC-PapersOnLine},
volume = {51},
number = {11},
pages = {782-789},
year = {2018},
note = {16th IFAC Symposium on Information Control Problems in Manufacturing INCOM 2018},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2018.08.414},
url = {https://www.sciencedirect.com/science/article/pii/S2405896318315404},
author = {Pat Turner and Peter Bernus and Ovidiu Noran},
keywords = {Internet of Things, Systems of Systems, Self-aware systems, Service Oriented Enterprise Architectures, Enterprise System Engineering, Self-organization},
abstract = {The paper aims to provide high-level guidance for architects of cyber-physical enterprises. We propose that interactions within such systems should be largely self-determined, based on system self-awareness and dynamic re-configuration, with the architecture evolving based on a set of foundational principles, rather than being pre-defined by an external designer. We investigate the suitability of typical development life cycles and identify architectural challenges in the context of dynamic cyber-physical systems that utilize the power of the Internet of Things. Desired systemic attributes are defined, which are necessary for making suitable core architectural choices. The application of the findings is exemplified through a case study, a synthesis of issues, and implications for further research.}
}
@incollection{PREISIG20121682,
title = {Thinking Ontologies},
editor = {Iftekhar A. Karimi and Rajagopalan Srinivasan},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {31},
pages = {1682-1686},
year = {2012},
booktitle = {11th International Symposium on Process Systems Engineering},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-444-59506-5.50167-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044459506550167X},
author = {Heinz A. Preisig},
keywords = {computer-aided modelling, software tools, process engineering},
abstract = {Ontologies are a means of abstraction and concentrating information. Whilst it has mostly found acceptance in the computer and information technology domain, it is an excellent thinking pattern promoting a more structural approach to chemical engineering problems on all levels, starting with the representation of functionalities, their combination to form processing units and combined again as whole plants. The concepts helps in constructing models that adhere to basic concepts as they are the foundation for physical processes: the conservation principles and the description of transport phenomena. The material models, the interaction between different chemical species or biological species form a knowledge framework suitable in in case of biological processes also intensively mapped into ontologies. When properly used, The high density of information, makes it easy to check consistency and the consistent use in all applications yields a framework that produces reliable, checkable results quickly and efficiently and consistency across applications that in the past have been without any information link.}
}
@article{WEST20121551,
title = {The importance of quantitative systemic thinking in medicine},
journal = {The Lancet},
volume = {379},
number = {9825},
pages = {1551-1559},
year = {2012},
issn = {0140-6736},
doi = {https://doi.org/10.1016/S0140-6736(12)60281-5},
url = {https://www.sciencedirect.com/science/article/pii/S0140673612602815},
author = {Geoffrey B West},
abstract = {Summary
The study and practice of medicine could benefit from an enhanced engagement with the new perspectives provided by the emerging areas of complexity science and systems biology. A more integrated, systemic approach is needed to fully understand the processes of health, disease, and dysfunction, and the many challenges in medical research and education. Integral to this approach is the search for a quantitative, predictive, multilevel, theoretical conceptual framework that both complements the present approaches and stimulates a more integrated research agenda that will lead to novel questions and experimental programmes. As examples, the importance of network structures and scaling laws are discussed for the development of a broad, quantitative, mathematical understanding of issues that are important in health, including ageing and mortality, sleep, growth, circulatory systems, and drug doses. A common theme is the importance of understanding the quantifiable determinants of the baseline scale of life, and developing corresponding parameters that define the average, idealised, healthy individual.}
}
@article{DELUCA2021101553,
title = {The development of machine intelligence in a computational universe},
journal = {Technology in Society},
volume = {65},
pages = {101553},
year = {2021},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2021.101553},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X21000282},
author = {Gabriele {De Luca}},
keywords = {Machine intelligence, Computational universe, Bohmian mechanics, History of AI, Mechanical rationalism},
abstract = {The paper is dedicated to the study of the theoretical and technological development that occurred, in particular in the XX century, in the sector of Artificial Intelligence. According to the theoretical framework of mechanical rationalism, we study how the development of machine intelligence is a continuation, through different means, of the old process of outsourcing of cognitive activities by humans onto parts of their physical environments. Because of this process, an increasingly larger portion of the non-human environment performs perceptive and cognitive activities. From this follows that machine systems, not necessarily humans anymore, are the components of the physical environment that perform measurements on the universe of which the humans are also components. We suggest that the scientific discussion on the topic of AI development could be framed in the context of a more general phenomenon of an increase in the computational and perceptual capabilities of the physical universe, as opposed to a merely human and technological problem. This is because, ever so slightly, humans are being removed from the cognitive processes of technological systems they created, which continue to perceive and think autonomously. The act of machine cognition, or rather, of machine measurements, causes an effect on the environment in which humans live, and ever more so than the human measurements. Finally, we discuss the current approach to the development of viable AI systems that aim at increasing the reciprocal intelligence of humans and machines, rather than the replacement of the former's cognitive faculties by the latter.}
}
@article{KERN2000341,
title = {Structuring financial statement analysis projects to enhance critical thinking skills development},
journal = {Journal of Accounting Education},
volume = {18},
number = {4},
pages = {341-353},
year = {2000},
issn = {0748-5751},
doi = {https://doi.org/10.1016/S0748-5751(01)00005-7},
url = {https://www.sciencedirect.com/science/article/pii/S0748575101000057},
author = {Beth B. Kern},
keywords = {Financial statement analysis, Critical thinking},
abstract = {This paper documents a method of structuring financial statement analysis projects to enhance the development of students’ critical thinking skills. The project is structured in a cooperative learning framework in which a student accesses financial statement information from the World Wide Web, performs a financial statement analysis, and then engages in an exercise with other students who have analyzed firms in the same industry. Both the individual and team phases of the project offer opportunities for students to develop several important critical thinking skills.}
}
@incollection{HARTSON2012251,
title = {Chapter 7 - Design Thinking, Ideation, and Sketching},
editor = {Rex Hartson and Partha S. Pyla},
booktitle = {The UX Book},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {251-297},
year = {2012},
isbn = {978-0-12-385241-0},
doi = {https://doi.org/10.1016/B978-0-12-385241-0.00007-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780123852410000075},
author = {Rex Hartson and Partha S. Pyla}
}
@article{SELICATI2021124932,
title = {The interoperability of exergy and Life Cycle Thinking in assessing manufacturing sustainability: A review of hybrid approaches},
journal = {Journal of Cleaner Production},
volume = {286},
pages = {124932},
year = {2021},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2020.124932},
url = {https://www.sciencedirect.com/science/article/pii/S0959652620349763},
author = {Valeria Selicati and Nicola Cardinale and Michele Dassisti},
keywords = {Exergy, Hybrid methods, Integration modelling, Life cycle assessment, Process reversibility, Sustainable manufacturing},
abstract = {Today, the Life Cycle Assessment (LCA) is the most employed tool for assessing the sustainability of products and processes, both from an environmental, social and economic point of view. Exergy is defined by literature as the amount of useful work that can be derived from a real system when it is brought into equilibrium with its environment. In the literature, it is considered an outstanding concept that can be applied to enhance the effectiveness of ordinary evaluation models such as LCA. The literature proposes a variety of hybrid approaches that combine Exergetic Analysis (EA) and LCA with different combination frameworks. The aim of this paper is to describe the potential of each hybrid method and to characterize the degree of interoperability between EA and LCA that each of them can provide. Nevertheless, there are drawbacks that seem to be too challenging to overcome: a variety of inconsistencies in the interpretation of the results due to the difficulty of the inventory phase and the ambiguity in the choice of the correct alternative in the standard databases; the link with old techniques that refers to obsolete approaches in finding data that suit to the updated goals and scopes; the difficulty in conducting an assessment affected by the least possible uncertainty. Following a theoretical overview of the principles of each hybrid method that binds EA and LCA, the authors want to provide a review from a completely different point of view than the state-of-the-art literature, on how effectively EA and LCA can interact with each other in order to provide a more holistic view of the system/process to be assessed. The fascinating circumstance that emerges from the review is that any exergy approach would be more effective if joined (not replaced) to the standard LCA, because it turned out to be complementary. This theory has long been developed by many authors in their case studies as a confirmation of what Gutowski wrote years ago: no single alternative criteria or subsidiary model, independently of how well aggregated, may offer a suitable answer for all conditions. Specifically, through this review, the practitioners would be able to choose the best suited hybrid methodology, according to their aims, join the outcomes together and achieve a transdisciplinary knowledge of the behavior of the study case system, in order to design the best improvement strategies.}
}
@article{PROULX2005345,
title = {Network thinking in ecology and evolution},
journal = {Trends in Ecology & Evolution},
volume = {20},
number = {6},
pages = {345-353},
year = {2005},
note = {SPECIAL ISSUE: BUMPER BOOK REVIEW},
issn = {0169-5347},
doi = {https://doi.org/10.1016/j.tree.2005.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S0169534705000881},
author = {Stephen R. Proulx and Daniel E.L. Promislow and Patrick C. Phillips},
abstract = {Although pairwise interactions have always had a key role in ecology and evolutionary biology, the recent increase in the amount and availability of biological data has placed a new focus on the complex networks embedded in biological systems. The increased availability of computational tools to store and retrieve biological data has facilitated wide access to these data, not just by biologists but also by specialists from the social sciences, computer science, physics and mathematics. This fusion of interests has led to a burst of research on the properties and consequences of network structure in biological systems. Although traditional measures of network structure and function have started us off on the right foot, an important next step is to create biologically realistic models of network formation, evolution, and function. Here, we review recent applications of network thinking to the evolution of networks at the gene and protein level and to the dynamics and stability of communities. These studies have provided new insights into the organization and function of biological systems by applying existing techniques of network analysis. The current challenge is to recognize the commonalities in evolutionary and ecological applications of network thinking to create a predictive science of biological networks.}
}
@article{SUMMERER2014242,
title = {Thinking tomorrows' space – Research trends of the ESA advanced concepts team 2002–2012},
journal = {Acta Astronautica},
volume = {95},
pages = {242-259},
year = {2014},
issn = {0094-5765},
doi = {https://doi.org/10.1016/j.actaastro.2013.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S0094576513003949},
author = {L. Summerer},
keywords = {Future, Technology trends, Advanced research topics, Disruptive innovation},
abstract = {This paper presents technological and conceptual visions beyond the traditional planning horizon of space agencies. It relies on the research and reflections within the larger advanced concepts research community created by and around the European Space Agency's Advanced Concepts Team as well as the results of a two-day long symposium in July 2012, including Europe's first space ‘un-conference’, focussed on re-thinking the future of space beyond the traditional thought boundaries of the space sector. For this purpose it reviews visions and expectations formulated at the creation of the ACT, results obtained and fundamental changes that are expected to shape space activities and the space sector in a 10–15+ years time frame, while relaying these to specific ongoing research activities.}
}
@article{SHOVLIN20253,
title = {When “loss-of-function” means proteostasis burden: Thinking again about coding DNA variants},
journal = {The American Journal of Human Genetics},
volume = {112},
number = {1},
pages = {3-10},
year = {2025},
issn = {0002-9297},
doi = {https://doi.org/10.1016/j.ajhg.2024.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0002929724004440},
author = {Claire L. Shovlin and Micheala A. Aldred},
abstract = {Each human genome has approximately 5 million DNA variants. Even for complete loss-of-function variants causing inherited, monogenic diseases, current understanding based on gene-specific molecular function does not adequately predict variability observed between people with identical mutations or fluctuating disease trajectories. We present a parallel paradigm for loss-of-function variants based on broader consequences to the cell when aberrant polypeptide chains of amino acids are translated from mutant RNA to generate mutated proteins. Missense variants that modify primary amino acid sequence, and nonsense/frameshift variants that generate premature termination codons (PTCs), are placed in context alongside emergent themes of chaperone binding, protein quality control capacity, and cellular adaptation to stress. Relatively stable proteostasis burdens are contrasted with rapid changes after induction of gene expression, or stress responses that suppress nonsense mediated decay (NMD) leading to higher PTC transcript levels where mutant proteins can augment cellular stress. For known disease-causal mutations, an adjunctive variant categorization system enhances clinical predictive power and precision therapeutic opportunities. Additionally, with typically more than 100 nonsense and frameshift variants, and ∼10,000 missense variants per human DNA, the paradigm focuses attention on all protein-coding DNA variants, and their potential contributions to multimorbid states beyond classically designated inherited diseases. Experimental testing in clinically relevant systems is encouraged to augment current atlases of protein expression at single-cell resolution, and high-throughput experimental data and deep-learning models that predict which amino acid substitutions generate enhanced degradative burdens. Incorporating additional dimensions such as pan-proteome competition for chaperones, and age-related loss of proteostasis capacity, should further accelerate health impacts.}
}
@article{CHAMPAGNE201912,
title = {Diagrams and alien ways of thinking},
journal = {Studies in History and Philosophy of Science Part A},
volume = {75},
pages = {12-22},
year = {2019},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2018.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S0039368118300281},
author = {Marc Champagne},
keywords = {Inference, Astrobiology, Messaging, Diagrams, Diagrammatic reasoning, C. S. Peirce},
abstract = {The recent wave of data on exoplanets lends support to METI ventures (Messaging to Extra-Terrestrial Intelligence), insofar as the more exoplanets we find, the more likely it is that “exominds” await our messages. Yet, despite these astronomical advances, there are presently no well-confirmed tests against which to check the design of interstellar messages. In the meantime, the best we can do is distance ourselves from terracentric assumptions. There is no reason, for example, to assume that all inferential abilities are language-like. With that in mind, I argue that logical reasoning does not have to be couched in symbolic notation. In diagrammatic reasoning, inferences are underwritten, not by rules, but by transformations of self-same qualitative signs. I use the Existential Graphs of C. S. Peirce to show this. Since diagrams are less dependent on convention and might even be generalized to cover non-visual senses, I argue that METI researchers should add some form of diagrammatic representations to their repertoire. Doing so can shed light, not just on alien minds, but on the deepest structures of reasoning itself.}
}
@article{AYDOGAN2018100,
title = {The effect of oxytocin on group formation and strategic thinking in men},
journal = {Hormones and Behavior},
volume = {100},
pages = {100-106},
year = {2018},
issn = {0018-506X},
doi = {https://doi.org/10.1016/j.yhbeh.2018.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0018506X17302908},
author = {Gökhan Aydogan and Andrea Jobst and Fabian Loy and Sandra Dehning and Peter Zill and Norbert Müller and Martin Kocher},
abstract = {Decision-making in groups is a remarkable and decisive element of human societies. Humans are able to organize themselves in groups, engage in collaborative decision-making processes and arrive at a binding agreement, even in the absence of unanimous consent. However, the transfer of decision-making autonomy requires a willingness to deliberately expose oneself to the decisions of others. A lack of trust in the abilities of others or of the underlying decision-making process, i.e. public trust, can lead to a breakdown of organizations in political or economic domains. Recent studies indicate that the biological basis of trust on an individual level is related to Oxytocin, an endogenous neuropeptide and hormone, which is also associated with pro-social behavior and positive conflict resolution. However, little is known about the effects of Oxytocin on the inclination of individuals to form or join groups and to deliberately engage in collaborative decision-making processes. Here, we show that intranasal administration of Oxytocin (n = 60) compared to placebo (n = 60) in males causes an adverse effect on the choice for forming groups in the presence of a competitive environment. In particular, Oxytocin negatively affects the willingness to work collaboratively in a p-Beauty contest game, whereas the effect is most pronounced for participants with relatively high strategic sophistication. Since our data provide initial evidence that Oxytocin has a positive effect on strategic thinking and performance in the p-Beauty contest game, we argue that the adverse effect on group formation might be rooted in an enhanced strategic sophistication of participants treated with Oxytocin.}
}
@incollection{ESTES2011249,
title = {Chapter eight - Thematic Thinking: The Apprehension and Consequences of Thematic Relations},
editor = {Brian H. Ross},
series = {Psychology of Learning and Motivation},
publisher = {Academic Press},
volume = {54},
pages = {249-294},
year = {2011},
booktitle = {Advances in Research and Theory},
issn = {0079-7421},
doi = {https://doi.org/10.1016/B978-0-12-385527-5.00008-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780123855275000085},
author = {Zachary Estes and Sabrina Golonka and Lara L. Jones},
keywords = {Categorization, Language, Similarity, Taxonomic relations, Thematic integration, Thematic relations},
abstract = {A thematic relation is a temporal, spatial, causal, or functional relation between things that perform complementary roles in the same scenario or event. For example, cows and milk are related by a production theme, and sails and anchors are related via a boating theme. Thematic relations are distinct from mere associations, scripts, and ad hoc categories. They also contrast and complement taxonomic (categorical) relations such as “fruits” and “furniture.” Thematic relations and taxonomic relations arise from distinct processes, as evidenced by numerous neuropsychological and behavioral dissociations. Thematic relations may be apprehended uncontrollably and rapidly according to how frequently and recently they have been encountered. They exert profound effects on many core cognitive processes, including similarity, categorization, memory, language, inference, and analogy, and they exhibit robust processing differences across individuals and cultures. In sum, without such thematic thinking, models of cognition will remain categorically limited.}
}
@article{SLEZAK2002353,
title = {Thinking about thinking: language, thought and introspection},
journal = {Language & Communication},
volume = {22},
number = {3},
pages = {353-373},
year = {2002},
issn = {0271-5309},
doi = {https://doi.org/10.1016/S0271-5309(02)00012-5},
url = {https://www.sciencedirect.com/science/article/pii/S0271530902000125},
author = {Peter Slezak},
keywords = {Language, Thought, Mentalese, Introspection, Imagery, Homunculus},
abstract = {I do not think that the world or the sciences would ever have suggested to me any philosophical problems. What has suggested philosophical problems to me is things which other philosophers have said about the world or the sciences.(G.E. Moore, 1942, p. 14) Peter Carruthers has made a vigorous attempt to defend the admittedly unfashionable doctrine that we think ‘in' language, despite its displacement by something like Fodor's ‘language of thought'. The idea that we think in language has considerable intuitive persuasiveness, but I suggest that this is not the force of good argument and evidence, but a familiar kind of introspective illusion. In this regard, the question of language and thought derives a more general interest, since the illusion is independently familiar from other notorious disputes in cognitive science such as the ‘imagery debate’.}
}
@article{CHOPARD2024102115,
title = {Preface—From the modeling of social behavior to computational diplomacy},
journal = {Journal of Computational Science},
volume = {77},
pages = {102115},
year = {2024},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2023.102115},
url = {https://www.sciencedirect.com/science/article/pii/S1877750323001758},
author = {Bastien Chopard and Stephan Davishofer and Dirk Helbing and Nicolas Levrat and Peter Sloot}
}
@article{MARUPAKA2012147,
title = {Connectivity and thought: The influence of semantic network structure in a neurodynamical model of thinking},
journal = {Neural Networks},
volume = {32},
pages = {147-158},
year = {2012},
note = {Selected Papers from IJCNN 2011},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2012.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608012000330},
author = {Nagendra Marupaka and Laxmi R. Iyer and Ali A. Minai},
keywords = {Semantic networks, Semantic cognition, Creativity, Cognitive dynamics, Itinerant dynamics, Attractor networks},
abstract = {Understanding cognition has been a central focus for psychologists, neuroscientists and philosophers for thousands of years, but many of its most fundamental processes remain very poorly understood. Chief among these is the process of thought itself: the spontaneous emergence of specific ideas within the stream of consciousness. It is widely accepted that ideas, both familiar and novel, arise from the combination of existing concepts. From this perspective, thought is an emergent attribute of memory, arising from the intrinsic dynamics of the neural substrate in which information is embedded. An important issue in any understanding of this process is the relationship between the emergence of conceptual combinations and the dynamics of the underlying neural networks. Virtually all theories of ideation hypothesize that ideas arise during the thought process through association, each one triggering the next through some type of linkage, e.g., structural analogy, semantic similarity, polysemy, etc. In particular, it has been suggested that the creativity of ideation in individuals reflects the qualitative structure of conceptual associations in their minds. Interestingly, psycholinguistic studies have shown that semantic networks across many languages have a particular type of structure with small-world, scale free connectivity. So far, however, these related insights have not been brought together, in part because there has been no explicitly neural model for the dynamics of spontaneous thought. Recently, we have developed such a model. Though simplistic and abstract, this model attempts to capture the most basic aspects of the process hypothesized by theoretical models within a neurodynamical framework. It represents semantic memory as a recurrent semantic neural network with itinerant dynamics. Conceptual combinations arise through this dynamics as co-active groups of neural units, and either dissolve quickly or persist for a time as emergent metastable attractors and are recognized consciously as ideas. The work presented in this paper describes this model in detail, and uses it to systematically study the relationship between the structure of conceptual associations in the neural substrate and the ideas arising from this system’s dynamics. In particular, we consider how the small-world and scale-free characteristics influence the effectiveness of the thought process under several metrics, and show that networks with both attributes indeed provide significant advantages in generating unique conceptual combinations.}
}
@article{KHALIL2022104656,
title = {A neurocomputational model of creative processes},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {137},
pages = {104656},
year = {2022},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2022.104656},
url = {https://www.sciencedirect.com/science/article/pii/S0149763422001452},
author = {Radwa Khalil and Ahmed A. Moustafa},
keywords = {Divergent Thinking, Convergent Thinking, Abstraction, Improvisation, Novelty, Computational Model, Prefrontal Cortex, Hippocampus, Basal Ganglia, Cerebellum, Dopamine, Usefulness, Surprise},
abstract = {Creativity is associated with finding novel, surprising, and useful solutions. We argue that creative cognitive processes, divergent thinking, abstraction, and improvisation are constructed on different novelty-based processes. The prefrontal cortex plays a role in creative ideation by providing a control mechanism. Moreover, thinking about novel solutions activates the distant or loosely connected neurons of a semantic network that involves the hippocampus. Novelty can also be interpreted as different combinations of earlier learned processes, such as the motor sequencing mechanism of the basal ganglia. In addition, the cerebellum is responsible for the precise control of movements, which is particularly important in improvisation. Our neurocomputational perspective is based on three creative processes centered on novelty seeking, subserved by the prefrontal cortex, hippocampus, cerebellum, basal ganglia, and dopamine. The algorithmic implementation of our model would enable us to describe commonalities and differences between these creative processes based on the proposed neural circuitry. Given that most previous studies have mainly provided theoretical and conceptual models of creativity, this article presents the first brain-inspired neural network model of creative cognition.}
}
@article{ELLIOTT2024307a,
title = {Utilizing a structured undergraduate research framework to improve student success and mentoring capacity in a computational biophysics lab},
journal = {Biophysical Journal},
volume = {123},
number = {3, Supplement 1},
pages = {307a},
year = {2024},
issn = {0006-3495},
doi = {https://doi.org/10.1016/j.bpj.2023.11.1898},
url = {https://www.sciencedirect.com/science/article/pii/S0006349523025985},
author = {Truitt J. Elliott and Jonathan Briganti and Anne M. Brown}
}
@article{WOLFENGAGEN2024101183,
title = {Building a cognitive system based on process interaction},
journal = {Cognitive Systems Research},
volume = {83},
pages = {101183},
year = {2024},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2023.101183},
url = {https://www.sciencedirect.com/science/article/pii/S1389041723001171},
author = {Viacheslav E. Wolfengagen and Larisa Ismailova and Sergey Kosikov},
keywords = {Computational thinking, Applicative prestructure, Theory of combinators, Cognitive modeling, Computation process, Interaction, Semantic modeling},
abstract = {According to modern notions, computing is not separable from cognitive modeling and activity. This paper continues the tradition of the uniform approach and proposes a small number of general mechanisms that cope with the main known effects of computing as a science — the interaction of objects-as-processes, the interaction of processes with the environment, generalized interaction. As shown, the applicative prestructure (objects-as-processes, application) generates an applicative structure (processes, application, values), which ensures the generation of the result — the value of interactions, enabling the process of evaluation. The theory of combinators is used as the main (meta)mathematical means. A diagram mechanism has been developed that implements the emerging applicative computational system of object interaction and reflects the arity of accompanying the induced information processes. The processes are bidirectional in nature, both with a decrease in arity – reduction, and with an increase in arity – expansion.}
}
@article{BAYAGA2024100491,
title = {Enhancing M Enhancing mathematics problem-solving skills in AI-driven environment: Integrated SEM-neural network approach},
journal = {Computers in Human Behavior Reports},
volume = {16},
pages = {100491},
year = {2024},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2024.100491},
url = {https://www.sciencedirect.com/science/article/pii/S2451958824001246},
author = {Anass Bayaga},
keywords = {Gamification, AI, Digitisation, Education, Higher-order thinking, Game-based learning},
abstract = {This study explores the nexus of gamification, artificial intelligence (AI), and mathematics cognition. Sample size of 71 responded in an intervention using game-based learning (GBL) approach. The purpose of designing the GBL was to enhance computational thinking and mathematical skills. The research employed multigroup partial least squares structural equation modelling (MGA-PLS-SEM) and artificial neural networks (ANN) through multilayer perceptron (MLP) as data analysis technique. The findings showed significant positive influence on class engagement, attitudes toward mathematics, as well as student performance. The analysis also revealed gender-related variations, which affirmed the model's consistency across diverse groups. The study validated the hypothesis and consequently advocated for the transformative potential of gamification, in preparation of 21st-century learners for AI-driven digital landscape. The implications are to ensure the integration of gamified elements into educational strategies, benefiting educators, curriculum developers, and policymakers resonating strongly for educators, curriculum developers, and policymakers.}
}
@article{HENRIQUE2023100546,
title = {Who creates our computational worlds? A review of Critically Conscious Computing: Methods for secondary education},
journal = {International Journal of Child-Computer Interaction},
volume = {35},
pages = {100546},
year = {2023},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2022.100546},
url = {https://www.sciencedirect.com/science/article/pii/S2212868922000642},
author = {Brendan Henrique and Collette Roberto and Michelle Hoda Wilkerson},
keywords = {Computational thinking, Computational literacy, Computer science education, Critical computing, Critical computational literacy, Critical computer science education},
abstract = {Despite growing attention to the social and ethical dimensions of Computer Science (CS), few practical resources exist to teach and learn CS through the lens of social responsibility. In Critically Conscious Computing, Ko and colleagues provide a comprehensive overview of foundational computing concepts with a sharp and needed critical perspective. In this review, we attend not only to the content of the book, but also to its format as a free, online, “living” text. The book is commendable for its tight integration of technical and socio-critical aspects of computing, approachable conversational style, and collection of flexible and practical resources for teachers. It would benefit from refinement of the integration chapters and a more explicit model for how educators themselves can approach new or different CS concepts through a critical frame. Overall, we strongly recommend this book for CS Educators at all levels for its balance of depth and practicality.}
}
@article{HEMERY2024114432,
title = {On a model of online analog computation in the cell with absolute functional robustness: Algebraic characterization, function compiler and error control},
journal = {Theoretical Computer Science},
volume = {991},
pages = {114432},
year = {2024},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2024.114432},
url = {https://www.sciencedirect.com/science/article/pii/S0304397524000471},
author = {Mathieu Hemery and François Fages},
keywords = {Analog computation, Online computation, Robustness, Stabilization, Algebraic functions, Chemical reaction networks, Chemical computation},
abstract = {The Turing completeness of continuous Chemical Reaction Networks (CRNs) states that any computable real function can be computed by a continuous CRN on a finite set of molecular species, possibly restricted to elementary reactions, i.e. with at most two reactants and mass action law kinetics. In this paper, we introduce a more stringent notion of robust online analog computation, called Absolute Functional Robustness (AFR), for the CRNs that stabilize the concentration values of some output species to the result of one function of the input species concentrations, while allowing arbitrary perturbations for intermediate and output species throughout the attraction basin. We prove that the set of real functions stabilized by a CRN with mass action law kinetics is precisely the set of real algebraic functions. Based on this result, we present a compiler which takes as input any algebraic function (defined by one polynomial and one point for selecting one branch of the algebraic curve defined by the polynomial) and generates an abstract CRN to stabilize it. Furthermore, we provide error bounds to estimate and control the error of an unperturbed system, under the assumption that the environment inputs are driven by k-Lipschitz functions.}
}
@article{NA202250,
title = {Computational mechanisms underlying illusion of control in delusional individuals},
journal = {Schizophrenia Research},
volume = {245},
pages = {50-58},
year = {2022},
note = {Computational Approaches to Understanding Psychosis},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2022.01.054},
url = {https://www.sciencedirect.com/science/article/pii/S0920996422000652},
author = {Soojung Na and Sylvia Blackmore and Dongil Chung and Madeline O'Brien and Sarah M. Banker and Matthew Heflin and Vincenzo G. Fiore and Xiaosi Gu},
keywords = {Delusion, Social controllability, Illusion of control, Beliefs, Schizophrenia, Computational psychiatry},
abstract = {Humans navigate complex situations that require the accurate estimation of the controllability of the environment. Aberrant controllability computation might lead to maladaptive behaviors and poor mental health outcomes. Illusion of control, which refers to a heightened sense of control while the environment is uncontrollable, is one such manifestation and has been conceptually associated with delusional ideation. Nevertheless, this association has not yet been formally characterized in a computational framework. To address this, we used a computational psychiatry approach to quantify illusion of control in human participants with high (n = 125) or low (n = 126) trait delusion. Participants played a two-party exchange game in which their choices either did (“Controllable condition”) or did not (“Uncontrollable condition”) influence the future monetary offers made by simulated partners. We found that the two groups behaved similarly in model-agnostic measures (i.e., offer size, rejection rate). However, computational modeling revealed that compared to the low trait delusion group, the high delusion group overestimated their influence (“expected influence” parameter) over the offers made by their partners under the Uncontrollable condition. Highly delusional individuals also reported a stronger sense of control than those with low trait delusion in the Uncontrollable condition. Furthermore, the expected influence parameter and self-reported beliefs about controllability were significantly correlated in the Controllable condition in individuals with low trait delusion, whereas this relationship was diminished in those with high trait delusion. Collectively, these findings demonstrate that delusional ideation is associated with aberrant computation of and belief about environmental controllability, as well as a belief-behavior disconnect.}
}
@article{KAHLE200053,
title = {Dialectical Thinking in Consumer Decision Making},
journal = {Journal of Consumer Psychology},
volume = {9},
number = {1},
pages = {53-58},
year = {2000},
issn = {1057-7408},
doi = {https://doi.org/10.1207/s15327663jcp0901_5},
url = {https://www.sciencedirect.com/science/article/pii/S1057740800703251},
author = {Lynn R. Kahle and Raymond R. Liu and Gregory M. Rose and Woo-Sung Kim},
abstract = {In this article, we examine the four processes of dialectical thinking: interconnection, development and change, transformation of quantitative into qualitative, and unity and struggle of opposites. We argue that the decisions of some consumers reflect dialectical thinking, at least some of the time.}
}
@article{HASTINGS2024103074,
title = {What's a parent to do? Measuring cultural logics of parenting with computational text analysis},
journal = {Social Science Research},
volume = {124},
pages = {103074},
year = {2024},
issn = {0049-089X},
doi = {https://doi.org/10.1016/j.ssresearch.2024.103074},
url = {https://www.sciencedirect.com/science/article/pii/S0049089X24000966},
author = {Orestes P. Hastings and Luca Maria Pesando},
keywords = {Family, Parenting, Socioeconomic status, Computational social science, Text as data, Topic modeling},
abstract = {Leading theories on parenting in the United States suggest that parenting varies widely by socioeconomic status, with middle-class parents practicing “concerted cultivation”—marked by parents' intensive efforts to foster their children's development—and working-class parents engaging in the “accomplishment of natural growth”—with children given more freedom to manage their own time. While frequently inferred that these parenting practices reflect different cultural logics of parenting, such logics are inherently hard to measure. Our paper proposes a new inductive way to study parenting logics using computational text analysis applied to a nationally representative survey where respondents provided parenting advice across three hypothetical parenting situations. Analyzing this advice using Biterm Topic Modeling we find that nearly all parenting logics reflect some form of intensive parenting, but within that are multiple nuanced versions varying across two dimensions: (1) assertive vs negotiated parenting, and (2) pedagogic vs pragmatic parenting. Using fractional multinomial logistic regression, we find little difference in how parenting logics vary by race/ethnicity, education, and income, suggesting more similarity across groups and more variability within groups than commonly understood. These findings also demonstrate how computational techniques may provide complementary tools to enrich the study of long-standing questions in social science research, at times offering an analytical naïveté that human coding cannot offer.}
}
@article{CHOU2024105940,
title = {The influence of anxiety on exploration: A review of computational modeling studies},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {167},
pages = {105940},
year = {2024},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2024.105940},
url = {https://www.sciencedirect.com/science/article/pii/S0149763424004093},
author = {Ko-Ping Chou and Robert C. Wilson and Ryan Smith},
keywords = {Directed exploration, Random exploration, Foraging, Anxiety, Information-seeking},
abstract = {Exploratory behaviors can serve an adaptive role within novel or changing environments. Namely, they facilitate information gain, allowing an organism to maintain accurate beliefs about the environment and select actions that better maximize reward. However, finding the optimal balance between exploration and reward-seeking behavior – the so-called explore-exploit dilemma – can be challenging, as it requires sensitivity to one’s own uncertainty and to the predictability of one’s surroundings. Given the close relationship between uncertainty and anxiety, a body of work has now also emerged identifying associated effects on exploration. In particular, the field of computational psychiatry has begun to use cognitive computational models to characterize how anxiety may modulate underlying information processing mechanisms, such as estimation of uncertainty and the value of information, and how this might contribute to psychopathology. Here, we review computational modeling studies investigating how exploration is influenced by anxiety. While some apparent inconsistencies remain to be resolved, studies using reinforcement learning tasks suggest that directed (but not random) forms of exploration may be elevated by trait and/or cognitive anxiety, but reduced by state and/or somatic anxiety. Anxiety is also consistently associated with less exploration in foraging tasks. Some differences in exploration may further stem from how anxiety modulates changes in uncertainty over time (learning rates). Jointly, these results highlight important directions for future work in refining choice of tasks and anxiety measures and maintaining consistent methodology across studies.}
}
@article{HALES2023105083,
title = {Computational approaches to modeling gambling behaviour: Opportunities for understanding disordered gambling},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {147},
pages = {105083},
year = {2023},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2023.105083},
url = {https://www.sciencedirect.com/science/article/pii/S0149763423000520},
author = {C.A. Hales and L. Clark and C.A. Winstanley},
keywords = {Gambling disorder, Reinforcement learning, Drift diffusion modeling, Bayesian, Computational psychiatry},
abstract = {Computational modeling has become an important tool in neuroscience and psychiatry research to provide insight into the cognitive processes underlying normal and pathological behavior. There are two modeling frameworks, reinforcement learning (RL) and drift diffusion modeling (DDM), that are well-developed in cognitive science, and have begun to be applied to Gambling Disorder. RL models focus on explaining how an agent uses reward to learn about the environment and make decisions based on outcomes. The DDM is a binary choice framework that breaks down decision making into psychologically meaningful components based on choice reaction time analyses. Both approaches have begun to yield insight into aspects of cognition that are important for, but not unique to, gambling, and thus relevant to the development of Gambling Disorder. However, these approaches also oversimplify or neglect various aspects of decision making seen in real-world gambling behavior. Gambling Disorder presents an opportunity for ‘bespoke’ modeling approaches to consider these neglected components. In this review, we discuss studies that have used RL and DDM frameworks to investigate some of the key cognitive components in gambling and Gambling Disorder. We also include an overview of Bayesian models, a methodology that could be useful for more tailored modeling approaches. We highlight areas in which computational modeling could enable progression in the investigation of the cognitive mechanisms relevant to gambling.}
}
@incollection{DELLAVERSANA201337,
title = {2 - Circular thinking in geophysics},
editor = {Paolo Dell'Aversana},
booktitle = {Cognition in Geosciences},
publisher = {EAGE},
address = {Oxford},
pages = {37-55},
year = {2013},
isbn = {978-90-73834-41-5},
url = {https://www.sciencedirect.com/science/article/pii/B9789073834415500098},
author = {Paolo Dell'Aversana}
}
@article{HE2024115752,
title = {Navigating the semantic space: Unraveling the structure of meaning in psychosis using different computational language models},
journal = {Psychiatry Research},
volume = {333},
pages = {115752},
year = {2024},
issn = {0165-1781},
doi = {https://doi.org/10.1016/j.psychres.2024.115752},
url = {https://www.sciencedirect.com/science/article/pii/S0165178124000398},
author = {Rui He and Claudio Palominos and Han Zhang and Maria Francisca Alonso-Sánchez and Lena Palaniyappan and Wolfram Hinzen},
keywords = {Connected speech, Incoherence, Semantic similarity, Semantic perplexity, Language model, Loosening of associations, Schizophrenia},
abstract = {Speech in psychosis has long been ascribed as involving ‘loosening of associations’. We pursued the aim to elucidate its underlying cognitive mechanisms by analysing picture descriptions from 94 subjects (29 healthy controls, 18 participants at clinical high risk, 29 with first-episode psychosis, and 18 with chronic schizophrenia), using five language models with different computational architectures: FastText, which represents meaning non-contextually/statically; BERT, which represents contextual meaning sensitive to grammar and context; Infersent and SBERT, which provide sentential representations; and CLIP, which evaluates speech relative to a visual stimulus. These models were used to quantify semantic distances crossed between successive tokens/sentences, and semantic perplexity indicating unexpectedness in continuations. Results showed that, among patients, semantic similarity increased when measured with FastText, Infersent, and SBERT, while it decreased with CLIP and BERT. Higher perplexity was observed in first-episode psychosis. Static semantic measures were associated with clinically measured impoverishment of thought and referential semantic measures with disorganization. These patterns indicate a shrinking conceptual semantic space as represented by static language models, which co-occurs with a widening in the referential semantic space as represented by contextual models. This duality underlines the need to separate these two forms of meaning for understanding mechanisms involved in semantic change in psychosis.}
}
@article{TIEJUN2021120322,
title = {Implementation Status and Development Thinking on “Cloud National Examination” in China under the situation of “Online Anti-COVID-19 Epidemic”},
journal = {Technological Forecasting and Social Change},
volume = {162},
pages = {120322},
year = {2021},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2020.120322},
url = {https://www.sciencedirect.com/science/article/pii/S0040162520311483},
author = {Zhu Tiejun},
keywords = {Cloud National Examination, Online Anti-COVID-19 Epidemic, Implementation Status, Analysis and discussion, Thinking and enlightenment, Empirical Research},
abstract = {At the beginning of 2020, China was first hit by the COVID-19 epidemic. In order to effectively prevent the spread of the virus, the Chinese people work online, teach online, study online and shop online from home, the whole country rapidly entered the era of “Cloud Anti-COVID-19 Epidemic”. With the passage of time, the Chinese relevant national examinations such as postgraduate second round examination, the senior high school and college entrance examination gradually approach. In response, some regions have launched the “Cloud National Examination” model. Based on this background, through the actual situation commentary and case proof of adaptive mock test of the “Cloud National Examination” that has been carried out in some areas and schools, this article analyzes, discusses, summarizes and deeply reflects the epidemic prevention and control, policy formulation, education care, scientific and technological progress, and social problems hidden behind the hot phenomenon of “Cloud National Examination”, so as to offer advice and suggestions for online education in such a special period. Also, to provide reference for the rapid deployment, preparation and implementation of “Cloud National Examination” by relevant education administrative departments, schools, candidates and their families, and supply the evaluation viewpoint and theoretical contribution for similar global problems and phenomena.}
}
@article{FOURNY2020102332,
title = {Perfect Prediction in normal form: Superrational thinking extended to non-symmetric games},
journal = {Journal of Mathematical Psychology},
volume = {96},
pages = {102332},
year = {2020},
issn = {0022-2496},
doi = {https://doi.org/10.1016/j.jmp.2020.102332},
url = {https://www.sciencedirect.com/science/article/pii/S0022249620300183},
author = {Ghislain Fourny},
keywords = {Counterfactual dependence, Necessary Rationality, Necessary Knowledge of Strategies, Perfect Prediction, Transparency, Non-cooperative game theory, Non-Nashian game theory, Strategic games, Superrationality},
abstract = {This paper introduces a new solution concept for non-cooperative games in normal form with no ties and pure strategies: the Perfectly Transparent Equilibrium. The players are rational in all possible worlds and know each other’s strategies in all possible worlds — which, together, we refer to as Perfect Prediction. The anticipation of a player’s decision by their opponents is counterfactually dependent on the decision, unlike in Nash Equilibria where the decisions are made independently. The equilibrium, when it exists, is unique and is Pareto optimal. This equilibrium is the normal-form counterpart of the Perfect Prediction Equilibrium; the prediction happens “in another room” rather than in the past. The equilibrium can also be seen as a natural extension of Hofstadter’s superrationality to non-symmetric games. Algorithmically, an iterated elimination of non-individually-rational strategy profiles is performed until at most one remains. An equilibrium is a strategy profile that is immune against knowledge of strategies in all possible worlds and rationality in all possible worlds, a stronger concept than common knowledge of rationality but also stronger than common counterfactual belief of rationality. We formalize and contrast the Non-Nashian Decision Theory paradigm, common to this and several other papers, with Causal Decision Theory and Evidential Decision Theory. We define the Perfectly Transparent Equilibrium algorithmically and prove (when it exists) that it is unique, that it is Pareto-optimal, and that it coincides with Hofstadter’s Superrationality on symmetric games. We relate the finding to concepts found in the literature such as Individual Rationality, Rationalizability, Minimax-Rationalizability, Second-Order Nash Equilibria, the Program Equilibrium, the Perfect Prediction Equilibrium, Shiffrin’s Joint-Selfish-Rational Equilibrium, the Stalnaker–Bonanno Equilibrium, the Perfect Cooperation Equilibrium, the Translucent Equilibrium, the Correlated Equilibrium, and Quantum Games. Finally, we specifically discuss inclusion relationships on the special case of symmetric games between Individual Rationality, Minimax-Rationalizability, Superrationality, and the Perfectly Transparent Equilibrium, and contrast them with asymmetric games.}
}
@article{KARUNATHILAKE201970,
title = {Optimal renewable energy supply choices for net-zero ready buildings: A life cycle thinking approach under uncertainty},
journal = {Energy and Buildings},
volume = {201},
pages = {70-89},
year = {2019},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2019.07.030},
url = {https://www.sciencedirect.com/science/article/pii/S0378778819309582},
author = {Hirushie Karunathilake and Kasun Hewage and Joshua Brinkerhoff and Rehan Sadiq},
keywords = {Hybrid renewable energy systems, Net-zero buildings, Optimisation, Fuzzy logic, Life cycle assessment},
abstract = {The increasing concerns about the environmental and economic impacts of conventional centralised energy generation and fossil fuel usage have prompted an interest in renewable-based decentralised energy systems. Implementing such systems at building level can facilitate the development of net-zero energy buildings. Energy system planning is a multi-faceted problem that involves technical, economic, environmental, and social dimensions, and affects multiple stakeholders at different levels. A multi-objective optimisation approach is needed to identify the optimal energy choices at building level, while paying attention to stakeholder priorities and other constraints. The objective of this study is to develop a model to identify the optimal mix of renewable energy (RE) while also accounting for uncertainties, which can be integrated at building level with life cycle thinking. A framework was proposed for planning an optimised hybrid RE system at building level to support the net-zero development goals. The optimisation model was developed considering the objectives of minimising energy system cost, maximising operational cost savings, minimising the life cycle environmental impacts, and maximising the RE fraction. A combinatorial optimisation approach was adopted to reflect the practical engineering aspects of energy planning problems based on technologies available in the market. The developed framework was demonstrated through a case study conducted for an average multi-unit residential buildings (MURB) located in British Columbia, Canada. The results indicated that under the defined stakeholder priorities and constraints, ground source heat pumps and solar photovoltaics (PV) are the optimal energy choices for MURB, and the optimal energy system combination supplied 44% of the building's energy demand through RE. The findings will inform and guide community developers and other stakeholders with an interest in residential buildings, on the most suitable clean energy options for their building project during the pre-project planning stage.}
}
@article{SALEEM2024100124,
title = {Understanding 21st century skills needed in response to industry 4.0: Exploring scholarly insights using bibliometric analysis},
journal = {Telematics and Informatics Reports},
volume = {13},
pages = {100124},
year = {2024},
issn = {2772-5030},
doi = {https://doi.org/10.1016/j.teler.2024.100124},
url = {https://www.sciencedirect.com/science/article/pii/S2772503024000100},
author = {Sumayya Saleem and Elizabeth Dhuey and Linda White and Michal Perlman},
keywords = {21st century skills, Industry 4.0, Bibliometric analysis, Co-citation, Bibliographic coupling},
abstract = {International policy agendas are increasingly focusing on the 21st century skills needed by future workers in response to Industry 4.0. In this study, we conduct a bibliometric analysis of 2662 articles published by 6579 authors in the last two decades to understand the structure of the scholarly knowledge in this field. We first identify influential articles, documents, journals and trends in this literature. We use co-citation analysis to identify foundational themes in the development of 21st century skills literature, then using bibliometric coupling, we identify communities in the current research front. We then use co-word analysis to identify future directions in the field. Overall, we find that research on 21st century skills has grown exponentially in the past two decades, however, few researchers focus primarily on this topic. The existing research is primarily dominated by psychologists, education researchers and technology researchers. We also find that specific disciplines such as industrial engineering and nursing are prominent contributors in the field, and that critical thinking and computational thinking are key areas of focus.}
}
@article{MIAO2024117850,
title = {Progress toward adsorption mechanism exploration method for capacitive deionization: Experimental, mathematical model, computational chemistry and machine learning},
journal = {Desalination},
volume = {586},
pages = {117850},
year = {2024},
issn = {0011-9164},
doi = {https://doi.org/10.1016/j.desal.2024.117850},
url = {https://www.sciencedirect.com/science/article/pii/S0011916424005617},
author = {Luwei Miao and Ming Gao and Weilong Xiao and Yuchen Kang and Ran Li and Hao Kong and Haiyan Mou and Wenqing Chen and Tianqi Ao},
keywords = {Capacitive deionization mechanism, Experimental, Mathematical model, Computational chemistry, Machine learning},
abstract = {Capacitive deionization (CDI) is a novel and prospective technique mainly for desalination, featuring low-cost, easy maintenance, and environmental-friendly. As CDI develops by leaps and bounds, the electrode materials, the cell architectures, and the application fields have gained a lot of progress as reported. In order to optimize electrode materials, innovate cell architectures, broaden application fields, CDI adsorption mechanism exploration, as a necessary and important approach, have aroused enormous interest by researchers. This work provides a review of the strategies for investigating CDI adsorption mechanism form four aspects: experimental, mathematical model, computational chemistry, and machine learning, accompanied by discussing the prospects of these methods. Through a fine-grained summarization of the correlative reports from initial studies to the publications of late, it is expected that the meticulous statement of the characteristics, progress, and challenges of these exploration methods in this review can provide a fundamental support to facilitate prospective development of CDI.}
}
@article{LECORCHICK2020655,
title = {Problem Solving Archetype - Computer Science},
journal = {Procedia Computer Science},
volume = {172},
pages = {655-659},
year = {2020},
note = {9th World Engineering Education Forum (WEEF 2019) Proceedings : Disruptive Engineering Education for Sustainable Development},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.05.085},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920314149},
author = {Douglas Lecorchick and Scott Nichols and Lauren Tabor},
keywords = {problem formulation, computational thinking, problem solving archetype},
abstract = {Problems that are carefully formulated lead students to develop more sufficient and realistic solutions. By front-loading the process of problem solving through problem formulation, students are able to reduce the amount of time spent on solution development, and thus increase their efficiency towards meeting their main objective. By teaching students problem formulation, especially in computer science related activities, foundational skills in computational thinking are introduced, used, and refined. Using a problem solving archetype as a means for this formulation is an effective tool for students to leverage. As computational thinking skills are honed, these concepts can translate across barriers into other content areas.}
}
@article{ARASTOOPOURIRGENS2022100541,
title = {Characterizing children’s conceptual knowledge and computational practices in a critical machine learning educational program},
journal = {International Journal of Child-Computer Interaction},
volume = {34},
pages = {100541},
year = {2022},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2022.100541},
url = {https://www.sciencedirect.com/science/article/pii/S2212868922000599},
author = {Golnaz {Arastoopour Irgens} and Hazel Vega and Ibrahim Adisa and Cinamon Bailey},
keywords = {Critical pedagogies, Machine learning education, Elementary education, Design-based research, Robotics, Informal education},
abstract = {In this study, we describe the design and implementation of a CML (critical machine learning) education program for children between the ages of 9 and 13 at an after-school center. In this participatory design-based research, we collected learner artifacts, recordings of interactions, and pre/post drawings and written responses to model children’s developing knowledge and practices related to critical machine learning. Drawing from constructionist and critical pedagogical perspectives, our research questions are: (1) How do children develop machine learning knowledge grounded in social, ethical, and political orientations in a CML education program? and (2) What computational practices do children engage in when developing robots for social good in a CML education program? We found that (1) children made more sophisticated connections with socio-political orientations and ML content as they progressed through the program, and (2) they engaged in computational practices, such as experimenting and iterating, testing and debugging, reusing and remixing, and abstracting and modularizing. Further, our findings indicate that a critical lens to ML education can be characterized by posing and answering questions about the roles of AI technologies producers and consumers and identifying how these technologies are designed to apply this knowledge to build applications for marginalized populations. This study suggests that a critical lens is an effective approach towards engaging young children in designing their own machine learning tools in socially responsible ways.}
}
@article{PANG2025102852,
title = {Towards cognition-augmented human-centric assembly: A visual computation perspective},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {91},
pages = {102852},
year = {2025},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2024.102852},
url = {https://www.sciencedirect.com/science/article/pii/S073658452400139X},
author = {Jiazhen Pang and Pai Zheng and Junming Fan and Tianyuan Liu},
keywords = {Cognitive assistance, Human-centric assembly, Computer vision, Metaverse, Cloud service, Large language model, Brain computer interface},
abstract = {Human-centric assembly is emerging as a promising paradigm for achieving mass personalization in the context of Industry 5.0, as it fully capitalizes on the advantages of human flexibility with robot assistance. However, in small-batch and highly customized assembly tasks, frequently changes in production procedures pose significant cognition challenges. To address this, leveraging computer vision technology to enhance human cognition becomes a feasible solution. Therefore, this review aims to explore the cognitive characteristics of human beings and classify existing computer vision technologies in a manner that discusses the future development of cognition-augmented human-centric assembly. The concept of cognition-augmented assembly is first proposed based on the brain's functional structure - the frontal, parietal, temporal, and occipital lobes. Corresponding to these brain regions, cognitive issues in spatiality, memory, knowledge, and decision-making are summarized. Recent studies conducted between 2014 and 2023 on visual computation of assembly are categorized into four groups: position registration, multi-layer recognition, contextual perception, and mixed-reality fusion, all aimed at addressing these cognitive challenges. The applications and limitations of current computer vision technology are discussed. Furthermore, considering the rapidly evolving technologies such as the metaverse, cloud services, large language models, and brain-computer interfaces, future trends on computer vision are prospected to augment human cognition corresponding to the cognitive issues.}
}
@article{KARVELIS2023105137,
title = {Individual differences in computational psychiatry: A review of current challenges},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {148},
pages = {105137},
year = {2023},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2023.105137},
url = {https://www.sciencedirect.com/science/article/pii/S0149763423001069},
author = {Povilas Karvelis and Martin P. Paulus and Andreea O. Diaconescu},
keywords = {Computational psychiatry, Reliability, Validity, Computational modelling, Individual differences},
abstract = {Bringing precision to the understanding and treatment of mental disorders requires instruments for studying clinically relevant individual differences. One promising approach is the development of computational assays: integrating computational models with cognitive tasks to infer latent patient-specific disease processes in brain computations. While recent years have seen many methodological advancements in computational modelling and many cross-sectional patient studies, much less attention has been paid to basic psychometric properties (reliability and construct validity) of the computational measures provided by the assays. In this review, we assess the extent of this issue by examining emerging empirical evidence. We find that many computational measures suffer from poor psychometric properties, which poses a risk of invalidating previous findings and undermining ongoing research efforts using computational assays to study individual (and even group) differences. We provide recommendations for how to address these problems and, crucially, embed them within a broader perspective on key developments that are needed for translating computational assays to clinical practice.}
}
@article{YAN2024107454,
title = {A computational social science approach to understanding predictors of Chafee service receipt},
journal = {Children and Youth Services Review},
volume = {158},
pages = {107454},
year = {2024},
issn = {0190-7409},
doi = {https://doi.org/10.1016/j.childyouth.2024.107454},
url = {https://www.sciencedirect.com/science/article/pii/S0190740924000264},
author = {Jason Yan and Seventy F. Hall and Melanie Sage and Yuhao Du and Kenneth Joseph},
keywords = {Chafee services, Computational social science, Predictive modeling, National Youth in Transition Database},
abstract = {The John H. Chafee Foster Care Program for Successful Transition to Adulthood (CFCIP) allocates funding to provide services to youth who are likely to age out of foster care. These services, covering everything from mentoring to financial aid, are expected to be distributed in ways that prepare youth for life after care. One natural question to ask is, which youth receive Chafee services? The present work makes use of the National Youth in Transition Database (NYTD), a large-scale administrative dataset that tracks services allocated to youth that use CFCIP funds to answer this question. Specifically, we conduct a forensic social science analysis of the NYTD data. To do so, we first use computational methods to help us uncover the factors that best predict which youth will receive services associated with service receipt. We find that the majority of variables in the Adoption and Foster Care Analysis and Reporting System (AFCARS) and NYTD have limited or no utility in predicting Chafee service receipt, and that a subset of three variables—youth age, youth time in care, and the state in which a youth is in care—explain almost all variability in service receipt. We conclude with a discussion of the implications of these and other findings on future research on Chafee service allocation, and the utility of predictive modeling in child welfare, with a particular focus on the utility of the NYTD in this context.}
}
@incollection{DEWOSKIN2024779,
title = {Virtual models (aka: in silico or computational models)},
editor = {Philip Wexler},
booktitle = {Encyclopedia of Toxicology (Fourth Edition)},
publisher = {Academic Press},
edition = {Fourth Edition},
address = {Oxford},
pages = {779-793},
year = {2024},
isbn = {978-0-323-85434-4},
doi = {https://doi.org/10.1016/B978-0-12-824315-2.00094-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780128243152000944},
author = {Robert S. DeWoskin and Thomas B. Knudsen and Imran Shah},
keywords = {Adverse outcome pathways, Computational model, Emergent properties, In silico models, Microphysiological systems (MPS), PBPK models, Physiome project, Systems biology, Virtual embryo, Virtual liver, Virtual model (vM), Virtual physiological human},
abstract = {Virtual models (vM) are mathematical representations of biological processes that are numerically solved computationally, and are used to investigate and predict system behaviors that cannot be predicted solely from studying the nature of the individual parts, or from the domain of the available data. Computational power is now available to develop advanced vMs capable of supporting predictive toxicology and drug efficacy, and of reducing the dependence on in vivo animal studies for basic research and risk assessment purposes. The ultimate goal is to simulate in vivo responses of biological organisms to environmental change, drugs, toxins, or human activities, and to predict the effects of defined perturbations on system behaviors. Examples of virtual models are presented from research in the fields of physiology, pharmacology, toxicology and risk assessment.}
}
@article{EPPE2018105,
title = {A computational framework for conceptual blending},
journal = {Artificial Intelligence},
volume = {256},
pages = {105-129},
year = {2018},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2017.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S000437021730142X},
author = {Manfred Eppe and Ewen Maclean and Roberto Confalonieri and Oliver Kutz and Marco Schorlemmer and Enric Plaza and Kai-Uwe Kühnberger},
keywords = {Computational creativity, Conceptual blending, Cognitive science, Answer set programming},
abstract = {We present a computational framework for conceptual blending, a concept invention method that is advocated in cognitive science as a fundamental and uniquely human engine for creative thinking. Our framework treats a crucial part of the blending process, namely the generalisation of input concepts, as a search problem that is solved by means of modern answer set programming methods to find commonalities among input concepts. We also address the problem of pruning the space of possible blends by introducing metrics that capture most of the so-called optimality principles, described in the cognitive science literature as guidelines to produce meaningful and serendipitous blends. As a proof of concept, we demonstrate how our system invents novel concepts and theories in domains where creativity is crucial, namely mathematics and music.}
}
@article{BONHAGE2016203,
title = {Thinking about thinking: Neural mechanisms and effects on memory},
journal = {NeuroImage},
volume = {127},
pages = {203-214},
year = {2016},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2015.11.067},
url = {https://www.sciencedirect.com/science/article/pii/S1053811915011040},
author = {Corinna Bonhage and Friederike Weber and Cornelia Exner and Philipp Kanske},
keywords = {Attention, Cognitive self-consciousness, Default mode network, Proactive interference/ memory, Salience network, fMRI},
abstract = {It is a well-established finding that memory encoding is impaired if an external secondary task (e.g. tone discrimination) is performed simultaneously. Yet, while studying we are also often engaged in internal secondary tasks such as planning, ruminating, or daydreaming. It remains unclear whether such a secondary internal task has similar effects on memory and what the neural mechanisms underlying such an influence are. We therefore measured participants' blood oxygenation level dependent responses while they learned word-pairs and simultaneously performed different types of secondary tasks (i.e., internal, external, and control). Memory performance decreased in both internal and external secondary tasks compared to the easy control condition. However, while the external task reduced activity in memory-encoding related regions (hippocampus), the internal task increased neural activity in brain regions associated with self-reflection (anterior medial prefrontal cortex), as well as in regions associated with performance monitoring and the perception of salience (anterior insula, dorsal anterior cingulate cortex). Resting-state functional connectivity analyses confirmed that anterior medial prefrontal cortex and anterior insula/dorsal anterior cingulate cortex are part of the default mode network and salience network, respectively. In sum, a secondary internal task impairs memory performance just as a secondary external task, but operates through different neural mechanisms.}
}
@article{ACKERMAN2017607,
title = {Meta-Reasoning: Monitoring and Control of Thinking and Reasoning},
journal = {Trends in Cognitive Sciences},
volume = {21},
number = {8},
pages = {607-617},
year = {2017},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2017.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S1364661317301055},
author = {Rakefet Ackerman and Valerie A. Thompson},
keywords = {reasoning, problem solving, metacognition, effort regulation, monitoring and control},
abstract = {Meta-Reasoning refers to the processes that monitor the progress of our reasoning and problem-solving activities and regulate the time and effort devoted to them. Monitoring processes are usually experienced as feelings of certainty or uncertainty about how well a process has, or will, unfold. These feelings are based on heuristic cues, which are not necessarily reliable. Nevertheless, we rely on these feelings of (un)certainty to regulate our mental effort. Most metacognitive research has focused on memorization and knowledge retrieval, with little attention paid to more complex processes, such as reasoning and problem solving. In that context, we recently developed a Meta-Reasoning framework, used here to review existing findings, consider their consequences, and frame questions for future research.}
}
@article{MANLY200899,
title = {Strategies and tactics for optimizing the Hit-to-Lead process and beyond—A computational chemistry perspective},
journal = {Drug Discovery Today},
volume = {13},
number = {3},
pages = {99-109},
year = {2008},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2007.10.019},
url = {https://www.sciencedirect.com/science/article/pii/S135964460700459X},
author = {Charles J. Manly and Jayaraman Chandrasekhar and Joseph W. Ochterski and Jack D. Hammer and Benjamin B. Warfield},
abstract = {The Hit-to-Lead-to-Candidate process continues to evolve rapidly, and while technological advances offer much potential, the reality often pales to the promise. Conversely, strategies and tactics implementing existing technologies may result in more benefit in the end. This article focuses on some of the thinking and approaches that may improve the efficiency and effectiveness of the beginnings of the drug discovery path. From the perspective of computational chemists, different types of strategy and philosophy of approach will be treated including: considerations of early lead choices, strategies for improving poor leads, multivariate optimization, opportunities for informatics, and engineering good decisions.}
}
@article{ANTONIOU2022,
title = {Predicting Mental Health Status in Remote and Rural Farming Communities: Computational Analysis of Text-Based Counseling},
journal = {JMIR Formative Research},
volume = {6},
number = {6},
year = {2022},
issn = {2561-326X},
doi = {https://doi.org/10.2196/33036},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X22006187},
author = {Mark Antoniou and Dominique Estival and Christa Lam-Cassettari and Weicong Li and Anne Dwyer and Abìlio de Almeida Neto},
keywords = {e-mental health, text-based, counseling, Linguistic Inquiry and Word Count, LIWC, depression, anxiety, stress},
abstract = {Background
Australians living in rural and remote areas are at elevated risk of mental health problems and must overcome barriers to help seeking, such as poor access, stigma, and entrenched stoicism. e-Mental health services circumvent such barriers using technology, and text-based services are particularly well suited to clients concerned with privacy and self-presentation. They allow the client to reflect on the therapy session after it has ended as the chat log is stored on their device. The text also offers researchers an opportunity to analyze language use patterns and explore how these relate to mental health status.
Objective
In this project, we investigated whether computational linguistic techniques can be applied to text-based communications with the goal of identifying a client’s mental health status.
Methods
Client-therapist text messages were analyzed using the Linguistic Inquiry and Word Count tool. We examined whether the resulting word counts related to the participants’ presenting problems or their self-ratings of mental health at the completion of counseling.
Results
The results confirmed that word use patterns could be used to differentiate whether a client had one of the top 3 presenting problems (depression, anxiety, or stress) and, prospectively, to predict their self-rated mental health after counseling had been completed.
Conclusions
These findings suggest that language use patterns are useful for both researchers and clinicians trying to identify individuals at risk of mental health problems, with potential applications in screening and targeted intervention.}
}
@incollection{RAAB202129,
title = {Chapter Four - How the body and the environment affect our thinking?},
editor = {Markus Raab},
booktitle = {Judgment, Decision-Making, and Embodied Choices},
publisher = {Academic Press},
pages = {29-46},
year = {2021},
isbn = {978-0-12-823523-2},
doi = {https://doi.org/10.1016/B978-0-12-823523-2.00004-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128235232000040},
author = {Markus Raab},
keywords = {Facial feedback, Court decision, Gut decision, Gesture, Emotional decision},
abstract = {This chapter deals with the question, why body conditions and the environment influence our choices. Therefore this chapter summarizes plenty of research and combines it with own experiences. One famous study cited is the one by Strack and colleagues [12] concerning the facial feedback effect: Subjects had to rate the funniness of cartoons which either a pen between their lips or their teeth. Depending on the condition, the movement facilitated either a smile or a neutral expression which transferred to the ratings of the cartoons. Also, the role of gut feelings is discussed again, as research shows that the state of hunger may influence judges’ decisions at the court and this connection therefore should not the neglected. Talking about the bacteria-brain-behavior relationship, research on probiotics is very promising, although the exact mechanism of action is not completely discovered yet. A last aspect covered in this chapter is the influence of the gut on risky behavior, which has not been fully explored neurophysiological, maybe due to the deficient distinction between risk and uncertainty.}
}
@article{KRASICH2024105624,
title = {A computational modeling approach to investigating mind wandering-related adjustments to gaze behavior during scene viewing},
journal = {Cognition},
volume = {242},
pages = {105624},
year = {2024},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2023.105624},
url = {https://www.sciencedirect.com/science/article/pii/S0010027723002585},
author = {Kristina Krasich and Kevin O'Neill and Samuel Murray and James R. Brockmole and Felipe {De Brigard} and Antje Nuthmann},
keywords = {Visual-cognitive processing, Mind wandering, Fixation duration, Computational modeling, Scene viewing},
abstract = {Research on gaze control has long shown that increased visual-cognitive processing demands in scene viewing are associated with longer fixation durations. More recently, though, longer durations have also been linked to mind wandering, a perceptually decoupled state of attention marked by decreased visual-cognitive processing. Toward better understanding the relationship between fixation durations and visual-cognitive processing, we ran simulations using an established random-walk model for saccade timing and programming and assessed which model parameters best predicted modulations in fixation durations associated with mind wandering compared to attentive viewing. Mind wandering-related fixation durations were best described as an increase in the variability of the fixation-generating process, leading to more variable—sometimes very long—durations. In contrast, past research showed that increased processing demands increased the mean duration of the fixation-generating process. The findings thus illustrate that mind wandering and processing demands modulate fixation durations through different mechanisms in scene viewing. This suggests that processing demands cannot be inferred from changes in fixation durations without understanding the underlying mechanism by which these changes were generated.}
}
@article{CHEN2022307,
title = {Computational markers of experience- but not description-based decision-making are associated with future depressive symptoms in young adults},
journal = {Journal of Psychiatric Research},
volume = {154},
pages = {307-314},
year = {2022},
issn = {0022-3956},
doi = {https://doi.org/10.1016/j.jpsychires.2022.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S0022395622004484},
author = {Chong Chen and Yasuhiro Mochizuki and Kosuke Hagiwara and Masako Hirotsu and Toshio Matsubara and Shin Nakagawa},
keywords = {Decision-making, Description-experience gap, Risk preference, Probability weighting, Reinforcement learning, Computational psychiatry},
abstract = {Background
Early prediction of high depressive symptoms is crucial for selective intervention and the minimization of functional impairment. Recent cross-sectional studies indicated decision-making deficits in depression, which may be an important contributor to the disorder. Our goal was to test whether description- and experience-based decision making, two major neuroeconomic paradigms of decision-making under uncertainty, predict future depressive symptoms in young adults.
Methods
One hundred young adults performed two decision-making tasks, one description-based, in which subjects chose between two gambling options given explicitly stated rewards and their probabilities, and the other experience-based, in which subjects were shown rewards but had to learn the probability of those rewards (or cue-outcome contingencies) via trial-and-error experience. We evaluated subjects' depressive symptoms with BDI-II at baseline (T1) and half a year later (T2).
Results
Comparing subjects with low versus high levels of depressive symptoms at T2 showed that the latter performed worse on the experience- but not description-based task at T1. Computational modeling of the decision-making process suggested that subjects with high levels of depressive symptoms had a more concave utility function, indicating enhanced risk aversion. Furthermore, a more concave utility function at T1 increased the odds of high depressive symptoms at T2, even after controlling depressive symptoms at T1, perceived stress at T2, and several covariates (OR = 0.251, 95% CI [0.085, 0.741]).
Conclusions
This is the first study to demonstrate a prospective link between experience-based decision-making and depressive symptoms. Our results suggest that enhanced risk aversion in experience-based decision-making may be an important contributor to the development of depressive symptoms.}
}
@article{RZEPA2023725,
title = {Teaching FAIR in computational chemistry: managing and publishing data using the twin tools of compute portals and repositories},
journal = {Canadian Journal of Chemistry},
volume = {101},
number = {9},
pages = {725-733},
year = {2023},
issn = {0008-4042},
doi = {https://doi.org/10.1139/cjc-2022-0255},
url = {https://www.sciencedirect.com/science/article/pii/S0008404223000724},
author = {Henry S. Rzepa},
keywords = {repository, FAIR data, knowledge graphs, emerging areas, teaching tools},
abstract = {The history of the emerging area of tools for managing research resources and the data produced from them is summarised from the perspective of two decades of use in teaching and research at one institution. These tools are a portal or electronic laboratory notebook for computational chemistry interfaced in one direction to a high-performance computing resource and in the other direction to a modern research data repository. The essential features of both these tools are described over two generations of each, with examples of student work cited as examples using persistent identifiers or PIDs, better known as DOIs. Underpinning this is the metadata describing the data being processed. The article outlines the evolution of managing such metadata-rich data and its progress towards what can now be summarised by the acronym FAIR data, itself enabling future emerging areas such as knowledge graphs.}
}
@article{JOHANNING2004371,
title = {Supporting the development of algebraic thinking in middle school: a closer look at students’ informal strategies},
journal = {The Journal of Mathematical Behavior},
volume = {23},
number = {4},
pages = {371-388},
year = {2004},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2004.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0732312304000458},
author = {Debra I. Johanning},
keywords = {Algebra, Algebraic thinking, Middle school, Guess and check},
abstract = {This study investigated how 31 sixth-, seventh-, and eighth-grade middle school students who had not previously, nor were currently taking a formal Algebra course, approached word problems of an algebraic nature. Specifically, these algebraic word problems were of the form x + (x + a) + (x + b) = c or ax + bx + cx = d. An examination of students’ understanding of the relationships expressed in the problems and how they used this information to solve problems was conducted. Data included the students’ written responses to problems, field notes of researcher–student interactions while working on the problems, and follow-up interviews. Results showed that students had many informal strategies for solving the problems with systematic guess and check being the most common approach. Analysis of researcher–student interactions while working on the problems revealed ways in which students struggled to engage in the problems. Support mechanisms for students who struggle with these problems are suggested. Finally, implications are provided for drawing upon students’ informal and intuitive knowledge to support the development of algebraic thinking.}
}
@article{LENG2025528,
title = {Review of manufacturing system design in the interplay of Industry 4.0 and Industry 5.0 (Part II): Design processes and enablers},
journal = {Journal of Manufacturing Systems},
volume = {79},
pages = {528-562},
year = {2025},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2025.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S0278612525000366},
author = {Jiewu Leng and Jiwei Guo and Junxing Xie and Xueliang Zhou and Ang Liu and Xi Gu and Dimitris Mourtzis and Qinglin Qi and Qiang Liu and Weiming Shen and Lihui Wang},
keywords = {Manufacturing system design, Production system design, Smart manufacturing, Industry 5.0, Design methods},
abstract = {Following up on our previous review paper ‘Review of manufacturing system design in the interplay of Industry 4.0 and Industry 5.0 (Part I): Design thinking and modeling methods’ [1], based on the proposed Thinking-Modelling-Process-Enabler (TMPE) framework of Manufacturing System Design (MSD), this paper (Part II of the two-part review) further reviews the Process and Enabler dimensions of MSD in the interplay of Industry 4.0 and Industry 5.0. MSD methods are reviewed from the single-dimensional design process and cross-dimensional design process perspectives, respectively. MSD methods are reorganized and categorized from the key enabler's perspective. Finally, challenges are discussed along with directions for future research in the domain of MSD. This review is anticipated to offer novel insights for advancing MSD research and engineering in the interplay of Industry 4.0 and Industry 5.0.}
}
@article{DEGIORGI2008470,
title = {The α-beauty contest: Choosing numbers, thinking intervals},
journal = {Games and Economic Behavior},
volume = {64},
number = {2},
pages = {470-486},
year = {2008},
note = {Special Issue in Honor of Michael B. Maschler},
issn = {0899-8256},
doi = {https://doi.org/10.1016/j.geb.2008.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S0899825608000511},
author = {Enrico {De Giorgi} and Stefan Reimann},
keywords = {Experiments, -beauty contest, Beliefs, Cognitive hierarchy model},
abstract = {We present a model for the α-beauty contest that explains common patterns in experimental data of one-shot and iterative games. The approach is based on two basic assumptions. First, players iteratively update their recent guesses. Second, players estimate intervals rather than exact numbers to cope with incomplete knowledge of other players' rationality. Under these assumptions we extend the cognitive hierarchy model of Camerer et al. [Camerer, C., Ho, T., Chong, J., 2003b. A cognitive hierarchy model of one-shot games. Quart. J. Econ. 119, 861–898]. The extended model is estimated on experimental data from a newspaper experiment.}
}
@article{ALTUN2024e00312,
title = {Parametric modeling and fabrication as capturing knowledge: A design computation workflow for historical brick surfaces in Anatolia},
journal = {Digital Applications in Archaeology and Cultural Heritage},
volume = {32},
pages = {e00312},
year = {2024},
issn = {2212-0548},
doi = {https://doi.org/10.1016/j.daach.2023.e00312},
url = {https://www.sciencedirect.com/science/article/pii/S2212054823000577},
author = {Sevgi Altun and Mine Özkar},
keywords = {Historical bricklaying, Shape grammars, Architectural heritage documentation, Robotic fabrication},
abstract = {Using computational design tools to create meaningful digital representations of architectural heritage delivers both challenges and opportunities. On one hand, digital tools aid the fast and detailed three-dimensional modeling of architectural elements. On the other hand, these models do not sufficiently document the materials and techniques of making. This research proposes a workflow to use computational design tools to analyze historic Anatolian brick elements while integrating their geometry, construction, and part-whole relations in parametric modeling and robotic fabrication processes. Our approach demonstrates a correlation between the design of the surface pattern and material application in historical bricklaying. The proposed workflow can be applied to formalize implicit design knowledge, integrating it into the digital environment and numeric control production codes. This holistic approach to heritage prioritizes both the tangible aspects, such as form and material, and intangible aspects such as the knowledge base of applied techniques.}
}
@incollection{MEINKE201939,
title = {Chapter 3 - The role of modeling and systems thinking in contemporary agriculture},
editor = {Riccardo Accorsi and Riccardo Manzini},
booktitle = {Sustainable Food Supply Chains},
publisher = {Academic Press},
pages = {39-47},
year = {2019},
isbn = {978-0-12-813411-5},
doi = {https://doi.org/10.1016/B978-0-12-813411-5.00003-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012813411500003X},
author = {Holger Meinke},
keywords = {Agriculture, Systems thinking, Complexity, Adaptation, Risk management, Modeling, Bioeconomy, Value chains, Social license, Industry 4.0, Sustainability},
abstract = {The images and perceived roles of agriculture in our societies have changed over the last few decades. Today agriculture is regarded as an integral part of interconnected value chains that sit at the heart of our economies, providing invaluable services to society. In response, most governments around the world are now actively developing policies to support and grow their bio-economies. This increases the expectations that society and governments have in terms of agriculture’s services and performance: agriculture is not only expected to generate food for our growing populations and income for farmers, it must be part of value chains that provide raw materials that can be incorporated or converted into feed, fiber, fuel, pharmaceuticals, and other industrial products. Farmers are expected to be responsible custodians of our landscapes and their farming practices must be economically, environmentally, and socially sustainable and aligned with the broader and changing values of our societies. Often these three objectives conflict and consequently societal expectations are not met. In a world that is increasingly data rich, practicing agriculture in a way that lives up to these expectations requires tools that can help to foresee the consequences of complex interactions. Hence, this chapter explores the role of modeling and systems thinking to manage this complexity by explicitly considering three attributes of complex, adaptive systems, whereby (i) order emerges rather than being predetermined; (ii) the system’s future can only be assessed probabilistically rather than deterministically predicted; and (iii) the history of the system is largely irreversible. The chapter reflects on the contemporary use of models against these three systems characteristics and concludes that scientifically based and tested algorithms (i.e., models) are already a ubiquitous and indispensable management tool for modern farming. Countless apps are already in use for short-term, tactical decision making, while more complex modeling approaches are vital for strategic scenario planning and risk assessments for farmers, policymakers, and scientists.}
}
@article{ASMUSSEN2025103328,
title = {Distrusting cores by separating computation from isolation},
journal = {Journal of Systems Architecture},
volume = {159},
pages = {103328},
year = {2025},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2024.103328},
url = {https://www.sciencedirect.com/science/article/pii/S1383762124002650},
author = {Nils Asmussen and Till Miemietz and Sebastian Haas and Michael Roitzsch},
keywords = {Multicore architectures, Hardware security, Reliability, Operating systems},
abstract = {Security mechanisms such as address spaces rely on the assumption that processor cores can be fully trusted. But the steady influx of side-channel vulnerabilities in processors is challenging this assumption. To minimize the impact of security vulnerabilities in processors, we need a system architecture that can tolerate potentially exploitable cores. In this paper, we propose the untrusted core isolation model to protect critical computation on trusted cores from untrusted and potentially buggy cores. We survey how current architectural building blocks such as MMUs fall short of this goal and derive requirements for untrusted core isolation. To demonstrate its feasibility, we discuss both changes to commodity platforms and show how research works such as fulfill the requirements. We evaluate the security benefits via a qualitative comparison of current architectures in both industry and academia and study its costs by a quantitative comparison of the most promising approaches on off-the-shelf and FPGA-based platforms.}
}
@article{OTANI2024104086,
title = {Computational study on the effects of central retinal blood vessels with asymmetric geometries on optic nerve head biomechanics},
journal = {Medical Engineering & Physics},
volume = {123},
pages = {104086},
year = {2024},
issn = {1350-4533},
doi = {https://doi.org/10.1016/j.medengphy.2023.104086},
url = {https://www.sciencedirect.com/science/article/pii/S1350453323001418},
author = {Tomohiro Otani and Kota Miyata and Atsuya Miki and Shigeo Wada},
keywords = {Central retinal vessel, Optic nerves head, Optical coherence tomography, Glaucoma, Smoothed finite element method},
abstract = {Optic nerve head (ONH) biomechanics are associated with glaucoma progression and have received considerable attention. Central retinal vessels (CRVs) oriented asymmetrically in the ONH are the single blood supply source to the retina and are believed to act as mechanically stable elements in the ONH in response to intraocular pressure (IOP). However, these mechanical effects are considered negligible in ONH biomechanical studies and received less attention. This study investigated the effects of CRVs on ONH biomechanics taking into consideration three-dimensional asymmetric CRV geometries. A CRV geometry was constructed based on CRV centerlines extracted from optical coherence tomography ONH images in eight healthy subjects and superimposed in the idealized ONH geometry established in previous studies. Mechanical analyses of the ONH in response to the IOP were conducted in the cases with and without CRVs for comparison. Obtained results demonstrated that the CRVs induced anisotropic ONH deformation, particularly in the lamina cribrosa and the associated upper neural tissues (prelamina) with wide ranges of spatial strain distributions. These results indicated that the CRVs result in anisotropic deformation with local strain concentration, rather than function to mechanically support in response to the IOP as in the conventional thinking in ophthalmology.}
}
@article{KASPERSEN2022100539,
title = {High school students exploring machine learning and its societal implications: Opportunities and challenges},
journal = {International Journal of Child-Computer Interaction},
volume = {34},
pages = {100539},
year = {2022},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2022.100539},
url = {https://www.sciencedirect.com/science/article/pii/S2212868922000575},
author = {Magnus Høholt Kaspersen and Karl-Emil Kjær Bilstrup and Maarten {Van Mechelen} and Arthur Hjort and Niels Olof Bouvin and Marianne Graves Petersen},
keywords = {Computational empowerment, Computational thinking, Machine learning, Learning tools, AI literacy},
abstract = {The increased use of AI and machine learning (ML) calls for a general AI literacy, in particular regarding understanding how ML works, the process behind creating ML models, and reflecting on its implications. Where existing learning tools focus on the first two, we explore opportunities and challenges for meaningfully engaging students in understanding and reflecting on ML in their everyday life. We designed VotestratesML, following a Constructive Design Research approach, as an ethics-first learning tool that allow students to explore implications of ML for democratic elections. Based on deployments of VotestratesML in two high school social studies classrooms, we found that safely exploring ML from a concrete starting point helped students reflect and form opinions about its use, that promoting iterative exploration through collaboration and competition motivated them to explore, and that foregrounding ethics in the design and grounding ML in a well-known subject area allowed them to engage with ML on a personal level.}
}
@article{BERS2019130,
title = {Coding as a playground: Promoting positive learning experiences in childhood classrooms},
journal = {Computers & Education},
volume = {138},
pages = {130-145},
year = {2019},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2019.04.013},
url = {https://www.sciencedirect.com/science/article/pii/S0360131519300995},
author = {Marina U. Bers and Carina González-González and Mª Belén Armas–Torres},
keywords = {Cooperative/collaborative learning, Teaching/learning strategies, Improving classroom teaching, Elementary education},
abstract = {In recent years, there has been a push to introduce coding and computational thinking in early childhood education, and robotics is an excellent tool to achieve this. However, the integration of these fundamental skills into formal and official curriculums is still a challenge and educators needs pedagogical perspectives to properly integrate robotics, coding and computational thinking concepts into their classrooms. Thus, this study evaluates a “coding as a playground” experience in keeping with the Positive Technological Development (PTD) framework with the KIBO robotics kit, specially designed for young children. The research was conducted with preschool children aged 3–5 years old (N = 172) from three Spanish early childhood centers with different socio-economic characteristics and teachers of 16 classes. Results confirm that it is possible to start teaching this new literacy very early (at 3 years old). Furthermore, the results show that the strategies used promoted communication, collaboration and creativity in the classroom settings. The teachers also exhibited autonomy and confidence to integrate coding and computational thinking into their formal curricular activities, connecting concepts with art, music and social studies. Through the evidence found in this study, this research contributes with examples of effective strategies to introduce robotics, coding and computational thinking into early childhood classrooms.}
}
@article{DEBNATH2023314,
title = {Opportunities and limitations of integrating computational and collaborative approaches to scenario planning},
journal = {Journal of Urban Management},
volume = {12},
number = {4},
pages = {314-326},
year = {2023},
issn = {2226-5856},
doi = {https://doi.org/10.1016/j.jum.2023.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S2226585623000468},
author = {Ripan Debnath and Christopher Pettit and Simone Zarpelon Leao},
keywords = {Scenario planning, Computational approach, CA-Model, Collaborative planning, Geodesign},
abstract = {In the context of changing global trends and growing uncertainties, creating and evaluating alternative future scenarios is crucial for urban and regional planning. Computational and collaborative approaches are two contemporary options for scenario planning. They have distinct roles and are often applied independently. This study investigates the integration of these two approaches, addressing a knowledge gap by explicitly integrating a Cellular Automata-based model within the collaborative geodesign framework. It assesses the integration process and scenario planning outcomes through a resilience planning case study. The key finding from this experiment is that integrating the information generated by a computational approach with the transparency and reliability inherent in a collaborative approach can enhance the end-user's scenario planning experience. The integration is also perceived to have positive effects on scenario outcomes, which is particularly relevant for joint evidence-based and collaborative resilience planning in cities and regions. However, the study also highlights the need for further investigation into the options for integrating computational methods into collaborative approaches and into the utility of integration in real-world planning with practitioners and the community.}
}
@article{NARAYANAMURTHY201884,
title = {Is the hospital lean? A mathematical model for assessing the implementation of lean thinking in healthcare institutions},
journal = {Operations Research for Health Care},
volume = {18},
pages = {84-98},
year = {2018},
note = {EURO 2016—New Advances in Health Care Applications},
issn = {2211-6923},
doi = {https://doi.org/10.1016/j.orhc.2017.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S2211692316301060},
author = {Gopalakrishnan Narayanamurthy and Anand Gurumurthy},
keywords = {Process improvement, Healthcare institution, Lean thinking, Implementation, Assessment, Fuzzy-logic, Lean implementation index},
abstract = {Many academic and practice articles have been published in healthcare operations management literature documenting the experience of implementing lean thinking (LT) in healthcare institutions. But, none of them have developed a procedure for assessing the implementation of LT in healthcare institutions. Lack of assessment procedures make it difficult to evaluate the progress made during the implementation of LT. The current study attempts to address this gap by developing and demonstrating an assessment procedure to evaluate the extent of lean implementation in a healthcare institution To begin with, different lean tenets and elements applied in healthcare institutions were identified through a literature review. Following it, a Fuzzy-Logic Input Based Healthcare Institution Lean Implementation Assessment (FLB-HLIA) was developed and deployed in an Indian case hospital to compute “Healthcare Institution’s Lean Implementation Index” (HLII). FLB-HLIA revealed that the case hospital has to focus on two lean tenets, namely establishing pull system, and seeking perfection, to improve its HLII. Assessment also revealed the lean elements that the case hospital can focus to upgrade its HLII. HLII can be used by practitioners to perform intra-benchmarking and inter-benchmarking of healthcare institutions. Results of FLB-HLIA provide a future action plan for the lean implementation journey of the healthcare institution by identifying the possible areas of improvement for future.}
}
@article{FUNK2015163,
title = {Thinking about the future of technology: Rates of improvement and economic feasibility},
journal = {Futures},
volume = {73},
pages = {163-175},
year = {2015},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2015.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S0016328715001081},
author = {Jeffrey L. Funk},
keywords = {Technology change, Economic feasibility, Transportation, Information technology, Health, Care, Telecommunications, Future, Rates of improvement, Scaling, Creating materials},
abstract = {This paper uses data on rates of improvement to discuss when new technologies or systems composed from them might become economically feasible. Technologies must provide some level of performance and price for specific applications before they will begin to diffuse and technologies that experience rapid rates of improvement are more likely to become economically feasible for a growing number of applications than are other technologies. Drawing from a large data base on rates of improvement, this paper describes a set of plausible futures that are very different from ones that are presented in public forums.}
}
@article{MAMMINO2023101151,
title = {Green chemistry and computational chemistry: A wealth of promising synergies},
journal = {Sustainable Chemistry and Pharmacy},
volume = {34},
pages = {101151},
year = {2023},
issn = {2352-5541},
doi = {https://doi.org/10.1016/j.scp.2023.101151},
url = {https://www.sciencedirect.com/science/article/pii/S2352554123001857},
author = {Liliana Mammino},
keywords = {Design of new molecules, Education to cross-disciplinary attitudes, Prediction of, Molecular properties, Prediction of reaction mechanisms},
abstract = {The green chemistry principles envisage the design of substances and production processes that are benign for human health and the environment, where ‘benign’ refers to the entire life of a substance, from production through usage and to final disposal. The design of new substances entails the design of new molecules, and the design of more benign processes may entail the design of other substances (besides reactants and products) facilitating the process' ‘greenness’, from catalysts to green solvents. Designing molecules with specific properties requires the possibility of predicting their properties before the actual synthesis. Computational chemistry has made molecular design rational by being able to predict the properties of not-yet-synthesized molecules. The results of molecular calculations enable a preliminary selection singling out the promising molecules among a high number of possibilities; only the promising ones are then synthesized and experimentally tested. Synergies between computational chemistry and green chemistry would thus appear a natural outcome. The present work outlines them with reference to the main components of an industrial process and of their potential ‘greening’. The presentation follows a pattern that can be used within educational contexts. The conclusions stress the importance to familiarise students with the variety of possible synergies and the benefits of each of them, within a perspective viewing a ‘knowing each other’ criterion as the main key to nurture true cross-areas attitudes, that will be valuable for the students' future professional activities.}
}
@article{LOCKWOOD2021100857,
title = {Reinforcing key combinatorial ideas in a computational setting: A case of encoding outcomes in computer programming},
journal = {The Journal of Mathematical Behavior},
volume = {62},
pages = {100857},
year = {2021},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2021.100857},
url = {https://www.sciencedirect.com/science/article/pii/S0732312321000183},
author = {Elise Lockwood and Adaline {De Chenne}},
keywords = {Combinatorics, Encoding outcomes, Computation, Programming, Discrete mathematics},
abstract = {Counting problems are difficult for students to solve, and there is a perennial need to investigate ways to help students solve counting problems successfully. One promising avenue for students’ successful counting is for them to think judiciously about how they encode outcomes – that is, how they symbolize and represent the outcomes they are trying to count. We provide a detailed case study of two students as they encoded outcomes in their work on several related counting problems within a computational setting. We highlight the role that a computational environment may have played in this encoding activity. We illustrate ways in which by-hand work and computer programming worked together to facilitate the students’ successful encoding activity. This case demonstrates ways in which the activity of computation seemed to interact with by-hand work to facilitate sophisticated encoding of outcomes.}
}
@article{CIMPIAN2012161,
title = {Remembering kinds: New evidence that categories are privileged in children’s thinking},
journal = {Cognitive Psychology},
volume = {64},
number = {3},
pages = {161-185},
year = {2012},
issn = {0010-0285},
doi = {https://doi.org/10.1016/j.cogpsych.2011.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S0010028511000909},
author = {Andrei Cimpian and Lucy C. Erickson},
keywords = {Conceptual development, Kinds, Generic language, Memory},
abstract = {What are the representations and learning mechanisms that underlie conceptual development? The present research provides evidence in favor of the claim that this process is guided by an early-emerging predisposition to think and learn about abstract kinds. Specifically, three studies (N=192) demonstrated that 4- to 7-year-old children have better recall for novel information about kinds (e.g., that dogs catch a bug called “fep”) than for similar information about individuals (e.g., that a particular dog catches a bug called “fep”). By showing that children are particularly likely to retain information about kinds, this work not only provides a first empirical demonstration of a phenomenon that may be key to conceptual development but also makes it apparent that young children’s thinking is suffused with abstractions rather than being perceptually-based and concrete.}
}
@article{XU2024100415,
title = {Measuring mutual engagement in the context of middle-school pair programming: Development and validation of a self-reported questionnaire},
journal = {Computers in Human Behavior Reports},
volume = {14},
pages = {100415},
year = {2024},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2024.100415},
url = {https://www.sciencedirect.com/science/article/pii/S2451958824000484},
author = {Fan Xu and Ana-Paula Correia},
keywords = {Mutual engagement, Engagement questionnaire, Dyadic collaborative learning, Pair programming, Computational thinking, Middle school},
abstract = {With the increasing importance of equipping young learners with computational thinking skills through learning to code, pair programming has emerged as a prevalent collaborative learning strategy in this context. Successful pair programming interventions necessitate mutual engagement between partners within a dyad. However, the measurement of mutual engagement in dyadic collaborative learning remains an under-researched area. This research represents a foundational stage in bridging this gap by developing a comprehensive 20-item Pair-Programming Mutual Engagement Questionnaire (PPME-Q) as a measure of mutual engagement in pair programming at the activity level. The questionnaire was validated through a sample of 86 eighth-grade students. Confirmatory factor analysis confirmed the existence of a four-factor structure comprising of the behavioral, cognitive, emotional, and social engagement factors. The findings demonstrate the validity (χ2/df = 1.32) and reliability (Cronbach's α = 0.888) of the PPME-Q, establishing it as an effective tool for assessing eighth graders' mutual engagement in pair programming activities. As this tool is in the nascent stages of development the measurement, we emphasize the need for further empirical studies to establish criterion validity. We also discuss the implications of these findings for future research and educational practices. This targeted instrument can then potentially be adapted or scaled to other age groups based on the insights gained.}
}
@article{AISH2017144,
title = {Comparative evaluation of parametric design systems for teaching design computation},
journal = {Design Studies},
volume = {52},
pages = {144-172},
year = {2017},
note = {Parametric Design Thinking},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2017.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X17300327},
author = {Robert Aish and Sean Hanna},
keywords = {architectural design, design education, human–computer interaction, parametric design, evaluation},
abstract = {Three parametric design systems were tested by the authors to assess their suitability for undergraduate teaching. We used criteria taken from the ‘cognitive dimensions’ literature and an exercise of typical geometric operations in ascending order of complexity. For each system the cognitive barriers associated with the sequence of operations were plotted to create a ‘learning curve’. Different parametric systems presented distinctly different learning curves. The test exercise had to be completed in its entirety to assess the potential challenges which students with different educational levels, skills and abilities might encounter, so a single expert user conducted the tests. This research is intended to develop methods, both design exercises and evaluative criteria that could be used in future empirical studies.}
}
@article{HALL2024541,
title = {The computational structure of consummatory anhedonia},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {6},
pages = {541-553},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S1364661324000068},
author = {Anna F. Hall and Michael Browning and Quentin J.M. Huys},
keywords = {anhedonia, reinforcement learning, reward, goals, stress response, emotion appraisal},
abstract = {Anhedonia is a reduction in enjoyment, motivation, or interest. It is common across mental health disorders and a harbinger of poor treatment outcomes. The enjoyment aspect, termed ‘consummatory anhedonia’, in particular poses fundamental questions about how the brain constructs rewards: what processes determine how intensely a reward is experienced? Here, we outline limitations of existing computational conceptualisations of consummatory anhedonia. We then suggest a richer reinforcement learning (RL) account of consummatory anhedonia with a reconceptualisation of subjective hedonic experience in terms of goal progress. This accounts qualitatively for the impact of stress, dysfunctional cognitions, and maladaptive beliefs on hedonic experience. The model also offers new views on the treatments for anhedonia.}
}

@article{RIBEIRO2011639,
title = {Re-thinking diagnosis for future automation systems: An analysis of current diagnostic practices and their applicability in emerging IT based production paradigms},
journal = {Computers in Industry},
volume = {62},
number = {7},
pages = {639-659},
year = {2011},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2011.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0166361511000303},
author = {Luis Ribeiro and Jose Barata},
keywords = {Diagnosis, Reconfigurable manufacturing systems, Adaptive production systems},
abstract = {With the advent of the Internet and the progressive development and consolidation of a wide range of web standards and technologies as well as the advances in distributed artificial intelligence (DAI), namely the multi agent system concept, new opportunities have emerged for conceiving, modelling and enhancing shop floor's performance and response. Modern IT-supported production paradigms denote a common concept where the shop floor is a lively entity composed by interacting intelligent modules whose individual and collective function adapts and evolves ensuring the fitness and adequacy of the organization, owning the system, in tackling profitable but volatile business opportunities. The self-organizing and peer to peer nature of these systems renders a collective behaviour and dynamics that are fundamentally new. Conventional diagnostic methods and tools have not been designed targeting the envisioned systems therefore lack the required support. In this paper the emerging IT-based production paradigms are surveyed as well as the existing diagnostic methods whose adequacy is analysed. The resulting requirements and characteristics are exposed to stress the need for rethinking current diagnostic practices in future automation systems.}
}
@article{YIP2023319,
title = {From Computation to Clinic},
journal = {Biological Psychiatry Global Open Science},
volume = {3},
number = {3},
pages = {319-328},
year = {2023},
issn = {2667-1743},
doi = {https://doi.org/10.1016/j.bpsgos.2022.03.011},
url = {https://www.sciencedirect.com/science/article/pii/S2667174322000507},
author = {Sarah W. Yip and Deanna M. Barch and Henry W. Chase and Shelly Flagel and Quentin J.M. Huys and Anna B. Konova and Read Montague and Martin Paulus},
keywords = {Cognitive neuroscience, Computational psychiatry, Machine learning, Neuroimaging, Reinforcement learning},
abstract = {Theory-driven and data-driven computational approaches to psychiatry have enormous potential for elucidating mechanism of disease and providing translational linkages between basic science findings and the clinic. These approaches have already demonstrated utility in providing clinically relevant understanding, primarily via back translation from clinic to computation, revealing how specific disorders or symptoms map onto specific computational processes. Nonetheless, forward translation, from computation to clinic, remains rare. In addition, consensus regarding specific barriers to forward translation—and on the best strategies to overcome these barriers—is limited. This perspective review brings together expert basic and computationally trained researchers and clinicians to 1) identify challenges specific to preclinical model systems and clinical translation of computational models of cognition and affect, and 2) discuss practical approaches to overcoming these challenges. In doing so, we highlight recent evidence for the ability of computational approaches to predict treatment responses in psychiatric disorders and discuss considerations for maximizing the clinical relevance of such models (e.g., via longitudinal testing) and the likelihood of stakeholder adoption (e.g., via cost-effectiveness analyses).}
}
@article{THOWYICK1998275,
title = {General information theory: Some macroscopic dynamics of the human thinking systems},
journal = {Information Processing & Management},
volume = {34},
number = {2},
pages = {275-290},
year = {1998},
issn = {0306-4573},
doi = {https://doi.org/10.1016/S0306-4573(97)00069-1},
url = {https://www.sciencedirect.com/science/article/pii/S0306457397000691},
author = {Liang Thow-Yick},
abstract = {This study is an attempt to put in place the component of the general information theory that explains the macroscopic dynamics of the human thinking systems. The fundamental structure of such a theory must include the domains of external basic entity interactions, external basic entity and information-coded energy quantum transformations, and energy quantum and information-coded matter interactions. In this respect, a human thinking system is perceived to have at least a natural energy-matter subsystem and a human-created physical symbol subsystem. The artifacts of the human-created subsystem are the external basic physical entities, namely, data, information, knowledge, and wisdom. The intrinsic and interactive properties of these entities depict the characteristics of the physical symbol subsystem. Besides interacting among themselves, the external entities also interact with the natural entities, the information-coded energy quanta, according to certain rules and principles. Subsequently, the energy quanta interact with the information-coded matter structure. Such interactions occurring within the individual subsystems and between the two subsystems constitute the dynamics of the human thinking systems. In intelligent systems of this nature information can exist in physical, energy and matter forms, and the different forms are interconvertible. The interactions among these entities and the conversion of one form to another is made possible by the existence of an intelligence space in the human mind.}
}
@article{KONG2024105016,
title = {The impact of school support for professional development on teachers' adoption of student-centered pedagogy, students’ cognitive learning and abilities: A three-level analysis},
journal = {Computers & Education},
volume = {215},
pages = {105016},
year = {2024},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2024.105016},
url = {https://www.sciencedirect.com/science/article/pii/S0360131524000307},
author = {Siu-Cheung Kong and Yi-Qing Wang},
keywords = {Cognitive learning, Computational thinking, Multilevel analysis, Student-centered pedagogy, Teacher professional development},
abstract = {Student-centered pedagogy (SCP) is highly considered for its potential to facilitate cognitive learning in Computational Thinking (CT) education. However, there is a noticeable gap in understanding its influence on students' cognitive development from a multilevel perspective. This study delves into cognitive learning theories and aims to bridge the existing gap by introducing a three-level conceptual model to illustrate how the influence of SCP on students' cognitive CT abilities is mediated through the cognitive learning processes. This multilevel approach simultaneously explores SCP within the intricate school environment where factors at the school, teacher, and student levels are closely intertwined. Data was collected from 82 programming teachers and their 2433 students across 43 Hong Kong primary schools. Using multilevel modeling, results indicate that the adoption of SCP is significantly anchored by school support on teacher professional development (TPD), which in turn enhances students’ cognitive learning (i.e., active, interactive, constructive, and reflective learning) in class, further contributing to their enhanced cognitive CT abilities. The findings underscore the nuances of SCP adoption in school scenarios, advocating for strategic approaches to maximize student achievements in CT education. Recommendations for future research are discussed.}
}
@article{ULLAH2024108394,
title = {Ubiquitous computation in internet of vehicles for human-centric transport systems},
journal = {Computers in Human Behavior},
volume = {161},
pages = {108394},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108394},
url = {https://www.sciencedirect.com/science/article/pii/S0747563224002620},
author = {Inam Ullah and Farhad Ali and Habib Khan and Faheem Khan and Xiaoshan Bai},
keywords = {Ubiquitous computing, Internet of vehicles, Ubiquitous learning, Human-centric dimensions, Multi-criterion decision-making, Computers in human behavior, Internet of things, 5G/6G communications},
abstract = {The Internet of Vehicles (IoV) has the potential to bring about a revolutionary transformation in transportation through its influence on human behavior and interactions between users and vehicles. However, interoperability challenges between retailer organizations and manufacturers present a barrier to decision-making processes and impact the human-centric nature of the IoV. Ethical dilemmas arise as a result of the IoV’s inability to prevent accidents, particularly in critical situations. This study aims to enhance the IoV’s effectiveness by carefully selecting and improving essential attributes from various data sources, including sensors, GPS, 5G or 6G communication networks, and real-time data provisioning. To achieve the aim of the proposed study, a Multi-criterion Decision-making (MCDM) approach is proposed, which allows for the analysis and selection of optimal choices while taking into account various quantitative and qualitative factors. Despite the challenges posed by complex models and ambiguous data, MCDM remains an indispensable technique for aligning transportation systems with current expectations. The CRITIC and TOPSIS MCDM-enabled methodologies are employed to analyze IoV architecture, prioritizing significant elements that impact system performance and identifying optimal solutions by considering complications from worst-case scenarios. The study will assist engineers, scientists, and organizations to develop smart IoV systems that will cater to human needs by improving mobility and inspiration among users.}
}
@article{MATHIAS202381,
title = {Enriched learning: behavior, brain, and computation},
journal = {Trends in Cognitive Sciences},
volume = {27},
number = {1},
pages = {81-97},
year = {2023},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2022.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S1364661322002686},
author = {Brian Mathias and Katharina {von Kriegstein}},
keywords = {multimodal enrichment, enriched learning, crossmodal processing, educational neuroscience, multisensory, sensorimotor},
abstract = {The presence of complementary information across multiple sensory or motor modalities during learning, referred to as multimodal enrichment, can markedly benefit learning outcomes. Why is this? Here, we integrate cognitive, neuroscientific, and computational approaches to understanding the effectiveness of enrichment and discuss recent neuroscience findings indicating that crossmodal responses in sensory and motor brain regions causally contribute to the behavioral benefits of enrichment. The findings provide novel evidence for multimodal theories of enriched learning, challenge assumptions of longstanding cognitive theories, and provide counterevidence to unimodal neurobiologically inspired theories. Enriched educational methods are likely effective not only because they may engage greater levels of attention or deeper levels of processing, but also because multimodal interactions in the brain can enhance learning and memory.}
}
@incollection{DASGUPTA2020554,
title = {Technology: Computational Creativity},
editor = {Mark Runco and Steven Pritzker},
booktitle = {Encyclopedia of Creativity (Third Edition)},
publisher = {Academic Press},
edition = {Third Edition},
address = {Oxford},
pages = {554-559},
year = {2020},
isbn = {978-0-12-815615-5},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.23765-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245237656},
author = {Subrata Dasgupta},
keywords = {Artifact, Artificer, Artificial intelligence, Computational creativity, Computational thinking, Creativity, Heuristics search, Historicity, Human creativity, Purposive evolution},
abstract = {The focus of this article is computational creativity, which is concerned with the problem of understanding, theorizing, designing and constructing computational artifacts that manifest behavior which would be deemed ‘creative’ if exhibited by human beings. Historically, this problem is a derivative of the agenda of artificial intelligence (AI) and, thus, is a technological problem. However, as will be seen, even in the specifically technological realm of computational creativity issues pertaining to human creativity cannot be evaded since, at the very least, the criteria for judging and evaluating the creativity of computational artifacts will originate in the realm of human creativity.}
}
@article{HEMMO201990,
title = {The physics of implementing logic: Landauer's principle and the multiple-computations theorem},
journal = {Studies in History and Philosophy of Science Part B: Studies in History and Philosophy of Modern Physics},
volume = {68},
pages = {90-105},
year = {2019},
issn = {1355-2198},
doi = {https://doi.org/10.1016/j.shpsb.2019.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S1355219819300048},
author = {Meir Hemmo and Orly Shenker},
keywords = {Entropy, Individuation of computation, Landauer's principle, Logical (ir)reversibility, Second law of thermodynamics},
abstract = {This paper makes a novel linkage between the multiple-computations theorem in philosophy of mind and Landauer's principle in physics. The multiple-computations theorem implies that certain physical systems implement simultaneously more than one computation. Landauer's principle implies that the physical implementation of “logically irreversible” functions is accompanied by minimal entropy increase. We show that the multiple-computations theorem is incompatible with, or at least challenges, the universal validity of Landauer's principle. To this end we provide accounts of both ideas in terms of low-level fundamental concepts in statistical mechanics, thus providing a deeper understanding of these ideas than their standard formulations given in the high-level terms of thermodynamics and cognitive science. Since Landauer's principle is pivotal in the attempts to derive the universal validity of the second law of thermodynamics in statistical mechanics, our result entails that the multiple-computations theorem has crucial implications with respect to the second law. Finally, our analysis contributes to the understanding of notions, such as “logical irreversibility,” “entropy increase,” “implementing a computation,” in terms of fundamental physics, and to resolving open questions in the literature of both fields, such as: what could it possibly mean that a certain physical process implements a certain computation.}
}
@article{SUMI199771,
title = {Computer-aided thinking by mapping text-objects into metric spaces},
journal = {Artificial Intelligence},
volume = {91},
number = {1},
pages = {71-84},
year = {1997},
note = {Artificial Intelligence Research in Japan},
issn = {0004-3702},
doi = {https://doi.org/10.1016/S0004-3702(96)00058-6},
url = {https://www.sciencedirect.com/science/article/pii/S0004370296000586},
author = {Yasuyuki Sumi and Koichi Hori and Setsuo Ohsuga},
keywords = {Computer-aided thinking, Concept formation, Visualizing thought space structure, Computer-supported cooperative work},
abstract = {This paper presents a system for computer-aided thinking. We propose the idea of reflecting the mental world indirectly into a metric space to support such human thinking activities as externalizing and forming new ideas. We use a method that maps text-objects into metric spaces for visualizing a user's thought space structure. Text-objects imply fragments of a user's idea, which have several keywords given by him/her. Spaces composed of text-objects are configured in the way “the higher the mutual relevance between a pair of text-objects is, the closer the text-objects are mapped”. The relevance values among text-objects are calculated due to cooccurrence of their keywords. Results of experiments with our implemented system, named CAT1 (computer-aided thinking, version 1), show that users of the system can get effective stimuli for further thinking in creative concept formation. The paper also discusses the potential application of CAT1 to collaborative work by groups of people.}
}
@article{DUANKHAN2024123734,
title = {The Differentiated Creative Search (DCS): Leveraging differentiated knowledge-acquisition and creative realism to address complex optimization problems},
journal = {Expert Systems with Applications},
volume = {252},
pages = {123734},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.123734},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424006006},
author = {Poomin Duankhan and Khamron Sunat and Sirapat Chiewchanwattana and Patchara Nasa-ngium},
keywords = {Population-based optimization algorithm, Divergent thinking, Convergent thinking, Linnik distribution, Creative realism, Differential evolution},
abstract = {This article introduces differentiated creative search (DCS), a groundbreaking optimization algorithm that revolutionizes traditional decision-making systems in complex environments. In contrast to conventional differential evolution methods, DCS integrates a unique knowledge-acquisition process with a creative realism paradigm, thereby transforming optimization strategies. The primary aim of DCS is to enhance decision-making efficacy by employing a newly proposed dual-strategy approach that balances divergent and convergent thinking within a team-based framework. High-performing members apply divergent thinking via the DCS/Xrand/Linnik(α,σ) strategy, which incorporates existing knowledge and Linnik flights. Conversely, the remaining team harnesses convergent thinking through the DCS/Xbest/Current-to-2rand strategy, which combines insights from both the team leader and fellow members. This division of labor, coupled with a strategy tailored to the performance levels of team members, allows for a dynamic and effective decision-making process. The methodology of DCS involves iterative cycles of divergent and convergent thinking, supported by a differentiated knowledge-acquisition process and retrospective assessments. The algorithm's novelty lies in its differentiated knowledge-acquisition, adjusted based on individual team member performance, fostering an environment of continuous learning and adaptation. The paper's contributions are demonstrated through rigorous testing of DCS on various benchmark functions, including CEC2017, classical, and sensor selection problems, as well as real-world applications such as car side impact design, gear train design, and FM sound wave parameter estimation. The results showcase the promising performance of DCS compared to that of existing algorithms, attributable to its innovative approach to problem solving and decision making in complex scenarios. The results and impact section highlights that DCS considerably outperforms traditional optimization algorithms, offering a robust and versatile tool for complex decision-making systems. Its impact is particularly notable in scenarios requiring a balance between innovative solutions and practical decision-making, making DCS a valuable asset in strategic planning and execution across various industries.}
}
@article{FENG2024121491,
title = {An analytical and adaptive method for solar photovoltaic modules parameters extraction},
journal = {Renewable Energy},
volume = {236},
pages = {121491},
year = {2024},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2024.121491},
url = {https://www.sciencedirect.com/science/article/pii/S0960148124015593},
author = {Junjie Feng and Xia Zeng and Baoqin Zhang and Jiahui Liu and Chuanzhong Xu and Fei Yu},
keywords = {Solar cells, Analytical parameter extraction method, Multiple-diode model, Effective-diode-based analysis, Recursive thinking},
abstract = {An analytical and adaptive parameter extraction method is proposed to accurately and efficiently extract the parameters of solar cells' triple-diode lumped-parameter equivalent circuit model. This method can obtain explicit expressions of parameters, facilitating seamless integration into photovoltaic systems for circuit-level simulation and design. The proposed method addresses the lack of analytical parameter extraction methods for triple-diode model, avoids the iteration of numerical methods, and significantly reduces computational complexity, thus improving the overall efficiency of the modeling process. In this method, the principle of effective-diode-based analysis is used to simplify the complex multi-diode model. Recursive thinking is then combined to adaptively extract all parameters through multiple steps according to the number of diodes in the model. Subsequently, the practicability of this method is evaluated by testing on three different equivalent circuit models of solar cells including the single-, double-, and triple-diode models. Furthermore, the universality of this method is demonstrated by testing on three photovoltaic modules of different types including Mono-crystalline, Multi-crystalline, Thin-film, and perovskite solar cells at different temperatures and irradiances. Finally, the simulation results based on the extracted parameters are compared with the experimental data to calculate the root mean square error (RMSE) magnitude, which ranges from 10−5 to 10−3, demonstrating the feasibility of the proposed method. As a result, this analytical parameter extraction method provides a robust tool and approach for research and applications in the field of solar cell modeling.}
}
@article{JANECK2003181,
title = {Too much thinking about thinking?: metacognitive differences in obsessive–compulsive disorder},
journal = {Journal of Anxiety Disorders},
volume = {17},
number = {2},
pages = {181-195},
year = {2003},
issn = {0887-6185},
doi = {https://doi.org/10.1016/S0887-6185(02)00198-6},
url = {https://www.sciencedirect.com/science/article/pii/S0887618502001986},
author = {Amy S. Janeck and John E. Calamari and Bradley C. Riemann and Susan K. Heffelfinger},
keywords = {Obsessive–compulsive disorder, Cognition, Metacognition},
abstract = {Negative appraisals of intrusive thoughts and beliefs about the importance of thoughts are considered core mechanisms in cognitive models of obsessive–compulsive disorder (OCD). In refinements of cognitive theory, differences in metacognitive processes have been emphasized. Cartwright-Hatton and Wells [J. Anxiety Disord. 37 (1997) 279–296] found that cognitive self-consciousness (CSC), a tendency to be aware of and monitor thinking, was the only metacognitive dimension that differentiated OCD patients from patients with generalized anxiety disorder. To evaluate the relative importance of different cognitive processes to OCD, we administered an expanded CSC scale and two state-of-the-art measures of thought appraisals and beliefs. Scores on the CSC scale reliably differentiated OCD patients (n=30), from an anxious comparison group (OAD, n=25) after controlling for scores on the two cognition measures. The tendency to excessively reflect upon one’s cognitive processes may increase opportunities for negative appraisals of intrusive thoughts, foster over-importance of thought beliefs, and increase the likelihood of developing OCD.}
}
@article{SIMON1999363,
title = {The foundations of numerical thinking in a brain without numbers},
journal = {Trends in Cognitive Sciences},
volume = {3},
number = {10},
pages = {363-365},
year = {1999},
issn = {1364-6613},
doi = {https://doi.org/10.1016/S1364-6613(99)01383-2},
url = {https://www.sciencedirect.com/science/article/pii/S1364661399013832},
author = {Tony J Simon},
keywords = {Brain, Number, Development, Counting, Attention}
}
@article{MARTINEZ20001657,
title = {Systems thinking and functional modeling of batch process management using projects},
journal = {Computers & Chemical Engineering},
volume = {24},
number = {2},
pages = {1657-1663},
year = {2000},
issn = {0098-1354},
doi = {https://doi.org/10.1016/S0098-1354(00)00446-4},
url = {https://www.sciencedirect.com/science/article/pii/S0098135400004464},
author = {E.C. Martinez},
keywords = {Batch process management, Systems thinking, Functional modeling},
abstract = {Intense competition and rapid environmental changes are revealing severe limitations in the effectiveness of the hierarchical, stable and Tayloristic management system currently used by the vast majority of batch manufacturing industries. A project-oriented enterprise model of batch plants which results of integrating together systems thinking and functional modeling is proposed here. The latter refers to the set of intents and relationships between goals, functions and components (both physical and abstract) that comprise an analytical viewpoint of batch processes involving product recipes, equipment capabilities, constraints and human competencies (skills and knowledge). Complementarily, the systemic perspective accounts for the organizational setting (roles, objectives and actors), and provides an orthogonal view through the duality of whole-parts relationships and the ubiquitous concepts of boundary, emergence and hierarchy upon which the project-oriented enterprise model is built. A case study that comprises a dairy facility involving the production + 100 different fresh products using an order-driven management system will be presented. To support the prototype implementation of a plant information system using a hierarchy of project-based objects, a conceptual design has been developed. The implementation of the resulting enterprise model in Project 98™ will be discussed to highlight its easy and cheap implementation, and a number of advantages including: accumulation of information and knowledge, direct tracing of activities and cost analysis.}
}
@article{FLETCHER2022299,
title = {The future of computational fluid dynamics (CFD) simulation in the chemical process industries},
journal = {Chemical Engineering Research and Design},
volume = {187},
pages = {299-305},
year = {2022},
issn = {0263-8762},
doi = {https://doi.org/10.1016/j.cherd.2022.09.021},
url = {https://www.sciencedirect.com/science/article/pii/S0263876222005202},
author = {David F. Fletcher},
keywords = {Computation, Scale-up, CFD, DEM, Process design},
abstract = {Computer-based simulation is a huge contributor to the understanding of processes because of the ability to simulate complex physics and chemistry, develop validated models and then use them in the scale-up and, more recently, the scale-down of processes, as well as process optimisation and control. Almost all processes in the Chemical Process Industries (CPIs) involve fluid flow or particles, so here we will focus on Computational Fluid Dynamics (CFD) and Discrete Element Modelling (DEM). Through my experience of computer modelling and supporting simulation groups over the last 40 years, I seek to draw out important lessons from the past to identify current and future trends, as well as to provide advice to help companies imbed this technology in their design processes. I see a very bright future for simulation and users with good computational skills in both academia and industry.}
}
@article{MENG2023103514,
title = {The price paid: Heuristic thinking and biased reference points in the housing market},
journal = {Journal of Urban Economics},
volume = {134},
pages = {103514},
year = {2023},
issn = {0094-1190},
doi = {https://doi.org/10.1016/j.jue.2022.103514},
url = {https://www.sciencedirect.com/science/article/pii/S0094119022000900},
author = {Charlotte C. Meng},
keywords = {Left-digit Bias, Reference dependence, Behavioural economics, Housing markets},
abstract = {Does the power of reference points mean that minute differences in a purchase price then reverberate in future sales prices? In this research, I show that if previous sales prices are round numbers, defined as multiples of £1,000 (e.g. £231,000), subsequent sales prices entail a considerable premium relative to similar properties that were previously priced at charm numbers that are marginally below those round numbers (e.g. £230,999 or £230,950). Using a sample of repeat sales from the Greater London region from 1995 to 2017, I estimate the premium to be approximately 4 percent after controlling for property characteristics and a large set of fixed effects. Increasing public accessibility of information attenuates the effect. Tax considerations, financial constraints, and pricing errors cannot explain the result. I propose a framework of reference dependence and left-digit bias to explain the result, highlighting the presence of behavioural biases in household decisions, even when very high stakes are involved.}
}
@article{MAJZOUB20231011,
title = {Investigating the adaptability and implementation of computational design methods in concept design taking plasterboard opportunities for dimensional coordination and waste reduction as a case study},
journal = {Frontiers of Architectural Research},
volume = {12},
number = {5},
pages = {1011-1029},
year = {2023},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2023.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S209526352300047X},
author = {Omar Majzoub and M. Hank Haeusler and Sisi Zlatanova},
keywords = {Computational design, Plasterboard dimensional coordination, Concept design},
abstract = {Construction material offcuts is a data problem that can largely be avoided by dimensional coordination during concept design. Besides the environmental benefits, early phase coordination is beneficial to the overall design process as it integrates information not typically considered until later in the design process. However, taking reality-changing actions is often challenged by uncertainty, time constraints, and lack of integration of available tools. Acknowledging the potential of computational design in enabling architects to manage design and coordination complexities and taking plasterboard opportunities for dimensional coordination, the paper presents a review and assessment of the existing methods to interrogate what, when, and how are these adaptable to the task. The study shows that ML-based methods outperform other methods and concludes that leveraging computational design powers to reduce offcuts is not a question of a tool, but one of a strategy. Eventually, the future steps to achieving such a strategy are discussed.}
}
@article{GOVINDAN2019653,
title = {Computational decision framework for enhancing resilience of the energy, water and food nexus in risky environments},
journal = {Renewable and Sustainable Energy Reviews},
volume = {112},
pages = {653-668},
year = {2019},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2019.06.015},
url = {https://www.sciencedirect.com/science/article/pii/S1364032119304083},
author = {Rajesh Govindan and Tareq Al-Ansari},
keywords = {Energy, water, and food nexus, Risk management, Artificial intelligence, Regime switching, Reinforcement learning},
abstract = {The energy, water and food (EWF) nexus modelling and analysis frameworks proposed recently have demonstrated their effectiveness in the assessment and quantification of synergies and trade-offs in the interlinkages between the three sectors. They largely rely on static, deterministic or equilibrium-based models that facilitate in making decisions for well-behaved and predictable resource systems over time. These frameworks, however, are partly limited in their functionality due to the fact that they do not consider the exposure of systems to the dynamic nature of extrinsic uncertainties and the associated risks in the nexus. Hence, there is a need for a sequential learning, planning and optimal control modelling framework which could help achieve adaptive systems under volatile conditions with the objective to maximise economic output and enhance their operational resilience. In this paper, the authors discuss the development of a novel computational framework which incorporates “algorithmic resilience thinking” to achieve adaptive and robust inter-networked systems. Here, the question of adaptive systems for EWF nexus resilience is posed as a reinforcement learning problem based on sequential decision-making called the Markov decision process (MDP). The authors further discuss a case study, considering weather volatility, its spatial impact on vegetation, and the consequent risks on the water-food nexus for outdoor agricultural operations in the State of Qatar. The application of the developed framework particularly demonstrates promise in providing the functionality to track and mitigate emerging risks that have the potential to cause unprecedented disruption in the operations of integrated natural resource systems. The outcome of this study has positive implications for the advancement and effectiveness of EWF nexus planning and risk management to avert resource shortages and price risks, socio-economic disruption, and cascading failures of critical infrastructures, particularly when the global supply chains are subjected to stresses and shocks, such as extreme weather conditions.}
}
@article{BUCCIARELLI2022100443,
title = {The causes of difficulty in children’s creation of informal programs},
journal = {International Journal of Child-Computer Interaction},
volume = {31},
pages = {100443},
year = {2022},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2021.100443},
url = {https://www.sciencedirect.com/science/article/pii/S2212868921001185},
author = {Monica Bucciarelli and Robert Mackiewicz and Sangeet S. Khemlani and P.N. Johnson-Laird},
keywords = {Computational thinking, Deduction, Informal programs, Kinematic simulations, Recursion},
abstract = {We present a theory of the causes of difficulty in children’s creation of informal programs. Ten-year-old children are able to devise such programs to rearrange the order of the cars in trains on a simple railway track with a single siding. According to the theory, they rely on kinematic mental models that simulate the required sequence of steps, and we devised a computer program, mAbducer, which does so too in creating its own programs for such rearrangements. An experiment showed that a simple measure of the complexity of its programs, based on Kolmogorov complexity, predicts ten-year-olds’ difficulty in this task: the measure is the number of words in mAbducer’s programs for solving the rearrangement in a minimal number of moves. Complexity, in turn, reflects the structure of the required programs, which need loops of moves to be repeated, and often moves before and after such a loop. Children’s errors are predictable in both their location and nature. Our results therefore have implications for the assessment and pedagogy of computational thinking.}
}
@article{YING2024e31883,
title = {Cross-cultural study of hotel practices as perceived by Chinese and North American travellers: A data mining analysis},
journal = {Heliyon},
volume = {10},
number = {11},
pages = {e31883},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e31883},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024079143},
author = {Shun Ying},
keywords = {Perception difference, Holistic thinking, Analytic thinking, Word frequency, LDA modelling, Content analysis},
abstract = {This paper aims to unearth the different perception styles of Chinese and North American travellers from analytic versus holistic thinking perspectives. Python was utilized to gather online textual data from Chinese and North American travellers, while word frequency analysis, latent Dirichlet allocation (LDA) topic modelling analysis and content analysis were employed to elucidate the perception styles in a cross-cultural context. In general, North American travellers mainly leaned towards analytic thinking, whereas Chinese travellers showcased a blend of holistic and analytic thought processes. The topic of travel, leisure and accommodation showed both holistic and analytic thinking styles. The topics of nature and environment, front desk service, and travel routes and scenic spot areas mainly represented a holistic thinking style. The topics of convenience and facilities, breakfast, transportation, hotel theme and features, and decoration and amenities mainly suggested an analytic thinking style. Hotels should consider the different perception styles of Chinese and North American travellers to facilitate strategies accordingly and to maximize the experience of travellers from different cultural backgrounds.}
}
@incollection{MAHER2025205,
title = {Reactive transport as a scientific framework},
editor = {Ariel Anbar and Dominique Weis},
booktitle = {Treatise on Geochemistry (Third edition)},
publisher = {Elsevier},
edition = {Third edition},
address = {Oxford},
pages = {205-254},
year = {2025},
isbn = {978-0-323-99763-8},
doi = {https://doi.org/10.1016/B978-0-323-99762-1.00071-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780323997621000711},
author = {K. Maher and Z. Perzan},
keywords = {Reactive transport, Advective transport, Advective velocity, Dispersion and diffusion, Hydrodynamic dispersion, Geochemical systems, Mineral dissolution and precipitation, Microbial reaction modeling, Sensitivity analysis, Uncertainty quantification},
abstract = {Reactive transport is a framework that integrates across disciplines and scales, and leverages cutting-edge computational techniques to advance a nuanced understanding of Earth's complex systems. As a way of thinking, it connects science, engineering, and natural systems, and unifies across experiment, field and modeling studies. This chapter links core reactive transport concepts to their mathematical constructs embodied in reactive transport models. Approaches for scaling, such as dimensionless numbers, enable translation from conceptual to numerical models. The increasing complexity of numerical models also requires both targeted measurements and tools for evaluating and learning from multifaceted numerical models, emphasizing the importance of implementing reactive transport frameworks early in the design of any scientific study.}
}
@article{INGRAO2018556,
title = {How can life cycle thinking support sustainability of buildings? Investigating life cycle assessment applications for energy efficiency and environmental performance},
journal = {Journal of Cleaner Production},
volume = {201},
pages = {556-569},
year = {2018},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2018.08.080},
url = {https://www.sciencedirect.com/science/article/pii/S0959652618324144},
author = {Carlo Ingrao and Antonio Messineo and Riccardo Beltramo and Tan Yigitcanlar and Giuseppe Ioppolo},
keywords = {Built environment, Buildings, Energy efficiency, Environmental sustainability, Life cycle assessment, Sustainable urban development},
abstract = {In the context of built environment, buildings are amongst the principal generators of environmental externalities. Life Cycle Assessment (LCAs) of energy efficiency and environmental performance of buildings are deemed critical to address sustainable development issues. This paper aims to investigate LCA as a tool to support the design of buildings with two objectives in mind. Firstly, it determines the role of LCA in the evaluation of energy efficiency and environmental performance of buildings. Secondly, it elaborates LCA of these constructions through the lens of international standards. The methodological approach of the study leads to development of a whole building life cycle formula that sums up the contributions from a set of LCAs. By doing so, the paper highlights the necessity of LCA applications in buildings, and the need for minimisation of resource and energy consumption, and environmental impact. The study helps in better understanding the way LCA supports the search for and identification of innovation pathways in buildings. This paper contributes to the efforts in providing theoretical expansions in LCA of buildings and stimulates the creation of technical standards for the residential building construction sector.}
}
@article{RAJPUT2023100147,
title = {Computational nanoscience and technology},
journal = {OpenNano},
volume = {12},
pages = {100147},
year = {2023},
issn = {2352-9520},
doi = {https://doi.org/10.1016/j.onano.2023.100147},
url = {https://www.sciencedirect.com/science/article/pii/S2352952023000269},
author = {Amarjitsing Rajput and Ganesh Shevalkar and Krutika Pardeshi and Prashant Pingale},
keywords = {Nanomaterials, Computational models, Mathematical models, Molecular dynamics, Drug development},
abstract = {Nanoscience and nanotechnology are the most widely utilized field of science in human healthcare, tissue engineering, food and agriculture. It has several advantages, such as superior surface area and nano-sized molecular structure. Nanomaterial properties like elasticity, mechanical characteristics like hardness, tensile strength, and magnetic and optical properties. It has capability to store high energy, which makes them applicable in the healthcare system. “Executable biology” is applied to the computational model of physiological processes. These models have the advantage of computer science and simulation of pharmacokinetic study. Because of their high potential and computational power, they are widely accepted in pharmaceutical research. US-FDA has tested and utilized computational models in manufacturing various pharmaceutical equipment's that also can be used in drug discovery and manufacturing. These models can create exact validated in vitro and in vivo pharmacological systems, which helps to obtain faster, accurate and more pertinent human data. These models suffer from simplicity, versatility and lack of cumulative research. Multiscale simulations, like the ones based on coarse-graining, are important areas for future research. More significantly, a collaboration between the pharmaceutical industry and computational scientists involved in this field could assist in work in areas wherein molecular dynamic simulations can influence substantially. In this review, different drug target identification models via chemo genomic methods are explained, and the advantages of computational modeling over mathematical model is studied. It also focuses on a wide range of simulation techniques, biomedical applications and challenges of computational modelling. Finally, it gives a brief account of compounds studied using computational modeling and its future perspectives.}
}
@article{LIU2023102331,
title = {A brain-inspired computational model for extremely few reference image quality assessment},
journal = {Displays},
volume = {76},
pages = {102331},
year = {2023},
issn = {0141-9382},
doi = {https://doi.org/10.1016/j.displa.2022.102331},
url = {https://www.sciencedirect.com/science/article/pii/S0141938222001494},
author = {Hongyan Liu and Shuang Shi and Ruxue Bai and Yuchen Liu and Xinkang Lian and Ting Shi},
keywords = {Extremely few reference (EFR), Image quality assessment (IQA), Brain science, Free energy principle, Attention perception mechanism},
abstract = {In the study of brain science, the free energy principle and attention perception mechanism have been the two of the most critical findings during the past few decades, arousing a wide range of attention and valuable applications from the research fields of image and video processing, computer vision, etc. Motivated by the aforementioned two important findings, we in this paper develop a brain-inspired computational model for extremely few reference image quality assessment (IQA), dubbed as BCM. The proposed BCM implements with the two main steps. First, we combine free energy principle and sparse perception mechanism to achieve the goal of only using extremely few reference for assessing the image quality. Second, we further introduce the attention perception mechanism to boost the assessment performance by improving the sparse perception mechanism mentioned above. Based on the most commonly used image quality database, it was found that our proposed model has derived higher performance than the peer extremely few reference IQA models and competitive performance as compared with the benchmark full reference IQA models.}
}
@article{BOURGEADE2023105390,
title = {New PWM inverter control based on optimal pulse pattern computation without phases symmetry constraints},
journal = {Control Engineering Practice},
volume = {132},
pages = {105390},
year = {2023},
issn = {0967-0661},
doi = {https://doi.org/10.1016/j.conengprac.2022.105390},
url = {https://www.sciencedirect.com/science/article/pii/S0967066122002210},
author = {Adrien Bourgeade and Malek Ghanes and Barbot Jean-Pierre and Bouarfa Abdelkader and Fadel Maurice and Boisliveau Robert},
keywords = {Power electronics, Simulation and Experimental Model Validation, Optimization, Pulse Width Modulation, Optimized pulse patterns, Phase symmetry relaxation},
abstract = {The control of inverters has degrees of freedom that open the way to improve the output harmonic spectrum. Numerous works dealing with this objective have been proposed in the literature, particularly within the definition of switching angles. Among them, the well-known PWM techniques such as Quarter Wave Symmetry (QWS), Half Wave Symmetry (HWS), and Full Wave Symmetry (FWS) are based on Optimal Pulse Patterns (OPP) computation using symmetries angles constraints. In this paper to improve the harmonic quality, the symmetry angles constraints are not considered leading to a new OPP method: Phases Symmetry Relaxation (PSR). To highlight the interest in the proposed PSR method, an evaluation in terms of Weighted Total Harmonic Distortion (WTHD) is performed. Simulation and experimental tests are conducted in comparison with the well known FWS, highlighting the interest in the proposed PSR strategy.}
}
@article{MANISCALCO2005305,
title = {The Cradle of Thought: Exploring the Origins of Thinking.},
journal = {Journal of the American Academy of Child & Adolescent Psychiatry},
volume = {44},
number = {3},
pages = {305},
year = {2005},
issn = {0890-8567},
doi = {https://doi.org/10.1097/00004583-200503000-00019},
url = {https://www.sciencedirect.com/science/article/pii/S0890856709614805},
author = {Joshua Maniscalco}
}
@article{NEDYALKOVA20249,
title = {Progress and future of the computational design of antimicrobial peptides (AMPs): bio-inspired functional molecules},
journal = {Digital Discovery},
volume = {3},
number = {1},
pages = {9-22},
year = {2024},
issn = {2635-098X},
doi = {https://doi.org/10.1039/d3dd00186e},
url = {https://www.sciencedirect.com/science/article/pii/S2635098X24000317},
author = {Miroslava Nedyalkova and Andrew S. Paluch and Diana Potes Vecini and Marco Lattuada},
abstract = {The effectiveness of antibiotics is greatly enhanced by their ability to target invasive organisms involved in the ancient evolutionary battle between hosts and pathogens. Conventional antibiotics no longer offer adequate protection due to the evolution of strategies to evade them. As a result, efforts are needed to design novel replacement antibiotics, making them unique from most other forms of drug development. As drug discovery costs have steadily increased along with the need for novel antibiotics, the interest in antimicrobial peptides (AMPs) as alternative antimicrobial treatments has grown in recent years. As a complement to experimental high-throughput screening, computational methods have become essential in hit and lead discovery in pharmaceutical research. It may be possible to access unexplored chemical space with customized virtual compound libraries. It has been questioned whether screening billions of molecules virtually with the risk of false positives is practical despite their unlimited potential size. In terms of finding novel chemical compounds capable of solving many global problems, machine learning, deep learning, and generative models hold significant promise. It is anticipated that the current challenges and limitations about the applicability of the stated approaches will be overcome in the coming years. However, plenty of advances are still required to achieve their full potential. In this perspective, we review the previous and ongoing work based on the latest scientific breakthroughs and technologies that could offer new opportunities and alternative strategies for developing novel AMPs.}
}
@article{YIM2024100321,
title = {Artificial intelligence literacy in primary education: An arts-based approach to overcoming age and gender barriers},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100321},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100321},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24001243},
author = {Iris Heung Yue Yim},
keywords = {Artificial intelligence, AI literacy education, AI thinking, Primary school students, Arts-based pedagogy, Age and gender difference},
abstract = {Artificial Intelligence (AI) literacy education was previously taught primarily at the university and secondary school levels but has recently started to be expanded to primary school settings. When available at the primary school level, AI literacy is often taught within computer science courses, which may potentially reinforce gender stereotypes and discourage female students' engagement. In AI literacy education, the predominant teaching methods are constructivist approaches, which, while effective in fostering active learning, heavily emphasize technical skills and are therefore limited in their pedagogical scope, as they underplay other important questions, such as disinformation, data justice, and AI's ethical and societal implications. The lack of a clear definition of AI literacy for primary education also raises questions about what to teach and how to teach it. Additionally, little attention has been devoted to understanding gender differences in learning outcomes within AI literacy primary education. This study advocates the use of an arts-based transdisciplinary approach for teaching AI literacy to 25 primary school students. A pilot study utilizing mixed methods was conducted to assess the effectiveness of this arts-based approach. Quantitative analysis through a paired t-test revealed a statistically significant improvement in AI literacy among students participating in knowledge tests. Moreover, the results of the Mann‒Whitney and Kruskal‒Wallis tests indicated that gender and age did not impact pre- and post-knowledge test scores. Qualitative analyses further revealed the pedagogical benefits of the arts-based approach, demonstrating that students enhance their conceptual understanding of AI literacy by reflecting on their artifacts. This study contributes to the literature by providing evidence with a small sample size that the arts-based approach can overcome age and gender barriers to accessing AI literacy education and can serve as a means to teach AI thinking.}
}
@article{CHANG201467,
title = {Understanding the paradigm shift to computational social science in the presence of big data},
journal = {Decision Support Systems},
volume = {63},
pages = {67-80},
year = {2014},
note = {1. Business Applications of Web of Things 2. Social Media Use in Decision Making},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2013.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S0167923613002212},
author = {Ray M. Chang and Robert J. Kauffman and YoungOk Kwon},
keywords = {Analytics, Big data, Computational social science, Data analytics, Interdisciplinary research, Managerial decision-making, Paradigm shift},
abstract = {The era of big data has created new opportunities for researchers to achieve high relevance and impact amid changes and transformations in how we study social science phenomena. With the emergence of new data collection technologies, advanced data mining and analytics support, there seems to be fundamental changes that are occurring with the research questions we can ask, and the research methods we can apply. The contexts include social networks and blogs, political discourse, corporate announcements, digital journalism, mobile telephony, home entertainment, online gaming, financial services, online shopping, social advertising, and social commerce. The changing costs of data collection and the new capabilities that researchers have to conduct research that leverages micro-level, meso-level and macro-level data suggest the possibility of a scientific paradigm shift toward computational social science. The new thinking related to empirical regularities analysis, experimental design, and longitudinal empirical research further suggests that these approaches can be tailored for rapid acquisition of big data sets. This will allow business analysts and researchers to achieve frequent, controlled and meaningful observations of real-world phenomena. We discuss how our philosophy of science should be changing in step with the times, and illustrate our perspective with comparisons between earlier and current research inquiry. We argue against the assertion that theory no longer matters and offer some new research directions.}
}
@article{ZHANG2022111493,
title = {mechanoChemML: A software library for machine learning in computational materials physics},
journal = {Computational Materials Science},
volume = {211},
pages = {111493},
year = {2022},
issn = {0927-0256},
doi = {https://doi.org/10.1016/j.commatsci.2022.111493},
url = {https://www.sciencedirect.com/science/article/pii/S0927025622002531},
author = {X. Zhang and G.H. Teichert and Z. Wang and M. Duschenes and S. Srivastava and E. Livingston and J. Holber and M. Faghih Shojaei and A. Sundararajan and K. Garikipati},
keywords = {Machine learning software library, Machine learning workflows, Computational materials physics, Partial differential equation solvers, Scientific software},
abstract = {We present mechanoChemML, a machine learning software library for computational materials physics. mechanoChemML is designed to function as an interface between platforms that are widely used for machine learning on one hand, and others for solution of partial differential equations-based models of physics. Of special interest here, and the focus of mechanoChemML, are applications to computational materials physics. These typically feature the coupled solution of material transport, reaction, phase transformation, mechanics, heat transport and electrochemistry. Central to the organization of mechanoChemML are machine learning workflows that arise in the context of data-driven computational materials physics. The mechanoChemML code structure is described, the machine learning workflows are laid out and their application to the solution of several problems in materials physics is outlined.}
}
@article{BERGER2022781,
title = {What are the keys to succeeding as a computational biologist in today’s research climate?},
journal = {Cell Systems},
volume = {13},
number = {10},
pages = {781-785},
year = {2022},
issn = {2405-4712},
doi = {https://doi.org/10.1016/j.cels.2022.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S2405471222004008},
author = {Bonnie Berger and Dechao Tian and Wei Vivian Li and Mohammed El-Kebir and Alexandru I. Tomescu and Ritambhara Singh and Niko Beerenwinkel and Yu Li and Christina Boucher and Ziv Bar-Joseph}
}
@article{YOSHIDA2023102799,
title = {Computational role of sleep in memory reorganization},
journal = {Current Opinion in Neurobiology},
volume = {83},
pages = {102799},
year = {2023},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2023.102799},
url = {https://www.sciencedirect.com/science/article/pii/S0959438823001241},
author = {Kensuke Yoshida and Taro Toyoizumi},
abstract = {Sleep is considered to play an essential role in memory reorganization. Despite its importance, classical theoretical models did not focus on some sleep characteristics. Here, we review recent theoretical approaches investigating their roles in learning and discuss the possibility that non-rapid eye movement (NREM) sleep selectively consolidates memory, and rapid eye movement (REM) sleep reorganizes the representations of memories. We first review the possibility that slow waves during NREM sleep contribute to memory selection by using sequential firing patterns and the existence of up and down states. Second, we discuss the role of dreaming during REM sleep in developing neuronal representations. We finally discuss how to develop these points further, emphasizing the connections to experimental neuroscience and machine learning.}
}
@article{DESAI2020893,
title = {Commentary: Flow Through Dynamic Thinking},
journal = {Seminars in Thoracic and Cardiovascular Surgery},
volume = {32},
number = {4},
pages = {893-894},
year = {2020},
issn = {1043-0679},
doi = {https://doi.org/10.1053/j.semtcvs.2020.06.051},
url = {https://www.sciencedirect.com/science/article/pii/S1043067920302458},
author = {Manan H. Desai and Aybala Tongut and Can Yerebakan}
}
@article{MANNILA2023100132,
title = {Student and teacher co-agency when combining CT with arts and design in a cross-curricular project},
journal = {Computers and Education Open},
volume = {4},
pages = {100132},
year = {2023},
issn = {2666-5573},
doi = {https://doi.org/10.1016/j.caeo.2023.100132},
url = {https://www.sciencedirect.com/science/article/pii/S2666557323000101},
author = {Linda Mannila and Teemu Leinonen and Merja Bauters and Marjaana Veermans},
keywords = {K-12 education, Computational thinking, Cross-curricular projects, Arts and design},
abstract = {The technological development has raised awareness for the importance of digital competence and computational thinking (CT) to understand the digital world and has resulted in revised curricula in many countries. In Finland, a new curriculum for grades 1–9 came into force in 2016 introducing digital competence (including programming) to be integrated in other subjects. Most teachers lack prior experience in programming and there is a need for suitable instructional models. This article presents a cross-curricular teaching sequence and the results from a case study conducted in four Finnish schools. Students in grades 4–6 collaboratively worked on a project combining arts, design and CT with other subjects. The results show that students demonstrated several CT abilities while working on their projects, in particular creativity, tinkering and debugging. The findings also indicate that teachers and students learned together (co-agency) and suggest that models like the teaching sequence can help and encourage teachers to integrate programming and CT in a cross-curricular manner. Still, the teachers’ knowledge, ambition level and understanding of the task at hand, as well as the organizational support appear to play a notable role when planning and carrying out projects of this kind. While CT is commonly seen as developed through programming, the teaching sequence seems to have fostered CT abilities through the project as a whole, with programming playing the role of a tool or a glue depending on the time available, and the students’ skill and ambition level.}
}
@article{BONANNI202525,
title = {Simplifying the calculation of residual properties using numerical methods},
journal = {Education for Chemical Engineers},
volume = {50},
pages = {25-31},
year = {2025},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2024.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S1749772824000253},
author = {Sebastián Bonanni and Tomás Melloni and J. Pablo Tomba},
keywords = {, , , },
abstract = {The calculation of thermodynamic properties using Residual properties (Rp) is a key element in Chemical Engineering curricula. Traditionally, the derivation of Rp involves solving analytical expressions through partial differentiation and integration of generalized thermodynamics equations combined with specific equations of state (EoS). This method is mathematically demanding, increasing cognitive load and often limiting classroom discussions to simpler EoS for which analytical solutions are readily available in textbooks. To enhance student engagement and reduce the time spent on complex derivations, we propose a simplified approach that numerically evaluates Rp using standard software tools. This approach not only minimizes the mathematical effort, allowing students to focus on thermodynamic concepts, but also extends the applicability to more complex EoS that are not covered in textbooks. By significantly reducing the instructional time required for Rp calculations, this method fosters critical thinking, promotes autonomy, and can be applied to other fundamental thermodynamics topics that traditionally rely on analytical expressions, such as multicomponent solution models.}
}
@incollection{PINKY2024379,
title = {Chapter 27 - Recent advances in computational modeling: An appraisal of stem cell and tissue engineering research},
editor = {Pawan Kumar Raghav and Rajesh Kumar and Anjali Lathwal and Navneet Sharma},
booktitle = {Computational Biology for Stem Cell Research},
publisher = {Academic Press},
pages = {379-394},
year = {2024},
isbn = {978-0-443-13222-3},
doi = {https://doi.org/10.1016/B978-0-443-13222-3.00006-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044313222300006X},
author = { Pinky and  Neha and Suhel Parvez},
keywords = {3D printing technology, Common modeling approaches, Computational models, Stem cell biology, Tissue engineering},
abstract = {Stem cell tissue engineering is an interdisciplinary area that employs engineering and biological science concepts to build biomimetic alternatives for the maintenance, improvement, and restoration of tissue function. The current developments in advanced technologies (bioprinting and biomanufacturing) are the most needed conditions for manufacturing scaffolds, along with their morphometric properties. With these advancements, the computational models used to produce tissue-engineered implants have become essential. Understanding the history of stem cells and how their use is implemented in disease modeling and pharmaceutical advancements is driving the rapid expansion of the computational biology market. This chapter explores various computational methods for stem cell-based modeling while focusing on computer-aided design in tissue engineering. Briefly, we introduce multiscale computational modeling, the process of cellular differentiation, reprogramming, and related tools and software, describe computer-aided tissue engineering, and also provide the strengths, weaknesses, opportunities and threats analysis.}
}
@article{KOPPL2008837,
title = {Thinking impossible things: A review essay},
journal = {Journal of Economic Behavior & Organization},
volume = {66},
number = {3},
pages = {837-847},
year = {2008},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2007.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S0167268107000340},
author = {Roger Koppl}
}
@article{AYDOGAN2018100,
title = {The effect of oxytocin on group formation and strategic thinking in men},
journal = {Hormones and Behavior},
volume = {100},
pages = {100-106},
year = {2018},
issn = {0018-506X},
doi = {https://doi.org/10.1016/j.yhbeh.2018.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0018506X17302908},
author = {Gökhan Aydogan and Andrea Jobst and Fabian Loy and Sandra Dehning and Peter Zill and Norbert Müller and Martin Kocher},
abstract = {Decision-making in groups is a remarkable and decisive element of human societies. Humans are able to organize themselves in groups, engage in collaborative decision-making processes and arrive at a binding agreement, even in the absence of unanimous consent. However, the transfer of decision-making autonomy requires a willingness to deliberately expose oneself to the decisions of others. A lack of trust in the abilities of others or of the underlying decision-making process, i.e. public trust, can lead to a breakdown of organizations in political or economic domains. Recent studies indicate that the biological basis of trust on an individual level is related to Oxytocin, an endogenous neuropeptide and hormone, which is also associated with pro-social behavior and positive conflict resolution. However, little is known about the effects of Oxytocin on the inclination of individuals to form or join groups and to deliberately engage in collaborative decision-making processes. Here, we show that intranasal administration of Oxytocin (n = 60) compared to placebo (n = 60) in males causes an adverse effect on the choice for forming groups in the presence of a competitive environment. In particular, Oxytocin negatively affects the willingness to work collaboratively in a p-Beauty contest game, whereas the effect is most pronounced for participants with relatively high strategic sophistication. Since our data provide initial evidence that Oxytocin has a positive effect on strategic thinking and performance in the p-Beauty contest game, we argue that the adverse effect on group formation might be rooted in an enhanced strategic sophistication of participants treated with Oxytocin.}
}
@incollection{WALLER2005589,
title = {Bayesian Thinking in Spatial Statistics},
editor = {D.K. Dey and C.R. Rao},
series = {Handbook of Statistics},
publisher = {Elsevier},
volume = {25},
pages = {589-622},
year = {2005},
booktitle = {Bayesian Thinking},
issn = {0169-7161},
doi = {https://doi.org/10.1016/S0169-7161(05)25020-4},
url = {https://www.sciencedirect.com/science/article/pii/S0169716105250204},
author = {Lance A. Waller},
abstract = {In the sections below we review basic motivations for spatial statistical analysis, review three general categories of data structure and associated inferential questions, and describe Bayesian methods for achieving inference. Our goal is to highlight similarities across spatial analytic methods, particularly with regards to how hierarchical probability structures often link approaches developed in one area of spatial analysis to components within other areas. By choosing to highlight similarities, we focus on general concepts in spatial inference, and often defer details of several interesting and current threads of development to the relevant literature. We conclude with a listing of some of these developing areas of interest and references for further reading.}
}
@article{WIGGINS202057,
title = {Response to commentaries on “Creativity, information, consciousness: The information dynamics of thinking”},
journal = {Physics of Life Reviews},
volume = {34-35},
pages = {57-61},
year = {2020},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2020.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S1571064520300634},
author = {Geraint A. Wiggins}
}
@article{NYBLOM201430,
title = {Making plans or “just thinking about the trip”? Understanding people’s travel planning in practice},
journal = {Journal of Transport Geography},
volume = {35},
pages = {30-39},
year = {2014},
issn = {0966-6923},
doi = {https://doi.org/10.1016/j.jtrangeo.2014.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S0966692314000040},
author = {Åsa Nyblom},
keywords = {Travel planning, Travel information, Sustainable social practices, Practice theory},
abstract = {ICT solutions have been proposed as a means for changing environmentally unfavourable traffic behaviour by providing better, real-time and more accessible travel information. However, prevailing models of travel choice and travel behaviour tend to overemphasise the impact and importance of information and the individualistic perspective. The issue of choice and travel planning in everyday life situations, and how information is used and acted on in these processes, was examined in a qualitative study in Stockholm, Sweden. Practice Theory was used as the theoretical framework for the study. Interviews were supplemented with an explorative diary and photo assignment to bring unreflected choices and actions of planning travel to the conscious level. The results showed that travel planning involves the immediate situation where planning and decisions are made, but also aspirations, cognitive/time/material limitations, social norms and social relations that extend widely in time and space. Definitions of travel planning and travel information based on the situated practices of planning are suggested. In the muddle of everyday life, travel planning takes place in the brief moments where circumstances at different levels – time, place, the social realm - interact and are considered or directly acted upon. In the development of new ICT-based travel information services, the role of technology in changing normal practices should be considered.}
}
@article{BEWAJI2024100115,
title = {A computational model of bilateral credit limits in payment systems and other financial market infrastructures},
journal = {Latin American Journal of Central Banking},
volume = {5},
number = {1},
pages = {100115},
year = {2024},
issn = {2666-1438},
doi = {https://doi.org/10.1016/j.latcb.2023.100115},
url = {https://www.sciencedirect.com/science/article/pii/S2666143823000364},
author = {Oluwasegun Bewaji},
keywords = {Agent-based computational economics, Market microstructure, High value payment systems, Financial market infrastructures, Bilateral credit limits, Intra-day liquidity management, Stochastic games, Multi-agent reinforcement learning},
abstract = {This paper provides the first steps towards a theoretical and structural modelling framework through which optimal decision making in financial market infrastructures such as payments clearing and settlement systems can be assessed from a market microstructure perspective. In particular, the paper focuses on the application of agent-based computational economics and stochastic games in modelling the bilateral credit limit establishing behaviour of Participants in loss sharing arrangements within financial market infrastructures such as the Canadian Large Value Payments System (LVTS). With specific focus on the LVTS, the paper presents a structural model where the payments system represents a market in which bilateral credit limits are the pricing mechanisms for intraday liquidity provisioning and the credit risk arising from the loss sharing arrangement. The data-driven stochastic game framework further illustrates how payments data, in conjunction with other financial market and credit data, can be used to assess emergent macroscopic outcomes in clearing and settlement systems from the underpinning interactions of autonomous decision making agents. The paper speaks to potential policy issues such as the effectiveness of policy levers such as the System-Wide Percentage, regulatory concerns around procyclicality and free-riding arising from the market microstructure behaviours, and design of the System.}
}
@article{DENOBEL2024109011,
title = {Biophysics-inspired spike rate adaptation for computationally efficient phenomenological nerve modeling},
journal = {Hearing Research},
volume = {447},
pages = {109011},
year = {2024},
issn = {0378-5955},
doi = {https://doi.org/10.1016/j.heares.2024.109011},
url = {https://www.sciencedirect.com/science/article/pii/S0378595524000649},
author = {Jacob {de Nobel} and Savine S.M. Martens and Jeroen J. Briaire and Thomas H.W. Bäck and Anna V. Kononova and Johan H.M. Frijns},
keywords = {Neural model, Spike rate adaptation, Auditory nerve, Cochlear implants, Optimization, Evolutionary algorithms},
abstract = {This study introduces and evaluates the PHAST+ model, part of a computational framework designed to simulate the behavior of auditory nerve fibers in response to the electrical stimulation from a cochlear implant. PHAST+ incorporates a highly efficient method for calculating accommodation and adaptation, making it particularly suited for simulations over extended stimulus durations. The proposed method uses a leaky integrator inspired by classic biophysical nerve models. Through evaluation against single-fiber animal data, our findings demonstrate the model’s effectiveness across various stimuli, including short pulse trains with variable amplitudes and rates. Notably, the PHAST+ model performs better than its predecessor, PHAST (a phenomenological model by van Gendt et al.), particularly in simulations of prolonged neural responses. While PHAST+ is optimized primarily on spike rate decay, it shows good behavior on several other neural measures, such as vector strength and degree of adaptation. The future implications of this research are promising. PHAST+ drastically reduces the computational burden to allow the real-time simulation of neural behavior over extended periods, opening the door to future simulations of psychophysical experiments and multi-electrode stimuli for evaluating novel speech-coding strategies for cochlear implants.}
}
@article{SWANSON2005313,
title = {Techniques: Subcellular imaging technologies – microscopic visual thinking},
journal = {Current Opinion in Microbiology},
volume = {8},
number = {3},
pages = {313-315},
year = {2005},
note = {Ecology and industrial microbiology/Edited by Sergio Sánchez and Betty Olson · Techniques/Edited by Peter J Peters and Joel Swanson},
issn = {1369-5274},
doi = {https://doi.org/10.1016/j.mib.2005.04.015},
url = {https://www.sciencedirect.com/science/article/pii/S136952740500055X},
author = {Joel A Swanson and Peter J Peters}
}
@article{MAYO2024105513,
title = {Dynamic mutual predictions during social learning: A computational and interbrain model},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {157},
pages = {105513},
year = {2024},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2023.105513},
url = {https://www.sciencedirect.com/science/article/pii/S0149763423004827},
author = {Oded Mayo and Simone Shamay-Tsoory},
keywords = {Social learning, Interbrain synchrony, Interbrain plasticity, Empathy, Predictive coding, Mutual predictions},
abstract = {During social interactions, we constantly learn about the thoughts, feelings, and personality traits of our interaction partners. Learning in social interactions is critical for bond formation and acquiring knowledge. Importantly, this type of learning is typically bi-directional, as both partners learn about each other simultaneously. Here we review the literature on social learning and propose a new computational and neural model characterizing mutual predictions that take place within and between interactions. According to our model, each partner in the interaction attempts to minimize the prediction error of the self and the interaction partner. In most cases, these inferential models become similar over time, thus enabling mutual understanding to develop. At the neural level, this type of social learning may be supported by interbrain plasticity, defined as a change in interbrain coupling over time in neural networks associated with social learning, among them the mentalizing network, the observation-execution system, and the hippocampus. The mutual prediction model constitutes a promising means of providing empirically verifiable accounts of how relationships develop over time.}
}
@article{BANKER2022104617,
title = {Disrupted computations of social control in individuals with obsessive-compulsive and misophonia symptoms},
journal = {iScience},
volume = {25},
number = {7},
pages = {104617},
year = {2022},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2022.104617},
url = {https://www.sciencedirect.com/science/article/pii/S2589004222008896},
author = {Sarah M. Banker and Soojung Na and Jacqueline Beltrán and Harold W. Koenigsberg and Jennifer H. Foss-Feig and Xiaosi Gu and Daniela Schiller},
keywords = {Biological sciences, Neuroscience, Behavioral neuroscience, Clinical neuroscience, Sensory neuroscience},
abstract = {Summary
Misophonia is a disorder in which certain sounds produced by other people lead to intense negative reactions. It remains unknown how misophonia relates to other psychiatric conditions or impairments. To identify latent constructs underlying symptoms, we conducted a factor analysis consisting of items from questionnaires assessing symptoms of misophonia and other psychiatric conditions. One thousand forty-two participants completed the questionnaires and a social exchange task in which they either could (“controllable”) or could not (“uncontrollable”) influence future monetary offers from other people. Misophonia and obsessive-compulsive (OC) symptoms loaded onto the same factor. Compared with individuals with low Miso-OC factor scores, individuals with high scores reported higher perceived controllability of their social interactions during the uncontrollable condition and stronger aversion to social norm violations in the uncontrollable compared with the controllable condition. Together, these results suggest misophonia, and OC symptoms share a latent psychiatric dimension characterized by aberrant computations of social controllability.}
}
@article{KURTHNELSON2023454,
title = {Replay and compositional computation},
journal = {Neuron},
volume = {111},
number = {4},
pages = {454-469},
year = {2023},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2022.12.028},
url = {https://www.sciencedirect.com/science/article/pii/S0896627322011254},
author = {Zeb Kurth-Nelson and Timothy Behrens and Greg Wayne and Kevin Miller and Lennart Luettgau and Ray Dolan and Yunzhe Liu and Philipp Schwartenbeck},
abstract = {Summary
Replay in the brain has been viewed as rehearsal or, more recently, as sampling from a transition model. Here, we propose a new hypothesis: that replay is able to implement a form of compositional computation where entities are assembled into relationally bound structures to derive qualitatively new knowledge. This idea builds on recent advances in neuroscience, which indicate that the hippocampus flexibly binds objects to generalizable roles and that replay strings these role-bound objects into compound statements. We suggest experiments to test our hypothesis, and we end by noting the implications for AI systems which lack the human ability to radically generalize past experience to solve new problems.}
}
@article{BANK2014540,
title = {Thinking too positive? Revisiting current methods of population genetic selection inference},
journal = {Trends in Genetics},
volume = {30},
number = {12},
pages = {540-546},
year = {2014},
issn = {0168-9525},
doi = {https://doi.org/10.1016/j.tig.2014.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S0168952514001589},
author = {Claudia Bank and Gregory B. Ewing and Anna Ferrer-Admettla and Matthieu Foll and Jeffrey D. Jensen},
keywords = {natural selection, background selection, population genetic inference, evolution, computational biology},
abstract = {In the age of next-generation sequencing, the availability of increasing amounts and improved quality of data at decreasing cost ought to allow for a better understanding of how natural selection is shaping the genome than ever before. However, alternative forces, such as demography and background selection (BGS), obscure the footprints of positive selection that we would like to identify. In this review, we illustrate recent developments in this area, and outline a roadmap for improved selection inference. We argue (i) that the development and obligatory use of advanced simulation tools is necessary for improved identification of selected loci, (ii) that genomic information from multiple time points will enhance the power of inference, and (iii) that results from experimental evolution should be utilized to better inform population genomic studies.}
}
@article{KOVALCHUK2023102102,
title = {The computational planet},
journal = {Journal of Computational Science},
volume = {72},
pages = {102102},
year = {2023},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2023.102102},
url = {https://www.sciencedirect.com/science/article/pii/S187775032300162X},
author = {Sergey V. Kovalchuk and Clélia {de Mulatier} and Derek Groen and Maciej Paszyński and Valeria V. Krzhizhanovskaya and Jack Dongarra and Peter M.A. Sloot}
}
@article{ABEL2024114607,
title = {Mapping the spatial turn in social science energy research. A computational literature review},
journal = {Renewable and Sustainable Energy Reviews},
volume = {201},
pages = {114607},
year = {2024},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2024.114607},
url = {https://www.sciencedirect.com/science/article/pii/S1364032124003332},
author = {Dennis Abel and Jonas Lieth and Stefan Jünger},
keywords = {Spatial analysis, Geography, Energy transition, Climate change, Computational text analysis},
abstract = {Social science scholars have identified a “spatial turn” in energy research over the last three decades. This article systematically reviews the literature on energy, space, and place and decomposes this inter- and transdisciplinary academic landscape. A corpus of 7879 research articles related to spatial perspectives on energy issues is processed and analyzed based on a step-by-step framework for the automated, transparent, and reproducible analysis of large sets of research articles. For this purpose, natural language processing approaches, including named entity recognition and structural topic modeling, are adopted. Based on this large-n selection procedure, selected topics related to the geographical political economy of the energy transition are reviewed in detail. The review maps the geographical scope and scale of the research field, highlights major topics, and shows the distribution of methodological approaches and the role of geographic information systems in this research field. The results show a growing body of literature attentive to socio-spatial variation and the uneven spatiality of energy systems. Nevertheless, uneven geographical distributions of studies with a strong focus on the major industrialized countries and generally only a few comparative cases were also found. In particular, research on the energy transition and renewable energy policy is strongly informed by studies addressing the Global North, limiting the evidence base for other regional contexts from the Global South.}
}
@article{CHEN2024769,
title = {The causal structure and computational value of narratives},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {8},
pages = {769-781},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S1364661324000822},
author = {Janice Chen and Aaron M. Bornstein},
keywords = {narratives, causality, reasoning, value, credit assignment, plausibility},
abstract = {Many human behavioral and brain imaging studies have used narratively structured stimuli (e.g., written, audio, or audiovisual stories) to better emulate real-world experience in the laboratory. However, narratives are a special class of real-world experience, largely defined by their causal connections across time. Much contemporary neuroscience research does not consider this key property. We review behavioral and neuroscientific work that speaks to how causal structure shapes comprehension of and memory for narratives. We further draw connections between this work and reinforcement learning, highlighting how narratives help link causes to outcomes in complex environments. By incorporating the plausibility of causal connections between classes of actions and outcomes, reinforcement learning models may become more ecologically valid, while simultaneously elucidating the value of narratives.}
}
@article{HEMMO202364,
title = {Is the mind in the brain in contemporary computational neuroscience?},
journal = {Studies in History and Philosophy of Science},
volume = {100},
pages = {64-80},
year = {2023},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2023.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S0039368123000870},
author = {Meir Hemmo and Orly Shenker},
keywords = {Mind-brain identity, Indeterminacy of computation, Multiple-computations, Multiple-realization, Physicalism},
abstract = {According to contemporary computational neuroscience the mental is associated with computations implemented in the brain. We analyze in physical terms based on recent results in the foundations of statistical mechanics two well-known (independent) problems that arise for this approach: the problem of multiple-computations and the problem of multiple-realization. We show that within the computational theory of the mind the two problems are insoluble by the physics of the brain. We further show that attempts to solve the problems by the interactions of the systems implementing the computations with an environment (in or outside the brain) must introduce non-physical factors, and therefore fail on physical grounds. We also show that the problems are endemic and pertain to other forms of functional theories of the mind, most notably, causal functionalism. Finally, we propose a physicalist reductive identity theory, which is a generalization of statistical mechanics for all the special sciences, and show that only a theory of this kind can provide physical solutions to the above two problems in computational neuroscience. We conclude that functionalism in the theory of mind must be replaced with a reductive identity theory. This result has far-reaching implications with respect to the research programs in brain science.}
}
@article{BHATT2005424,
title = {Self-referential thinking and equilibrium as states of mind in games: fMRI evidence},
journal = {Games and Economic Behavior},
volume = {52},
number = {2},
pages = {424-459},
year = {2005},
note = {Special Issue on Neuroeconomics},
issn = {0899-8256},
doi = {https://doi.org/10.1016/j.geb.2005.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S0899825605000308},
author = {Meghana Bhatt and Colin F. Camerer},
abstract = {Sixteen subjects' brain activity were scanned using fMRI as they made choices, expressed beliefs, and expressed iterated 2nd-order beliefs (what they think others believe they will do) in eight games. Cingulate cortex and prefrontal areas (active in “theory of mind” and social reasoning) are differentially activated in making choices versus expressing beliefs. Forming self-referential 2nd-order beliefs about what others think you will do seems to be a mixture of processes used to make choices and form beliefs. In equilibrium, there is little difference in neural activity across choice and belief tasks; there is a purely neural definition of equilibrium as a “state of mind.” “Strategic IQ,” actual earnings from choices and accurate beliefs, is negatively correlated with activity in the insula, suggesting poor strategic thinkers are too self-focused, and is positively correlated with ventral striatal activity (suggesting that high IQ subjects are spending more mental energy predicting rewards).}
}
@incollection{FISH2024303,
title = {2.10 - Predictive Multiscale Paradigm for Computational Design Certification},
editor = {Vadim Silberschmidt},
booktitle = {Comprehensive Mechanics of Materials (First Edition)},
publisher = {Elsevier},
edition = {First Edition},
address = {Oxford},
pages = {303-351},
year = {2024},
isbn = {978-0-323-90647-0},
doi = {https://doi.org/10.1016/B978-0-323-90646-3.00052-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780323906463000526},
author = {Jacob Fish and Karel Matouš and Roger Ghanem and WaiChing Sun},
keywords = {Artificial Intelligence, Certification, Data creation, Design, Icme, Industry 4.0, Machine learning, Manufacturing, Multiscale, Statistical framework, Validation, Verification},
abstract = {The book chapter offers a detailed exploration of the significant influence that a predictive multiscale paradigm has on computational design certification, particularly in the realms of Industry 4.0 and the Industrial Internet of Things (IIoT). It surveys the latest advancements in multiscale methodologies, data creation, and statistical framework for multiscale certification, underscoring the pivotal role of artificial intelligence within this paradigm. The narrative underscores how this predictive multiscale approach propels the creation of novel product designs and eco-friendly manufacturing practices, crucial for meeting the emerging demands of engineering and materials science.Throughout, the book chapter underscores the significance of Integrated Computational Materials Engineering (ICME), which melds computational science, applied mathematics, and statistics into a coherent framework for certifying products. This strategy is paramount for overcoming the intricate challenges associated with the properties of materials at multiple scales, system efficacy, and the mechanisms of failure across various scales and scenarios.In essence, the book chapter envisions a future where the convergence of science, technology, and innovation propels the fields of manufacturing and design forward through the use of comprehensive computational tools, and cutting-edge manufacturing technologies. This fusion is projected to usher in a new epoch of innovation and operational efficiency in the development of products.}
}
@article{KORUKONDA2003240,
title = {Taking stock of Turing test: a review, analysis, and appraisal of issues surrounding thinking machines},
journal = {International Journal of Human-Computer Studies},
volume = {58},
number = {2},
pages = {240-257},
year = {2003},
issn = {1071-5819},
doi = {https://doi.org/10.1016/S1071-5819(02)00139-8},
url = {https://www.sciencedirect.com/science/article/pii/S1071581902001398},
author = {Appa Rao Korukonda},
keywords = {Turing test, artificial intelligence},
abstract = {The Turing test (TT) has provided the inspiration for the inception and rapid development of artificial intelligence (AI) as a discipline. Additionally, it provided a platform for what might be termed a spirited, enduring, and enlightening—albeit occasionally frustrating—rounds of debate on a broad range of questions. Turing, who proved to be much ahead of his time in more ways than one, predicted that it would be possible to develop machines capable of passing the TT in about 50 years time, that is just about now. Perhaps, Turing overestimated the rate of progress of technology, or of transformation of deeply entrenched paradigms of thought; but whatever the reason, his prediction about the feasibility of “thinking machines” is yet to come true in an engineering or in a symbolic-semantic sense. This paper presents a set of reflections on this and other predictions made by Turing and relates them to what has actually transpired in the 50 years since his original paper was published. Contributions of TT to the field of AI are assessed and directions for the future are presented.}
}
@article{FITRIANTO2016249,
title = {Modeling Asia's Child Mortality Rate: A Thinking of Human Development in Asia},
journal = {Procedia Economics and Finance},
volume = {35},
pages = {249-255},
year = {2016},
note = {7th International Economics & Business Management Conference (IEBMC 2015)},
issn = {2212-5671},
doi = {https://doi.org/10.1016/S2212-5671(16)00031-9},
url = {https://www.sciencedirect.com/science/article/pii/S2212567116000319},
author = {Anwar Fitrianto and Imam Hanafi and Tan Li Chui},
keywords = {Regression, Mortality rate, Backward elimination, Asia, Variable selection},
abstract = {Multiple linear regression model was employed to model child under age of five mortality rate and related factors in Asia of year 2010. Data analysis was carried out to find factors which influence the child mortality in Asia. Correlation analysis was done to check on the relationship among all the variables, as well as to identify the problem of multicollinearity in the data. Having fitted multiple linear regression, it was found that mortality rate of children under age of five in Asia countries are significantly influenced by percentage of case detection for all forms of tuberculosis, number of reported deaths on measles, number of population using an improved drinking water source, and number of birth trauma reported. Among those variable, it was identified that number of population using an improved drinking water source is the most important factor.}
}
@article{CHANG202322,
title = {A look into feedback neural computation upon collision selectivity},
journal = {Neural Networks},
volume = {166},
pages = {22-37},
year = {2023},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.06.039},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023003519},
author = {Zefang Chang and Qinbing Fu and Hao Chen and Haiyang Li and Jigen Peng},
keywords = {Bio-inspired, Collision selectivity, LGMD, Feedback neural computation, ON/OFF channels},
abstract = {Physiological studies have shown that a group of locust’s lobula giant movement detectors (LGMDs) has a diversity of collision selectivity to approaching objects, relatively darker or brighter than their backgrounds in cluttered environments. Such diversity of collision selectivity can serve locusts to escape from attack by natural enemies, and migrate in swarm free of collision. For computational studies, endeavours have been made to realize the diverse selectivity which, however, is still one of the most challenging tasks especially in complex and dynamic real world scenarios. The existing models are mainly formulated as multi-layered neural networks with merely feed-forward information processing, and do not take into account the effect of re-entrant signals in feedback loop, which is an essential regulatory loop for motion perception, yet never been explored in looming perception. In this paper, we inaugurate feedback neural computation for constructing a new LGMD-based model, named F-LGMD to look into the efficacy upon implementing different collision selectivity. Accordingly, the proposed neural network model features both feed-forward processing and feedback loop. The feedback control propagates output signals of parallel ON/OFF channels back into their starting neurons, thus makes part of the feed-forward neural network, i.e. the ON/OFF channels and the feedback loop form an iterative cycle system. Moreover, the feedback control is instantaneous, which leads to the existence of a fixed point whereby the fixed point theorem is applied to rigorously derive valid range of feedback coefficients. To verify the effectiveness of the proposed method, we conduct systematic experiments covering synthetic and natural collision datasets, and also online robotic tests. The experimental results show that the F-LGMD, with a unified network, can fulfil the diverse collision selectivity revealed in physiology, which not only reduces considerably the handcrafted parameters compared to previous studies, but also offers a both efficient and robust scheme for collision perception through feedback neural computation.}
}
@article{SCARR201755,
title = {Examining the temporo-mandibular joint from a biotensegrity perspective: A change in thinking},
journal = {Journal of Applied Biomedicine},
volume = {15},
number = {1},
pages = {55-62},
year = {2017},
issn = {1214-021X},
doi = {https://doi.org/10.1016/j.jab.2016.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S1214021X15300545},
author = {Graham Scarr and Helen Harrison},
keywords = {Biomechanics, Biotensegrity, Four-bar mechanism, Joint loading, Kinematic chain, Orthodontic, Temporomandibular, Tensegrity},
abstract = {The temporo-mandibular joint is a characteristic feature of mammalian development, and essential to mastication and speech, yet it causes more problems than any other joint in the body and remains the least understood. While it is generally accepted that the normal joint is loaded under compression, the problems and controversies surrounding this view remain unresolved and the disparity in opinion over its treatment continues. Although difficulties in the acquisition of reliable information have undoubtedly contributed to this situation, it is now considered that deficits in neural control and shortcomings in the underlying biomechanical theory and analysis have also played a part, and that a re-assessment from a different perspective could resolve these. Biotensegrity considers the TMJ from this position, where the mandible is suspended within a tensioned network that extends over a much wider anatomical field than is generally recognized and significant motion control is contained within the structure itself. It is an evolutionary-conserved arrangement that enables the system to rapidly respond to changing functional demands and provides a more complete model of joint physiology that can be used to guide further research.}
}
@article{LAZEBNIK2023110422,
title = {Computational applications of extended SIR models: A review focused on airborne pandemics},
journal = {Ecological Modelling},
volume = {483},
pages = {110422},
year = {2023},
issn = {0304-3800},
doi = {https://doi.org/10.1016/j.ecolmodel.2023.110422},
url = {https://www.sciencedirect.com/science/article/pii/S0304380023001539},
author = {Teddy Lazebnik},
keywords = {Agent-based simulation, Extended SIR model, Biomathematical modeling, Pandemics dynamics},
abstract = {Epidemiological-Mathematical models are powerful tools for estimating the course of a pandemic and exploring different scenarios through pandemic intervention policies (PIPs). These models are commonly developed to provide decision-support tools for policymakers who are forced to make difficult decisions in a timely manner. Done properly, these models are able to provide a safe, quick, and cheap solution for this challenge. There are numerous types of mathematical models for epidemiological disease spread and control. However, in order to become applicative tools for decision-making, the modelers of these models are required to overcome three computational challenges: efficiently define the model, develop it as computer software, and fit it into historical data. Performed efficiently, one can use the obtained tool to explore possible scenarios and PIPs. In this paper, we present a critical review of models that extend the Susceptible–Infected–Recovered (SIR) model and explore the efficiency of these models, their software characteristics, and model performance on real-world data. We further provide a guide for epidemiological-mathematical model development and implementation, exploring several modeling approaches and their respective implementation options. Lastly, we outline the current trends, limitations, and opportunities in this field. In particular, we find that the spatial properties of a model play a critical role in its accuracy and ability to explain historical pandemic spread, especially in the context of airborne diseases. Moreover, we show that agent-based simulations are preferable over partial/ordinary differential solvers when considering a highly-realistic pandemic model or focusing on a relatively small population size.}
}
@article{STUMPF202158,
title = {Statistical and computational challenges for whole cell modelling},
journal = {Current Opinion in Systems Biology},
volume = {26},
pages = {58-63},
year = {2021},
issn = {2452-3100},
doi = {https://doi.org/10.1016/j.coisb.2021.04.005},
url = {https://www.sciencedirect.com/science/article/pii/S2452310021000160},
author = {Michael P.H. Stumpf},
keywords = {Inference, Inverse problems, Synthetic biology, Reproducible modelling},
abstract = {Mathematical modelling of whole biological cells opens up new opportunities for fundamental and applied biology. In particular in the context of synthetic biology, it opens up the scope for rational engineering and design principles to be applied. But there are precious few such models available. Here I outline the challenges in the way of generating such whole cell models. The inference of parameters, the choice among competing models, and, first and foremost, the reliable construction of such models pose considerable challenges. Recent work in statistical inference, especially parameter estimation, and model selection, coupled to new computationally more efficient methods to simulate large (and stochastic) biochemical reaction systems will be pivotal for the generation of a new generation of whole cell models. But these need to be coupled to better ways of generating models de novo. I outline how this may be achieved, and why this is necessary.}
}
@incollection{SAHIN202431,
title = {Chapter Two - Computational psychiatry and AI - High hopes: heralded heights or hollow hype?},
editor = {Marcello Ienca and Georg Starke},
series = {Developments in Neuroethics and Bioethics},
publisher = {Academic Press},
volume = {7},
pages = {31-47},
year = {2024},
booktitle = {Brains and Machines: Towards a Unified Ethics of AI and Neuroscience},
issn = {2589-2959},
doi = {https://doi.org/10.1016/bs.dnb.2024.02.013},
url = {https://www.sciencedirect.com/science/article/pii/S2589295924000183},
author = {Derya Şahin},
keywords = {computational psychiatry, epistemology, reductionism, psychiatry ethics, medical ethics, AI ethics in health, fairness, bias, explainability},
abstract = {Computational psychiatry is a multidisciplinary field that utilizes mathematical, statistical, and computational methods to better understand mental disorders. The integration of AI in computational psychiatry has opened new possibilities for creating more precise and nuanced models of psychiatric disorders, simultaneously raising important ethical concerns related to privacy, data security, transparency, bias, alignment, and limits of computational psychiatry. This chapter provides an overview of the ethical considerations and challenges of computational psychiatry and the use of AI, specifically related to nosology, reductionism, and data constraints specific to psychiatry. Finally, it questions the epistemological limits of computational psychiatry.}
}
@article{MASEL2007216,
title = {A Bayesian model of quasi-magical thinking can explain observed cooperation in the public good game},
journal = {Journal of Economic Behavior & Organization},
volume = {64},
number = {2},
pages = {216-231},
year = {2007},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2005.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167268106000977},
author = {Joanna Masel},
keywords = {Conditional expected utility, Rationality},
abstract = {Models of learning, reciprocity and altruism cannot explain all aspects of observed contributions in the public good game. Here a new model is described in which players recognize a correlation between their own contribution and the likely contributions of other players. The correlation is calculated by treating a player's own conjectured contribution just like any other data point within a learning model. Although players recognize that this correlation is not causal, they nevertheless choose to maximize expected utility conditional on their own action rather than standard expected utility. Results from the model explain previously puzzling quantitative trends in the data.}
}
@article{LI2024,
title = {Investigating Health and Well-Being Challenges Faced by an Aging Workforce in the Construction and Nursing Industries: Computational Linguistic Analysis of Twitter Data},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/49450},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124003030},
author = {Weicong Li and Liyaning Maggie Tang and Jed Montayre and Celia B Harris and Sancia West and Mark Antoniou},
keywords = {social media, construction, nursing, aging, health and well-being, Twitter},
abstract = {Background
Construction and nursing are critical industries. Although both careers involve physically and mentally demanding work, the risks to workers during the COVID-19 pandemic are not well understood. Nurses (both younger and older) are more likely to experience the ill effects of burnout and stress than construction workers, likely due to accelerated work demands and increased pressure on nurses during the COVID-19 pandemic. In this study, we analyzed a large social media data set using advanced natural language processing techniques to explore indicators of the mental status of workers across both industries before and during the COVID-19 pandemic.
Objective
This social media analysis aims to fill a knowledge gap by comparing the tweets of younger and older construction workers and nurses to obtain insights into any potential risks to their mental health due to work health and safety issues.
Methods
We analyzed 1,505,638 tweets published on Twitter (subsequently rebranded as X) by younger and older (aged <45 vs >45 years) construction workers and nurses. The study period spanned 54 months, from January 2018 to June 2022, which equates to approximately 27 months before and 27 months after the World Health Organization declared COVID-19 a global pandemic on March 11, 2020. The tweets were analyzed using big data analytics and computational linguistic analyses.
Results
Text analyses revealed that nurses made greater use of hashtags and keywords (both monograms and bigrams) associated with burnout, health issues, and mental health compared to construction workers. The COVID-19 pandemic had a pronounced effect on nurses’ tweets, and this was especially noticeable in younger nurses. Tweets about health and well-being contained more first-person singular pronouns and affect words, and health-related tweets contained more affect words. Sentiment analyses revealed that, overall, nurses had a higher proportion of positive sentiment in their tweets than construction workers. However, this changed markedly during the COVID-19 pandemic. Since early 2020, sentiment switched, and negative sentiment dominated the tweets of nurses. No such crossover was observed in the tweets of construction workers.
Conclusions
The social media analysis revealed that younger nurses had language use patterns consistent with someone experiencing the ill effects of burnout and stress. Older construction workers had more negative sentiments than younger workers, who were more focused on communicating about social and recreational activities rather than work matters. More broadly, these findings demonstrate the utility of large data sets enabled by social media to understand the well-being of target populations, especially during times of rapid societal change.}
}
@article{TOYOTA2025109094,
title = {Cerebellum as a neural substrate for impoverishment in early psychosis},
journal = {Neuropsychologia},
volume = {210},
pages = {109094},
year = {2025},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2025.109094},
url = {https://www.sciencedirect.com/science/article/pii/S0028393225000296},
author = {Eric Toyota and Michael Mackinley and Angelica M. Silva and Yuchao Jiang and Tyler C. Dalal and Caroline Nettekoven and Lena Palaniyappan},
abstract = {Background
Formal Thought Disorder and includes both positive (i.e., disorganized speech) and negative (i.e., impoverished speech) symptoms. Emerging evidence suggests that the cerebellum plays a critical role in cognitive functions, including language processing. This study leverages Natural Language Processing to objectively measure language disturbances in patients with first-episode psychosis and investigates the relationship between these disturbances and cerebellar structure.
Methods
Fifty-four patients with schizophrenia, either drug-naïve or minimally medicated, were recruited from an early psychosis program. Impoverished thought was assessed using the Thought Language Index while lexico-semantic features (affect, cognitive, linguistic, perception, time) were identified from speech samples analyzed using the Linguistic Inquiry Word Count-22 software. Structural cerebellar analysis was completed on 7.0 Tesla MRI scans using voxel-based morphometry (VBM) to measure global and regional grey matter volume changes.
Results
Linear regression analysis revealed that reduced perceptual word usage was the strongest predictor of impoverished thinking. Correlational analysis identified reduced cerebellar volumes in patients with lower LIWC-based perception scores. VBM localized this relationship to a cluster in the right posterolateral cerebellar hemisphere, an area related to executive demand and verb generation function.
Conclusion
The cerebellum contributes to impoverished thinking in early psychosis, likely by influencing the lexical expression of perceptual experiences. This underscores the cerebellum's role in higher-order cognitive processes relevant to psychotic disorders and its potential as a therapeutic target for language and cognitive deficits in schizophrenia.}
}
@incollection{NAGARAJAN2025197,
title = {Chapter 11 - Computational intelligence approach for anomaly detection and prediction in health care information},
editor = {Balamurugan Balusamy and Vinayakumar Ravi and Rajesh Kumar Dhanaraj and Sudha Senthilkumar and Brindha K.},
booktitle = {Computational Intelligence in Sustainable Computing and Optimization},
publisher = {Morgan Kaufmann},
pages = {197-224},
year = {2025},
isbn = {978-0-443-23724-9},
doi = {https://doi.org/10.1016/B978-0-443-23724-9.00011-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780443237249000116},
author = {Sivakumar Nagarajan and K. Sasikumar},
keywords = {Anomaly detection, Autoencoder, Cancer, Chest X-rays, Classification, CNN, Deep learning, Diabetes, Healthcare information, Lung diseases, Machine learning, Mammography, Respiratory anomalies, Supervised and unsupervised anomaly detection, SVM, Time-series data analysis},
abstract = {The prevalence of diseases and their impacts are rapidly increasing worldwide. In addition, the use of digital medical records is increasing significantly. However, owing to the exponential growth of patients and health information, manual analysis of abnormalities in medical information has become increasingly difficult for doctors. Computational intelligence approaches can be employed to address this issue. Machine learning and deep learning play crucial roles in identifying anomalies in healthcare information. Machine learning for anomaly detection plays an essential role in recognizing unexpected patterns or outliers in the data. Anomaly detection is an active research subject. This is important in areas such as information security, banking, medical care, and industrial monitoring. Anomaly detection is an important aspect of healthcare analytics. In reality, abnormal occurrences must be accurately identified with few false negative alarms, even when operating with high-noise data. This study aims to provide comprehensive information on different machine and deep learning models and their efficient utilization in detecting anomalies in health-related records. Furthermore, this chapter will analyze anomaly detection methods for significant diseases, such as cancer, diabetes, and lung-related diseases. Finally, we discuss the benefits and limitations of popular anomaly detection methods and, explore recent trends in anomaly detection.}
}
@article{MELO20232833,
title = {Fostering discoveries in the era of exascale computing: How the next generation of supercomputers empowers computational and experimental biophysics alike},
journal = {Biophysical Journal},
volume = {122},
number = {14},
pages = {2833-2840},
year = {2023},
issn = {0006-3495},
doi = {https://doi.org/10.1016/j.bpj.2023.01.042},
url = {https://www.sciencedirect.com/science/article/pii/S0006349523000917},
author = {Marcelo C.R. Melo and Rafael C. Bernardi},
abstract = {Over a century ago, physicists started broadly relying on theoretical models to guide new experiments. Soon thereafter, chemists began doing the same. Now, biological research enters a new era when experiment and theory walk hand in hand. Novel software and specialized hardware became essential to understand experimental data and propose new models. In fact, current petascale computing resources already allow researchers to reach unprecedented levels of simulation throughput to connect in silico and in vitro experiments. The reduction in cost and improved access allowed a large number of research groups to adopt supercomputing resources and techniques. Here, we outline how large-scale computing has evolved to expand decades-old research, spark new research efforts, and continuously connect simulation and observation. For instance, multiple publicly and privately funded groups have dedicated extensive resources to develop artificial intelligence tools for computational biophysics, from accelerating quantum chemistry calculations to proposing protein structure models. Moreover, advances in computer hardware have accelerated data processing from single-molecule experimental observations and simulations of chemical reactions occurring throughout entire cells. The combination of software and hardware has opened the way for exascale computing and the production of the first public exascale supercomputer, Frontier, inaugurated by the Oak Ridge National Laboratory in 2022. Ultimately, the popularization and development of computational techniques and the training of researchers to use them will only accelerate the diversification of tools and learning resources for future generations.}
}
@article{ROSENBLAU2023105181,
title = {A neuro-computational social learning framework to facilitate transdiagnostic classification and treatment across psychiatric disorders},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {149},
pages = {105181},
year = {2023},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2023.105181},
url = {https://www.sciencedirect.com/science/article/pii/S0149763423001501},
author = {Gabriela Rosenblau and Koen Frolichs and Christoph W. Korn},
keywords = {Mental health, Transdiagnostic, Social learning, Reinforcement learning, Neuro-computational modelling, Autism spectrum disorder, Personality disorders, Major depressive disorder},
abstract = {Social deficits are among the core and most striking psychiatric symptoms, present in most psychiatric disorders. Here, we introduce a novel social learning framework, which consists of neuro-computational models that combine reinforcement learning with various types of social knowledge structures. We outline how this social learning framework can help specify and quantify social psychopathology across disorders and provide an overview of the brain regions that may be involved in this type of social learning. We highlight how this framework can specify commonalities and differences in the social psychopathology of individuals with autism spectrum disorder (ASD), personality disorders (PD), and major depressive disorder (MDD) and improve treatments on an individual basis. We conjecture that individuals with psychiatric disorders rely on rigid social knowledge representations when learning about others, albeit the nature of their rigidity and the behavioral consequences can greatly differ. While non-clinical cohorts tend to efficiently adapt social knowledge representations to relevant environmental constraints, psychiatric cohorts may rigidly stick to their preconceived notions or overly coarse knowledge representations during learning.}
}
@article{CHICK2002371,
title = {Collaborative influences on emergent statistical thinking — a case study},
journal = {The Journal of Mathematical Behavior},
volume = {21},
number = {3},
pages = {371-400},
year = {2002},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(02)00135-9},
url = {https://www.sciencedirect.com/science/article/pii/S0732312302001359},
author = {Helen L Chick and Jane M Watson},
keywords = {Emergent statistical thinking, Collaboration, Elementary students, Data handling, Cognitive change},
abstract = {The purpose of this case study is to examine how collaboration affects the emergent statistical thinking of a group of three Grade 6 boys. Results of previous studies of students in Grades 3, 6, and 9 suggested that (a) when finding and justifying associations in data sets students working in groups may produce higher level outcomes than those working individually, and (b) there are numerous factors that influence the success or otherwise of collaborative activity. The current study, based on detailed analysis of video tape and transcripts of a group working collaboratively on a data handling task, documents various factors that affect collaboration and how these contribute to the attainment of desirable cognitive outcomes in terms of the task set. These outcomes are classified by emergent statistical themes and insight is gained into how naı̈ve statistical thinking begins to develop during the collaborative process. Implications for educators and researchers are considered.}
}
@article{PERKINS2015492,
title = {Thinking too much: self-generated thought as the engine of neuroticism},
journal = {Trends in Cognitive Sciences},
volume = {19},
number = {9},
pages = {492-498},
year = {2015},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2015.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S1364661315001540},
author = {Adam M. Perkins and Danilo Arnone and Jonathan Smallwood and Dean Mobbs},
keywords = {personality, neuroticism, creativity, self-generated thought, medial prefrontal cortex},
abstract = {Neuroticism is a dimension of personality that captures trait individual differences in the tendency to experience negative thoughts and feelings. Established theories explain neuroticism in terms of threat sensitivity, but have limited heuristic value since they cannot account for features of neuroticism that are unrelated to threat, such as creativity and negative psychological states experienced in benign, threat-free environments. We address this issue by proposing that neuroticism stems from trait individual differences in activity in brain circuits that govern the nature of self-generated thought (SGT). We argue our theory explains not only the association of neuroticism with threat sensitivity but also the prominence within the neurotic mind of representations of information that are unrelated to the way the world is right now, such as creativity and nonsituational ‘angst’.}
}
@article{DECARVALHO202196,
title = {The enactive computational basis of cognition and the explanatory cognitive basis for computing},
journal = {Cognitive Systems Research},
volume = {67},
pages = {96-103},
year = {2021},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2020.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S1389041720301108},
author = {Leonardo Lana {de Carvalho} and João Eduardo Kogler},
keywords = {Cognitive systems, Enaction, Computing, Socio-natural practices},
abstract = {The computational theory of cognition, or computationalism, holds that cognition is a form of computation. Two issues related to this view are comprised by the goal of this paper: A) Computing systems are traditionally seen as representational systems, but functional and enactive approaches support non-representational theories; B) Recently, a sociocultural theory against computationalism was proposed with the aim of ontologically reducing computing to cognition. We defend, however, that cognition and computation are in action, thus cognition is just a form of computing and that cognition is the explanatory basis for computation. We state that: 1. Representational theories of computing recurring to intentional content run into metaphysical problems. 2. Functional non-representational theories do not incur this metaphysical problem when describing computing in terms of the abstract machine. 3. Functional theories are consistent with enactive in describing computing machines not in a strictly functional way, but especially in terms of their organization. 4. Enactive cognition is consistent with the computationalism in describing Turing machines as functionally and organizationally closed systems. 5. The cognitive explanatory basis for computing improves the computational theory of cognition. When developed in the human linguistic domain, computer science is seen as a product of human socionatural normative practices, however, cognition is just an explanatory, not ontological, basis for computing. The paper concludes by supporting that computation is in action, that cognition is just one form of computing in the world and the explanatory basis for computation.}
}
@article{OHARA2022102540,
title = {Automated Epistemology: Bots, Computational Propaganda & Information Literacy Instruction},
journal = {The Journal of Academic Librarianship},
volume = {48},
number = {4},
pages = {102540},
year = {2022},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2022.102540},
url = {https://www.sciencedirect.com/science/article/pii/S0099133322000568},
author = {Ian O'Hara},
keywords = {Computational propaganda, Information literacy, Bots, Social media, Epistemology, Misinformation, Epistemic crisis, Algorithms, Algorithmic systems},
abstract = {Computational technologies have vastly replaced our prior modalities of information seeking. Social media platforms have become the first choice of many information seekers. Increasingly, these platforms are also becoming vehicles for coordinated, manipulative disinformation campaigns. These campaigns of computational propaganda have resulted in an information environment in which the assignment of authority and trust in information sources has become increasingly opaque. This epistemic process of information evaluation has increasingly become the purview of automated algorithmic systems that we as human beings tend to falsely implicitly trust to provide us with the most accurate information available. Propagandists have begun to exploit the algorithmic components of these systems as well as human cognitive deficits in order to manipulate public opinion, control the narrative of public discourse, and flood our information ecosystems in order to work towards the manufacture of false consensus on a wide range of political and cultural issues. This work aims to review and synthesize the literature on computational propaganda, how it manipulates our human cognitive deficits, and how information literacy can be utilized in order to correct for the resultant epistemic failure.}
}
@article{ISMAILOVA2022463,
title = {Applicative approach to construe a computational model of concepts and individuals},
journal = {Procedia Computer Science},
volume = {213},
pages = {463-470},
year = {2022},
note = {2022 Annual International Conference on Brain-Inspired Cognitive Architectures for Artificial Intelligence: The 13th Annual Meeting of the BICA Society},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.11.092},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922017835},
author = {Larisa Ismailova and Viacheslav Wolfengagen and Sergey Kosikov},
keywords = {concept-as-a-process, application, abstraction, conceptual minimalism, computational model},
abstract = {This paper considers the application of conceptual mathematics to construct a computational model of concepts and individuals. An applicative approach is systematically applied to build a concept-as-process design. Since modern computing considers information processes as the main objects of modeling, the developed design is indeed representative of the semantic processing of information. The nature of concepts – what concepts are – and the constraints that govern the theory of concepts have been, and continue to be, the subject of debate. It is especially interesting to discuss the nature of concepts in connection with the recently established fundamental nature of information processes that are attributable to all phenomena and events occurring in the world around us. The current trend elevates information processes to forms of computing, which can also be implemented through practices, for example, in the form of programming. The deep component is computational models, one way or another expressed by means of mathematics and metamathematics. The main meta-operations used are abstraction and application. Of greatest interest is functional abstraction and application in the form of applying a function to an argument. Despite this “conceptual minimalism”, a rich theory of concepts can be developed. Using this theory, it is possible to focus further discussion not only on the nature of concepts, but also to characterize the position on each of the five important issues that are central to many theories of concepts: (1) ontology of concepts, (2) structure of concepts, (3) empiricism, and nativism about concepts, (4) concepts and natural language, and (5) concepts and conceptual analysis.}
}
@article{FYFE201917,
title = {Mathematical thinking in children with developmental language disorder: The roles of pattern skills and verbal working memory},
journal = {Journal of Communication Disorders},
volume = {77},
pages = {17-30},
year = {2019},
issn = {0021-9924},
doi = {https://doi.org/10.1016/j.jcomdis.2018.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0021992417300588},
author = {Emily R. Fyfe and Lauren Eisenband Matz and Kayla M. Hunt and Martha W. Alibali},
keywords = {Developmental language disorder (DLD), Patterning, Mathematics, Working memory},
abstract = {Previous research suggests that children with language disorders often have difficulties in mathematical tasks. In the current study, we investigated two relevant factors – working memory and pattern skills – that may underlie children’s poor mathematics performance. Children with developmental language disorder (DLD, n = 18, ages 6–13) and age-matched typically-developing children (n = 18) completed three math tasks that tapped calculation skill and knowledge of concepts. Children also completed a visual pattern extension task and a verbal working memory task. There were four key findings: (1) children with DLD exhibited poorer mathematical knowledge than typically-developing children, both in calculation and on key math concepts, (2) children with DLD performed similarly to typically-developing children on the visual pattern extension task, (3) children with DLD had lower verbal working memory scores than typically-developing children, and these differences in working memory accounted in part for their poorer calculation performance, and (4) children’s pattern extension scores predicted their arithmetic calculation scores, but not their concept scores.}
}
@article{RANJAN2024496,
title = {An Indigenous Computational Platform for Nowcasting and Forecasting Non-Linear Spread of COVID-19 across the Indian Sub-continent: A Geo-Temporal Visualization of Data},
journal = {Procedia Computer Science},
volume = {235},
pages = {496-505},
year = {2024},
note = {International Conference on Machine Learning and Data Engineering (ICMLDE 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.04.049},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924007257},
author = {Priya Ranjan and Dhruva Nandi and Karuna Nidhi Kaur and Rohan Rajiv and Kumar Dron Shrivastav and Anirban Ghosh and Anuj Deshpande and Sibendu Samanta and Rajiv Janardhanan},
keywords = {COVID-19 pandemic, epidemiological techniques, geocoding, health information systems},
abstract = {The rapid spread of the COVID-19 pandemic necessitated unprecedented collective action against coronavirus disease. In this light,we are proposing a novel online platform for the visualization of epidemiological data incorporating social determinants for understanding the patterns associated with the spread of COVID-19. The current AI computational platform combines modeling methodologies along with temporal geospatial visualization of COVID-19 data, providing real-time sharing of graphic analytical simulation of vulnerable hotspots of recurrent (nowcasting) and emergent (forecasting) infections visualized on a spatiotemporal scale on geoportals. The proposed study will be a secondary data analysis of primary data accessed from the national portal (Indian Council of Medical Research (ICMR)) incorporating 766 districts in India. Epidemiological data related to spatiotemporal visualization of the demographic spread of COVID-19 will be displayed using a compartmental socio-epidemiological model, reproduction number R, epi-curve diagrams as well as choropleth maps for different levels of administrative and development units at the district levels.}
}
@article{OCAK2023100146,
title = {An AI-enhanced pattern recognition approach to temporal and spatial analysis of children's embodied interactions},
journal = {Computers and Education: Artificial Intelligence},
volume = {5},
pages = {100146},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100146},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000255},
author = {Ceren Ocak and Theodore J. Kopcha and Raunak Dey},
keywords = {Computational thinking (CT), Multimodality, Embodied interactions, Artificial Intelligence (AI), Machine learning},
abstract = {Multimodal video analysis is a complex and time-consuming process for a researcher; it entails capturing, watching, and re-watching video data to identify which segments best inform or address the questions that drive the research. Modern AI applications can alleviate the challenges that arise during the fine-grained analysis of learners' multimodal interactions captured through video. In this study, we present a supervised approach to training a deep neural network to analyze children's computational thinking (CT) captured through multimodal video data. The approach first uses a set of images extracted from video data to train the AI to map them to labels generated using a priori theory. Confusion matrices were used to establish the performance of the AI by comparing AI predictions to human analysis on a validation set of data. The findings suggested that the AI classified several aspects of children's CT in a way that was highly consistent with human analysis, demonstrating how the AI could serve as an additional team member during multimodal analysis. Implications for using AI to ease the challenges of multimodal analysis of video data are discussed.}
}
@incollection{DAVID20241,
title = {Chapter One - Why is implementing computational intelligence for social good so challenging? Principles and its application},
editor = {Preetha Evangeline David and P. Anandhakumar},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {132},
pages = {1-17},
year = {2024},
booktitle = {Applying Computational Intelligence for Social Good},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2023.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0065245823000530},
author = {Preetha Evangeline David and P. Anandhakumar},
keywords = {Decision-making, Business models, Risk mitigation, health care, criminal justice, Smart cities},
abstract = {Computational intelligence (CI) has the potential to help tackle some of the world's most challenging social problems. Real-life examples of AI are already being applied in about one-third of these use cases They range from diagnosing cancer to helping blind people navigate their surroundings, identifying victims of online sexual exploitation, and aiding disaster-relief efforts etc. AI is only part of a much broader tool kit of measures that can be used to tackle societal issues, however. For now, issues such as data accessibility and shortages of AI talent constrain its application for social good. This chapter has grouped use cases into 10 social-impact domains based on taxonomies in use among social-sector organizations. Each use case highlights a type of meaningful problem that can be solved by one or more AI capability. The cost of human suffering, and the value of alleviating it, are impossible to gauge and compare. Nonetheless, employing usage frequency as a proxy, we measure the potential impact of different AI capabilities.}
}
@article{MALGAROLI202213,
title = {Machine yearning: How advances in computational methods lead to new insights about reactions to loss},
journal = {Current Opinion in Psychology},
volume = {43},
pages = {13-17},
year = {2022},
issn = {2352-250X},
doi = {https://doi.org/10.1016/j.copsyc.2021.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S2352250X21000683},
author = {Matteo Malgaroli and Fiona Maccallum and George A. Bonanno},
keywords = {Grief, Machine learning, Computation, Trajectories, Networks},
abstract = {The loss of a loved one is a potentially traumatic event that can result in disparate outcomes and symptom patterns. Machine learning methods offer computational tools to probe this heterogeneity and understand grief psychopathology in its complexity. In this article, we examine the latest contributions to the scientific study of bereavement reactions garnered through the use of computational methods. We focus on findings originating from trajectory modeling studies, as well as the recent insights originating from the network analysis of prolonged grief symptoms. We also discuss applications of artificial intelligence for the accurate identification of major depression and post-traumatic stress, as examples for their potential applications to the study of loss reactions.}
}
@article{BANERJEE2017227,
title = {A computational model for the endogenous arousal of thoughts through Z*-numbers},
journal = {Information Sciences},
volume = {405},
pages = {227-258},
year = {2017},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2017.03.035},
url = {https://www.sciencedirect.com/science/article/pii/S0020025517306321},
author = {Romi Banerjee and Sankar K. Pal},
keywords = {Artificial general intelligence, Attention dynamics, Man-machine interaction, Multimodal integration, Perception of meaning, Self-aware systems},
abstract = {Natural language provides a rich combinatorial mechanism for encoding meanings - a finite set of words can express an unbounded number of thoughts. Framed in 2015 to extend the purpose of Zadeh's Z-numbers, a Z*-number is a perceptual symbol of the meaning of a natural language expression and consequently mentalese – or internal speech. This article, through decomposition of the Z*-macro-parameters into its atomic constituents, presents a model for the endogenous arousal of thoughts during empathetic, bespoke comprehension of the real-world. Based on Minsky's Society of Mind, the framework is founded on the assimilation of multimodal experiences, a sense of ‘unified self’ and its derivatives (choice, interest, curiosity, etc.), objective and subjective components of knowledge, commonsense, and attention dynamics over a real-world scenario. The model attempts emulation of slow and fast thinking, instinctive reactions, learning, deliberation, reflection and self-conscious decisions. The design has been validated against human responses, and aims to contribute to the development of autonomous artificial systems for man-machine symbiosis.}
}
@article{SCHWAB2021104536,
title = {Thinking outside the box: The cross-border effect of tax cuts on R&D},
journal = {Journal of Public Economics},
volume = {204},
pages = {104536},
year = {2021},
issn = {0047-2727},
doi = {https://doi.org/10.1016/j.jpubeco.2021.104536},
url = {https://www.sciencedirect.com/science/article/pii/S0047272721001729},
author = {Thomas Schwab and Maximilian Todtenhaupt},
keywords = {Taxation, Cross-border, Innovation, Multinational corporations},
abstract = {We analyze how a reduction of the tax rate on corporate income from intellectual property (IP) in one country, known as a patent box regime, affects corporate R&D activity in other countries. Combining data on patents and multinational corporation networks, we show that the cross-border effect of tax policy changes depends on whether co-location of the IP and the underlying R&D activity is required. Patent boxes without such a requirement increase patent output in other countries. Patent boxes with such a requirement reduce patent output abroad but only when relocation costs for R&D activity are small.}
}
@article{KACZANOWSKA2022111287,
title = {Molecular archaeology of human cognitive traits},
journal = {Cell Reports},
volume = {40},
number = {9},
pages = {111287},
year = {2022},
issn = {2211-1247},
doi = {https://doi.org/10.1016/j.celrep.2022.111287},
url = {https://www.sciencedirect.com/science/article/pii/S221112472201107X},
author = {Joanna Kaczanowska and Florian Ganglberger and Olga Chernomor and Dominic Kargl and Bence Galik and Andreas Hess and Yoshan Moodley and Arndt {von Haeseler} and Katja Bühler and Wulf Haubensak},
keywords = {evolutionary genetics, neurogenetic evolution, computational neuroanatomy, human cognition, archaic brains, Neanderthal, Denisovan, language, attention, strategic thinking},
abstract = {Summary
The brains and minds of our human ancestors remain inaccessible for experimental exploration. Therefore, we reconstructed human cognitive evolution by projecting nonsynonymous/synonymous rate ratios (ω values) in mammalian phylogeny onto the anatomically modern human (AMH) brain. This atlas retraces human neurogenetic selection and allows imputation of ancestral evolution in task-related functional networks (FNs). Adaptive evolution (high ω values) is associated with excitatory neurons and synaptic function. It shifted from FNs for motor control in anthropoid ancestry (60–41 mya) to attention in ancient hominoids (26–19 mya) and hominids (19–7.4 mya). Selection in FNs for language emerged with an early hominin ancestor (7.4–1.7 mya) and was later accompanied by adaptive evolution in FNs for strategic thinking during recent (0.8 mya–present) speciation of AMHs. This pattern mirrors increasingly complex cognitive demands and suggests that co-selection for language alongside strategic thinking may have separated AMHs from their archaic Denisovan and Neanderthal relatives.}
}
@article{MADSEN2022103671,
title = {Soft City Sensing: A turn to computational humanities in data-driven urbanism},
journal = {Cities},
volume = {126},
pages = {103671},
year = {2022},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2022.103671},
url = {https://www.sciencedirect.com/science/article/pii/S026427512200110X},
author = {Anders Koed Madsen and Anders Grundtvig and Sofie Thorsen},
keywords = {Soft City Sensing, Urban studies, Big data, Social web, Digital city, Computational humanities},
abstract = {Data-driven urbanism is often entangled with the smart city and practiced in a way that prioritizes control over physical objects and downplays the human and political aspects of data. We label this approach ‘hard city sensing’ (HCS) and we argue that the rise of the ‘digital city’ offers the empirical foundation for more humanistic approaches. Driven by the ambition to untangle data-driven urbanism from HCS, this paper reviews two decades of scholarship that has used digital traces as an empirical ground for understanding urban phenomena. The review identifies four distinct ways of working with digital traces of which three pave the way for new ways of problematizing the city. Instead of abandoning the idea of data-driven urbanism, we propose the framework of 'soft city sensing' (SCS) as way to re-engage with it with inspiration from these pioneering works. However, this requires a willingness to revisit central epistemological commitments that currently serve as standards for how to “properly” do data projects. We therefore urge qualitative urban scholars to ponder the possibilities of furthering their urban interest by ‘thinking with algorithms’ while retaining their interpretative ambitions just as we identify a need for urban decion-makers to expand their criteria for what serves as valid data inputs to urban planning.}
}
@incollection{KENNEDY2001261,
title = {chapter six - Thinking Is Social},
editor = {James Kennedy and Russell C. Eberhart and Yuhui Shi},
booktitle = {Swarm Intelligence},
publisher = {Morgan Kaufmann},
address = {San Francisco},
pages = {261-284},
year = {2001},
series = {The Morgan Kaufmann Series in Artificial Intelligence},
isbn = {978-1-55860-595-4},
doi = {https://doi.org/10.1016/B978-155860595-4/50006-1},
url = {https://www.sciencedirect.com/science/article/pii/B9781558605954500061},
author = {James Kennedy and Russell C. Eberhart and Yuhui Shi},
abstract = {Publisher Summary
Neural networks, simulated annealing, cultural algorithms, ant colony optimization, and evolutionary algorithms are several instances where psychological, physical, and biological theories have influenced the development of computational methods for problem solving. This chapter takes simulation from the social sciences and shows how it can be modified slightly to perform combinatorial optimization. It explains that thinking is a social activity; human culture and cognition are aspects of a single process. A recent simulation of the spread of culture provides insights into the effects of social interaction and gives a starting point for demonstrating that a small number of simple principles can cause an artificial system to behave remarkably like a complex human society. Though all interactions are local, insights and innovations are transported by culture from the originator to distant individuals; moreover, a combination of various innovations results in more improved methods.}
}
@article{ROBSON2022102517,
title = {A dynamical systems view of neuroethology: Uncovering stateful computation in natural behaviors},
journal = {Current Opinion in Neurobiology},
volume = {73},
pages = {102517},
year = {2022},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2022.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0959438822000022},
author = {Drew N. Robson and Jennifer M. Li},
keywords = {Neural dynamics, Neuroethology, Internal state, Innate behavior, Neuromodulation, Dynamical systems},
abstract = {State-dependent computation is key to cognition in both biological and artificial systems. Alan Turing recognized the power of stateful computation when he created the Turing machine with theoretically infinite computational capacity in 1936. Independently, by 1950, ethologists such as Tinbergen and Lorenz also began to implicitly embed rudimentary forms of state-dependent computation to create qualitative models of internal drives and naturally occurring animal behaviors. Here, we reformulate core ethological concepts in explicitly dynamical systems terms for stateful computation. We examine, based on a wealth of recent neural data collected during complex innate behaviors across species, the neural dynamics that determine the temporal structure of internal states. We will also discuss the degree to which the brain can be hierarchically partitioned into nested dynamical systems and the need for a multi-dimensional state-space model of the neuromodulatory system that underlies motivational and affective states.}
}
@article{FAVERO2024111903,
title = {Ten questions concerning statistical data analysis in human-centric buildings research: A focus on thermal comfort investigations},
journal = {Building and Environment},
volume = {264},
pages = {111903},
year = {2024},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2024.111903},
url = {https://www.sciencedirect.com/science/article/pii/S0360132324007455},
author = {Matteo Favero and Salvatore Carlucci and Giorgia Chinazzo and Jan Kloppenborg Møller and Marcel Schweiker and Marika Vellei and Andrew Sonta},
keywords = {Thermal comfort, Human-centric research, Statistical data analysis, Simulations, Causal thinking, Statistical thinking},
abstract = {Given the large amount of time we spend indoors, designing and operating buildings that are safe, comfortable, and conducive to productivity and well-being is essential. To achieve this goal, in the past decades, research has been conducted to investigate the influence of the indoor environment on occupants. Thermal comfort has been the subject of most investigations in this field. However, despite being a consolidated research topic since the 1920s, statistical practices for analysing thermal comfort data often rely on simplified premises, which may be due to several possible factors (e.g., limited computational capabilities and lack of training). Consequently, important aspects of data analysis are often absent or overlooked. Recent statistics and statistical software advances have provided more options for effectively modelling complex issues. However, properly using these tools requires a solid understanding of statistical analysis, increasing the risk of misuse in practice. This paper presents ten questions highlighting the most critical issues regarding statistical analysis for thermal comfort research and practice. The first four questions provide general perspectives concerning statistical data analysis, while the remaining ones address specific problems related to thermal comfort research, but that can extend to all human-centric research in the built environment. Additionally, the last five questions demonstrate the practical significance of analysis pitfalls (i.e., sampling variability, selection bias, variable selection, clustered/nested observations, and measurement error) through examples with synthetic data. This study provides insights into the current statistical ‘habits’ in thermal comfort research and, more importantly, help researchers better define and conduct their statistical analyses.}
}
@article{FELDMANHALL20211045,
title = {The computational challenge of social learning},
journal = {Trends in Cognitive Sciences},
volume = {25},
number = {12},
pages = {1045-1057},
year = {2021},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2021.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S1364661321002291},
author = {Oriel FeldmanHall and Matthew R. Nassar},
keywords = {social learning, computational modeling, inference, reward, emotion, coordination, uncertainty},
abstract = {The complex reward structure of the social world and the uncertainty endemic to social contexts poses a challenge for modeling. For example, during social interactions, the actions of one person influence the internal states of another. These social dependencies make it difficult to formalize social learning problems in a mathematically tractable way. While it is tempting to dispense with these complexities, they are a defining feature of social life. Because the structure of social interactions challenges the simplifying assumptions often made in models, they make an ideal testbed for computational models of cognition. By adopting a framework that embeds existing social knowledge into the model, we can go beyond explaining behaviors in laboratory tasks to explaining those observed in the wild.}
}
@article{JAYBONK1998261,
title = {Alternative instructional strategies for creative and critical thinking in the accounting curriculum},
journal = {Journal of Accounting Education},
volume = {16},
number = {2},
pages = {261-293},
year = {1998},
issn = {0748-5751},
doi = {https://doi.org/10.1016/S0748-5751(98)00012-8},
url = {https://www.sciencedirect.com/science/article/pii/S0748575198000128},
author = {Curtis {Jay Bonk} and G {Stevenson Smith}},
abstract = {In the midst of numerous accounting reform reports declaring that the memorization of accounting facts will no longer suffice, global economies have increased the pressure on universities to develop higher-order thinking skill curricula. This paper suggests that a consultative model of teaching can meet these challenges. From this framework, learning environments can be reshaped to support both the creative and critical thinking skills demanded by workplaces of the 21st century. In contrast to the passive reception of knowledge of teacher-centered classrooms, this style of teaching promotes active, student-centered learning. Importantly, a myriad of critical and creative thinking techniques, activities, and examples are detailed for developing accounting curricula in accordance with these views. Peripheral issues related to assessing higher-order thinking as well as cooperative grouping also are considered.}
}
@article{GONI2024103324,
title = {Analytical categories to describe imaginations about the collective futures: From theory to linguistics to computational analysis},
journal = {Futures},
volume = {156},
pages = {103324},
year = {2024},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2024.103324},
url = {https://www.sciencedirect.com/science/article/pii/S0016328724000077},
author = {Julian “Iñaki” Goñi and Maria Paz Raveau and Claudio {Fuentes Bravo}},
keywords = {Imaginations about the collective futures, Images of the future, Linguistic markers, Natural language processing},
abstract = {Anticipation of collective futures has been described as one of the most critical challenges of contemporary societies. Imaginations or images of the collective future are a form of narrative and social activity that involves many complex political, psychological and cultural nuances that pose significant challenges in terms of assessment. In this article, we propose six analytical categories to describe qualitative information regarding imaginations about the collective futures. These categories reflect a conceptual integration of normative stances in Science, Technology and Society and capacity approaches to Futures Studies. We translated those analytical categories into grammatical markers that allow for their operationalisation. Using a large-scale participatory process in Chile aimed at systematising images of the future, we utilised Natural Language Process to transform the grammatical markers into computational codes that allowed us to automatically assess large amounts of qualitative data. Ultimately, our main argument is that analytical categories to describe imaginations about collective futures can be generated with reasonable foundations in the humanities and social sciences.}
}
@article{ROYCHOWDHURY20231,
title = {Brain inspired face recognition: A computational framework},
journal = {Cognitive Systems Research},
volume = {78},
pages = {1-13},
year = {2023},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2022.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S1389041722000687},
author = {Pinaki {Roy Chowdhury} and Angad {Singh Wadhwa} and Nikhil Tyagi},
keywords = {ANN, CNN, Deep learning, Classification algorithms, Brain inspired face recognition, Feature extraction, Scaled conjugate gradient, Adam},
abstract = {This paper presents a new proposal of an efficient computational model of face recognition which uses cues from the distributed face recognition mechanism of the brain, and by gathering engineering equivalent of these cues from existing literature. Three distinct and widely used features – Histogram of Oriented Gradients (HOG), Local Binary Patterns (LBP), and Principal components (PCs) extracted from target images are used in a manner which is simple, and yet effective. The HOG and LBP features further undergo Principal Component Analysis (PCA) for dimensionality reduction. Our model uses multi-layer perceptrons (MLP) to classify these three features and fuse them to form a sparsely connected model. A computational theory is first developed by using concepts from the information processing mechanism of the brain. Extensive experiments are carried out using eight publicly available face datasets to validate our proposed model’s performance in recognizing faces with extreme variation of illumination, pose angle, expression, and background. We also investigate the same mechanism because of reasons discussed later, on object recognition tasks as well. Results obtained are extremely promising when compared with other face and object recognition algorithms including CNN and deep learning-based methods. This highlights that simple computational processes, if clubbed properly, can produce competing performance with best algorithms.}
}
@article{BERTOLDI2025108397,
title = {Linking systems to agencies in urban metabolism studies: A conceptual framework and computational analysis of research literature},
journal = {Ecological Economics},
volume = {227},
pages = {108397},
year = {2025},
issn = {0921-8009},
doi = {https://doi.org/10.1016/j.ecolecon.2024.108397},
url = {https://www.sciencedirect.com/science/article/pii/S0921800924002945},
author = {Nicola Bertoldi and Daniela Perrotti},
keywords = {Urban metabolism, Agency, Social ecology, Stock-flow-practice nexus, Semantic network analysis, Computational linguistics, Text mining},
abstract = {This study outlines a conceptual framework linking a conceptualization of agency in urban metabolism studies with a systems-based perspective. To this aim, we engage with contributions to socio-metabolic studies, notably from social ecology, that are not directly concerned with the urban dimension but explicitly question how systems and actors shape each other and how social practices can influence the distribution of resource flows and stocks and their interdependencies. Based on those contributions, we identify three critical axes of investigation that help track implicit uses of the concept of “agency” in urban metabolism studies and constitute the pillars of our proposed framework: (1) characterizing structures comprising urban social-ecological systems – understood as patterns of connections among elements and subsystems – as actors, (2) identifying the chains of events that such actors influence by exerting their agentic capacities, and (3) associating those same actors with definite agentic dimensions, i.e., specific modalities of agency. By drawing on methods from computational linguistics, text mining, and semantic network analysis, we extract concepts cognate to “urban metabolism” from a relevant body of research literature. Through our framework, we show how such concepts define forms of agency that can be ascribed to structural components of urban social-ecological systems.}
}
@article{SCHWABE201360,
title = {Stress and multiple memory systems: from ‘thinking’ to ‘doing’},
journal = {Trends in Cognitive Sciences},
volume = {17},
number = {2},
pages = {60-68},
year = {2013},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2012.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S1364661312002811},
author = {Lars Schwabe and Oliver T. Wolf},
abstract = {Although it has been known for decades that stress influences memory performance, it was only recently shown that stress may alter the contribution of multiple, anatomically and functionally distinct memory systems to behavior. Here, we review recent animal and human studies demonstrating that stress promotes a shift from flexible ‘cognitive’ to rather rigid ‘habit’ memory systems and discuss, based on recent neuroimaging data in humans, the underlying brain mechanisms. We argue that, despite being generally adaptive, this stress-induced shift towards ‘habit’ memory may, in vulnerable individuals, be a risk factor for psychopathology.}
}
@article{LOVE2022100543,
title = {A screen-based or physical computing unit? Examining secondary students’ attitudes toward coding},
journal = {International Journal of Child-Computer Interaction},
volume = {34},
pages = {100543},
year = {2022},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2022.100543},
url = {https://www.sciencedirect.com/science/article/pii/S2212868922000617},
author = {Tyler S. Love and Reuben S. Asempapa},
keywords = {Computational thinking, Physical computing, Integrated STEM education, Design and technology, Technology and engineering education, Tangible interaction},
abstract = {In recent years there has been a growing emphasis placed on access to computational thinking (CT) instruction for every K-12 student in the United States (U.S.). Concurrently, calls for integrating CT concepts within authentic science, technology, engineering, and mathematics (STEM) contexts have also increased. This is reflected by the inclusion of CT in the Next Generation Science Standards and the Standards for Technological and Engineering Literacy. However, methods for teaching CT concepts within secondary level STEM courses vary drastically. Physical computing, the design and programming of physical systems or devices using computational thinking skills, has become increasingly popular in the U.S. in attempts to integrate CT within authentic STEM problem-solving contexts. Despite this rise in popularity, there remains a limited but growing body of research investigating physical computing pedagogy and student learning. A mixed methods design was used in this study to examine 170 middle school students’ attitudes toward coding and after participating in either a screen-based or physical computing unit. The results indicated that students who completed the screen-based unit reported statistically greater attitudes toward the classroom applications and career/future use of computing concepts. Students in the treatment group believed that physical computing made learning computing concepts more difficult, but they preferred the hands-on learning opportunities provided by physical computing. Furthermore, male students reported higher attitudinal ratings than females regarding the influence computing would have on their future academic and career choices. This study provides implications for improving physical computing instruction and integration within STEM education contexts.}
}
@article{OPRISAN2022101642,
title = {Interdisciplinary curriculum for computational neuroscience at primarily undergraduate institutions},
journal = {Journal of Computational Science},
volume = {61},
pages = {101642},
year = {2022},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2022.101642},
url = {https://www.sciencedirect.com/science/article/pii/S187775032200062X},
author = {Sorinel A. Oprisan},
keywords = {Computational neuroscience, Undergraduate education, Interdisciplinary curricula},
abstract = {Developing interdisciplinary undergraduate courses is challenging at all levels; it requires involving trained faculty who can successfully cover more than one discipline and creating a new curriculum that crosses discipline boundaries. While such integrative curricula are expected in a graduate school setting, they are challenging at the undergraduate level since they require proficiency in multiple disciplines. However, making this transition to interdisciplinary, project-based teaching at the undergraduate level gives a competitive edge to undergraduates. As part of a broader effort of developing a comprehensive neuroscience curriculum, we implemented an interdisciplinary, one-semester, upper-level course called Biophysical Modeling of Excitable Cells (BMEC). The course exposes undergraduate students to broad areas of computational biology. It focuses on computational neuroscience, develops scientific literacy, and promotes teamwork between biology, psychology, physics, and mathematics-oriented undergraduates. This course also provides pedagogical experience for senior Ph.D. students in Neuroscience. BMEC is a three contact hours per week lecture-based course that includes a set of computer-based activities designed to gradually increase the undergraduates’ ability to apply mathematics and computational concepts to solving biologically-relevant problems. The class brings together two different groups of students with very dissimilar and complementary backgrounds, i.e., biology/psychology and physics/mathematics oriented. The teamwork allows students with more substantial biology/psychology backgrounds to explain to physics/mathematics students the biological implications and instill realism into the computer modeling project they completed for this class. Simultaneously, students with substantial physics/mathematics backgrounds can apply techniques learned in specialized mathematics, physics, or computer science classes to generate mathematical hypotheses and implement them in computer codes. This study expands on Oprisan (2021) by including examples of hands-on activities, student projects, and a brief overview of course assessment tools and results. This study also includes more recent approaches to teaching computational neuroscience using cloud computing.}
}
@article{OXMAN2002135,
title = {The thinking eye: visual re-cognition in design emergence},
journal = {Design Studies},
volume = {23},
number = {2},
pages = {135-164},
year = {2002},
issn = {0142-694X},
doi = {https://doi.org/10.1016/S0142-694X(01)00026-6},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X01000266},
author = {Rivka Oxman},
keywords = {perception, design cognition, visual reasoning, emergence, creativity},
abstract = {Emergence has been widely recognized as a significant phenomenon of visual reasoning in design. Despite its centrality as a cognitive phenomenon, research in emergence currently lacks a comprehensive theoretical foundation. A broadened view of design emergence that adds to the perceptual phenomenon of shape emergence in reflecting the way the design domains are conceptualized is proposed. An expanded theory of emergence in which visual cognition plays an important role is presented. Beginning with an attempt to broaden the perceptual perspectives of shape emergence, the process of cognitive emergence is defined. The duality of related perceptual and cognitive components provides a working basis for conceptualizing visual emergence in design. Antithetical to the idea of accidental emergence, it is proposed that emergence is guided and anticipated. We claim that it is the re-cognition of visual shapes and images in design that enables emergence. This kind of guidance function in emergence is termed ‘anticipated emergence’. We demonstrate how high-level domain knowledge of visual forms can be accommodated as cognitive content, and how this can contribute to establishing a cognitive basis for emergence. An empirical experiment from the domain of architecture is presented.}
}
@article{CHEN2022101855,
title = {Fairness optimization in IRS-assisted MEC computational offloading},
journal = {Physical Communication},
volume = {54},
pages = {101855},
year = {2022},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2022.101855},
url = {https://www.sciencedirect.com/science/article/pii/S1874490722001410},
author = {Mingkai Chen and Yafang Wan and Mengtian Wen and Tianzhe Zhou},
keywords = {MEC, Computational offloading, IRS, Convex optimization, Fairness},
abstract = {Nowadays, more and more multimedia services are supported by Mobile Edge Computing (MEC). However, the instability of the wireless environment brings a lot of uncertainty to the computational offloading. Additionally, intelligent reflecting surface (IRS) is considered as a potential technology to enhance Quality of Service (QoS). Therefore, in this paper, we establish a framework for IRS-assisted MEC computational offloading to solve this problem and take fairness optimization as a key point involving communication and computing resources. Minimize user consumption by optimizing bandwidth allocation, task offloading ratio, edge computing resources, transmission power and IRS phase shifts. Firstly, we decompose the problem into three aspects, such as bandwidth allocation, computing resource allocation, transmission power and IRS phase shifts. Then, an alternative optimization algorithm is proposed to find the optimum solution and its convergence is proved. Secondly, since the optimization problem on transmission power and IRS phase shifts is non-convex, we propose Riemann gradient descent (R-SGD) algorithm to solve it. Finally, numerical results show that our proposed algorithm performs better than other algorithms and achieves a superiority in the framework.}
}
@article{ANANE2023104782,
title = {BIM-driven computational design for robotic manufacturing in off-site construction: an integrated Design-to-Manufacturing (DtM) approach},
journal = {Automation in Construction},
volume = {150},
pages = {104782},
year = {2023},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2023.104782},
url = {https://www.sciencedirect.com/science/article/pii/S0926580523000420},
author = {Walid Anane and Ivanka Iordanova and Claudiane Ouellet-Plamondon},
keywords = {Design-to-manufacturing, BIM, Computational design, Robotic manufacturing, Off-site construction, Interoperability},
abstract = {Technological interoperability is a driver for seamless data and information exchange between project team members in the Architecture, Engineering, and Construction (AEC) industry. It is defined as the ability of different systems to exchange information with minimum loss. Therefore, interoperability lack is often a barrier in modern construction applications, such as robotics. Construction and robotics, seen from their respective areas, are highly divergent in context, organization, procedures, and technologies. However, both paradigms use computation, which gives computational systems the potential to enable construction robotics. This research is based on the Design Science Research (DSR) methodology and aims to develop a framework for operationalizing industrial robots in construction. To this end, it uses Computational Design (CD) driven by Building Information Modeling (BIM) for Robotic Manufacturing (RM) within Off-Site Construction (OSC) systems. This technological alignment allowed the development of an integrated Design-to-Manufacturing (DtM) framework, validated by 16 evaluators.}
}
@article{DUBLJEVIC2023113168,
title = {Computational BIM tool for automated LEED certification process},
journal = {Energy and Buildings},
volume = {292},
pages = {113168},
year = {2023},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2023.113168},
url = {https://www.sciencedirect.com/science/article/pii/S0378778823003985},
author = {Sanja Dubljević and Bojan Tepavčević and Branko Markoski and Aleksandar S. Anđelković},
keywords = {Building information modeling, LEED, Visual programming language, Computational BIM},
abstract = {Building information modeling (BIM) and sustainable building certification integration have been the focus of several studies in recent years, aiming to create a simpler and more effective building certification process. This paper describes a novel computational tool for architects and engineers, considering that the certification process takes place in a work environment that is familiar to them. The goal is to present a method for developing a computational tool that will automate the process of verifying the achievement of certain Leadership in Energy and Environmental Design (LEED) credits using visual programming in a BIM environment. In this way, designers can have an insight into the achievement of certain LEED credits at any phase during the design process. Considering the complexity of the digital parameterization of LEED credits, this method includes the achievement of three credits listed in the Material and Resources chapter of the LEED for Building Design and Construction protocol. Apart from similar research, the presented tool enables visibility of real-time LEED credits achievement at every moment of the design, from the building concept development to the final stage. The presented method creates space for the elaboration on the other LEED credits, as well as research in the area of applicability to other green rating certification programs and evaluation of existing building stock.}
}
@article{MCKOWN2004597,
title = {Age and ethnic variation in children's thinking about the nature of racism},
journal = {Journal of Applied Developmental Psychology},
volume = {25},
number = {5},
pages = {597-617},
year = {2004},
issn = {0193-3973},
doi = {https://doi.org/10.1016/j.appdev.2004.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0193397304000668},
author = {Clark McKown},
keywords = {Racism, Stereotypes, Ethnic conflict, Elaboration, Differentiation},
abstract = {A content analysis of interviews with an ethnically diverse group of 202 children aged 6 to 10 describes what children think racism is, and examines associations between age, ethnicity, and children's thinking about racism. Children's narratives capture many dimensions of racism, including stereotypes, prejudice, discrimination, and ethnic conflict. With age, children's ideas about racism become more elaborated and differentiated. At every age, compared to their peers, African American children have more elaborated and differentiated ideas about racism and mention those dimensions of racism that overtly reflect power relations more frequently. Qualitative analyses suggest that children's ideas about racism are abstract, increasingly coherent with age, and sometimes incorporate causal language. Findings are discussed in terms of origins of individual differences, the extent to which children's ideas about racism might be considered a lay theory, and the likely consequences of such a theory in daily life.}
}
@article{CABRERA2008311,
title = {Distinctions, systems, relationships, and perspectives (DSRP): A theory of thinking and of things},
journal = {Evaluation and Program Planning},
volume = {31},
number = {3},
pages = {311-317},
year = {2008},
issn = {0149-7189},
doi = {https://doi.org/10.1016/j.evalprogplan.2008.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0149718908000359},
author = {Derek Cabrera and Laura Colosi}
}
@article{PAPIN2004641,
title = {Hierarchical thinking in network biology: the unbiased modularization of biochemical networks},
journal = {Trends in Biochemical Sciences},
volume = {29},
number = {12},
pages = {641-647},
year = {2004},
issn = {0968-0004},
doi = {https://doi.org/10.1016/j.tibs.2004.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0968000404002610},
author = {Jason A. Papin and Jennifer L. Reed and Bernhard O. Palsson},
abstract = {As reconstructed biochemical reaction networks continue to grow in size and scope, there is a growing need to describe the functional modules within them. Such modules facilitate the study of biological processes by deconstructing complex biological networks into conceptually simple entities. The definition of network modules is often based on intuitive reasoning. As an alternative, methods are being developed for defining biochemical network modules in an unbiased fashion. These unbiased network modules are mathematically derived from the structure of the whole network under consideration.}
}
@incollection{DAWES200112082,
title = {Probabilistic Thinking},
editor = {Neil J. Smelser and Paul B. Baltes},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences},
publisher = {Pergamon},
address = {Oxford},
pages = {12082-12089},
year = {2001},
isbn = {978-0-08-043076-8},
doi = {https://doi.org/10.1016/B0-08-043076-7/00431-9},
url = {https://www.sciencedirect.com/science/article/pii/B0080430767004319},
author = {R.M. Dawes},
abstract = {While games of chance have been played for thousands of years, and while experienced players often had good intuitive ideas of the relative frequencies of various outcomes, the concept of probability as referring to the ratio of favorable outcomes to total outcomes of a ‘fair’ gambling device emerged only 500 or so years ago in Western societies. That allowed evaluation of new games not yet played and later led to a more abstract conception of probability as a measure satisfying certain conditions (‘axioms’). Only in the past 150 years or so has probability had a major role in science and only in the last 50 years or so in everyday life—as for example in evaluating medical outcomes or technological risks or manufacturer liability. Thus, especially in attempting to assess probability in everyday situations, our intuitions are often deficient—more so than those concerning quantity, space, and time. The major problem is not, however, one of making random errors in probability judgments but of making systematic ones that result from a number of well-known and research systematic cognitive biases and heuristics, which are described in this article. These systematic departures from rational assessment do not imply that coherent and accurate probabilistic thinking is (anywhere near) impossible, but that when departures from coherence and accuracy occur, they tend to follow a predictable pattern.}
}

@article{LONG201743,
title = {A framework for data-driven computational experiments of inter-organizational collaborations in supply chain networks},
journal = {Information Sciences},
volume = {399},
pages = {43-63},
year = {2017},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2017.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S0020025517305807},
author = {Qingqi Long},
keywords = {Data-driven, Computational experiment, Inter-organizational collaboration, Supply chain network},
abstract = {Internet+ecosystems, big data applications, customers’ specific demands, and internal and external values integration of enterprises pose new challenges to inter-organizational collaborations in supply chain networks. To confront these challenges, this paper integrates computational experiment and data analysis, and proposes a methodology for data-driven computational experiments for inter-organizational collaborations in supply chain networks. It explores a paradigm shift to the development of data-driven computational experiments that supports decision making in the domain of inter-organizational collaborations. A basic principle for integrated solutions generation in the parallel worlds of virtual reality interaction is studied and the corresponding key issues in the paradigm are analyzed. To support the paradigm and solve key issues, a six-layered framework with four viewpoints for data-driven computational experiments is proposed. This framework systematically presents conceptual and technical solutions for data-driven computational experiments and decision support in the domain of inter-organizational collaborations in supply chain networks. The effectiveness of the framework is verified by theoretical analysis and a case study.}
}
@article{HUNG1997311,
title = {Meanings, contexts, and mathematical thinking: The meaning-context model},
journal = {The Journal of Mathematical Behavior},
volume = {16},
number = {4},
pages = {311-324},
year = {1997},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(97)90010-9},
url = {https://www.sciencedirect.com/science/article/pii/S0732312397900109},
author = {David Wei Loong Hung},
abstract = {The aim of this paper is to describe the meaning-context model which integrates three different levels of contextual factors that influence students' mathematical thinking and problem solving. These factors can be primarily classified according to: (1) the problem-task at hand; (2) the individual problem solver's personal epistemology of mathematics; and (3) the social and cultural influences through which the individual develops his or her mathematical disposition. We have referred to these three different contextual factors as the meaning-symbol context, meaning-interpretation context, and the meaning-intersubjectivity context respectively. The paper also discusses the implications of this model.}
}
@article{BORREGO2024101948,
title = {DPGraphJ: A Java package for the implementation of dynamic programming algorithms},
journal = {SoftwareX},
volume = {28},
pages = {101948},
year = {2024},
issn = {2352-7110},
doi = {https://doi.org/10.1016/j.softx.2024.101948},
url = {https://www.sciencedirect.com/science/article/pii/S2352711024003182},
author = {Diana Borrego and Irene Barba and Carmelo {Del Valle} and Miguel Toro},
keywords = {Dynamic programming, AND/OR graphs, Design & implementation, Software quality, Computational thinking},
abstract = {This paper introduces the DPGraphJ package, a collection of reusable Java functions to solve optimisation problems using a dynamic programming algorithm. The latter is based on a recursive schema that follows a top-down approach and uses the memoisation technique. This algorithm is a reusable software component that is generic and efficient. Moreover, it has been developed by paying special attention to good practices in the design of software. For using DPGraphJ, the problem to be solved needs to be modelled as an AND/OR graph. In the DPGraphJ package, we provide 5 academic case studies with detailed comments. We strongly believe that our proposal can be helpful for several kinds of users, such as students, researchers, and practitioners.}
}
@article{CHECIU2024127324,
title = {Reconstructing creative thoughts: Hopfield neural networks},
journal = {Neurocomputing},
volume = {575},
pages = {127324},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.127324},
url = {https://www.sciencedirect.com/science/article/pii/S092523122400095X},
author = {Denisa Checiu and Mathias Bode and Radwa Khalil},
keywords = {Creative Thinking, Hopfield Neural Network, Patterns, Memory, Associative Chains, Semantic Association},
abstract = {From a brain processing perspective, the perception of creative thinking is rooted in the underlying cognitive process, which facilitates exploring and cultivating novel avenues and problem-solving strategies. However, it is challenging to emulate the intricate complexity of how the human brain presents a novel way to uncover unique solutions. One potential approach to mitigating this complexity is incorporating creative cognition into the evolving artificial intelligence systems and associated neural models. Hopfield neural network (HNN) are commonly acknowledged as a simplified neural model, renowned for their biological plausibility to store and retrieve information, specifically patterns of neurons. Our findings suggest utilizing modern HNN to emulate creative thinking by making meaningful associations between seemingly disparate concepts. This semantic link is represented as a radio knob that can be set to determine whether the network solves problems creatively or shuts down; the threshold is a parameter. We used the term "first knob of creativity" to describe a certain pattern and utilized the "second knob of creativity" to aid in the examination of alternatives within the network. By manipulating the knobs, it is possible to selectively suppress specific patterns, facilitating the creative functioning of the HNN and identifying other patterns with which input can be linked.}
}
@article{DELANEY201839,
title = {Thinking outside the box: Innovative solutions for dairy goat management},
journal = {Small Ruminant Research},
volume = {163},
pages = {39-44},
year = {2018},
note = {Contributions of caprine agro-sylvopastoral production systems to society and environment},
issn = {0921-4488},
doi = {https://doi.org/10.1016/j.smallrumres.2017.04.011},
url = {https://www.sciencedirect.com/science/article/pii/S0921448817301074},
author = {Carol Delaney},
keywords = {Dairy goat breeding and selection, Extensive grazing, Longevity, Milk production, Efficiency, Environmental adaptation},
abstract = {For the geneticist or breeder, the individual animal is like a potential masterpiece resulting from years of attention to physical details and planned matings. The importance of culturing and nourishing this individual to not only reach its potential but to pass its selected genetics on to progeny is paramount. Thus, all the investment in genetic improvement is now at the mercy of management. Once the goats are in the herd on the farm and the responsibility of the farmer or farm manager, the expression and proliferation of the genotype will be strongly influenced by environmental factors. If maximum milk production per lactation were the real and only goal that could promise farm business and land sustainability, genetic selection would be easy. However, the real goal on farms is to have healthy goats that produce efficiently and are adapted to their environment. This places the development of the goat breeding program in the hands of farmers. To aid farmers in moving beyond the use of total milk production per goat as the feedback mechanism to farm sustainability, the integration of more appropriate progress indicators could include longevity (which, in humans, is estimated at 20% genetic and 80% environmental), the amount of milk or milk component production per body weight of goat, and the degree of involuntary culling.}
}
@article{KALRO1998267,
title = {3D computation of unsteady flow past a sphere with a parallel finite element method},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {151},
number = {1},
pages = {267-276},
year = {1998},
note = {Containing papers presented at the Symposium on Advances in Computational Mechanics},
issn = {0045-7825},
doi = {https://doi.org/10.1016/S0045-7825(97)00120-5},
url = {https://www.sciencedirect.com/science/article/pii/S0045782597001205},
author = {V. Kalro and T. Tezduyar},
abstract = {We present parallel computation of 3D, unsteady, incompressible flow past a sphere. The Navier-Stokes equations of incompressible flows are solved using a stabilized finite element formulation. Equal-order interpolation functions are used for velocity and pressure. The second-order accurate time-marching within the solution process is carried out in an implicit fashion. The coupled, nonlinear equations generated at each time step are solved using an element-vector-based iteration technique. The computed value of the primary frequency associated with vortex shedding is in close agreement with experimental measurements. The computation was performed on the Thinking Machines CM-5.}
}
@article{HARRY20228413,
title = {Rational Computational Design of Systems Exhibiting Strong Halogen Bonding Involving Fluorine in Bicyclic Diamine Derivatives},
journal = {The Journal of Organic Chemistry},
volume = {87},
number = {13},
pages = {8413-8419},
year = {2022},
issn = {0022-3263},
doi = {https://doi.org/10.1021/acs.joc.2c00497},
url = {https://www.sciencedirect.com/science/article/pii/S0022326322023404},
author = {Stefan Andrew Harry and Srini Vemulapalli and Travis Dudding and Thomas Lectka},
abstract = {ABSTRACT
Perhaps the most controversial and rare aspect of the halogen bonding interaction is the potential of fluorine in compounds to serve as a halogen bond donor. In this note, we provide clear and convincing examples of hypothetical molecules in which fluorine is strongly halogen bonding in a metastable state. Of particular note is a polycyclic system inspired by Selectfluor, which has been controversially proposed to engage in halogen bonding.}
}
@article{ZOCCA2019100,
title = {Decision-making computationally aided in the management of energy sources used in agrifood industries},
journal = {Energy Procedia},
volume = {161},
pages = {100-107},
year = {2019},
note = {Proceedings of the 2nd International Conference on Sustainable Energy and Resource Use in Food Chains including Workshop on Energy Recovery Conversion and Management;ICSEF 2018, 17 – 19 October 2018, Paphos, Cyprus},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2019.02.063},
url = {https://www.sciencedirect.com/science/article/pii/S1876610219311427},
author = {Renan Zocca and Pedro D. Gaspar and Pedro D. Silva and Fernando C. Santos and Luís P. Andrade and José Nunes},
keywords = {Energy consumption, Energy management, Computational tool, decision making},
abstract = {In an increasingly competitive society with an unfavourable economic environment, it is necessary for Small and Medium Enterprises (SMEs) to update themselves, thereby increasing their efficiency. Companies increasingly use computational tools to support the development of predictive scenarios in order to facilitate decision-making. However, the tools developed for SMEs are not always expedite and simple to use. The tool presented in this article intends to support the management of energy sources used by agro-industrial companies. It aims to facilitate and promote the implementation of a new culture of business management, in this sector so important at national level. The computational part is directed to support the decision-making on the selection of fossil or renewable energy sources to be used in a particular agroindustry, by presenting the average values of the energy consumption, cost and emissions associated with each selected energy source.}
}
@incollection{HASS202094,
title = {Measurement: Computerized Creativity Testing and Scoring},
editor = {Mark Runco and Steven Pritzker},
booktitle = {Encyclopedia of Creativity (Third Edition)},
publisher = {Academic Press},
edition = {Third Edition},
address = {Oxford},
pages = {94-99},
year = {2020},
isbn = {978-0-12-815615-5},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.23810-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245238108},
author = {Richard W. Hass},
keywords = {Creativity, Measurement, Assessment, Semantic memory, Computer algorithms, Divergent thinking, Remote association, Brainstorming, Domain-specificity, Creative problem solving},
abstract = {This entry discusses the use of computers in creativity measurement and assessment. Special emphasis is placed on the use of algorithms for scoring the responses generated during divergent thinking tasks. These algorithms are rooted in various theories of semantics, the details of which are also reviewed. In addition, advances in the use of computers for electronic brainstorming and for domain-specific creativity measurement beyond verbal divergent thinking are also reviewed. The objective is to provide readers with information on the various methods that are available, and a brief discussion of computational semantics.}
}
@article{ANANE20221103,
title = {Modular Robotic Prefabrication of Discrete Aggregations Driven by BIM and Computational Design},
journal = {Procedia Computer Science},
volume = {200},
pages = {1103-1112},
year = {2022},
note = {3rd International Conference on Industry 4.0 and Smart Manufacturing},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.01.310},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922003192},
author = {Walid Anane and Ivanka Iordanova and Claudiane Ouellet-Plamondon},
keywords = {BIM, Computational Design, Robotic Fabrication, Discrete Architecture, Modular Construction},
abstract = {Discrete architecture is recognized as a computational design approach which uses computation to generate algorithmically combinable aggregations. It is therefore a promising innovation for increasing design process productivity through the adaptability of the aggregations it generates. In the built environment, discrete design is usually identified with the modular method. It is a construction process based on the aggregation of different modules assembled according to well-defined connections to ensure the building’s integrity and functionality. It involves off-site manufacturing, and hence a controlled environment ensuring more predictability over weathering and change. But like in conventional construction practices, the fragmentation of modular construction processes hinders its productivity. As a result, this construction approach requires adequate technologies and communication tools to improve collaboration and productivity. This paper aims to address these requirements by adopting a BIM-driven computational approach to design processes and a robotic approach to prefabrication processes. It proposes a modular construction framework for design and production, and presents the results through a study adopting BIM-driven discrete design and robotic manufacturing.}
}
@article{AKRAMI20124,
title = {Lateral thinking, from the Hopfield model to cortical dynamics},
journal = {Brain Research},
volume = {1434},
pages = {4-16},
year = {2012},
note = {Selected papers presented at the International Workshop on Neural Coding, Limassol, Cyprus, 29 October - 3 November 2010},
issn = {0006-8993},
doi = {https://doi.org/10.1016/j.brainres.2011.07.030},
url = {https://www.sciencedirect.com/science/article/pii/S0006899311013151},
author = {Athena Akrami and Eleonora Russo and Alessandro Treves},
keywords = {Neural computation, Associative memory, Cortical dynamics, Modular network},
abstract = {Self-organizing attractor networks may comprise the building blocks for cortical dynamics, providing the basic operations of categorization, including analog-to-digital conversion, association and auto-association, which are then expressed as components of distinct cognitive functions depending on the contents of the neural codes in each region. To assess the viability of this scenario, we first review how a local cortical patch may be modeled as an attractor network, in which memory representations are not artificially stored as prescribed binary patterns of activity as in the Hopfield model, but self-organize as continuously graded patterns induced by afferent input. Recordings in macaques indicate that such cortical attractor networks may express retrieval dynamics over cognitively plausible rapid time scales, shorter than those dominated by neuronal fatigue. A cortical network encompassing many local attractor networks, and incorporating a realistic description of adaptation dynamics, may be captured by a Potts model. This network model has the capacity to engage long-range associations into sustained iterative attractor dynamics at a cortical scale, in what may be regarded as a mathematical model of spontaneous lateral thought. This article is part of a Special Issue entitled: Neural Coding.}
}
@article{MORTOLA201628,
title = {Thinking about breathing: Effects on respiratory sinus arrhythmia},
journal = {Respiratory Physiology & Neurobiology},
volume = {223},
pages = {28-36},
year = {2016},
issn = {1569-9048},
doi = {https://doi.org/10.1016/j.resp.2015.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S1569904815300963},
author = {Jacopo P. Mortola and Domnica Marghescu and Rosemarie Siegrist-Johnstone},
keywords = {Neural control of breathing, Parasympathetic control, Vagal tone},
abstract = {Respiratory sinus arrhythmia (RSA), the increase and decrease in instantaneous heart rate (HR) with inspiration and expiration, is commonly evaluated as function of breathing frequency f. However, to the extent that RSA plays a role in the efficiency of gas exchange, it may be expected to correlate better with HR/f (‘breathing specific heart rate’) than with f, because the former is a better reflection of the cardio-respiratory coupling. We measured RSA breath-by-breath in 209 young men and women during spontaneous breathing and during volitional breathing under auditory cues at vastly different f. In either case, and for both genders, RSA correlated better with HR/f than with f. As HR/f increased so did RSA, in a linear manner. When compared on the basis of HR/f, RSA did not differ significantly between spontaneous and volitional breathing. It is proposed that RSA is a central mechanism that ameliorates the matching between the quasi-continuous pulmonary blood flow and the intermittent airflow, irrespective of the type of ventilatory drive (cortical or autonomic).}
}
@article{ISMAILOVA202293,
title = {Lambda-calculus, combinators and applicative computational technologies},
journal = {Cognitive Systems Research},
volume = {76},
pages = {93-100},
year = {2022},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2022.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S1389041722000468},
author = {Larisa Ismailova and Viacheslav Wolfengagen and Sergey Kosikov},
keywords = {Lambda-calculus, Combinators, Compositional system, Cognitive activity},
abstract = {Applicative computing systems and technologies have taken a strong position in modern computing. In this paper, the basic applicative system, whether it is a lambda calculus or a system of combinators, is considered as a prototype concept system, using which it is possible to build individual systems that are practically significant for mathematics, computing, or programming. They are families of computational models that have both their own semantics and applied areas. This conceptualization/individualization technique is characteristic of the field of semantic studies. As it turns out, the applicative approach forms a metatheoretical framework that provides the basis for cognitive systems that consider abstract objects and interpret their properties and behavior in the environment of modern computing.}
}
@article{RYU2021107857,
title = {An efficient computational algorithm for Hausdorff distance based on points-ruling-out and systematic random sampling},
journal = {Pattern Recognition},
volume = {114},
pages = {107857},
year = {2021},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2021.107857},
url = {https://www.sciencedirect.com/science/article/pii/S0031320321000443},
author = {Jegoon Ryu and Sei-ichiro Kamata},
keywords = {Hausdorff distance, Computational complexity, Point matching, 3-D point sets},
abstract = {This paper proposes a novel algorithm for fast and accurate Hausdorff distance (HD) computation. The Hausdorff distance is used to measure the similarity between two point sets in various applications. However, it is hard to compute the HD algorithm efficiently between very large-scale point sets while ensuring the accuracy of the HD. The directed HD algorithm has two loops (called the outer loop and the inner loop) for calculating MAX-MIN distance, and the state-of-the-art algorithms, such as the Early break method and the Diffusion search method, focused on reducing the iterations of the inner loop. Our algorithm, however, concentrates on reducing the iterations of the outer loop. The proposed method simultaneously computes the temporary HD and temporary minimum distances of points corresponding to the outer loop using the opposite HD computation with very small systematic samples. Thereafter, a strategy of ruling out is employed to exclude non-contributing points. The new approach reduces the problems of different grid sizes and highly overlapping point sets as well as the very large-scale point sets. 3-D point clouds and real brain tumor segmentation (MRI 3-D volumes) are used for comparing the performance of the proposed algorithm and the state-of-the-art HD algorithms. In experimental results with 3-D point clouds, the proposed method is more than at least 1.5 times as faster as the compared algorithms. And, in experimental results with MRI 3-D volumes, the proposed method achieves a better performance than the compared algorithms over all pairs regardless of the grid size. Thus, as a whole, the proposed algorithm outperforms the compared algorithms.}
}
@article{KONSTANTINIDOU2022104424,
title = {Teaching with technology: A large-scale, international, and multilevel study of the roles of teacher and school characteristics},
journal = {Computers & Education},
volume = {179},
pages = {104424},
year = {2022},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2021.104424},
url = {https://www.sciencedirect.com/science/article/pii/S0360131521003018},
author = {Evi Konstantinidou and Ronny Scherer},
keywords = {Data science applications in education, Information literacy, Teaching/learning strategies, 21st century abilities},
abstract = {Providing high-quality instruction with technology has become more important than ever before. However, the instructional practices and the degree to which key skills, such as digital literacy and computational thinking, are emphasized in classrooms vary considerably between teachers, schools, and countries. The present study was aimed at explaining this variation in the frequency of teaching practices with technology and teachers' emphasis on developing students' computer and information literacy and computational thinking by key aspects of teacher motivation and expertise, school conditions and priorities, and countries' economy and innovation. Utilizing large-scale, representative data from the International Computer and Information Literacy Study (ICILS) 2018 (15,015 teachers in 1195 schools in eight countries), we performed multilevel structural equation modeling and regression trees and found that teacher motivation and collaboration were positively and consistently linked to teaching practices across countries. Besides, principals' expectations concerning the teaching with technology explained variation in Finnish and German schools. In three countries, teachers' professional development was related to their teaching practices. Finally, countries’ economic development and innovation explained variation in the teacher-level effects. Our study sheds new light on the possible factors related to teaching with technology and advances the field by taking a multilevel and international perspective on these factors.}
}
@article{PICKETT2024,
title = {Social Media Discourse Related to Caregiving for Older Adults Living With Alzheimer Disease and Related Dementias: Computational and Qualitative Study},
journal = {JMIR Aging},
volume = {7},
year = {2024},
issn = {2561-7605},
doi = {https://doi.org/10.2196/59294},
url = {https://www.sciencedirect.com/science/article/pii/S2561760524000537},
author = {Andrew C Pickett and Danny Valdez and Kelsey L Sinclair and Wesley J Kochell and Boone Fowler and Nicole E Werner},
keywords = {caregiving, dementia, social support, social media, Reddit},
abstract = {Background
In the United States, caregivers of people living with Alzheimer disease and Alzheimer disease–related dementias (AD/ADRD) provide >16 billion hours of unpaid care annually. These caregivers experience high levels of stress and burden related to the challenges associated with providing care. Social media is an emerging space for individuals to seek various forms of support.
Objective
We aimed to explore the primary topics of conversation on the social media site Reddit related to AD/ADRD. We then aimed to explore these topics in depth, specifically examining elements of social support and behavioral symptomology discussed by users.
Methods
We first generated an unsupervised topic model from 6563 posts made to 2 dementia-specific subreddit forums (r/Alzheimers and r/dementia). Then, we conducted a manual qualitative content analysis of a random subset of these data to further explore salient themes in the corpus.
Results
The topic model with the highest overall coherence score (0.38) included 10 topics, including caregiver burden, anxiety, support-seeking, and AD/ADRD behavioral symptomology. Qualitative analyses provided added context, wherein users sought emotional and informational support for many aspects of the care experience, including assistance in making key care-related decisions. Users expressed challenging and complex emotions on Reddit, which may be taboo to express in person.
Conclusions
Reddit users seek many different forms of support, including emotional and specific informational support, from others on the internet. Users expressed a variety of concerns, challenges, and behavioral symptoms to manage as part of the care experience. The unique (ie, anonymous and moderated) nature of the forum allowed for a safe space to express emotions free from documented caregiver stigma. Additional support structures are needed to assist caregivers of people living with AD/ADRD.}
}
@article{SHIN2025101771,
title = {Exploring creative problem-solving in computer-supported collaborative learning: Focusing on group cohesiveness and socially shared metacognitive regulation},
journal = {Thinking Skills and Creativity},
volume = {56},
pages = {101771},
year = {2025},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2025.101771},
url = {https://www.sciencedirect.com/science/article/pii/S1871187125000203},
author = {Yoonhee Shin and Haengkyung Lee and Wooyoung Kim},
keywords = {Creative problem-solving, Knowledge construction, Computer-supported collaborative learning, Group cohesiveness, Socially shared metacognitive regulation},
abstract = {This study investigated the creative problem-solving (CPS) process in computer-supported collaborative learning (CSCL), examining its relationship with CPS skills and interaction patterns, with a particular focus on group cohesiveness and socially shared metacognitive regulation (SSMR). The research sought to determine how group cohesiveness within Design Thinking (DT) phases influences CPS skills and to identify the characteristics of SSMR in high- versus low-creativity groups. Participants included 108 first-year undergraduate students majoring in humanities and social sciences at a South Korean university. The study found a significant relationship between group cohesiveness and CPS skill levels across various CPS phases. Specifically, substantial differences in SSMR patterns, particularly concerning exploration and evaluation, were observed among low- and high-creativity groups. These findings suggest that the interplay of divergent and convergent thinking during CPS is crucial for devising novel and practical solutions. Employing a mixed-methods approach and collaboration analysis, the study closely examined the CPS process using CSCL tools, offering valuable insights for informing future CPS instructional strategies.}
}
@article{POULOVA20151996,
title = {Education in Computational Sciences},
journal = {Procedia Computer Science},
volume = {51},
pages = {1996-2005},
year = {2015},
note = {International Conference On Computational Science, ICCS 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.05.464},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915012727},
author = {Petra Poulova and Blanka Klimova},
keywords = {Computational education, Key competences, Study programmes},
abstract = {The last two decades have witnessed an enormously rapid development of computational technologies which have undoubtedly affected all the fields of human activities, including education. In fact, computational science is one of the most evolving profile study programmes at technical universities nowadays. This article thus focuses on the description of the key content courses, curricula and degrees offered within the study programmes at the Faculty of Informatics and Management of the University of Hradec Kralove, Czech Republic. Moreover, this study characterizes teaching and learning of university undergraduate computational professionals with a special focus on core competences such as an ability to identify and solve problems, knowledge of analytical methods, or operating systems, but also on active and passive knowledge of English since English as lingua franca can help these professionals together with other core competences succeed in the job market after their graduation.}
}
@article{MOINGEON2022215,
title = {Artificial intelligence-enhanced drug design and development: Toward a computational precision medicine},
journal = {Drug Discovery Today},
volume = {27},
number = {1},
pages = {215-222},
year = {2022},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2021.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S1359644621003962},
author = {Philippe Moingeon and Mélaine Kuenemann and Mickaël Guedj},
keywords = {Artificial Intelligence, Big data, Computational precision medicine, Disease model, Drug discovery & development, Machine learning},
abstract = {Artificial Intelligence (AI) relies upon a convergence of technologies with further synergies with life science technologies to capture the value of massive multi-modal data in the form of predictive models supporting decision-making. AI and machine learning (ML) enhance drug design and development by improving our understanding of disease heterogeneity, identifying dysregulated molecular pathways and therapeutic targets, designing and optimizing drug candidates, as well as evaluating in silico clinical efficacy. By providing an unprecedented level of knowledge on both patient specificities and drug candidate properties, AI is fostering the emergence of a computational precision medicine allowing the design of therapies or preventive measures tailored to the singularities of individual patients in terms of their physiology, disease features, and exposure to environmental risks.}
}
@article{SCHORR2000209,
title = {Impact at the student level: a study of the effects of a teacher development intervention on students' mathematical thinking},
journal = {The Journal of Mathematical Behavior},
volume = {19},
number = {2},
pages = {209-231},
year = {2000},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(00)00045-6},
url = {https://www.sciencedirect.com/science/article/pii/S0732312300000456},
author = {Roberta Y Schorr},
keywords = {mathematics education, problem solving, teacher development},
abstract = {This research was conducted to study the impact on students of a long-term professional development intervention in mathematics for teachers in a low-wealth, urban school district. The emphasis in this assessment design was on obtaining a more accurate picture of student's problem-solving performance which challenged us to raise our expectations about student success from improved standardized test score data to an approach that focused on the way students think about mathematical tasks. The design used in this assessment provides a framework for considering teacher development and student assessment simultaneously. Results show that students taught by project teachers performed better in both classroom problem-solving activities and task-based interviews than students taught by nonproject teachers. In addition, there were major differences in the problem-solving behaviors of the two groups. Experimental students (students of project teachers) displayed greater mathematical confidence, and were more likely to see mathematics as a powerful way of thinking about the real world and approach mathematics as such.}
}
@article{KELLOGG2023255,
title = {Merging cultures and disciplines to create a drug discovery ecosystem at Virginia commonwealth university: Medicinal chemistry, structural biology, molecular and behavioral pharmacology and computational chemistry},
journal = {SLAS Discovery},
volume = {28},
number = {6},
pages = {255-269},
year = {2023},
note = {Emerging Drug Discovery Ecosystems},
issn = {2472-5552},
doi = {https://doi.org/10.1016/j.slasd.2023.02.006},
url = {https://www.sciencedirect.com/science/article/pii/S2472555223000175},
author = {Glen E. Kellogg and Yana Cen and Malgorzata Dukat and Keith C. Ellis and Youzhong Guo and Jiong Li and Aaron E. May and Martin K. Safo and Shijun Zhang and Yan Zhang and Umesh R. Desai},
keywords = {Drug discovery ecosystem, Structure-based drug discovery, Quantitative structure-activity relationships, Computational glycomics, Drug Discrimination, Allosteric effectors of hemoglobin, G protein-coupled receptors, Experimental structural biology, High-throughput screening},
abstract = {The Department of Medicinal Chemistry, together with the Institute for Structural Biology, Drug Discovery and Development, at Virginia Commonwealth University (VCU) has evolved, organically with quite a bit of bootstrapping, into a unique drug discovery ecosystem in response to the environment and culture of the university and the wider research enterprise. Each faculty member that joined the department and/or institute added a layer of expertise, technology and most importantly, innovation, that fertilized numerous collaborations within the University and with outside partners. Despite moderate institutional support with respect to a typical drug discovery enterprise, the VCU drug discovery ecosystem has built and maintained an impressive array of facilities and instrumentation for drug synthesis, drug characterization, biomolecular structural analysis and biophysical analysis, and pharmacological studies. Altogether, this ecosystem has had major impacts on numerous therapeutic areas, such as neurology, psychiatry, drugs of abuse, cancer, sickle cell disease, coagulopathy, inflammation, aging disorders and others. Novel tools and strategies for drug discovery, design and development have been developed at VCU in the last five decades; e.g., fundamental rational structure-activity relationship (SAR)-based drug design, structure-based drug design, orthosteric and allosteric drug design, design of multi-functional agents towards polypharmacy outcomes, principles on designing glycosaminoglycans as drugs, and computational tools and algorithms for quantitative SAR (QSAR) and understanding the roles of water and the hydrophobic effect.}
}
@article{MANNODIKANAKKITHODI202179,
title = {Computational Data-Driven Materials Discovery},
journal = {Trends in Chemistry},
volume = {3},
number = {2},
pages = {79-82},
year = {2021},
note = {Special Issue: Machine Learning for Molecules and Materials},
issn = {2589-5974},
doi = {https://doi.org/10.1016/j.trechm.2020.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S2589597420303178},
author = {Arun Mannodi-Kanakkithodi and Maria K.Y. Chan},
keywords = {computational materials design, machine learning, first principles density functional theory},
abstract = {Machine learning (ML) from large materials datasets enables accelerated materials discovery. Currently, the most accessible way to generate uniform, well-curated, voluminous datasets is by the application of high-throughput first principles computations. Here, we present the guiding principles of using computational data and ML to drive new materials discovery.}
}
@article{POEPPEL20221054,
title = {We don’t know how the brain stores anything, let alone words},
journal = {Trends in Cognitive Sciences},
volume = {26},
number = {12},
pages = {1054-1055},
year = {2022},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2022.08.010},
url = {https://www.sciencedirect.com/science/article/pii/S1364661322002066},
author = {David Poeppel and William Idsardi},
abstract = {Cognitive, computational, and neurobiological approaches have made impressive advances in characterizing the operations that transform linguistic signals into meanings. But our understanding of how words and concepts are retained in the brain remains inadequate. How is the long-term storage of words, or in fact any representations, achieved? This puzzle requires new thinking to stimulate reinvestigation of the storage problem.}
}
@article{SMITH2012210,
title = {Losing our way with mapping: Thinking critically about marine spatial planning in Scotland},
journal = {Ocean & Coastal Management},
volume = {69},
pages = {210-216},
year = {2012},
issn = {0964-5691},
doi = {https://doi.org/10.1016/j.ocecoaman.2012.08.016},
url = {https://www.sciencedirect.com/science/article/pii/S0964569112002335},
author = {Glen Smith and Ruth E. Brennan},
abstract = {Marine spatial planning (MSP) is the dominant management tool for marine environments around the world and is an attempt to move beyond the sectoral governance of marine spaces. Scotland is no exception and MSP is central to its management plans. The interpretation and use of spatial data informs these plans and maps provide the backbone of the decision-making process. Whilst not refuting MSP as a governance tool, this paper examines more closely some of the inherent problems with representing marine environments spatially and how the practice of map-making inevitably interacts with social-ecological networks. Borrowing from critical cartography and Actor-Network Theory (ANT), four observations are made: 1) due to the necessary procedure of categorising and simplifying data, maps do not always accurately represent changeable marine environments and situations; 2) maps can produce reality as much as represent it; 3) mapping has become the point through which all actors and stakeholders must pass; 4) as they are obliged to pass through this point, the roles and definition of certain actors can change. This discussion of marine spatial planning in Scotland demonstrates what can be learnt from viewing marine spaces as a tightly coupled social-ecological environment.}
}
@article{PENG20231143,
title = {Design of Data Persistence for Network Resources Recommendation System Based on Hibernate Architecture},
journal = {Procedia Computer Science},
volume = {228},
pages = {1143-1151},
year = {2023},
note = {3rd International Conference on Machine Learning and Big Data Analytics for IoT Security and Privacy},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.11.149},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923019804},
author = {Xia Peng and Jun Li and Yongchang Ren},
keywords = {Hibernate, "Python Programming", Network Resources, Recommendation System, Data Persistence},
abstract = {The Python language is more focused on problem solving, which is in line with the era of computational thinking, and the teaching of Python language course requires students to systematically master the basic concepts, programming ideas and programming techniques of Python, and have the idea of object-oriented software design technology. We have developed a recommended system of online resources for "Python Programming" course to solve the problem of students' access to resources and deepen the teaching reform of the Python Programming course. Data persistence is an important task in system development, and Hibernate is the most popular O/R Mapping framework. The data persistence design based on Hibernate solves the key technical problems in the development of the network resource recommendation system for the "Python Programming" course, and improves the efficiency and maintainability of the software system development.}
}
@article{DAVIS2023105580,
title = {Identifying social partners through indirect prosociality: A computational account},
journal = {Cognition},
volume = {240},
pages = {105580},
year = {2023},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2023.105580},
url = {https://www.sciencedirect.com/science/article/pii/S0010027723002147},
author = {Isaac Davis and Ryan Carlson and Yarrow Dunham and Julian Jara-Ettinger},
keywords = {Theory of mind, Social mindfulness, Computational modeling, Naive utility calculus},
abstract = {The ability to identify people who are prosocial, supportive, and mindful of others is critical for choosing social partners. While past work has emphasized the information value of direct social interactions (such as watching someone help or hinder others), social tendencies can also be inferred from indirect evidence, such as how an agent considers others when making personal choices. Here we present a computational model of this capacity, grounded in a Bayesian framework for action understanding. Across four experiments we show that this model captures how people infer social preferences based on how agents act when their choices indirectly impact others (Experiments 1a, 1b, & 1c), and how people infer what an agent knows about others from knowledge of that agent’s social preferences (Experiment 2). Critically, people’s patterns of inferences could not be explained by simpler alternatives. These findings illuminate how people can discern potential social partners from indirect evidence of their prosociality, thus deepening our understanding of partner detection, and social cognition more broadly.}
}
@article{KAO2023105008,
title = {Computational models of subjective feelings in psychiatry},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {145},
pages = {105008},
year = {2023},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2022.105008},
url = {https://www.sciencedirect.com/science/article/pii/S0149763422004973},
author = {Chang-Hao Kao and Gloria W. Feng and Jihyun K. Hur and Huw Jarvis and Robb B. Rutledge},
keywords = {Computational psychiatry, Subjective feelings, Depression, Happiness, Reward prediction errors, Computational model, Decision making, Smartphone},
abstract = {Research in computational psychiatry is dominated by models of behavior. Subjective experience during behavioral tasks is not well understood, even though it should be relevant to understanding the symptoms of psychiatric disorders. Here, we bridge this gap and review recent progress in computational models for subjective feelings. For example, happiness reflects not how well people are doing, but whether they are doing better than expected. This dependence on recent reward prediction errors is intact in major depression, although depressive symptoms lower happiness during tasks. Uncertainty predicts subjective feelings of stress in volatile environments. Social prediction errors influence feelings of self-worth more in individuals with low self-esteem despite a reduced willingness to change beliefs due to social feedback. Measuring affective state during behavioral tasks provides a tool for understanding psychiatric symptoms that can be dissociable from behavior. When smartphone tasks are collected longitudinally, subjective feelings provide a potential means to bridge the gap between lab-based behavioral tasks and real-life behavior, emotion, and psychiatric symptoms.}
}
@incollection{MAINZER2007115,
title = {The emergence of mind and brain: an evolutionary, computational, and philosophical approach},
editor = {Rahul Banerjee and Bikas K. Chakrabarti},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {168},
pages = {115-132},
year = {2007},
booktitle = {Models of Brain and Mind},
issn = {0079-6123},
doi = {https://doi.org/10.1016/S0079-6123(07)68010-8},
url = {https://www.sciencedirect.com/science/article/pii/S0079612307680108},
author = {Klaus Mainzer},
keywords = {brain, mind, complex systems, nonlinear dynamics, self-organization, computational systems, artificial minds},
abstract = {Modern philosophy of mind cannot be understood without recent developments in computer science, artificial intelligence (AI), robotics, neuroscience, biology, linguistics, and psychology. Classical philosophy of formal languages as well as symbolic AI assume that all kinds of knowledge must explicitly be represented by formal or programming languages. This assumption is limited by recent insights into the biology of evolution and developmental psychology of the human organism. Most of our knowledge is implicit and unconscious. It is not formally represented, but embodied knowledge, which is learnt by doing and understood by bodily interacting with changing environments. That is true not only for low-level skills, but even for high-level domains of categorization, language, and abstract thinking. The embodied mind is considered an emergent capacity of the brain as a self-organizing complex system. Actually, self-organization has been a successful strategy of evolution to handle the increasing complexity of the world. Genetic programs are not sufficient and cannot prepare the organism for all kinds of complex situations in the future. Self-organization and emergence are fundamental concepts in the theory of complex dynamical systems. They are also applied in organic computing as a recent research field of computer science. Therefore, cognitive science, AI, and robotics try to model the embodied mind in an artificial evolution. The paper analyzes these approaches in the interdisciplinary framework of complex dynamical systems and discusses their philosophical impact.}
}
@article{PILEGGI2021115065,
title = {Knowledge interoperability and re-use in Empathy Mapping: an ontological approach},
journal = {Expert Systems with Applications},
volume = {180},
pages = {115065},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.115065},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421005066},
author = {Salvatore F. Pileggi},
keywords = {Ontology, Data integration and re-use, Semantic interoperability, Semantic web, Data engineering, Knowledge engineering, Design thinking, Empathy mapping},
abstract = {Design Thinking is a human-centered approach extensively used across different domains that aims at problem solving, value creation for stakeholders and innovation by fostering creativity. The most characterising and critical step along the Design Thinking process is the empathy phase, in which stakeholder analysis is performed by looking at a given scenario from the perspective of different stakeholders. Such a methodology enables a systematic information gathering and organization that results in a deep understanding of actual problems, needs and expectations from the target stakeholders. The uniqueness of problems and the need for situation-specific data makes knowledge re-use not always practical, even within the most consolidated and experienced environments. In this paper we propose an ontological support to empathy mapping that aims to (i) establish an interoperable fine-grained data layer among the different data collected throughout the empathy mapping process, (ii) enable multi-scenario analysis underpinned by formal specifications and (iii) further empower the process through semantic enrichment and integration of insight from multiple sources and contexts. We believe this is the first step to design and properly integrate effective computational and AI-based functionalities along the creative design thinking process, as well as to enable in practice richer and more sophisticated approaches (e.g. through social networks).}
}
@article{WU2021106622,
title = {“Should’ve known better”: Counterfactual processing in disordered gambling},
journal = {Addictive Behaviors},
volume = {112},
pages = {106622},
year = {2021},
issn = {0306-4603},
doi = {https://doi.org/10.1016/j.addbeh.2020.106622},
url = {https://www.sciencedirect.com/science/article/pii/S0306460320307528},
author = {Yin Wu and Dawn Kennedy and Caylee-Britt Goshko and Luke Clark},
keywords = {Gambling disorder, Regret, Risk-taking, Counterfactual thinking, Affective sensitivity},
abstract = {Counterfactual thinking is a component of human decision-making that entails “if only” thinking about unselected choices and outcomes. It is associated with strong emotional responses of regret (when the obtained outcome is inferior to the counterfactual) and relief (vice versa). Counterfactual thinking may play a role in various cognitive phenomena in disordered gambling, such as the effects of near-misses. This study compared individuals with gambling disorder (n = 46) and healthy controls (n = 25) on a behavioural economic choice task that entailed choosing between two gambles, designed to measure counterfactual thinking. Participants provided affect ratings following both the obtained and the non-obtained outcomes. Choices were analyzed using a computational model that derived parameters reflecting sensitivity to expected value, risk variance, and anticipated regret. In the computational choice model, the group with gambling disorder showed increased sensitivity to anticipated regret, reduced sensitivity to expected value, and increased preference for high risk-variance gambles. On the affect ratings, the group with gambling disorder displayed blunted emotional sensitivity to obtained and counterfactual outcomes. Effect sizes of the group differences were modest. Participants with gambling disorder show wide-ranging alterations in decision-making processes and emotional reactivity to choice outcomes. Altered sensitivity to anticipatory regret in gambling disorder may contribute to the development of gambling-related cognitive distortions, and the influences of gambling marketing.}
}
@article{DECHENNE2022100932,
title = {A task to connect counting processes to lists of outcomes in combinatorics},
journal = {The Journal of Mathematical Behavior},
volume = {65},
pages = {100932},
year = {2022},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2021.100932},
url = {https://www.sciencedirect.com/science/article/pii/S0732312321000936},
author = {Adaline {De Chenne} and Elise Lockwood},
keywords = {Combinatorics, Student thinking, Discrete mathematics, Computational setting},
abstract = {Research has shown that solving counting problems correctly can be difficult for students at all levels, and mathematics educators have sought to identify strategies and interventions to help students reason conceptually about combinatorial tasks. A set-oriented perspective (Lockwood, 2014) is a way of thinking about counting problems that emphasizes the importance of reasoning about the set of outcomes being counted. From a set-oriented perspective, one possible type of intervention is to have students focus on the sets of outcomes rather than formulas and expressions, and specifically to reason about the structure of the set of outcomes. Yet, reasoning about sets of outcomes is not sufficient for students to make connections between outcomes and counting processes. In this paper, we investigate tasks where students wrote computer code to enumerate the set of outcomes in a specific order by implementing listing processes, and they were then asked to determine a specific numbered outcome in their list by using the structure of their enumeration scheme. We clarify particular aspects of a set-oriented perspective that were productive for students, and we demonstrate that tasks that asked students to name a specific outcome in their list elicited meaningful connections between counting processes and sets of outcomes. Further, such tasks reinforce desirable mathematical practices such as leveraging structure and connecting representations.}
}
@article{GREEN20214139,
title = {Computational biology: Turing’s lessons in simplicity},
journal = {Biophysical Journal},
volume = {120},
number = {19},
pages = {4139-4141},
year = {2021},
issn = {0006-3495},
doi = {https://doi.org/10.1016/j.bpj.2021.08.041},
url = {https://www.sciencedirect.com/science/article/pii/S000634952100727X},
author = {Jeremy B.A. Green},
abstract = {Biophysical modeling of development started with Alan Turing. His two-morphogen reaction-diffusion model was a radical but powerful simplification. Despite its apparent limitations, the model captured real developmental processes that only recently have been validated at the molecular level in many systems. The precision and robustness of reaction-diffusion patterning, despite boundary condition-dependence, remain active areas of investigation in developmental biology.}
}
@article{HSU2021100012,
title = {Behavioral-pattern exploration and development of an instructional tool for young children to learn AI},
journal = {Computers and Education: Artificial Intelligence},
volume = {2},
pages = {100012},
year = {2021},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2021.100012},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X21000060},
author = {Ting-Chia Hsu and Hal Abelson and Natalie Lao and Yu-Han Tseng and Yi-Ting Lin},
keywords = {Artificial intelligence education, Interdisciplinary instructional tool, Behavioral patterns},
abstract = {This study aimed at developing an instructional tool for the artificial intelligence education of young students, and used learning analytics to identify the sequential learning behavioral patterns of students during the process of learning with the instructional tool. The instructional experiment took 9 weeks. The first stage of the course was 5 weeks spent on individual learning of MIT App Inventor and Personal Image Classifier. The second stage was 4 weeks spent on cooperative learning to make a robot car and play a computational thinking board game. In the second stage, the students worked in pairs to make the robot car. Finally, they played the computational thinking board game with the personal image classification application they developed in the first stage and the robot car they made in the second stage. The innovative studies found meaningful behavioral patterns when the young students learned the application of artificial intelligence with the instructional tool developed and proposed in the study.}
}
@article{MELHAM2013129,
title = {Modelling, abstraction, and computation in systems biology: A view from computer science},
journal = {Progress in Biophysics and Molecular Biology},
volume = {111},
number = {2},
pages = {129-136},
year = {2013},
note = {Conceptual Foundations of Systems Biology},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2012.08.015},
url = {https://www.sciencedirect.com/science/article/pii/S0079610712000892},
author = {Tom Melham},
keywords = {Algorithmic biological modelling, Abstraction, Multi-scale modelling, Biological computation},
abstract = {Systems biology is centrally engaged with computational modelling across multiple scales and at many levels of abstraction. Formal modelling, precise and formalised abstraction relationships, and computation also lie at the heart of computer science—and over the past decade a growing number of computer scientists have been bringing their discipline's core intellectual and computational tools to bear on biology in fascinating new ways. This paper explores some of the apparent points of contact between the two fields, in the context of a multi-disciplinary discussion on conceptual foundations of systems biology.}
}
@article{VAEVER2005137,
title = {Thinking within the spectrum: schizophrenic thought disorder in six Danish pedigrees},
journal = {Schizophrenia Research},
volume = {72},
number = {2},
pages = {137-149},
year = {2005},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2004.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S092099640400132X},
author = {Mette S. Væver and Deborah M. Licht and Lise Møller and Dorthe Perlt and Åge Jørgensen and Peter Handest and Josef Parnas},
keywords = {Formal thought disorder, TDI, Schizophrenia spectrum, Pedigree},
abstract = {Formal thought disorder (FTD), a major symptom of schizophrenia, is known to aggregate in families. Our aim was to examine the specificity of FTD in the schizophrenia spectrum disorders and the hypothesized linear aggregation of FTD within pedigrees. Six individuals with a diagnosis of schizophrenia were identified in the Copenhagen High-Risk study and each pedigree was centered on one of the six original schizophrenic probands' nuclear families. The 329 pedigree members in the study were considered at risk for schizophrenia spectrum disorders because most were genetically related to the originating schizophrenic probands. The participants were administered the Copenhagen Interview of Functional Illness to determine diagnoses and the Thought Disorder Index (TDI) was used to assess FTD. Individuals with a schizophrenia diagnosis had higher global levels of FTD, exhibited more severe types of FTD, and had a qualitatively different type of FTD than did participants with other diagnoses or no mental illness. Individuals with Cluster A diagnoses exhibited more FTD and FTD similar in quality to participants with schizophrenia. These results support the construct of a spectrum of schizophrenia conditions. There was a generally high level of FTD in the pedigrees, in part due to assortative mating in this sample. However, there was no apparent pattern of linear aggregation of FTD within the families.}
}
@article{CARDENASSAINZ2022100381,
title = {Integration and acceptance of Natural User Interfaces for interactive learning environments},
journal = {International Journal of Child-Computer Interaction},
volume = {31},
pages = {100381},
year = {2022},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2021.100381},
url = {https://www.sciencedirect.com/science/article/pii/S2212868921000817},
author = {Brandon Antonio Cárdenas-Sainz and María Lucia Barrón-Estrada and Ramón Zatarain-Cabada and José Mario Ríos-Félix},
keywords = {Natural user interfaces, Gesture recognition, Interactive learning environments, Computational thinking, Secondary education, Technology Acceptance Model},
abstract = {This study focuses on the design of interactive learning environments (ILE) enhanced with Natural User Interfaces (NUI) for educational applications. It presents a 3D virtual environment, namely THINKMOTION which enables students to practice computational thinking skills. THINKMOTION combines a visual programming interface for coding and creating 3D virtual scenes with physics simulations, with a gesture recognition system for interaction over virtual objects. The ILE integrates a NUI called Leap Motion Controller, which recognizes the users’ hand movements and gestures A questionnaire was designed in order to evaluate the perceptions toward experimental learning with students of public and private secondary schools. It applies Technology Acceptance Model (TAM) and enhanced with new constructs such as perceived enjoyment and interface style. Results from our study highlight that: (1) NUI technologies positively impacted enjoyment and perceived ease of use among ILE users; (2) The ease of use provided by NUIs improved the enjoyment of students; (3) The perceived enjoyment considerably increased the intention to use; (4) For public school students, NUI technology has a significant impact on their first impressions and overall interest, followed by a positive attitude toward using ILE; (5) Private school students who are more accustomed to and familiar with using natural interfaces presented a positive attitude and enjoyment when using the ILE.}
}
@article{VATUTIN2021250,
title = {Computational psychometric approach for assessing mathematical problem-solving skills},
journal = {Procedia Computer Science},
volume = {193},
pages = {250-255},
year = {2021},
note = {10th International Young Scientists Conference in Computational Science, YSC2021, 28 June – 2 July, 2021},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.10.025},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921020664},
author = {Alexander Vatutin and Maria Moskalenko and Maxim Skryabin and Michael Svintsov and Alexander Trifanov},
keywords = {evidence-centered design, computational psychometrics, collateral information, educational data mining},
abstract = {In this paper, we described a computational approach in educational assessment and illustrated it with an interactive textbook of mathematics for undergraduate students. To maintain the validity of assessment results, we used evidence-centered design since data collection in psychometrics is aligned with a theoretical framework. However, the results of computational methods can be used as collateral information to extend psychometric models.}
}
@article{BENZEEV1995341,
title = {The nature and origin of rational errors in arithmetic thinking: Induction from examples and prior knowledge},
journal = {Cognitive Science},
volume = {19},
number = {3},
pages = {341-376},
year = {1995},
issn = {0364-0213},
doi = {https://doi.org/10.1016/0364-0213(95)90022-5},
url = {https://www.sciencedirect.com/science/article/pii/0364021395900225},
author = {Talia Ben-Zeev},
abstract = {Students systematically and deliberately apply rule-based but erroneous algorithms to solving unfamiliar arithmetic problems. These algorithms result in erroneous solutions termed rational errors. Computationally, students' erroneous algorithms can be represented by perturbations or bugs in otherwise correct arithmetic algorithms (Brown & VanLehn, 1980; Langley & Ohilson, 1984; VanLehn, 1983, 1986, 1990; Young S O'Sheo, 1981). Bugs are useful for describing how rational errors occur but bugs are not sufficient for explaining their origin. A possible explanation for this is that rational errors are the result of incorrect induction from examples. This prediction is termed the “induction hypothesis” (VanLehn, 1986). The purpose of the present study was to: (a) expand on post formulations of the induction hypothesis, and (b) use a new methodology to test the induction hypothesis more carefully than has been done previously. The first step involved teaching participants a new number system called NewAbacus, a written modification of the abacus system. The second step consisted of dividing them into different groups, where each individual received an example of only one port of the NewAbacus addition algorithm. During the third and final step, participants were instructed to solve both familiar and unfamiliar types of addition problems in NewAbacus. The induction hypothesis was supported by using both empirical and computational investigations.}
}
@article{MOUAKHER201915,
title = {On the efficient stability computation for the selection of interesting formal concepts},
journal = {Information Sciences},
volume = {472},
pages = {15-34},
year = {2019},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2018.08.056},
url = {https://www.sciencedirect.com/science/article/pii/S0020025518306741},
author = {A. Mouakher and S. {Ben Yahia}},
keywords = {Data mining, Pattern selection, Formal concept analysis, Formal concept, Interestingness measure, Stability measure, Minimal generator},
abstract = {The lattice theory under the framework of formal concept analysis has brought mathematical thinking to knowledge representation and discovery. In this respect, this mathematical framework offers a conceptual knowledge representation through the Galois lattice. This hierarchical conceptual structure has been beneficial within the task of knowledge discovery in databases. However, its effective use in large datasets is always limited by the overwhelming number of extracted formal concepts. To select interesting formal concepts, the stability measure can be of valuable help. The dedicated literature has highlighted non-scalable approaches to compute such a stability measure. In an effort to tackle this issue, we introduce the Dfsp algorithm dedicated to efficiently compute the quality measure of the stability of formal concepts. We also show that the stability computation is an instantiation of a larger issue: locating minimal generators given the closed pattern as a reference point. The guiding idea of the Dfsp algorithm is to maximize as far as possible the quantity of the useless search space through the swift localization of maximal non-generator cliques. The experiments performed demonstrate the efficiency of the Dfsp algorithm.}
}
@article{NOORIGOODARZI2023105449,
title = {Reverse vaccinology approaches to introduce promising immunogenic and drug targets against antibiotic-resistant Neisseria gonorrhoeae: Thinking outside the box in current prevention and treatment},
journal = {Infection, Genetics and Evolution},
volume = {112},
pages = {105449},
year = {2023},
issn = {1567-1348},
doi = {https://doi.org/10.1016/j.meegid.2023.105449},
url = {https://www.sciencedirect.com/science/article/pii/S1567134823000473},
author = {Narjes {Noori Goodarzi} and Soheila Ajdary and Mir Saeed Yekaninejad and Sepideh Fereshteh and Mohammad Reza Pourmand and Farzad Badmasti},
keywords = {Gonorrhea, Reverse vaccinology, Comparative genomics, Essential proteins, Immunogenic targets},
abstract = {Gonorrhea is an urgent antimicrobial resistance threat and its therapeutic options are continuously getting restricted. Moreover, no vaccine has been approved against it so far. Hence, the present study aimed to introduce novel immunogenic and drug targets against antibiotic-resistant Neisseria gonorrhoeae strains. In the first step, the core proteins of 79 complete genomes of N. gonorrhoeae were retrieved. Next, the surface-exposed proteins were evaluated from different aspects such as antigenicity, allergenicity, conservancy, and B-cell and T-cell epitopes to introduce promising immunogenic candidates. Then, the interactions with human Toll-like receptors (TLR-1, 2, and 4), and immunoreactivity to elicit humoral and cellular immune responses were simulated. On the other hand, to identify novel broad-spectrum drug targets, the cytoplasmic and essential proteins were detected. Then, the N. gonorrhoeae metabolome-specific proteins were compared to the drug targets of the DrugBank, and novel drug targets were retrieved. Finally, the protein data bank (PDB) file availability and prevalence among the ESKAPE group and common sexually transmitted infection (STI) agents were assessed. Our analyses resulted in the recognition of ten novel and putative immunogenic targets including murein transglycosylase A, PBP1A, Opa, NlpD, Azurin, MtrE, RmpM, LptD, NspA, and TamA. Moreover, four potential and broad-spectrum drug targets were identified including UMP kinase, GlyQ, HU family DNA-binding protein, and IF-1. Some of the shortlisted immunogenic and drug targets have confirmed roles in adhesion, immune evasion, and antibiotic resistance that can induce bactericidal antibodies. Other immunogenic and drug targets might be associated with the virulence of N. gonorrhoeae as well. Thus, further experimental studies and site-directed mutations are recommended to investigate the role of potential vaccine and drug targets in the pathogenesis of N. gonorrhoeae. It seems that the efforts for proposing novel vaccines and drug targets appear to be paving the way for a prevention-treatment strategy against this bacterium. Additionally, a combination of bactericidal monoclonal antibodies and antibiotics is a promising approach to curing N. gonorrhoeae.}
}
@incollection{CORICELLI2015153,
title = {Strategic Mentalizing: The Neural Correlates of Strategic Choice},
editor = {Arthur W. Toga},
booktitle = {Brain Mapping},
publisher = {Academic Press},
address = {Waltham},
pages = {153-157},
year = {2015},
isbn = {978-0-12-397316-0},
doi = {https://doi.org/10.1016/B978-0-12-397025-1.00171-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780123970251001718},
author = {G. Coricelli},
keywords = {Belief learning, Beliefs, Game theory, Medial prefrontal cortex, Mentalizing, Neuroeconomics, Neuroimaging, Recursive thinking, Social cognitive neuroscience, Strategic thinking, Theory of mind},
abstract = {This article adopts a neuroeconomics perspective on the study of the neural computations of human social interaction. Reported findings support a cognitive hierarchy model of human brain and behavior, according to which people use different levels of strategic thinking that are associated with specific neural computations. A higher level is associated with recursive thinking, which is the realization that others can also produce any thought process that we produce, while low level reflects self-referential thinking. The medial prefrontal cortex clearly distinguishes high level versus low level of strategic thinking, thus encoding the complexity underlying human social behavior.}
}
@article{KLUGE2025250,
title = {Extreme ingroup and outgroup perspectives counter-intuitively impact intergroup polarisation at the level of neural oscillations},
journal = {Cortex},
volume = {184},
pages = {250-262},
year = {2025},
issn = {0010-9452},
doi = {https://doi.org/10.1016/j.cortex.2024.12.020},
url = {https://www.sciencedirect.com/science/article/pii/S0010945225000097},
author = {Annika Kluge and Jonathan Levy},
keywords = {Social neuroscience, Affective polarisation, Covid-19 vaccination, Intergroup interventions, Magnetoencephalography, paradoxical thinking, IAT},
abstract = {A powerful example of affective polarisation occurred between vaccine-supporters and -opposers when vaccinations were implemented to counter the recent global pandemic. In this social neuroscience study, we scanned 121 vaccine-supporters using magnetoencephalography to evaluate three levels of polarisation: explicit, implicit, and neural — and then to test whether exposing people to extreme ingroup perspectives (following the paradoxical thinking principles) or extreme outgroup perspectives can modulate those levels of affective polarisation between vaccinated and unvaccinated individuals. We show that a neural proxy for intergroup polarisation, expressed as late prefrontal beta rhythm suppression, can detect subtle changes in affective polarisation. More specifically, we find that exposing vaccine-supporters to extreme ingroup (i.e., pro-vaccination) viewpoints leads to a decrease in this neural proxy of affective polarisation. Conversely, exposure to extreme outgroup (i.e., anti-vaccination) narratives increases polarisation, which in turn predicts a decrease in positive affect towards vaccine opposers almost one year later. Altogether, the results show that although it may seem intuitive to expose people to counter-arguments (i.e., extreme outgroup perspectives) to change their opinions, such an approach can backlash and increase polarisation instead. However, using subtler methods such as the paradoxical thinking intervention (i.e., extreme ingroup perspectives) for attitude change can have the desired effects and reduce intergroup polarisation.}
}
@article{REDKO202371,
title = {Computational modeling of insight processes and artificial cognitive ontogeny},
journal = {Cognitive Systems Research},
volume = {78},
pages = {71-86},
year = {2023},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2022.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S1389041722001061},
author = {Vladimir G. Red'ko and Alexei V. Samsonovich and Valentin V. Klimov},
keywords = {Computational creativity, Insight, Dual process theory, Cognitive architectures, Symbol grounding, Socially emotional intelligence},
abstract = {Many approaches were proposed to model complex socially emotional behavior in virtual actors, such as intelligent tutors, creative assistants, or team partners. They still lack the ‘magic’ of human-level cognition: systems built for one paradigm appear clueless outside of its boundary. Natural cognitive systems, on the other hand, can adapt to unexpected environments and paradigms. To capture the robustness of natural cognitive development, a new approach is proposed here that enables the formation of new higher cognitive abilities in a model system, embedded in an unexpected environment. This is achieved based on the naturally developing grounding of innate abstract constructs (schemas). The mechanism producing this binding is that of creative insight. In this study, principles of insight processes borrowed from psychology are formalized and adapted for computer modeling. To do this, several examples of insight phenomena at different evolutionary levels and in different species are analyzed before the model is formulated based on the dual process theory, the signal model of insight, and the eBICA cognitive architecture framework. Results of its computer simulations prove the concept. One specific finding is that the accumulation of activation during the incubation period increases creative abilities of the system. It is argued that the proposed approach can explain a range of facts and mysteries associated with the human cognitive ontogeny and can provide the basis for a self-sustained evolution of future Artificial Intelligence.}
}
@article{SEWING2008e9,
title = {Evolution in thinking and processes?},
journal = {Drug Discovery Today: Technologies},
volume = {5},
number = {1},
pages = {e9-e14},
year = {2008},
note = {HTS revisted},
issn = {1740-6749},
doi = {https://doi.org/10.1016/j.ddtec.2008.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S1740674908000140},
author = {Andreas Sewing},
abstract = {Pharmaceutical R&D transforms scientific ideas into drugs on the market. Owing to the complexity and low overall success rate, Drug Discovery needs to be as much about science as about operational excellence. In vitro screening groups, underwriting early discovery from exploratory to candidate selection, are trying to combine the search for new scientific concepts with a production-like focus on logistics, reproducibility and delivery on time. Moving beyond high-throughput technologies, we begin to ask how to improve processes and work more seamlessly across functional lines. In this context lean methods have become a front runner in discussions at drug discovery meetings. What are these methods and are they delivering what is promised, or are we looking at yet another management initiative?}
}
@article{MAGANA2016427,
title = {A case study of undergraduate engineering students' computational literacy and self-beliefs about computing in the context of authentic practices},
journal = {Computers in Human Behavior},
volume = {61},
pages = {427-442},
year = {2016},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2016.03.025},
url = {https://www.sciencedirect.com/science/article/pii/S0747563216301868},
author = {Alejandra J. Magana and Michael L. Falk and Camilo Vieira and Michael J. Reese},
keywords = {Computational literacy, Self-beliefs, Modeling and simulation practices, Anchored instruction},
abstract = {Engineering students, as compared to computing-related majors, are not traditionally introduced to computing in the context of authentic learning experiences, i.e., real-world applications within their discipline. This paper identifies the impact of computation delivered by authentic learning experiences in the form of anchored instruction on students' self-beliefs and their capacity to leverage computation to acquire disciplinary concepts in subsequent computationally-based engineering coursework. This case study included 130 students with different programing preparation (authentic or traditional), who were exposed to computational learning modules. Control-Value Theory of Achievement Emotions is the conceptual framework that guided the evaluation of this investigation. Measures included student self-beliefs such as control and value appraisals, and their relationship with academic performance. Results suggest that programming preparation presented in an authentic engineering context provides an important foundation that goes beyond increasing students' control self-beliefs. This preparation seems to effectively enable students to leverage computational practices for the purpose of acquiring disciplinary concepts. Implications for teaching relate to the integration of computation sooner, more often and within a disciplinary context in the undergraduate engineering curriculum. Implications for learning relate to fostering engineering computational literacy guided by anchored instruction to support disciplinary problem solving.}
}
@incollection{BAXTER20033,
title = {On the Foundations of Computational Mathematics},
series = {Handbook of Numerical Analysis},
publisher = {Elsevier},
volume = {11},
pages = {3-34},
year = {2003},
booktitle = {Handbook of Numerical Analysis},
issn = {1570-8659},
doi = {https://doi.org/10.1016/S1570-8659(02)11001-5},
url = {https://www.sciencedirect.com/science/article/pii/S1570865902110015},
author = {B.J.C. Baxter and A. Iserles},
abstract = {Publisher Summary
This chapter discusses the interaction of computational numerical with pure mathematics.. As far as computer scientists are concerned, their genuine “interface of interaction” with numerical thinking is in two distinct areas: complexity theory and high-performance computing. While complexity theory has always been a glamourous activity in theoretical computer science, it has only recently emerged as a focus of concerted activity in numerical circles, occasionally leading to a measure of acrimony. It is to be hoped that, eventually, computer scientists will find complexity issues involving real-number computations to be challenging, worthwhile, and central to the understanding of theoretical computation. Likewise, the ongoing development of parallel computer architectures and the computational grid is likely to lead to considerably better numerical/computational interaction at the more practical, engineering-oriented end.}
}
@article{CHANDRASEGARAN2023101182,
title = {Constructing design activity in words: Exploring linguistic methods to analyse the design process},
journal = {Design Studies},
volume = {86},
pages = {101182},
year = {2023},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2023.101182},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X23000236},
author = {Senthil Chandrasegaran and Almila Akdag Salah and Peter Lloyd},
keywords = {design thinking, collaborative design, design activity, research methods, text analysis},
abstract = {Analysing transcripts of design activity typically involve either close reading or manual coding of data, which limits the amount of data that can be analysed. In contrast, we explore a machine-learning based linguistic analysis tool called Empath to identify patterns of reasoning in design talk. The data we use derives from the Design Thinking Research Symposium (DTRS) shared-data workshops which we analyse to look at two contrasting aspects of design talk: the expression of tentativeness, characterising designers' generative thinking; and the articulation of explanations, characterising their deductive or analytical thinking. We show, at the level of speech turns, how tentativeness and explanation relate to, and overlap, each other. Finally, we discuss the limitations of this ‘linguistic analysis at scale’ approach.}
}
@article{DISSANAYAKE2025104098,
title = {The state-of-the-art of crowdsourcing systems: A computational literature review and future research agenda using a text analytics approach},
journal = {Information & Management},
volume = {62},
number = {2},
pages = {104098},
year = {2025},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2025.104098},
url = {https://www.sciencedirect.com/science/article/pii/S0378720625000011},
author = {Indika Dissanayake and Sridhar P. Nerur and Roman Lukyanenko and Minoo Modaresnezhad},
keywords = {Crowdsourcing, Crowdwork, Literature review, Topic modeling, Text analytics, LDA, BERT},
abstract = {Crowdsourcing effectively harnesses diverse skills and perspectives of crowds beyond organizational, geographical, and cultural boundaries. Organizations are gaining invaluable insights through crowdsourcing across diverse domains. This study reviews the growing academic literature on crowdsourcing using advanced topic modeling, an approach to unraveling key themes latent in the literature. Following a systems approach, we adopted inter- and intra-systems perspectives to identify distinct crowdsourcing models and their interrelated components based on a text analysis of the crowdsourcing literature. The paper elucidates the intellectual foundations of crowdsourcing as represented in the literature and offers suggestions for pursuing research that will extend its conceptual boundaries.}
}
@incollection{AHAMED2017163,
title = {Chapter 12 - From Primal Thinking to Potential Computing},
editor = {Syed V. Ahamed},
booktitle = {Evolution of Knowledge Science},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {163-185},
year = {2017},
isbn = {978-0-12-805478-9},
doi = {https://doi.org/10.1016/B978-0-12-805478-9.00012-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128054789000121},
author = {Syed V. Ahamed},
keywords = {Philosophic approaches and their limitations, Digital inroads into Knowledge, Positive and negative shifts of knowledge, Oscillations in knowledge domain},
abstract = {Chapter Summary
In this chapter, we investigate the generic representations of human functions and machine operations in the same framework for execution on the current computers, i.e., how a machine would execute human functions and conversely how a human would execute machine functions. This approach would facilitate the encoding of the (common) human functions as precisely as the machine language instructions for a computer. Conversely, the approach would facilitate the transfer of the lower-level intelligence of a human being into the adaptation of the HW, SW, and FW modules of an intelligent machine. Though not entirely feasible, the approach digs deep inroads in how human intelligent-machines can be and conversely, how robotic mundane-human beings can be. The later situation occurs in prisoner-, slave-, military-camps. The methodology is practical since machines have already started to imitate human behavior and some of the human tasks are routine and programmable into the robots. The challenge lies when some of the higher levels functions (such as conceptualize, hypothesize, optimize, generalize, axiomize, etc.) of human beings need to be programed into intelligent machines, even though middle level functions (such as summarize, generalize, rationalize, etc.) can be forced by appropriate knowledge-ware (KW) into intelligent machines. These middle level functions are encoded into the KW by searching for embedded knowledge centric objects (KCOs) in human beings, cultures, societies, and other contributing objects. Related and pertinent knowledge is found by exploring the local and the Internet knowledge bases (KBs) and selecting the attributes of these objects and or related objects. The Chapter outlines and elaborates the proposed approach.}
}
@article{SERIES202466,
title = {Can computational models help elucidate the link between complex trauma and hallucinations?},
journal = {Schizophrenia Research},
volume = {265},
pages = {66-73},
year = {2024},
note = {Hallucinations: Neurobiology and Patient Experience},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2023.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0920996423001834},
author = {Peggy Seriès and Emilie Veerapa and Renaud Jardri},
keywords = {Trauma, Voice hearing, Belief, Inference, Predictive coding, Bayesian models},
abstract = {Recently, a number of predictive coding models have been proposed to account for post-traumatic stress disorder (PTSD)'s symptomatology, including intrusions, flashbacks and hallucinations. These models were usually developed to account for traditional/type-1 PTSD. We here discuss whether these models also apply or can be translated to the case of complex/type-2 PTSD and childhood trauma (cPTSD). The distinction between PTSD and cPTSD is important because the disorders differ in terms of symptomatology and potential mechanisms, how they relate to developmental stages, but also in terms of illness trajectory and treatment. Models of complex trauma could give us insights on hallucinations in physiological/pathological conditions or more generally on the development of intrusive experiences across diagnostic classes.}
}
@article{PETERS2022104903,
title = {Towards characterizing the canonical computations generating phenomenal experience},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {142},
pages = {104903},
year = {2022},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2022.104903},
url = {https://www.sciencedirect.com/science/article/pii/S014976342200392X},
author = {Megan A.K. Peters},
keywords = {Metacognition, Consciousness, Computational modeling, Phenomenology, Qualia},
abstract = {Science and philosophy have long struggled with how to even begin studying the neural or computational basis of qualitative experience. Here I review psychological, neuroscience, and philosophical literature to reveal how perceptual metacognition possesses five unique properties that provide a powerful opportunity for studying the neural and computational correlates of subjective experience: (1) Metacognition leads to subjective experiences (we “feel” confident); (2) Metacognition is “about” internal representations, formalizing introspection; (3) Metacognitive computations are “recursive” (applying to meta-cognition and meta-meta-cognition), so we might discover “canonical computations” preserved across processing levels and implementations; (4) Metacognition is anchored to observable behavior; and (5) Metacognitive computations are unobservable yet hierarchically dependent, requiring development of sensitive, specific models. Given these properties, computational models of metacognition provide an empirically-tractable early step in characterizing the generative process that constructs qualitative experience. I also present practical ways to make progress in this vein, applying decades of developments in nearby fields to perceptual metacognition to reveal new and exciting insights about how the brain constructs subjective conscious experiences.}
}
@article{CHUNG200896,
title = {Revealing dimensions of thinking in open-ended self-descriptions: An automated meaning extraction method for natural language},
journal = {Journal of Research in Personality},
volume = {42},
number = {1},
pages = {96-132},
year = {2008},
issn = {0092-6566},
doi = {https://doi.org/10.1016/j.jrp.2007.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S0092656607000451},
author = {Cindy K. Chung and James W. Pennebaker},
keywords = {LIWC, Meaning extraction method, Natural language, Self-descriptions},
abstract = {A new method for extracting common themes from written text is introduced and applied to 1165 open-ended self-descriptive narratives. Drawing on a lexical approach to personality, the most commonly-used adjectives within narratives written by college students were identified using computerized text analytic tools. A factor analysis on the use of these adjectives in the self-descriptions produced a 7-factor solution consisting of psychologically meaningful dimensions. Some dimensions were unipolar (e.g., Negativity factor, wherein most loaded items were negatively valenced adjectives); others were dimensional in that semantically opposite words clustered together (e.g., Sociability factor, wherein terms such as shy, outgoing, reserved, and loud all loaded in the same direction). The factors exhibited modest reliability across different types of writing samples and were correlated with self-reports and behaviors consistent with the dimensions. Similar analyses with additional content words (adjectives, adverbs, nouns, and verbs) yielded additional psychological dimensions associated with physical appearance, school, relationships, etc. in which people contextualize their self-concepts. The results suggest that the meaning extraction method is a promising strategy that determines the dimensions along which people think about themselves.}
}
@incollection{HASKELL2001205,
title = {Chapter 12 - The Harmonic Structure of Mind: Higher Level Everyday Transfer Thinking},
editor = {Robert E. Haskell},
booktitle = {Transfer of Learning},
publisher = {Academic Press},
address = {San Diego},
pages = {205-218},
year = {2001},
series = {Educational Psychology},
issn = {18716148},
doi = {https://doi.org/10.1016/B978-012330595-4/50013-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780123305954500135},
author = {Robert E. Haskell},
abstract = {Publisher Summary
This chapter focuses on harmonic mind and its structure, and its importance in everyday transfer thinking. The harmonic structure of higher level transfer thinking helps to efficiently store, integrate, remember, process, and retrieve information. Such a structure becomes a memory or mnemonic device for learning. This form of analogical transfer is also seen in the basic structure of higher level mathematical thinking. Thus it appears that transfer ability and mathematical ability are integrally related on some fundamental neurological level. Although analogical transfer ability, which is manifested mathematically in abstract proportional forms, is characteristic of all good mathematicians, those not skilled in higher mathematics may nevertheless be good at transfer thinking.}
}
@article{CHRISTOU2001321,
title = {Mapping and development of intuitive proportional thinking},
journal = {The Journal of Mathematical Behavior},
volume = {20},
number = {3},
pages = {321-336},
year = {2001},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(02)00077-9},
url = {https://www.sciencedirect.com/science/article/pii/S0732312302000779},
author = {Constantinos Christou and George Philippou},
keywords = {Multiplicative problems, Conceptual field, Cardinalities},
abstract = {The purpose of this study was two-fold. First, to find out students’ informal understanding of proportional problems, and discuss their solution strategies. Second, to investigate how the intuitions developed by students influence their strategies to solve proportional problems. To this end, we interviewed 16 students in Grades 4 and 5, while they were solving proportional problems. It was found that students intuitively used the unit-rate strategy indicating an attempt to transfer the knowledge resulted by their experience with solving simple multiplicative problems. Fourth and fifth graders tended to shift from the unit-rate strategy to other strategies if there was no easy way to calculate the unit-value directly from the context of the problems. Since fifth graders were more comfortable than fourth graders in calculating the unit-value, they felt less the need to invent other solution strategies.}
}
@incollection{KASTURIRANGAN2007105,
title = {Thinking is believing},
editor = {Rahul Banerjee and Bikas K. Chakrabarti},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {168},
pages = {105-114},
year = {2007},
booktitle = {Models of Brain and Mind},
issn = {0079-6123},
doi = {https://doi.org/10.1016/S0079-6123(07)68009-1},
url = {https://www.sciencedirect.com/science/article/pii/S0079612307680091},
author = {Rajesh Kasturirangan},
keywords = {thoughts, beliefs, stories, mathematical modeling},
abstract = {Philosophers as well lay people often think of beliefs as psychological states with dubious epistemic properties. Beliefs are conceptualized as unregulated conceptual structures, for the most part hypothetical and often fanciful or deluded. Thinking and reasoning on the other hand are seen as rational activities regulated by rules and governed by norms. Computational modeling of the mind has focused on rule-governed behavior, ultimately trying to reduce them to rules of logic. What if thinking is less like reasoning and more like believing? I argue that the classical model of thought as rational is mistaken and that thinking is fundamentally constituted by believing. This new approach forces us to re-evaluate classical epistemic concepts like “truth”, “justification” etc. Furthermore, if thinking is believing, then it is not clear how thoughts can be modeled computationally. We need new mathematical ideas to model thought, ideas that are quite different from traditional logic-based mathematical structures.}
}
@article{CUI2021412,
title = {Artificial intelligence and computational pathology},
journal = {Laboratory Investigation},
volume = {101},
number = {4},
pages = {412-422},
year = {2021},
issn = {0023-6837},
doi = {https://doi.org/10.1038/s41374-020-00514-0},
url = {https://www.sciencedirect.com/science/article/pii/S0023683722006468},
author = {Miao Cui and David Y. Zhang},
abstract = {Data processing and learning has become a spearhead for the advancement of medicine, with pathology and laboratory medicine has no exception. The incorporation of scientific research through clinical informatics, including genomics, proteomics, bioinformatics, and biostatistics, into clinical practice unlocks innovative approaches for patient care. Computational pathology is burgeoning subspecialty in pathology that promises a better-integrated solution to whole-slide images, multi-omics data, and clinical informatics. However, computational pathology faces several challenges, including the ability to integrate raw data from different sources, limitation of hardware processing capacity, and a lack of specific training programs, as well as issues on ethics and larger societal acceptable practices that are still solidifying. The establishment of the entire industry of computational pathology requires far-reaching changes of the three essential elements connecting patients and doctors: the local laboratory, the scan center, and the central cloud hub/portal for data processing and retrieval. Computational pathology, unlocked through information integration and advanced digital communication networks, has the potential to improve clinical workflow efficiency, diagnostic quality, and ultimately create personalized diagnosis and treatment plans for patients. This review describes clinical perspectives and discusses the statistical methods, clinical applications, potential obstacles, and future directions of computational pathology.}
}
@article{STUPURIENE2024104939,
title = {Teachers’ perceptions of the barriers and drivers for the integration of Informatics in primary education},
journal = {Computers & Education},
volume = {208},
pages = {104939},
year = {2024},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2023.104939},
url = {https://www.sciencedirect.com/science/article/pii/S0360131523002166},
author = {Gabrielė Stupurienė and Margarida Lucas and Pedro Bem-Haja},
keywords = {Primary education, Teacher professional development, Thematic analysis, Network analysis, Informatics education},
abstract = {A growing trend of integrating and teaching Informatics and Computational Thinking (CT) skills at primary education levels poses different challenges for teachers. Research demonstrates that it is challenging to introduce Informatics in schools without well-prepared teachers. In this paper, we examine Lithuanian teachers' perceptions of the barriers and drivers to integrate the renewed Informatics curricula in primary education and the relation between them. Fifteen semi-structured interviews were conducted with primary school teachers, and a mixed-methods approach was employed to analyze them. The results show that explicit guidelines for renewed curricula and motivation to learn Informatics are both identified as the main barriers and drivers for integrating Informatics. The study further highlights the critical role of resources, appropriate tools, and guidelines in facilitating the successful implementation of Informatics. The study provides knowledge that could, for instance, benefit teacher training programmes and help better understand how teachers can be better supported to meet current and future challenges.}
}
@article{CHAKRABORTY2021113486,
title = {Conformations and tautomerisation between (Z)-4-(hydroxyethyl) isochroman-1, 3-dione and and 4-acetyl-3-hydroxyisochroman-1-one: A computational study through Energy, electron Distribution, vibrational analysis and hardness profiles},
journal = {Computational and Theoretical Chemistry},
volume = {1206},
pages = {113486},
year = {2021},
issn = {2210-271X},
doi = {https://doi.org/10.1016/j.comptc.2021.113486},
url = {https://www.sciencedirect.com/science/article/pii/S2210271X21003443},
author = {Abhijit Chakraborty and Goutam Dey},
keywords = {, , (Z)-4-(hydroxyethyl) isochroman-1, 3-dione, , , },
abstract = {The saturated and unsaturated rings in the tautomers of (Z)-4-(hydroxyethyl) isochroman-1, 3-dione (EIC) and 4-acetyl-3-hydroxyisochroman-1-one (AOC) are found to be nonplanar. All the DFT and ab-initio computational methods with various basis sets identify EIC as the global minimum in S0. IRC and frequency computations locate the transition states (TS). AOC and TS are located about 3.5 ± 0.5 kcal/mole and 4.5 ± 0.8 kcal/mole higher in energy than EIC. The transition region is clearly marked with the evaluation of reaction force and force constants. CIS and TDDFT computations show inconsistent results. MHP is obeyed by the EIC tautomer, while MEP is obeyed by the TS structure. Frontier molecular orbitals confirms the S0 → S1 transition as π-π* in nature. The vibrational signatures in the tautomers corresponding to CO stretching modes and ring modes are identified. The earlier observed 1740 cm-1C = O stretching mode is computed to appear at 1763 cm−1 in EIC.}
}
@article{KAUFFMAN1999256,
title = {Thinking combinatorially},
journal = {Current Opinion in Chemical Biology},
volume = {3},
number = {3},
pages = {256-259},
year = {1999},
issn = {1367-5931},
doi = {https://doi.org/10.1016/S1367-5931(99)80040-4},
url = {https://www.sciencedirect.com/science/article/pii/S1367593199800404},
author = {Stuart Kauffman and Andrew D Ellington},
abstract = {Biopolymers and chemical compounds with novel functions can be selected or screened from randomized libraries. Recently, it has become possible to augment the functions of biopolymers via the conjugation or incorporation of unnatural chemical moieties. In the future, it should prove possible to engineer systems that can self-evolve and thereby reveal unexpected emergent properties.}
}
@article{GOLDMAN201725,
title = {Computational training for the next generation of neuroscientists},
journal = {Current Opinion in Neurobiology},
volume = {46},
pages = {25-30},
year = {2017},
note = {Computational Neuroscience},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2017.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S0959438817301599},
author = {Mark S Goldman and Michale S Fee},
abstract = {Neuroscience research has become increasingly reliant upon quantitative and computational data analysis and modeling techniques. However, the vast majority of neuroscientists are still trained within the traditional biology curriculum, in which computational and quantitative approaches beyond elementary statistics may be given little emphasis. Here we provide the results of an informal poll of computational and other neuroscientists that sought to identify critical needs, areas for improvement, and educational resources for computational neuroscience training. Motivated by this survey, we suggest steps to facilitate quantitative and computational training for future neuroscientists.}
}
@article{HERMANN2024114720,
title = {Artificial intelligence and consumer behavior: From predictive to generative AI},
journal = {Journal of Business Research},
volume = {180},
pages = {114720},
year = {2024},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2024.114720},
url = {https://www.sciencedirect.com/science/article/pii/S0148296324002248},
author = {Erik Hermann and Stefano Puntoni},
keywords = {Artificial intelligence, Consumer behavior, Algorithms, Predictive AI, Generative AI},
abstract = {Since the introduction of ChatGPT, the leading example of Generative Artificial Intelligence (GenAI), the research community and the general public have been captivated by GenAI’s remarkable advances in performance, and its ability to both imitate and, in some respects, surpass human capabilities. This paper offers a comprehensive analysis of the impact of AI on consumer behavior, focusing on the two pivotal phases of AI development over the past 15 years. We start by reviewing the extensively researched, yet still growing, field of algorithmic predictions and decision-making, alongside the varied positive and negative consumer reactions it elicits. Subsequently, we delve into the just emerging field of GenAI. Here, we differentiate between Convergent Thinking GenAI, which is more domain-specific and geared towards pre-defined task completion, and Divergent Thinking GenAI, which is more domain-general and oriented towards new task fulfillment. For each of these realms, we identify key areas for future investigation.}
}
@article{TUTHILL2020R739,
title = {What we think about when we think about thinking},
journal = {Current Biology},
volume = {30},
number = {13},
pages = {R739-R740},
year = {2020},
issn = {0960-9822},
doi = {https://doi.org/10.1016/j.cub.2020.05.034},
url = {https://www.sciencedirect.com/science/article/pii/S0960982220306734},
author = {John Tuthill}
}
@article{MOLLER2021103155,
title = {Computational models of the “active self” and its disturbances in schizophrenia},
journal = {Consciousness and Cognition},
volume = {93},
pages = {103155},
year = {2021},
issn = {1053-8100},
doi = {https://doi.org/10.1016/j.concog.2021.103155},
url = {https://www.sciencedirect.com/science/article/pii/S1053810021000817},
author = {Tim Julian Möller and Yasmin Kim Georgie and Guido Schillaci and Martin Voss and Verena Vanessa Hafner and Laura Kaltwasser},
keywords = {Schizophrenia, Self-disorders, Minimal self, Active self, Sense of agency, Sense of ownership, Computational psychiatry, Cognitive robotics, Developmental robotics, Predictive processing},
abstract = {The notion that self-disorders are at the root of the emergence of schizophrenia rather than a symptom of the disease, is getting more traction in the cognitive sciences. This is in line with philosophical approaches that consider an enactive self, constituted through action and interaction with the environment. We thereby analyze different definitions of the self and evaluate various computational theories lending to these ideas. Bayesian and predictive processing are promising approaches for computational modeling of the “active self”. We evaluate their implementation and challenges in computational psychiatry and cognitive developmental robotics. We describe how and why embodied robotic systems provide a valuable tool in psychiatry to assess, validate, and simulate mechanisms of self-disorders. Specifically, mechanisms involving sensorimotor learning, prediction, and self-other distinction, can be assessed with artificial agents. This link can provide essential insights to the formation of the self and new avenues in the treatment of psychiatric disorders.}
}
@article{KOCH1996193,
title = {Students' understanding of computation-related rational number skills},
journal = {The Journal of Mathematical Behavior},
volume = {15},
number = {2},
pages = {193-205},
year = {1996},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(96)90016-4},
url = {https://www.sciencedirect.com/science/article/pii/S0732312396900164},
author = {Laura Coffin Koch and Xiaoming Li},
abstract = {The purpose of this study was to investigate the differences between students' and instructors' perceptions of similarities among basic computation-related rational number skills. Multidimensional scaling was used to determine how the students organized their thinking about the computational problems. This was done by estimating the parameters and assessing the fit of various spatial distance models for proximity. Results indicate that college students enrolled in developmental mathematics do see some relationships among rational number computation skills, although not necessarily the ones seen by instructors.}
}
@article{YAO2023102216,
title = {Accelerating surface remeshing through GPU-based computation of the restricted tangent face},
journal = {Computer Aided Geometric Design},
volume = {104},
pages = {102216},
year = {2023},
issn = {0167-8396},
doi = {https://doi.org/10.1016/j.cagd.2023.102216},
url = {https://www.sciencedirect.com/science/article/pii/S0167839623000481},
author = {Yuyou Yao and Jingjing Liu and Wenming Wu and Gaofeng Zhang and Benzhu Xu and Liping Zheng},
keywords = {Restricted tangent face, Centroidal Voronoi tessellation, Parallel computation, GPU acceleration, Surface remeshing},
abstract = {High-quality mesh surfaces are crucial for geometric processing in a variety of applications. To generate these meshes, polyhedral remeshing techniques truncate Voronoi cells of the original surface and yield precise intersections, but the calculation is complicated. Some methods apply auxiliary points to construct Voronoi diagrams to simplify these techniques, thereby extracting co-planar facets to approximate the original surface. However, extracting these approximate facets from the constructed Voronoi diagram makes it inefficient and non-parallelizable. To this end, we propose an efficient GPU method for manifold surface remeshing, where the restricted tangent face (RTF) is utilized to approximate the original surface. By intersecting the pre-clipped Voronoi cell with the tangent plane, this method directly calculates the RTF of each point without any auxiliary points or traversing Voronoi cells. Moreover, to restrict the movement of points, we introduce a projection method based on the KNN strategy, where each point is projected onto the triangular facet in the original surface. Owing to the independence and non-interference of the RTF computation and projection of each point, our method is implemented in parallel on the GPU. Experimental results on various mesh surfaces demonstrate the superior performance of our method in the viability, effectiveness, and efficiency.}
}
@article{TONTINI2021101720,
title = {Artificial intelligence: Thinking outside the box},
journal = {Best Practice & Research Clinical Gastroenterology},
volume = {52-53},
pages = {101720},
year = {2021},
note = {Artificial intelligence in GI-endoscopy},
issn = {1521-6918},
doi = {https://doi.org/10.1016/j.bpg.2020.101720},
url = {https://www.sciencedirect.com/science/article/pii/S152169182030055X},
author = {Gian Eugenio Tontini and Helmut Neumann},
keywords = {AI, Artificial intelligence, Learning, Advanced imaging},
abstract = {Artificial intelligence (AI) for luminal gastrointestinal endoscopy is rapidly evolving. To date, most applications have focused on colon polyp detection and characterization. However, the potential of AI to revolutionize our current practice in endoscopy is much more broadly positioned. In this review article, the Authors provide new ideas on how AI might help endoscopists in the future to rediscover endoscopy practice.}
}
@article{IRSAL20241165,
title = {Computational exploration of palmitoyl-protein thioesterase 1 inhibition by Juniperus phoenicea L. for anti-dementia treatment},
journal = {Journal of Taibah University Medical Sciences},
volume = {19},
number = {6},
pages = {1165-1180},
year = {2024},
issn = {1658-3612},
doi = {https://doi.org/10.1016/j.jtumed.2024.12.005},
url = {https://www.sciencedirect.com/science/article/pii/S1658361224001495},
author = {Riyan A. Putera Irsal and Gusnia Meilin Gholam and Maheswari Alfira Dwicesaria and Tiyara F. Mansyah and Fernanda Chairunisa},
keywords = {Alternative medicine, Docking, Molecular dynamics, PASS server, Toxicity}
}
@article{HOWLAND2015224,
title = {Learning to communicate computationally with Flip: A bi-modal programming language for game creation},
journal = {Computers & Education},
volume = {80},
pages = {224-240},
year = {2015},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2014.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S036013151400195X},
author = {Kate Howland and Judith Good},
keywords = {Evaluation of CAL systems, Interactive learning environments, Programming and programming languages, Secondary education},
abstract = {Teaching basic computational concepts and skills to school children is currently a curricular focus in many countries. Running parallel to this trend are advances in programming environments and teaching methods which aim to make computer science more accessible, and more motivating. In this paper, we describe the design and evaluation of Flip, a programming language that aims to help 11–15 year olds develop computational skills through creating their own 3D role-playing games. Flip has two main components: 1) a visual language (based on an interlocking blocks design common to many current visual languages), and 2) a dynamically updating natural language version of the script under creation. This programming-language/natural-language pairing is a unique feature of Flip, designed to allow learners to draw upon their familiarity with natural language to “decode the code”. Flip aims to support young people in developing an understanding of computational concepts as well as the skills to use and communicate these concepts effectively. This paper investigates the extent to which Flip can be used by young people to create working scripts, and examines improvements in their expression of computational rules and concepts after using the tool. We provide an overview of the design and implementation of Flip before describing an evaluation study carried out with 12–13 year olds in a naturalistic setting. Over the course of 8 weeks, the majority of students were able to use Flip to write small programs to bring about interactive behaviours in the games they created. Furthermore, there was a significant improvement in their computational communication after using Flip (as measured by a pre/post-test). An additional finding was that girls wrote more, and more complex, scripts than did boys, and there was a trend for girls to show greater learning gains relative to the boys.}
}
@article{PREISIG201259,
title = {Thinking Towards Synergistic Green Refineries},
journal = {Energy Procedia},
volume = {20},
pages = {59-67},
year = {2012},
note = {Technoport 2012 - Sharing Possibilities and 2nd Renewable Energy Research Conference (RERC2012)},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2012.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S1876610212007382},
author = {Heinz A. Preisig and Bernd Wittgens},
keywords = {Bioreﬁnery, Green reﬁnery, Biobased Economy},
abstract = {The switch from a mined-carbon-based society to a bio-carbon based society requires a major shift not only of the resources,but alsoin the typeof processes that produce the products on which ourcivilizationbuilds;a richer approach to handling and production is required. Natural products from renewable sources will substitute today'spurely synthetic products from fossil resources, associated waste streams will have to be utilized for the production of usable materials, with chemical processing being one of the main options.Fuel represents a main class of chemicals that we increasingly rely on. They have to be substituted as quick as possible as they represent the largest use of mined carbon. The paper presents some of the stumbling blocks which prohibit the transfer and high lights the most needed research objectives.}
}
@article{DINOV2008284,
title = {Pedagogical utilization and assessment of the statistic online computational resource in introductory probability and statistics courses},
journal = {Computers & Education},
volume = {50},
number = {1},
pages = {284-300},
year = {2008},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2006.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S0360131506001059},
author = {Ivo D. Dinov and Juana Sanchez and Nicolas Christou},
keywords = {Education research, Teaching with technology, Java applets, Online course materials, Probability and statistics},
abstract = {Technology-based instruction represents a new recent pedagogical paradigm that is rooted in the realization that new generations are much more comfortable with, and excited about, new technologies. The rapid technological advancement over the past decade has fueled an enormous demand for the integration of modern networking, informational and computational tools with classical pedagogical instruments. Consequently, teaching with technology typically involves utilizing a variety of IT and multimedia resources for online learning, course management, electronic course materials, and novel tools of communication, engagement, experimental, critical thinking, and assessment. The NSF-funded Statistics Online Computational Resource (SOCR) provides a number of interactive tools for enhancing instruction in various undergraduate and graduate courses in probability and statistics. These resources include online instructional materials, statistical calculators, interactive graphical user interfaces, computational and simulation applets, tools for data analysis and visualization. The tools provided as part of SOCR include conceptual simulations and statistical computing interfaces, which are designed to bridge between the introductory and the more advanced computational and applied probability and statistics courses. In this manuscript, we describe our designs for utilizing SOCR technology in instruction in a recent study. In addition, present the results of the effectiveness of using SOCR tools at two different course intensity levels on three outcome measures: exam scores, student satisfaction and choice of technology to complete assignments. Learning styles assessment was completed at baseline. We have used three very different designs for three different undergraduate classes. Each course included a treatment group, using the SOCR resources, and a control group, using classical instruction techniques. Our findings include marginal effects of the SOCR treatment per individual classes; however, pooling the results across all courses and sections, SOCR effects on the treatment groups were exceptionally robust and significant. Coupling these findings with a clear decrease in the variance of the quantitative examination measures in the treatment groups indicates that employing technology, like SOCR, in a sound pedagogical and scientific manner enhances overall the students’ understanding and suggests better long-term knowledge retention.}
}
@article{CASALS201981,
title = {Who and what can contribute to improve the statistical thinking in sports injury research? A humorous analogy between basketball and members of the multidisciplinary research team},
journal = {Apunts. Medicina de l'Esport},
volume = {54},
number = {203},
pages = {81-84},
year = {2019},
issn = {1886-6581},
doi = {https://doi.org/10.1016/j.apunts.2019.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S1886658119300271},
author = {Marti Casals and Rasmus Oestergaard Nielsen}
}
@article{UPADHYAY20171055,
title = {Future Directions and a Roadmap in Digital Computational Humanities for a Data Driven Organization},
journal = {Procedia Computer Science},
volume = {122},
pages = {1055-1060},
year = {2017},
note = {5th International Conference on Information Technology and Quantitative Management, ITQM 2017},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.11.473},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917327266},
author = {Shalini Upadhyay and Nitin Upadhyay},
keywords = {Digital Humanities, Computational Humanities, Social-technical infrastructure, Data driven organization},
abstract = {The development in the computational artifacts, social media, and network infrastructure has provided a unique opportunity to scholars, academicians and researchers to enhance their understanding of the presence of “Humanities” in the digital spectrum. The current research work explores the continuum of “Digital Computational Humanities” and provides the future directions and a roadmap for its establishment, sustainability and usefulness for data driven organizations.}
}
@article{COTTAM2022104671,
title = {Chaos, complexity and computation in the evolution of biological systems},
journal = {Biosystems},
volume = {217},
pages = {104671},
year = {2022},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2022.104671},
url = {https://www.sciencedirect.com/science/article/pii/S0303264722000612},
author = {Ron Cottam and Roger Vounckx},
abstract = {Chaos, complexity and computation are especially important concepts with respect to both the Evolution of biological systems and the evolution of the Universe. We consider each of these five entities separately, and then view their combination in an overall consideration of both evolution and Evolution. The concept of computation can be directly derived from processes characteristic of the Evolution of biology or the evolution of the Universe, rather than presumed from our own mathematical ideas. We advocate the inclusion of meaning in science's deliberations, and support this by insisting that physically embodied abstractions should be considered part concrete in character. Combination of our initial five conceptual entities indicates that biological Evolution follows the same developmental criteria as the evolution of the Universe, albeit with an intermediate change in strategy. We conclude that evolutionarily derived computation is the prime driver of evolution/Evolutions' implications.}
}
@article{SHKLOVSKIYKORDI2022104653,
title = {Natural computation and its limits: Efim Liberman at the dawn of a new science},
journal = {Biosystems},
volume = {215-216},
pages = {104653},
year = {2022},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2022.104653},
url = {https://www.sciencedirect.com/science/article/pii/S0303264722000454},
author = {Nikita E. Shklovskiy-Kordi and Abir U. Igamberdiev},
keywords = {Efim Liberman, Quantum computation, Biological computation, Unity of science, Encoding, Genetic language, Natural algorithm, Molecular computer of the cell, Quantum regulator},
abstract = {Efim A. Liberman (1925–2011) can be considered as a founder of the new field of science that explores natural computation and its limits. He named it Chaimatics and suggested its generalization to the ultimate all-encompassing theory that unites biology, physics and mathematics. He made a number of experimental discoveries, including color coding in the retina, the participation mechanisms of Ca2+ ions in synaptic transmission, and the measurement of potential in the coupling membranes of mitochondria and chloroplasts. He also made a decisive contribution to the proof of the chemiosmotic hypothesis of oxidative phosphorylation. In a series of works started in 1972, Liberman developed the concept of the molecular computer of the cell, which includes the programs written on DNA and RNA nucleotide sequences and executed by enzymes playing the role of processing units whereas nucleotide sequences are interpreted as commands and addresses. In this framework, Liberman predicted RNA splicing before its discovery and suggested the role of processing of small informational molecules (later defined as small RNAs) in controlling biological processes. Efim Liberman defined the fundamental property of life as a molecular and quantum computational system and introduced the idea of quantum computing inside a cell for making decisions on complex control tasks described by equations of mathematical physics. He approached the brain as a net of molecular computers and created a model of neuron operation based on the transmission of hypersound signals via cytoskeleton where the molecular computational system encodes the digital output. In 1979 Liberman published a hypothesis of human self-consciousness associated with not a chemical, but with a physical quantum coherent system and named it “extremal quantum regulator”. We review here the contributions of Liberman in understanding the mechanisms of intracellular processing of information and his efforts to create an integrative theory of natural computation that aims to unite biology, physics and mathematics.}
}
@article{GUTIERREZBELTRAN2025103198,
title = {Mi Superpoder es la Programación: A tool for teaching programming to children and youth},
journal = {Science of Computer Programming},
volume = {240},
pages = {103198},
year = {2025},
issn = {0167-6423},
doi = {https://doi.org/10.1016/j.scico.2024.103198},
url = {https://www.sciencedirect.com/science/article/pii/S0167642324001217},
author = {Erika J. {Gutiérrez Beltrán} and Juan C. {Martínez Arias}},
keywords = {Programming for children, STEAM education, Digital educational tools, Game-based learning, Software engineering},
abstract = {Mi Superpoder es la Programación is a web tool designed to teach programming to children and young people. It focuses on developing logical thinking through interactive exercises that cover computer parts recognition, sequences, patterns, and flowcharts. The tool was developed to address the educational needs identified in the social project of the same name, where modern technologies and a serverless-based architecture were used to create an accessible and effective solution for teaching programming. Initial results indicate that students found the tool useful and demonstrated improvements in their understanding of computational logic. This analysis is framed within the global challenge of teaching programming to children and youth, demonstrating the potential of gamified tools across diverse educational contexts. Future plans include expanding the tool to incorporate more modules, allowing customization by teachers, and conducting broader evaluations in different educational environments.}
}
@article{WANG2021119,
title = {Computational pharmaceutics - A new paradigm of drug delivery},
journal = {Journal of Controlled Release},
volume = {338},
pages = {119-136},
year = {2021},
issn = {0168-3659},
doi = {https://doi.org/10.1016/j.jconrel.2021.08.030},
url = {https://www.sciencedirect.com/science/article/pii/S0168365921004363},
author = {Wei Wang and Zhuyifan Ye and Hanlu Gao and Defang Ouyang},
keywords = {Computational pharmaceutics, Artificial intelligence, Machine learning, Molecular modeling, Process simulation, Mathematical modeling, PBPK modeling},
abstract = {In recent decades pharmaceutics and drug delivery have become increasingly critical in the pharmaceutical industry due to longer time, higher cost, and less productivity of new molecular entities (NMEs). However, current formulation development still relies on traditional trial-and-error experiments, which are time-consuming, costly, and unpredictable. With the exponential growth of computing capability and algorithms, in recent ten years, a new discipline named “computational pharmaceutics” integrates with big data, artificial intelligence, and multi-scale modeling techniques into pharmaceutics, which offered great potential to shift the paradigm of drug delivery. Computational pharmaceutics can provide multi-scale lenses to pharmaceutical scientists, revealing physical, chemical, mathematical, and data-driven details ranging across pre-formulation studies, formulation screening, in vivo prediction in the human body, and precision medicine in the clinic. The present paper provides a comprehensive and detailed review in all areas of computational pharmaceutics and “Pharma 4.0”, including artificial intelligence and machine learning algorithms, molecular modeling, mathematical modeling, process simulation, and physiologically based pharmacokinetic (PBPK) modeling. We not only summarized the theories and progress of these technologies but also discussed the regulatory requirements, current challenges, and future perspectives in the area, such as talent training and a culture change in the future pharmaceutical industry.}
}
@article{ZECHMEISTER2023104889,
title = {Concurrent, computational design and modelling of structural, coreless-wound building components},
journal = {Automation in Construction},
volume = {151},
pages = {104889},
year = {2023},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2023.104889},
url = {https://www.sciencedirect.com/science/article/pii/S0926580523001498},
author = {C. Zechmeister and M. {Gil Pérez} and J. Knippers and A. Menges},
keywords = {Coreless filament winding, Carbon fibre, Feedback-based computational design, Co-design, Computational modelling, Digital-physical workflow, Interdisciplinary design, Finite element analysis (FEA), Robotic fabrication},
abstract = {Coreless filament winding extends established industrial processes, enabling the fabrication of building parts with minimal formwork. Since the part's final geometry is unknown until completed, it creates uncertainties for design and engineering. Existing architectural design workflows are insufficient, and industrial software packages cannot capture the complexity of self-deforming fibres to model complex fibre layups. This research introduces a feedback-based computational method conceived as four development cycles to design and evaluate fibre layups of large-scale architectural building components, and a multi-scalar digital-physical design and evaluation toolset to model and evaluate them at multiple resolutions. The universal applicability of the developed methods is showcased by two different architectural fibre structures. The results show how the systematization of methods and toolset allow for increased design flexibility and deeper integration of interdisciplinary collaborators. They constitute an important step towards a consolidated co-design methodology and demonstrate the potential to simultaneously co-evolve design and evaluation methods.}
}
@incollection{DOMINOWSKI19941,
title = {CHAPTER 1 - History of Research on Thinking and Problem Solving},
editor = {Robert J. Sternberg},
booktitle = {Thinking and Problem Solving},
publisher = {Academic Press},
address = {San Diego},
pages = {1-35},
year = {1994},
volume = {2},
series = {Handbook of Perception and Cognition},
isbn = {978-0-08-057299-4},
doi = {https://doi.org/10.1016/B978-0-08-057299-4.50007-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780080572994500074},
author = {Roger L. Dominowski and Lyle E. Bourne},
abstract = {Publisher Summary
The two problems that characterize the modern psychology of thinking are mental representation and mental computation. Throughout the history of psychology, there has been an agreement that the essential features of a problem are that an organism has a goal but lacks a clear or well-learned route to the goal. Thus the emphasis in research on problem solving has been on response discovery—how the organism arrives at an effective, goal-attaining behavior. There have often been controversies over the role of learning or past experiences in problem solving. This chapter illustrates the conflict between emphases on learning and emphases on perception as central components of problem solving. Because a problem solver must find a solution, it might seem inevitable that an essential activity tries different approaches makes errors until the right approach is found. Earlier in problem-solving research, trial and error became associated with the view that acquiring a solution was a gradual, undirected process that did not involve perception or comprehension of problem requirements or structure.}
}
@article{GILL1995349,
title = {Bridging second-grade children's thinking and mathematical recording},
journal = {The Journal of Mathematical Behavior},
volume = {14},
number = {3},
pages = {349-362},
year = {1995},
issn = {0732-3123},
doi = {https://doi.org/10.1016/0732-3123(95)90016-0},
url = {https://www.sciencedirect.com/science/article/pii/0732312395900160},
author = {Alice J. Gill and Arlene Thompson},
abstract = {The focus of this article is how what students do and say to solve a problem may be recorded to mirror the student's actions or thoughts rather than portraying a common algorithm that is not connected to the student's thinking. It illustrates the multiple strategies used by a second-grade class that has solved a problem with three addends and how the teacher tries to faithfully map their thinking into the system of mathematical notation. Emphasis is placed on the step-by-step linking of action, thought, and symbol that must occur. The AFT Thinking Mathematics program that the teacher is using is briefly described as well as how the teacher developed number sense and a culture in which student thinking is respected. The article stresses that teachers need professional development experiences that help them understand how children best learn mathematics to be able to effectively address the needs of a class of heterogeneous learners and open doors to greater achievement.}
}
@article{LIU2006267,
title = {New tectonics: a preliminary framework involving classic and digital thinking},
journal = {Design Studies},
volume = {27},
number = {3},
pages = {267-307},
year = {2006},
note = {Digital Design},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2005.11.008},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X05000852},
author = {Yu-Tung Liu and Chor-Kheng Lim},
keywords = {tectonics, design technology, design process, computer aided design, design theory},
abstract = {The digital tectonic studies noticed the dramatic change of traditional architectural construction in association with digital technology. A more systematic framework of new tectonics combining digital and classic elements and processes is needed to explore the digital theory in the architecture field. The first step of this case-study research is to determine both the analytical factors of classic tectonics and the digital cases. The next step discusses emergent digital factors of tectonics. The third step applies the four new factors to the tectonic processes of five digital projects by well-known architects who have actual building experience in both predigital and digital works. Some phenomena of digital tectonics have emerged to reveal the dynamic factors of motion, information, generation and fabrication. In a preliminary framework of new tectonics, seven classic and four digital factors form a whole and interact with each other.}
}
@article{CASALI2022105,
title = {Role of Anion in Determining the Stereoselectivity of Mg-Ph-BOX-Catalyzed Diels–Alder Reactions: A Computational Study},
journal = {Organometallics},
volume = {41},
number = {2},
pages = {105-114},
year = {2022},
issn = {0276-7333},
doi = {https://doi.org/10.1021/acs.organomet.1c00550},
url = {https://www.sciencedirect.com/science/article/pii/S0276733322004502},
author = {Emanuele Casali and Giuseppe Faita and Lucio Toma},
abstract = {ABSTRACT
In the realm of enantioselective Diels–Alder reactions, a role of primary importance is held by Mg-BOX catalysis. The main features of both catalysts and ligand in directing the stereoselective outcome have been extensively studied in several papers mainly through 1H NMR and X-ray diffraction (XRD) techniques. However, over the years, no computational studies have been reported to support the models proposed to rationalize the observed stereoselectivity for the reaction between 3-acryloyl-1,3-oxazolidin-2-one and cyclopentadiene catalyzed by the BOX ligand (R,R)-(+)-2,2′-isopropylidenebis­(4-phenyl-2-oxazoline) and Mg­(II) salts. To approach the problem, we performed a density functional theory (DFT) computational study, aiming to locate the preferred transitions states deriving from these proposed models, but we only found a correspondence in selectivities for the reaction catalyzed by Mg­(OTf)2, where the model suggests an octahedral complex with the two triflate anions coordinating magnesium. For the other cases [i.e., Mg­(ClO4)2, Mg­(ClO4)2·2H2O, and MgI2·I2], the commonly accepted tetrahedral or octahedral models suggest no involvement of the perchlorate or iodide anions, but the corresponding calculations did not reproduce the experimental selectivities. Only when we considered also in these cases coordination complexes involving their presence, the observed selectivities were reproduced, thus opening new insights to better understand the role and the action of the counterion to determine the stereochemical outcome of these reactions.}
}
@article{TOHIDIFAR2024105696,
title = {Make it till you fake it: Construction-centric computational framework for simultaneous image synthetization and multimodal labeling},
journal = {Automation in Construction},
volume = {167},
pages = {105696},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2024.105696},
url = {https://www.sciencedirect.com/science/article/pii/S0926580524004321},
author = {Ali Tohidifar and Daeho Kim and SangHyun Lee},
keywords = {Visual artificial intelligence, Deep neural network, DNN training, Image synthetization, Automated labeling, Computer-generated imagery, 2D worker detection},
abstract = {This paper introduces BlendCon, a fully automated framework capable of simultaneously synthesizing and labeling construction imagery data. This framework simulates a construction site by orchestrating 3D mobile objects against a 3D background and produces multimodal labels for target entities. The effectiveness of the synthetic data in training object detection models was thoroughly validated. For the construction worker detection task, a YOLOv7 model trained with synthetic data nearly matched the performance of a model trained with real data: it achieved 71% AP@0.5–0.95 compared to 75% for the real data-trained model. Moreover, the model trained with synthetic data surpassed its real data counterpart in scenarios requiring stricter IoU thresholds, particularly above 85%. Acquiring a sufficient quantity and diverse range of imagery data has been a primary challenge in construction studies that focus on automation and digitization through deep neural networks. BlendCon can significantly contribute to addressing this data scarcity challenge.}
}
@incollection{KOROMINA202221,
title = {2.03 - Pharmacogenomics in the Era of “Big Data” and Advanced Computational Approaches},
editor = {Terry Kenakin},
booktitle = {Comprehensive Pharmacology},
publisher = {Elsevier},
address = {Oxford},
pages = {21-26},
year = {2022},
isbn = {978-0-12-820876-2},
doi = {https://doi.org/10.1016/B978-0-12-820472-6.00114-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128204726001146},
author = {Maria Koromina and George P. Patrinos},
keywords = {GWAS, Large-scale genomics studies, NGS, PGx, Rare variants, Text-mining},
abstract = {Undoubtedly, next generation sequencing (NGS) technologies have led to the production of a voluminous amount of data, which can be exploited towards the delineation and identification of novel pharmacogenomics (PGx) associations. Herein, we describe how NGS and genome-wide association (GWA) technologies have changed the landscape of the pharmacogenomics field, whilst proceeding with thorough details on the contribution of rare pharmacogenomics variants to the heritability of drug response trait. Moreover, we summarize some state-of-the-art text mining techniques which if harnessed properly can lead to a plethora of PGx retrieved associations. Overall, we conclude by stating that there is often a knowledge gap between (clinical) pharmacologists and researchers who exploit (pharmaco)genomics big data by using advanced computing methods. To overcome the limited number of advanced computational, statistical and mathematical methods and protocols, we propose a broad implementation and standardization of NGS techniques that should be explored by the PGx community.}
}
@article{JOSWICK2025104908,
title = {Opportunities to collectively reason about numbers while building connections to key conceptual ideas in mathematics: Examining the questions used by teachers studying and implementing Number Talks},
journal = {Teaching and Teacher Education},
volume = {155},
pages = {104908},
year = {2025},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2024.104908},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X24004414},
author = {Candace Joswick and Brandon G. McMillan and Kimberly A. Conner},
keywords = {Number Talks, Questioning},
abstract = {Teachers' questioning practices play a pivotal role in shaping classroom discussions. Analysis of 30 Number Talks from classrooms across the US reveals the majority of teachers' questions helped to surface student strategies (confirm, elaborate, invite questions), but did not provide opportunities for students to collectively reason about numbers while building connections to key conceptual ideas in mathematics (connect, justify, orient questions). Data excerpts illustrate how questions can be used to support this reasoning. Implications include the need to focus on pedagogical and content knowledge centered in student mathematical thinking within professional development to develop teachers’ ability to support this reasoning.}
}
@article{GEPSHTEIN2021221,
title = {Thinking Outside the Lineup Box: Eyewitness Identification by Perceptual Scaling},
journal = {Journal of Applied Research in Memory and Cognition},
volume = {10},
number = {2},
pages = {221-224},
year = {2021},
issn = {2211-3681},
doi = {https://doi.org/10.1016/j.jarmac.2021.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S2211368121000310},
author = {Sergei Gepshtein and Thomas D. Albright}
}
@article{RAJU2022,
title = {Computational evaluation of the effect of femoral component curvature on the mechanical response of the UHMWPE tibial insert in total knee replacement implants},
journal = {Materials Today: Proceedings},
year = {2022},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2022.12.224},
url = {https://www.sciencedirect.com/science/article/pii/S2214785322075964},
author = {Vaishakh Raju and Poornesh Kumar Koorata},
keywords = {Femoral component, Knee implant, Total knee replacement, Tibial insert, UHMWPE},
abstract = {Total knee replacement (TKR) surgery is done on individuals with end-stage osteoarthritis to restore knee function and alleviate joint discomfort. There have been recent developments in the design of customized implants based on patient-specific data obtained from MRI scans and subsequent image processing techniques. Here curvature of the femoral component plays an important role in effective implant design. Therefore, the objective here is to investigate the influence of this curvature of the femoral component on the mechanical response of the bearing component. A 3D finite element knee implant model with a circular and an elliptical femoral component is developed and investigated for gait kinetics and kinematics. Responses such as contact pressure, stresses, strains, and wear produced on the tibial insert are estimated throughout the gait cycle. These findings suggest that the elliptical femoral component generates less contact pressure on the tibial insert than its circular counterpart. It is also inferred that too much variation in this curvature is not recommended as it may affect the patient's comfort level. In addition, the wear of the tibial insert is computed based on the contact pressure created by both knee implant models. Our study suggests an optimum value for the curvature and the comfort level of the patients over the existing knee implant designs.}
}
@incollection{KUMAR202485,
title = {Chapter 8 - Computational and stem cell biology: Challenges and future perspectives},
editor = {Pawan Kumar Raghav and Rajesh Kumar and Anjali Lathwal and Navneet Sharma},
booktitle = {Computational Biology for Stem Cell Research},
publisher = {Academic Press},
pages = {85-104},
year = {2024},
isbn = {978-0-443-13222-3},
doi = {https://doi.org/10.1016/B978-0-443-13222-3.00003-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780443132223000034},
author = {Rajiv Kumar and Agnieszka Maria Jastrzębska and Magali Cucchiarin and Neelam Chhillar and Mitrabasu Chhillar},
keywords = {Challenges and future perspectives, Computational biology, Computational tools, Mathematical modeling, Stem cell tissue engineering},
abstract = {Computational biology has amplified the current research on stem cells and the ability to transform them into innovative novel drugs to treat and prevent diseases as well as apply as regenerative medicine. For more than fivedecades, one of the critical purposes of computational biology has been to explore the dynamics underlying developmental routes. Challenges that currently exist between computational biology and biological computation were outlined and further discussed for a solution to fill the persistent “wet dry” research gap for a better future. Emerging proper techniques for combining data from several modalities is the foremost challenge in handling single-cell multimodal data. This process has been referred to as “data integration” It includes various strategies, from batch-correcting individual omics datasets to correlating chromatin accessibility to development in virtually all genetic mutations with transcription. In this chapter, we offer solutions for how researchers can overcome challenges to inspire the creation of various computer science algorithms and approaches, as well as how computational methods and mathematical modeling have aided in the comprehension of different biological domains, including computational and stem cell biology. A few current references and examples have been incorporated to explain the emerging concepts in computational biology and address existing problems. They are discussed here with their future aspects, hoping to encourage younger researchers to work in this fascinating field and deal with the challenges mentioned before with a modern approach.}
}
@article{SCHAUERTE2023801,
title = {The managerial relevance of marketing science: Properties and genesis},
journal = {International Journal of Research in Marketing},
volume = {40},
number = {4},
pages = {801-822},
year = {2023},
issn = {0167-8116},
doi = {https://doi.org/10.1016/j.ijresmar.2023.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0167811623000472},
author = {Nico Schauerte and Maren Becker and Monika Imschloss and Julian R.K. Wichmann and Werner J. Reinartz},
keywords = {Managerial relevance, Research–practice gap, Research properties and genesis, Marketing science value chain, Computational grounded theory},
abstract = {Part of marketing academia’s mandate is to generate findings that improve management practice. Managerial relevance plays a key role in this mandate as it describes a research project’s potential to influence managerial decision-making and thinking. Therefore, it is crucial to understand what makes research managerially relevant and to uncover success factors in the genesis of such research. This study addresses these issues through a qualitative analysis of 65 depth interviews with senior editors of business transfer journals, marketing managers, and academic researchers. The authors carve out distinct, multidimensional properties that determine managerial relevance. From specific configurations of these properties, four archetypical relevance types emerge: (1) problem-solving, (2) explicating, (3) consolidating, and (4) forward-thinking relevance. Finally, the authors develop a unifying framework and identify success factors for generating highly relevant research. Based on these insights, they suggest concrete courses of action for academics who seek to increase the managerial relevance of their research.}
}
@article{KRAUSE2001432,
title = {Entropy reduction in human mathematical thinking: A microstate study of EEG oscillations},
journal = {NeuroImage},
volume = {13},
number = {6, Supplement },
pages = {432},
year = {2001},
note = {Originally published as Volume 13, Number 6, Part 2},
issn = {1053-8119},
doi = {https://doi.org/10.1016/S1053-8119(01)91775-6},
url = {https://www.sciencedirect.com/science/article/pii/S1053811901917756},
author = {Werner Krause and Barbara Schack and Gundula Seidel and Frank Heinrich and Ursula Krause}
}
@article{BATZIAS20121889,
title = {Thinking by Analogy for Technology Transfer from Catalysts to Biosensors and Vice versa–a Knowledge-based Approach},
journal = {Procedia Engineering},
volume = {42},
pages = {1889-1896},
year = {2012},
note = {CHISA 2012},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2012.07.585},
url = {https://www.sciencedirect.com/science/article/pii/S187770581202992X},
author = {F.A. Batzias and Ch. G. Siontorou},
keywords = {Catalytic biosensors, Regeneration, Modeling, Case based reasoning, Industrial catalysis, Enzyme fuel cells},
abstract = {This work presents a methodological framework for facilitating knowledge transfer between process engineering to biosensing, employing case based reasoning to match successfully solved problems in industrial catalysts with biosensor drawbacks, adapted to the latter through their common scientific background, where ‘compatibility’ and ‘comparability’ are more prominent. The proposed framework has been implemented in mediator-based electrochemical biosensors, where the inability to recycle the cofactors in situ without compromising the functionality of the whole system remains a pending issue. The opening of technology channels between the two domains may, also, contribute to solving the problem of enzyme stability in industrial catalysis.}
}
@article{DEGELDER2021744,
title = {A computational neuroethology perspective on body and expression perception},
journal = {Trends in Cognitive Sciences},
volume = {25},
number = {9},
pages = {744-756},
year = {2021},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2021.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S1364661321001479},
author = {Beatrice {de Gelder} and Marta {Poyo Solanas}},
keywords = {body, emotion, movement, ethology, computational features},
abstract = {Survival prompts organisms to prepare adaptive behavior in response to environmental and social threat. However, what are the specific features of the appearance of a conspecific that trigger such adaptive behaviors? For social species, the prime candidates for triggering defense systems are the visual features of the face and the body. We propose a novel approach for studying the ability of the brain to gather survival-relevant information from seeing conspecific body features. Specifically, we propose that behaviorally relevant information from bodies and body expressions is coded at the levels of midlevel features in the brain. These levels are relatively independent from higher-order cognitive and conscious perception of bodies and emotions. Instead, our approach is embedded in an ethological framework and mobilizes computational models for feature discovery.}
}
@article{MARENKO2015110,
title = {When making becomes divination: Uncertainty and contingency in computational glitch-events},
journal = {Design Studies},
volume = {41},
pages = {110-125},
year = {2015},
note = {Special Issue: Computational Making},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2015.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X15000587},
author = {Betti Marenko},
keywords = {philosophy of design, computational models, digital design, design processes, uncertainty},
abstract = {This article investigates those aspects of computation that concern uncertainty, contingency and indeterminacy. Starting from a critique of current dominant models of computation, and drawing on the philosophical notions of the virtual and the event, uncertainty, contingency and indeterminacy are proposed as virtualities that express the ongoing differentiation of digital matter. On these grounds, the glitch is reframed as an event capable of revealing the potential of the digital in processes of computational making. Ideas concerning the incomputable and non-human intelligence of the algorithm underpin this argument. Finally, it is proposed that intuitive and uncognitive modes of apprehending digital making operate as forms of divination that capture the unprogrammed unfolding of matter.}
}
@article{HAO2024102662,
title = {Exploring collaborative decision-making: A quasi-experimental study of human and Generative AI interaction},
journal = {Technology in Society},
volume = {78},
pages = {102662},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102662},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24002100},
author = {Xinyue Hao and Emrah Demir and Daniel Eyers},
keywords = {ChatGPT, Artificial intelligence, Human intuition, Decision-making, Cognitive biases},
abstract = {This paper explores the effects of integrating Generative Artificial Intelligence (GAI) into decision-making processes within organizations, employing a quasi-experimental pretest-posttest design. The study examines the synergistic interaction between Human Intelligence (HI) and GAI across four group decision-making scenarios within three global organizations renowned for their cutting-edge operational techniques. The research progresses through several phases: identifying research problems, collecting baseline data on decision-making, implementing AI interventions, and evaluating the outcomes post-intervention to identify shifts in performance. The results demonstrate that GAI effectively reduces human cognitive burdens and mitigates heuristic biases by offering data-driven support and predictive analytics, grounded in System 2 reasoning. This is particularly valuable in complex situations characterized by unfamiliarity and information overload, where intuitive, System 1 thinking is less effective. However, the study also uncovers challenges related to GAI integration, such as potential over-reliance on technology, intrinsic biases particularly ‘out-of-the-box’ thinking without contextual creativity. To address these issues, this paper proposes an innovative strategic framework for HI-GAI collaboration that emphasizes transparency, accountability, and inclusiveness.}
}
@article{CECCHI20231,
title = {Exploring language and cognition in schizophrenia: Insights from computational analysis},
journal = {Schizophrenia Research},
volume = {259},
pages = {1-3},
year = {2023},
note = {Language and Speech Analysis in Schizophrenia and Related Psychoses},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2023.07.030},
url = {https://www.sciencedirect.com/science/article/pii/S0920996423002566},
author = {Guillermo A. Cecchi and Cheryl M. Corcoran},
keywords = {Coherence, Philosophy, Semantic, Syntactic, Disorganization, Emotion, Mentalizing, Natural language processing (NLP)}
}
@incollection{DIETRICH19943,
title = {CHAPTER 1 - Thinking Computers and The Problem of Intentionality},
editor = {Eric Dietrich},
booktitle = {Thinking Computers and Virtual Persons},
publisher = {Academic Press},
pages = {3-34},
year = {1994},
isbn = {978-0-12-215495-9},
doi = {https://doi.org/10.1016/B978-0-12-215495-9.50006-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780122154959500065},
author = {Eric Dietrich},
abstract = {Publisher Summary
This chapter is an attempt to clear the names of artificial intelligence (AI) and computational cognitive science. These two related disciplines have been accused of a conceptual error so profound that their very existence is jeopardized. Sometimes, however, philosophers successfully arrest and lock up the guilty. The best example of this, ironically, is in psychology. Artificial intelligence and computational cognitive science are both committed to the claim that computers can think. The former is committed to the claim that human-made computers can think, while computational cognitive science is committed to the view that naturally occurring computers, brains, think. AI is the field dedicated to building intelligent computers. AI ultimately wants a machine that could solve very difficult, novel problems like proving Fermat's last theorem, correcting the greenhouse effect, or figuring out the fundamental structure of space-time. Historically, AI is associated with computer science, but the compleat AI researcher frequently knows a fair amount of psychology, linguistics, neuroscience, mathematics, and possibly some other discipline.}
}
@article{ZHANG2023102373,
title = {Contextualizing the rural in digital studies: A computational literature review of rural-digital relations},
journal = {Technology in Society},
volume = {75},
pages = {102373},
year = {2023},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2023.102373},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X23001781},
author = {Qian Zhang and Natasha A. Webster and Shengnan Han and Workneh Yilma Ayele},
keywords = {Rural geography, Digital geography, Rural-digital relations, Context, Computational literature review, Topic modelling, Qualitative content analysis, Global, Nordic},
abstract = {Digital technologies are changing how and where we live, work and socialize. Rural areas are distinctive spaces and places but in the current debates of new digital phenomena, digital spaces and practices risk not being contextualized with sensitivities to rural geographies. This study aims to map how digital has been examined to date in rural-focused studies, and accordingly present propositions for how rural-digital studies can be sensitive to the distinctive and diverse character of rural spaces and places. We conduct a two-stage/scale literature review, combining 1) computational topic modelling from a Global Dataset (459 article abstracts) with 2) qualitative content analysis from a sub-dataset focusing on the Nordic region (Nordic Sub-Dataset, 17 full articles). We begin with a topic modelling analysis generating ten major themes (topics) leading to an overview of how research areas are connected to the meaning of rural context. Turning to the Nordic region, as an in-depth example, we illustrate the complexity of rural digital geographies, through a qualitative content analysis. This demonstrates that digital in rural contexts are primarily positioned outwardly as social/regional development and business/economy, and less situated inwardly through individual experience and community building. Combined we show a wide spectrum of rural-digital relations but demonstrate that rural contexts in rural-digital relations need more attention. We propose three propositions to invite deeper rural contextualizations in future digital studies to uphold the importance of rural spaces and places through, by and with digital geography.}
}
@article{CAVAZZA2014422,
title = {Ways of thinking about the incinerator: A typology of citizens’ mindsets},
journal = {The Social Science Journal},
volume = {51},
number = {3},
pages = {422-430},
year = {2014},
issn = {0362-3319},
doi = {https://doi.org/10.1016/j.soscij.2013.10.008},
url = {https://www.sciencedirect.com/science/article/pii/S0362331913001705},
author = {Nicoletta Cavazza and Sandro Rubichi},
keywords = {Attitude, Social representations, Waste disposal, Trust, Self-efficacy},
abstract = {This paper considers the social representation of an incinerator plant operating for more than 30 years in a medium-sized city in Italy. A survey was carried out with a representative sample of an Italian town, a community that was not generally hostile to it. On the basis of self-efficacy and trust in institutions, and by applying cluster analyses, we obtain evidence for four distinct groups labelled as Fatalists, Collaboratives, Activists, and Delegants. The four groups express systematic variations in social representation. We discuss the theoretical and practical impacts of these results.}
}
@article{MCDONOUGH2002211,
title = {Understanding, assessing and developing children's mathematical thinking: the power of a one-to-one interview for preservice teachers in providing insights into appropriate pedagogical practices},
journal = {International Journal of Educational Research},
volume = {37},
number = {2},
pages = {211-226},
year = {2002},
issn = {0883-0355},
doi = {https://doi.org/10.1016/S0883-0355(02)00061-7},
url = {https://www.sciencedirect.com/science/article/pii/S0883035502000617},
author = {Andrea McDonough and Barbara Clarke and Doug M. Clarke},
keywords = {Preservice teacher education, Mathematics education, One-to-one interview, Children, Questioning, Listening, Reflection},
abstract = {At Australian Catholic University and Monash University, preservice mathematics teachers are required to conduct and analyse one-to-one mathematics assessment interviews with primary-aged children. The assessment tool is drawn from the Early Numeracy Research Project, where it was used with over 11,000 children in Victorian schools. The interview assesses content from Number, Measurement and Geometry, in an interactive, hands-on format, with children's responses and strategies determining the path through the interview protocol. Follow-up discussion in class enabled preservice teachers to explore appropriate pedagogies that build upon what had been learned from the interviews. The research described in this chapter sought to investigate the effectiveness of this process. Interviews and written questionnaires were the data sources. Analysis of the data suggested that teachers were more aware of the kinds of strategies that children use including their variety and relative level of sophistication, and that the interview and subsequent discussion stimulated preservice teachers to reflect upon appropriate classroom experiences for young mathematics learners.}
}
@article{HADAS2024101549,
title = {Using large language models to evaluate alternative uses task flexibility score},
journal = {Thinking Skills and Creativity},
volume = {52},
pages = {101549},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101549},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124000877},
author = {Eran Hadas and Arnon Hershkovitz},
keywords = {Creativity, Divergent thinking, Alternative uses task, Flexibility, Large language models},
abstract = {In the Alternative Uses Task (AUT) test, a group of participants is asked to list as many uses as possible for a simple object. The test measures Divergent Thinking (DT), which involves exploring possible solutions in various semantic domains. In this study we employ a Machine Learning approach to automatically generate suitable categories for object uses and classify given responses into them. We show that the results yielded by this automated approach are correlated with results given by humans and can be used to predict expected behavior in the field. Educators and researchers may utilize this approach to address the limitations of subjective scoring, save time, and use the AUT as a tool for cultivating creativity.}
}
@article{OMER2024100308,
title = {Computational studies of a series of closely related acenaphthopyrazine derivative},
journal = {Results in Surfaces and Interfaces},
volume = {17},
pages = {100308},
year = {2024},
issn = {2666-8459},
doi = {https://doi.org/10.1016/j.rsurfi.2024.100308},
url = {https://www.sciencedirect.com/science/article/pii/S2666845924001284},
author = {Rebaz Anwar Omer and Rebaz Obaid Kareem and Yousif Hussein Azeez and Lana Omer Ahmed and Damir A. Safin and karukh Ali Babakr},
keywords = {Gaussian software, DFT, NLO, Thermal properties, Monte Carlo simulations},
abstract = {The novelty of the study is in the use of quantum computing analysis of acenaphthopyrazine derivatives using Density Functional Theory (DFT) with the B3LYP/6-31G(d,p) basis set. The research focused on intramolecular charge transfer (ICT) and its influence on non-linear optical (NLO) properties. The NLO analysis revealed that the protonated forms of these compounds exhibit higher dipole moments, indicating their potential for NLO applications. Natural Bond Orbital (NBO) analysis identified molecule 5 as having the highest E(2) value of 509.41 kcal/mol, signifying strong electron donation from nitrogen to hydrogen atoms. The study also evaluated the thermal properties, showing that the Gibbs free energy remained positive across a wide temperature range, suggesting that none of the compounds are spontaneously formed in either neutral or protonated states. Additionally, Monte Carlo simulations indicated favorable adsorption energies for these derivatives on the Fe (110) surface, with compound 5 demonstrating the most significant inhibitory potential. We conduced of that, lower negative adsorption energy (−216.729) compound 1 are confirm with highest energy gap (3.396 eV), and smaller refractive index, and electrical conductivityof compound 1 indicates a small metal-inhibitor molecule interaction, as well as are agreement with Monte Carlo simulation for adsorption on Fe (110) non protonated case.}
}

@article{CHEN2015247,
title = {Reinforcement learning in depression: A review of computational research},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {55},
pages = {247-267},
year = {2015},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2015.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S0149763415001311},
author = {Chong Chen and Taiki Takahashi and Shin Nakagawa and Takeshi Inoue and Ichiro Kusumi},
keywords = {Anhedonia, Computational psychiatry, Depression, Dopamine, Incentive salience, Learning rate, ‘Liking’, Model-free, Model-based, Motivation, Prediction error, Reinforcement learning, Reward sensitivity, Stress, ‘Wanting’},
abstract = {Despite being considered primarily a mood disorder, major depressive disorder (MDD) is characterized by cognitive and decision making deficits. Recent research has employed computational models of reinforcement learning (RL) to address these deficits. The computational approach has the advantage in making explicit predictions about learning and behavior, specifying the process parameters of RL, differentiating between model-free and model-based RL, and the computational model-based functional magnetic resonance imaging and electroencephalography. With these merits there has been an emerging field of computational psychiatry and here we review specific studies that focused on MDD. Considerable evidence suggests that MDD is associated with impaired brain signals of reward prediction error and expected value (‘wanting’), decreased reward sensitivity (‘liking’) and/or learning (be it model-free or model-based), etc., although the causality remains unclear. These parameters may serve as valuable intermediate phenotypes of MDD, linking general clinical symptoms to underlying molecular dysfunctions. We believe future computational research at clinical, systems, and cellular/molecular/genetic levels will propel us toward a better understanding of the disease.}
}
@article{COSSENTINO2024101257,
title = {Using a trie-based approach for storage and retrieval of goal-oriented plans in an S1/S2 cognitive architecture},
journal = {Cognitive Systems Research},
volume = {87},
pages = {101257},
year = {2024},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2024.101257},
url = {https://www.sciencedirect.com/science/article/pii/S1389041724000512},
author = {Massimo Cossentino and Giovanni Pilato},
keywords = {System 1/System 2, Cognitive architectures, Goal-oriented plan, Trie},
abstract = {In the last years, the System 1/System 2 cognitive architecture, proposed by psychologist Daniel Kahneman, raised the interest of many researchers in the field. System 1 is an intuitive, automatic, and fast-thinking system working effortlessly, without conscious effort. System 2 is a deliberate, analytical, and slower-thinking system employing conscious effort and attention. This work proposes an innovative approach that exploits techniques typical of information retrieval (the trie data structure) to efficiently encode the solutions’ repository at the border between System 2 and System 1. This repository stores the solutions (successful plans) the agent has already used and can re-enact to achieve the goals. System 2 conceives new plans and delegates System 1 to execute them. If the plan is successful (and so it becomes a solution), System 1 stores that in the repository to quickly retrieve any solution that may help fulfil the goals deliberated by System 2 in the future.}
}
@article{CHANG2023100529,
title = {Management accounting system: Insights from the decision making theories},
journal = {Social Sciences & Humanities Open},
volume = {8},
number = {1},
pages = {100529},
year = {2023},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2023.100529},
url = {https://www.sciencedirect.com/science/article/pii/S2590291123001341},
author = {Kirk Chang and Alhashmi Aboubaker Lasyoud and Diaeldin Osman},
keywords = {Decision making, MAS, Management account system, Pre-factor, Thinking styles},
abstract = {Management accounting system (MAS) improves business growth through quality decision making process, but scholars have mixed views about MAS and constantly debate its efficacy. Drawing on the decision-making theories, the current research deviates from the debates and adopts a ‘think-outside-the-box’ approach, aiming to advance the knowledge of MAS's efficacy. Research data are gathered from the MAS literatures and cognate studies. Following the research findings, we identify a new pre-factor (thinking style) and incorporate it into the MAS. Specifically, decision makers' cognitive process is found to affect the design and implementation of MAS, as rational thinking style, administrative thinking style, and political thinking style may affect the MAS's efficacy differently. Research findings have brought valuable insights to the MAS literatures, by highlighting the strength and weakness of different thinking styles in designing management accounting system. Moreover, decision makers, such as organizational leaders and business managers, are encouraged to monitor their thinking styles: that is, with better understanding of thinking styles, decision makers can better utilize MAS and rectify the style-driven deficits in time.}
}
@article{RUIZ20221641,
title = {Computational simulation as a decision-making support tool for prefabricated pillars production},
journal = {Canadian Journal of Civil Engineering},
volume = {49},
number = {10},
pages = {1641-1654},
year = {2022},
issn = {0315-1468},
doi = {https://doi.org/10.1139/cjce-2021-0565},
url = {https://www.sciencedirect.com/science/article/pii/S0315146822000451},
author = {Phelipe Viana Ruiz and Carlos Eduardo Marmorato Gomes and Patricia Stella Pucharelli Fontanini},
keywords = {industrialized building system, simulation, decision support systems, production control, prefabricated concrete elements, système de construction industrialisé, simulation, systèmes d’aide à la décision, contrôle de la production, éléments préfabriqués en béton},
abstract = {Competitive industrialization pressures the construction sector to move activities away from the construction site, contemplating the prefabricated elements use. Companies willing to remain in the competitive market must seek new positions and developments in their production and management chains. To support the managers' decision-making about the prefabricated concrete elements production line, this article presents a computer simulation model for prefabricated pillars production line productivity scenarios creation. The data used for this model development were collected through a case study in the production line of prefabricated pillars. A simulation software modelled the production line with a dashboard that enables multiple-scenario generation. The adopted approach works with stochastic data, allowing nonprogrammer users to: manipulate and control scenarios and layout settings, analyze results through a dashboard and provide management and decision-makers with a comprehensive view of possible solutions.
L’industrialisation concurrentielle pousse le secteur de la construction à s’éloigner du chantier, en envisageant l’utilisation des éléments préfabriqués. Les entreprises désireuses de demeurer sur le marché concurrentiel doivent rechercher de nouvelles positions et de nouveaux développements dans leurs chaînes de production et de gestion. Pour aider les gestionnaires à prendre des décisions au sujet de la ligne de production d’éléments préfabriqués en béton, cet article présente un modèle de simulation informatique pour la création de scénarios de productivité de ligne de production de piliers préfabriqués. Les données utilisées pour l’élaboration de ce modèle ont été recueillies au moyen d’une étude de cas sur la chaîne de production de piliers préfabriqués. Un logiciel de simulation a modélisé la ligne de production avec un tableau de bord permettant l’élaboration de scénarios multiples. L’approche adoptée fonctionne avec des données stochastiques, permettant aux utilisateurs non-programmeurs : de manipuler et contrôler les scénarios et les paramètres de mise en page, d’analyser les résultats au moyen d’un tableau de bord et de fournir à la direction et aux décideurs une vue d’ensemble des solutions possibles. [Traduit par la Rédaction]}
}
@incollection{ASPRION202257,
title = {Chapter 3 - Thinking multicriteria—A jackknife when it comes to optimization},
editor = {Michael Bortz and Norbert Asprion},
booktitle = {Simulation and Optimization in Process Engineering},
publisher = {Elsevier},
pages = {57-75},
year = {2022},
isbn = {978-0-323-85043-8},
doi = {https://doi.org/10.1016/B978-0-323-85043-8.00012-X},
url = {https://www.sciencedirect.com/science/article/pii/B978032385043800012X},
author = {Norbert Asprion and Michael Bortz},
keywords = {Multicriteria optimization, Decision support, Robust optimization, Pareto set, Adaptive scalarization, Optimal control, Sensitivity analysis},
abstract = {Multicriteria optimization (MCO) can offer insight into trade-offs between different alternatives in process design and flowsheet alternatives. This chapter highlights the practical benefit obtained by integrating MCO into an industrial flowsheet simulator. Parametric model uncertainties, model adjustment, and design of experiments are considered as well from an MCO point of view.}
}
@article{BEATTIE2003909,
title = {Post-genomic technologies – thinking beyond the hype},
journal = {Drug Discovery Today},
volume = {8},
number = {20},
pages = {909-910},
year = {2003},
issn = {1359-6446},
doi = {https://doi.org/10.1016/S1359-6446(03)02862-9},
url = {https://www.sciencedirect.com/science/article/pii/S1359644603028629},
author = {John Beattie and Peter Ghazal},
keywords = {Post-genomic, Proteomics, Biochip, DNA chip, Bioinformatics, Microarrays}
}
@article{WANG2025112869,
title = {Development and validation of the long and short forms of the rest intolerance scale for college students},
journal = {Personality and Individual Differences},
volume = {233},
pages = {112869},
year = {2025},
issn = {0191-8869},
doi = {https://doi.org/10.1016/j.paid.2024.112869},
url = {https://www.sciencedirect.com/science/article/pii/S0191886924003295},
author = {Fei Wang and Haoran Song and Xiaoxuan Meng and Ting Wang and Qian Zhang and Ziying Yu and Siyuan Fan and Yibo Wu},
keywords = {Rest intolerance, Negative feelings, Obsessive thinking, Social comparison, Cognitive bias},
abstract = {With the development of Chinese society, “rest intolerance” has become a topic of great concern and discussion. The purpose of this study was to investigate the dimensions and psychological connotations of rest intolerance and to develop both short and long versions of the rest intolerance scale suitable for Chinese university students. We used three steps to development the scales. In Study 1, we first used interviews and the grounded theory to propose the psychological connotation of rest intolerance and its characteristic dimensions, i.e., negative feelings, obsessive thinking, social comparison, and cognitive bias. On this basis, the rest intolerance scale was compiled, and a four-dimensional scale containing 24 items was obtained through item analysis, exploratory factor analysis, and exploratory graph analysis. Study 2 validated the 4 characteristic dimensions of rest intolerance in a new sample through confirmatory factor analysis, content validity test, and criterion-related validity test, the results show that the 24-item rest intolerance scale (RIS-24) has good reliability and validity. Study 3 developed a short version of the 8-item Rest Intolerance Scale (RIS-8) using genetic algorithms. Overall, the present study provides two instruments for the measurement of rest intolerance that will facilitate the progress of future research.}
}
@article{VOYER2022101734,
title = {Symbols of class: A computational analysis of class distinction-making through etiquette, 1922-2017},
journal = {Poetics},
volume = {94},
pages = {101734},
year = {2022},
issn = {0304-422X},
doi = {https://doi.org/10.1016/j.poetic.2022.101734},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X22001164},
author = {Andrea Voyer and Zachary D. Kline and Madison Danton},
keywords = {Social class, Status symbols, Word embeddings, Cultural sociology, Computational sociology},
abstract = {Social scientists of class and inequality have documented the rise of omnivorousness, informality, ordinariness, and emphasis on meritocracy. This apparent decline in class closure contrasts sharply with rising inequality and declining economic mobility. How are these competing developments reflected in everyday class distinction-making? In this article, we answer this question by applying Goffman's work on the symbols of class status to the analysis of unique data: a corpus of etiquette books published between 1922 and 2017. We use word embeddings to quantify the salience of six class concepts (affluence, cultivation, education, employment, morality, and status) in the corpus. We find that education and employment are increasingly salient while status, affluence, cultivation, and morality decline in their salience to class distinction-making. These results signal a decline of class operating as a status group through cultural closure, the rise of education and employment as the carriers of class in everyday life, and the corresponding legitimation of class position and class inequality based on supposedly meritocratic grounds. This research opens up new avenues for studies of class and the application of computational methods to investigations of social change.}
}
@article{NAGURNEY19981467,
title = {A massively parallel implementation of a discrete-time algorithm for the computation of dynamic elastic demand traffic problems modeled as projected dynamical systems},
journal = {Journal of Economic Dynamics and Control},
volume = {22},
number = {8},
pages = {1467-1485},
year = {1998},
issn = {0165-1889},
doi = {https://doi.org/10.1016/S0165-1889(98)00022-0},
url = {https://www.sciencedirect.com/science/article/pii/S0165188998000220},
author = {Anna Nagurney and Ding Zhang},
abstract = {In this paper we consider the solution of a dynamic traffic network model with elastic demands formulated as a projected dynamical system. We propose a discrete-time algorithm, the Euler method, which resolves the problem at each iteration into subproblems in path flow variables, all of which can be solved simultaneously and in closed form. Convergence results are also presented. We then discuss the implementation of the algorithm in CM Fortran on the massively parallel architecture, the Thinking Machine’s CM-5. Finally, we present numerical results for the parallel implementation on the CM-5 and for a serial implementation of the algorithm in Fortran on the IBM SP2 for several traffic network examples.}
}
@article{BANDYOPADHYAY2025110117,
title = {AI-enabled Computational Intelligence Approach to Neurodevelopmental Disorders Detection Using rs-fMRI Data},
journal = {Computers and Electrical Engineering},
volume = {123},
pages = {110117},
year = {2025},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2025.110117},
url = {https://www.sciencedirect.com/science/article/pii/S0045790625000606},
author = {Soham Bandyopadhyay and Monalisa Sarma and Debasis Samanta},
keywords = {Neurodevelopmental disorder, Brain functional connectivity, Functional magnetic resonance imaging(fMRI), Data-driven brain topology, Frequency specific connectivity, Graph convolutional networks},
abstract = {Neurodevelopmental disorders (NDDs), including ADHD and ASD, profoundly impact children and adolescents. Leveraging Machine Learning (ML), Deep Learning (DeepL) on Functional magnetic resonance imaging (fMRI) data offers enhanced insights, advancing the understanding and diagnostic capabilities of NDDs. Traditionally, researchers extract time series data from predefined brain regions (ROIs) using atlas-based methods and focus on generating brain functional connectivity using Pearson correlation by analyzing changes in signal amplitude over time. This conventional approach assumes that the brain’s structure can be modeled in a simple Euclidean space and predicted with conventional ML/DeepL techniques. However, these traditional methods have several drawbacks. Predefined ROI extraction fails to capture the inherent variability in brain connectivity patterns across individuals, potentially missing crucial information, while relying on Pearson correlation to analyze functional brain connectivity is sensitive to amplitude fluctuations caused by high neural oscillations, leading to inaccurate representations of true neural relationships. Modeling brain functional structure in Euclidean space does not account for the brain’s complex, non-linear neural dynamics, limiting the effectiveness of ML/DeepL models. To address these issues, we propose: 1) An approach that adapts ROIs for each subject using combined grouped Independent Component Analysis (ICA) and Dictionary Learning (DL), better representing individual brain topologies; 2) The application of Phase Locking Value (PLV) to estimate functional connectivity in the frequency domain, reducing sensitivity to amplitude variations while effectively capturing both linear and non-linear signal relationships; 3) The implementation of a Graph Convolutional Network (GCN) to address the brain’s non-Euclidean topological structure with graph architecture, enhancing the classification and diagnosis of neural disorders. This method was tested on the ADHD-200 dataset for ADHD and the ABIDE-I dataset for ASD, achieving high accuracy (94% ±1.3% for ADHD and 89.3% ±2.3% for ASD) through 10-fold cross-validation. The integration of data-driven ROI extraction, frequency-domain connectivity analysis, and non-Euclidean graph-based brain architecture representation collectively represents a novel approach to improving the understanding and prediction of NDDs.}
}
@article{NOORIGOODARZI2022105372,
title = {Subtractive genomic approach toward introduction of novel immunogenic targets against Clostridioides difficile: Thinking out of the box},
journal = {Microbial Pathogenesis},
volume = {162},
pages = {105372},
year = {2022},
issn = {0882-4010},
doi = {https://doi.org/10.1016/j.micpath.2021.105372},
url = {https://www.sciencedirect.com/science/article/pii/S088240102100646X},
author = {Narjes {Noori Goodarzi} and Sepideh Fereshteh and Omid Azizi and Hamzeh Rahimi and Negin Bolourchi and Farzad Badmasti},
keywords = {, Reverse vaccinology, Immunogenic target},
abstract = {Clostridioides difficile is one of the major causatives of nosocomial infections worldwide. Antibiotic-associated diarrhea, pseudomembranous colitis, and toxic megacolon are the most common forms of C. difficile infection (CDI). Considering the high antibiotic resistance of C. difficile isolates and the low efficacy of immunization with toxin-related vaccines, we suggested that surface-exposed and secreted proteins could be considered as potential immunogenic targets against CDI. Various immuninformatics databases were used to predict antigenicity, allergenicity, B-cell epitopes, MHC-II binding sites, conserved domains, prevalence and conservation of proteins among the most common sequence types, molecular docking, and immunosimulation of immunogenic targets. Finally, 16 proteins belonging to three functional groups were identified, including proteins involved in the cell wall and peptidoglycan layer (nine proteins), flagellar assembly (five proteins), spore germination (one protein), and a protein with unknown function. Molecular docking results showed that among all the mentioned proteins, WP_009892971.1 (Acd) and WP_009890599.1 (a C40 family peptidase) had the strongest interactions with human Toll-like receptor 2 (TLR-2) and TLR-4. This study proposes a combination of C. difficile toxoid (Tcd) and surface-exposed proteins such as Acd as a promising vaccine formulation for protection against circulating clinical strains of C. difficile.}
}
@article{DERREUMAUX2023105304,
title = {Computational underpinnings of partisan information processing biases and associations with depth of cognitive reasoning},
journal = {Cognition},
volume = {230},
pages = {105304},
year = {2023},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2022.105304},
url = {https://www.sciencedirect.com/science/article/pii/S001002772200292X},
author = {Yrian Derreumaux and Kimia Shamsian and Brent L. Hughes},
keywords = {Partisan bias, Motivated cognition, Sequential sampling, Drift diffusion modeling, Cognitive reflection},
abstract = {Despite unprecedented access to information, partisans increasingly disagree about basic facts that are backed by data, posing a serious threat to a democracy that relies on finding common ground based on objective truths. We examine the underpinnings of this phenomenon using drift diffusion modeling (DDM). Partisans (N = 148) completed a sequential sampling task where they evaluated the honesty of Democrat or Republican politicians during a debate based on fact-check scores. We found that partisans required less and weaker evidence to correctly categorize the ingroup as more honest, and were more accurate on trials when the ingroup candidate was more honest, compared to the outgroup. DDM revealed that such tendencies arise from both a prior preference for categorizing the ingroup as more honest (i.e., biased starting point) and more precise accumulation of information favoring the ingroup candidate compared to the outgroup (i.e., biased drift rate). Moreover, individual differences in cognitive reasoning moderated task performance for the most devoted partisans and maintained divergent associations with the DDM parameters. This suggests that partisans may reach biased conclusions via different pathways depending on their depth of cognitive reasoning. These findings provide key insights into the mechanisms driving partisan divides in polarized environments, and can inform interventions that reduce impasse and conflict.}
}
@article{2024267,
title = {Commentator Discussion: Autonomous Fontan pump: Computational feasibility study},
journal = {JTCVS Open},
volume = {21},
pages = {267},
year = {2024},
issn = {2666-2736},
doi = {https://doi.org/10.1016/j.xjon.2024.07.010},
url = {https://www.sciencedirect.com/science/article/pii/S2666273624001906}
}
@article{BAUSO20161,
title = {Strategic thinking under social influence: Scalability, stability and robustness of allocations},
journal = {European Journal of Control},
volume = {32},
pages = {1-15},
year = {2016},
issn = {0947-3580},
doi = {https://doi.org/10.1016/j.ejcon.2016.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S0947358016300115},
author = {Dario Bauso and Tamer Başar},
keywords = {Mean-field games, Coalitional game theory, Differential games, Optimal control},
abstract = {This paper studies the strategic behavior of a large number of game designers and studies the scalability, stability and robustness of their allocations in a large number of homogeneous coalitional games with transferable utilities (TU). For each TU game, the characteristic function is a continuous-time stochastic process. In each game, a game designer allocates revenues based on the extra reward that a coalition has received up to the current time and the extra reward that the same coalition has received in the other games. The approach is based on the theory of mean-field games with heterogeneous groups in a multi-population regime.}
}
@article{TREUR2013449,
title = {Conceptual and Computational Analysis of the Role of Emotions and Social Influence in Learning},
journal = {Procedia - Social and Behavioral Sciences},
volume = {93},
pages = {449-467},
year = {2013},
note = {3rd World Conference on Learning, Teaching and Educational Leadership},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2013.09.220},
url = {https://www.sciencedirect.com/science/article/pii/S1877042813033235},
author = {Jan Treur and Arlette {van Wissen}},
keywords = {emotion, learning, social influence, reflection.},
abstract = {In this paper, it is analyzed how emotions and social environment affect people's active and reflective learning processes. First, a conceptual analysis is made using recent insights from Cognitive, Affective and Social Neuroscience on the roles of emotions and social interactions on learning. Next, a computational analysis is made using a computational model of learning processes following these insights. In this analysis, neural mechanisms for the impact of both a person's own emotions and the emotions of others are taken into account. In particular, it is considered how these impacts influence different learning types, such as active or reflective learners. The analysis shows how the impacts of emotions and social interaction strengthen the learning process. It is discussed how from these insights indicators can be obtained that can be used to design technology-enhanced learning environments able to exploit these impacts.}
}
@article{JOHNSONLAIRD1994189,
title = {Mental models and probabilistic thinking},
journal = {Cognition},
volume = {50},
number = {1},
pages = {189-209},
year = {1994},
issn = {0010-0277},
doi = {https://doi.org/10.1016/0010-0277(94)90028-0},
url = {https://www.sciencedirect.com/science/article/pii/0010027794900280},
author = {Philip N. Johnson-Laird},
abstract = {This paper outlines the theory of reasoning based on mental models, and then shows how this theory might be extended to deal with probabilistic thinking. The same explanatory framework accommodates deduction and induction: there are both deductive and inductive inferences that yield probabilistic conclusions. The framework yields a theoretical conception of strength of inference, that is, a theory of what the strength of an inference is objectively: it equals the proportion of possible states of affairs consistent with the premises in which the conclusion is true, that is, the probability that the conclusion is true given that the premises are true. Since there are infinitely many possible states of affairs consistent with any set of premises, the paper then characterizes how individuals estimate the strength of an argument. They construct mental models, which each correspond to an infinite set of possibilities (or, in some cases, a finite set of infinite sets of possibilities). The construction of models is guided by knowledge and beliefs, including lay conceptions of such matters as the “law of large numbers”. The paper illustrates how this theory can account for phenomena of probabilistic reasoning.}
}
@article{KLIMOVA20231,
title = {Strategic Trends in Artificial Intelligence Through Impact of Computational Science: What Young Scientists Should Expect},
journal = {Procedia Computer Science},
volume = {229},
pages = {1-7},
year = {2023},
note = {12th International Young Scientists Conference in Computational Science, YSC2023},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923019919},
author = {Alexandra Klimova and Denis Nasonov and Alexander Hvatov and Nikolay O. Nikitin and Sergey V. Ivanov and Anna V. Kalyuzhnaya and Alexander Boukhanovsky},
keywords = {Artificial Intelligence, Computational Science, Trends, Impact, Young Scientists},
abstract = {This volume presents selected papers of the 12th Young Scientists Conference in Computational Science (YSC'2023). ITMO University annually organises the event with various academic partners to disseminate current trends in Artificial Intelligence and Computational science among young researchers. In this paper, we present our view on major trends and challenges today in front of scientific and industrial society in this promising area.}
}
@article{FONTES2024101470,
title = {“Viewing puzzles as two-faced: theoretical and practical implications for Puzzle-based Learning”},
journal = {Thinking Skills and Creativity},
volume = {52},
pages = {101470},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101470},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124000099},
author = {Mario Madureira Fontes and Leonel Caseiro Morgado and Pedro Pestana and Daniela Pedrosa and José Paulo Cravino},
keywords = {Puzzle-based Learning, Puzzle Triggers, Creativity skills, Critical thinking, Puzzle-Solving},
abstract = {The Puzzle-based Learning approach has been applied to several fields of knowledge. In education research papers, the instructional usage of puzzles is considered to improve learners' motivation and engagement and help them to develop critical skills but difficulties concerning learners' interaction with puzzles have also been pointed out. Our paper investigates the dynamics of the concept of a puzzle and its interface to provide a better understanding of its form and functions, and help learners interact with puzzles. We consider Puzzle-based Learning tenets as well as their educational impacts on both critical thinking and learner engagement and provide an original proposal concerning the understanding of puzzles. Our proposal centered on the dynamics of puzzles bears conceptual and educational facets. Conceptually, puzzle dynamics is viewed as composed of two elements: a mechanism, the Puzzle Trigger, and a process, the Puzzle-Solving. From an educational point of view, the rationale for integrating Puzzle Triggers in Puzzle-based Learning is meant to help learners interact with puzzles and consequently become motivated and engaged in the Puzzle-Solving process. This way, learners' critical thinking skills are reinforced and focused on finding solutions to challenges. We illustrate the implementation of Puzzle Triggers and Puzzle-Solving by considering two instructional activities in a Software Development undergraduate course of an online learning Informatics Engineering Program.}
}
@article{GRIFFITHS201521,
title = {Manifesto for a new (computational) cognitive revolution},
journal = {Cognition},
volume = {135},
pages = {21-23},
year = {2015},
note = {The Changing Face of Cognition},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2014.11.026},
url = {https://www.sciencedirect.com/science/article/pii/S0010027714002467},
author = {Thomas L. Griffiths},
keywords = {Computational modeling, Big data, Crowdsourcing},
abstract = {The cognitive revolution offered an alternative to merely analyzing human behavior, using the notion of computation to rigorously express hypotheses about the mind. Computation also gives us new tools for testing these hypotheses – large behavioral databases generated by human interactions with computers and with one another. This kind of data is typically analyzed by computer scientists, who focus on predicting people’s behavior based on their history. A new cognitive revolution is needed, demonstrating the value of minds as intervening variables in these analyses and using the results to evaluate models of human cognition.}
}
@article{LI2022175260,
title = {Deep learning and machine intelligence: New computational modeling techniques for discovery of the combination rules and pharmacodynamic characteristics of Traditional Chinese Medicine},
journal = {European Journal of Pharmacology},
volume = {933},
pages = {175260},
year = {2022},
issn = {0014-2999},
doi = {https://doi.org/10.1016/j.ejphar.2022.175260},
url = {https://www.sciencedirect.com/science/article/pii/S0014299922005210},
author = {Dongna Li and Jing Hu and Lin Zhang and Lili Li and Qingsheng Yin and Jiangwei Shi and Hong Guo and Yanjun Zhang and Pengwei Zhuang},
keywords = {AI technology, Drug discovery, Virtual screening, Traditional Chinese medicine},
abstract = {It has been increasingly accepted that Multi-Ingredient-Based interventions provide advantages over single-target therapy for complex diseases. With the growing development of Traditional Chinese Medicine (TCM) and continually being refined of a holistic view, “multi-target” and “multi-pathway” integration characteristics of which are being accepted. However, its effector substances, efficacy targets, especially the combination rules and mechanisms remain unclear, and more powerful strategies to interpret the synergy are urgently needed. Artificial intelligence (AI) and computer vision lead to a rapidly expanding in many fields, including diagnosis and treatment of TCM. AI technology significantly improves the reliability and accuracy of diagnostics, target screening, and new drug research. While all AI techniques are capable of matching models to biological big data, the specific methods are complex and varied. Retrieves literature by the keywords such as “artificial intelligence”, “machine learning”, “deep learning”, “traditional Chinese medicine” and “Chinese medicine”. Search the application of computer algorithms of TCM between 2000 and 2021 in PubMed, Web of Science, China National Knowledge Infrastructure (CNKI), Elsevier and Springer. This review concentrates on the application of computational in herb quality evaluation, drug target discovery, optimized compatibility and medical diagnoses of TCM. We describe the characteristics of biological data for which different AI techniques are applicable, and discuss some of the best data mining methods and the problems faced by deep learning and machine learning methods applied to Chinese medicine.}
}
@article{GIRARD202297,
title = {Computational analysis of spoken language in acute psychosis and mania},
journal = {Schizophrenia Research},
volume = {245},
pages = {97-115},
year = {2022},
note = {Computational Approaches to Understanding Psychosis},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2021.06.040},
url = {https://www.sciencedirect.com/science/article/pii/S0920996421002528},
author = {Jeffrey M. Girard and Alexandria K. Vail and Einat Liebenthal and Katrina Brown and Can Misel Kilciksiz and Luciana Pennant and Elizabeth Liebson and Dost Öngür and Louis-Philippe Morency and Justin T. Baker},
keywords = {Language, Schizophrenia, Bipolar disorder, Positive symptoms, Negative symptoms},
abstract = {Objectives
This study aimed to (1) determine the feasibility of collecting behavioral data from participants hospitalized with acute psychosis and (2) begin to evaluate the clinical information that can be computationally derived from such data.
Methods
Behavioral data was collected across 99 sessions from 38 participants recruited from an inpatient psychiatric unit. Each session started with a semi-structured interview modeled on a typical “clinical rounds” encounter and included administration of the Positive and Negative Syndrome Scale (PANSS).
Analysis
We quantified aspects of participants' verbal behavior during the interview using lexical, coherence, and disfluency features. We then used two complementary approaches to explore our second objective. The first approach used predictive models to estimate participants' PANSS scores from their language features. Our second approach used inferential models to quantify the relationships between individual language features and symptom measures.
Results
Our predictive models showed promise but lacked sufficient data to achieve clinically useful accuracy. Our inferential models identified statistically significant relationships between numerous language features and symptom domains.
Conclusion
Our interview recording procedures were well-tolerated and produced adequate data for transcription and analysis. The results of our inferential modeling suggest that automatic measurements of expressive language contain signals highly relevant to the assessment of psychosis. These findings establish the potential of measuring language during a clinical interview in a naturalistic setting and generate specific hypotheses that can be tested in future studies. This, in turn, will lead to more accurate modeling and better understanding of the relationships between expressive language and psychosis.}
}
@article{CUI20226,
title = {Green biomanufacturing promoted by automatic retrobiosynthesis planning and computational enzyme design},
journal = {Chinese Journal of Chemical Engineering},
volume = {41},
pages = {6-21},
year = {2022},
issn = {1004-9541},
doi = {https://doi.org/10.1016/j.cjche.2021.08.017},
url = {https://www.sciencedirect.com/science/article/pii/S1004954121004286},
author = {Ziheng Cui and Shiding Zhang and Shengyu Zhang and Biqiang Chen and Yushan Zhu and Tianwei Tan},
keywords = {Biomanufacturing, Retrobiosynthesis, Computational enzyme design, Biobased chemicals},
abstract = {Biomanufacturing, which uses renewable resources as raw materials and uses biological processes to produce energy and chemicals, has long been regarded as a production model that replaces the unsustainable fossil economy. The construction of non-natural and efficient biosynthesis routes of chemicals is an important goal of green biomanufacturing. Traditional methods that rely on experience are difficult to support the realization of this goal. However, with the rapid development of information technology, the intelligence of biomanufacturing has brought hope to achieve this goal. Retrobiosynthesis and computational enzyme design, as two of the main technologies in intelligent biomanufacturing, have developed rapidly in recent years and have made great achievements and some representative works have demonstrated the great value that the integration of the two fields may bring. To achieve the final integration of the two fields, it is necessary to examine the information, methods and tools from a bird's-eye view, and to find a feasible idea and solution for establishing a connection point. For this purpose, this article briefly reviewed the main ideas, methods and tools of the two fields, and put forward views on how to achieve the integration of the two fields.}
}
@article{PETSCHE199231,
title = {Thinking with images or thinking with language: a pilot EEG probability mapping study},
journal = {International Journal of Psychophysiology},
volume = {12},
number = {1},
pages = {31-39},
year = {1992},
issn = {0167-8760},
doi = {https://doi.org/10.1016/0167-8760(92)90040-I},
url = {https://www.sciencedirect.com/science/article/pii/016787609290040I},
author = {Hellmuth Petsche and Denis Lacroix and Klaus Lindner and Peter Rappelsberger and Eva Schmidt-Henrich},
keywords = {EEG probability mapping, Mental imagery, Thinking process, Cognitive activation, Sex difference},
abstract = {This pilot EEG mapping study was designed to explore thinking processes using complex mental imagery and thought processes. EEG was recorded with 19 electrodes (10/20 system against averaged ear lobe signals) while volunteers (n = 42) performed two separate tasks: visualization of an abstract concept and interpretation of a painting. Average spectral parameters such as amplitude, local and interhemispheric coherences were computed for five frequency bands (theta, alpha, beta 1, 2 and 3). Results indicate that the frontal regions are strongly involved during these tasks as evidenced by coherence changes. Changes are also present in temporal, parietal and occipital regions and are discussed in relation to information processing with the frontal regions considering the different cognitive functions required by the tasks.}
}
@article{POON2006177,
title = {Lay personality knowledge and dispositionist thinking: A knowledge-activation framework},
journal = {Journal of Experimental Social Psychology},
volume = {42},
number = {2},
pages = {177-191},
year = {2006},
issn = {0022-1031},
doi = {https://doi.org/10.1016/j.jesp.2005.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S002210310500051X},
author = {Connie S.K. Poon and Derek J. Koehler},
keywords = {Lay theories, Dispositional inferences, Knowledge activation},
abstract = {We explicate a knowledge-activation framework depicting the link between lay personality knowledge and dispositional judgments, building on work by Dweck et al., 1995a, Dweck et al., 1995b. According to this framework, most people possess knowledge consistent with an entity theory (personality is fixed) and incremental theory (personality is malleable), which operates according to knowledge-activation principles. Consistent with this claim, we find that people render more confident dispositional judgments when their entity knowledge is made relatively more accessible through priming manipulations that activate aspects of their existing knowledge. Findings also illustrate the usefulness of incorporating both specific and general knowledge in our analysis. The present framework enhances and complements the individual-differences approach to the study of person theories prevalent in the literature.}
}
@article{YILDIRIM201973,
title = {An integrative computational architecture for object-driven cortex},
journal = {Current Opinion in Neurobiology},
volume = {55},
pages = {73-81},
year = {2019},
note = {Machine Learning, Big Data, and Neuroscience},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2019.01.010},
url = {https://www.sciencedirect.com/science/article/pii/S0959438818301995},
author = {Ilker Yildirim and Jiajun Wu and Nancy Kanwisher and Joshua Tenenbaum},
abstract = {Computational architecture for object-driven cortex Objects in motion activate multiple cortical regions in every lobe of the human brain. Do these regions represent a collection of independent systems, or is there an overarching functional architecture spanning all of object-driven cortex? Inspired by recent work in artificial intelligence (AI), machine learning, and cognitive science, we consider the hypothesis that these regions can be understood as a coherent network implementing an integrative computational system that unifies the functions needed to perceive, predict, reason about, and plan with physical objects—as in the paradigmatic case of using or making tools. Our proposal draws on a modeling framework that combines multiple AI methods, including causal generative models, hybrid symbolic-continuous planning algorithms, and neural recognition networks, with object-centric, physics-based representations. We review evidence relating specific components of our proposal to the specific regions that comprise object-driven cortex, and lay out future research directions with the goal of building a complete functional and mechanistic account of this system.}
}
@article{SHEARER1996465,
title = {Computational optimization of finite difference methods on the CM5},
journal = {Parallel Computing},
volume = {22},
number = {3},
pages = {465-481},
year = {1996},
issn = {0167-8191},
doi = {https://doi.org/10.1016/0167-8191(95)00009-7},
url = {https://www.sciencedirect.com/science/article/pii/0167819195000097},
author = {M.M. Shearer},
keywords = {Finite-difference method, Partial differential equation, CM5, Distributed memory multiprocessor, Optimization, Data partitioning, Performance},
abstract = {Techniques used to optimize a finite-difference program on a Thinking Machines' CM5 parallel processing system are presented. These techniques are discussed within several categories: vector unit optimization, separation of communications and computations, and optimal data partitioning. A simplified model is employed to illustrate these concepts. The results of applying these techniques to a more complicated finite-difference calculation are also reported.}
}
@article{ROOTBERNSTEIN2025100097,
title = {An Art-Science Perspective on Artificial Intelligence Creativity: From Problem Finding to Materiality and Embodied Cognition},
journal = {Journal of Creativity},
pages = {100097},
year = {2025},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2025.100097},
url = {https://www.sciencedirect.com/science/article/pii/S2713374525000044},
author = {Robert Root-Bernstein},
keywords = {artificial intelligence, expert systems, creativity, creative process, problem recognition, innovation, art, science, The Illiac Suite, Aspire Mirror},
abstract = {Current large language models, image generators and discovery engines fuel fears that artificial intelligence systems will replace human-driven creativity. However, analysing AI systems from the perspective of creative process reveals significant limitations. Human creativity begins with finding or recognizing novel problems or challenges, which no AI system has managed. The problems AI systems address are predetermined by human users, who also provide the data and constraints bounding effective answers. Thus, human beings still carry out the vast majority of creative process-related functions for AI. Moreover, most human creativity is embodied and involves the manipulation of tools and materials. Furthermore, all human creativity is based on “tagging” information and experiences through perceptions, sensations and emotions with meanings or actions. No AI has these attributes. All human innovations also involve “untagging” preconceived meanings and actions so as to “retag” them in novel and effective ways that change how we feel, understand and act. No AI can untag or retag data, let alone act. Finally, human creative thinking is based on observing, imaging, abstracting, analogizing, playacting, modelling, body thinking, etc., of which AI systems are capable only of pattern forming and pattern recognition. Thus, the challenges for developing true AI creativity are extensive.}
}
@article{SHENHAV2022,
title = {Using Community Ecology Theory and Computational Microbiome Methods To Study Human Milk as a Biological System},
journal = {mSystems},
volume = {7},
number = {1},
year = {2022},
issn = {2379-5077},
doi = {https://doi.org/10.1128/msystems.01132-21},
url = {https://www.sciencedirect.com/science/article/pii/S2379507722000873},
author = {Liat Shenhav and Meghan B. Azad and Jack A. Gilbert},
keywords = {computational methods, human microbiome, human milk, chronobiology, community ecology theory, system biology, lactation, breastfeeding},
abstract = {Human milk is a complex and dynamic biological system that has evolved to optimally nourish and protect human infants. Yet, according to a recent priority-setting review, “our current understanding of human milk composition and its individual components and their functions fails to fully recognize the importance of the chronobiology and systems biology of human milk in the context of milk synthesis, optimal timing and duration of feeding, and period of lactation.” We attribute this critical knowledge gap to three major reasons as follows. (i) Studies have typically examined each subsystem of the mother-milk-infant “triad” in isolation and often focus on a single element or component (e.g., maternal lactation physiology or milk microbiome or milk oligosaccharides or infant microbiome or infant gut physiology).
ABSTRACT
Human milk is a complex and dynamic biological system that has evolved to optimally nourish and protect human infants. Yet, according to a recent priority-setting review, “our current understanding of human milk composition and its individual components and their functions fails to fully recognize the importance of the chronobiology and systems biology of human milk in the context of milk synthesis, optimal timing and duration of feeding, and period of lactation” (P. Christian et al., Am J Clin Nutr 113:1063–1072, 2021, https://doi.org/10.1093/ajcn/nqab075). We attribute this critical knowledge gap to three major reasons as follows. (i) Studies have typically examined each subsystem of the mother-milk-infant “triad” in isolation and often focus on a single element or component (e.g., maternal lactation physiology or milk microbiome or milk oligosaccharides or infant microbiome or infant gut physiology). This undermines our ability to develop comprehensive representations of the interactions between these elements and study their response to external perturbations. (ii) Multiomics studies are often cross-sectional, presenting a snapshot of milk composition, largely ignoring the temporal variability during lactation. The lack of temporal resolution precludes the characterization and inference of robust interactions between the dynamic subsystems of the triad. (iii) We lack computational methods to represent and decipher the complex ecosystem of the mother-milk-infant triad and its environment. In this review, we advocate for longitudinal multiomics data collection and demonstrate how incorporating knowledge gleaned from microbial community ecology and computational methods developed for microbiome research can serve as an anchor to advance the study of human milk and its many components as a “system within a system.”}
}
@article{CAKIROGLU2021100888,
title = {Understanding students’ abstractions in block-based programming environments: A performance based evaluation},
journal = {Thinking Skills and Creativity},
volume = {41},
pages = {100888},
year = {2021},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2021.100888},
url = {https://www.sciencedirect.com/science/article/pii/S1871187121001036},
author = {Ünal Çakıroğlu and İsak Çevik and Engin Köşeli and Merve Aydın},
keywords = {Abstraction, Block-based programming, Computational thinking, Computer science education},
abstract = {Providing computational problems for enhancing students’ abstraction skills and monitoring how students make abstractions is difficult in block-based programming environments (BBPEs). Thus, concrete examples and principles are needed to guide computer science teachers about understanding and enhancing students’ abstractions. This study aims to examine the effect of using block-based coding environments on enhancing secondary school students’ abstraction skills. Referring to the programming knowledge, a rubric was created to analyze the data from screen recordings, observation and interviews were used together to reveal the students’ abstraction performances. The results suggested that students performed high in elimination, focusing and generalization; however, students’ performances were relatively low in customization. Students’ explanations were mostly related the nature of the problems, affordances of BBPE and the programming constructs used in coding. We hope the study will provide insights for the efforts on instructional designs for successful abstraction experiences for young students.}
}
@article{IGLESIAS2011744,
title = {Re-thinking water policy priorities in the Mediterranean region in view of climate change},
journal = {Environmental Science & Policy},
volume = {14},
number = {7},
pages = {744-757},
year = {2011},
note = {Adapting to Climate Change: Reducing Water-related Risks in Europe},
issn = {1462-9011},
doi = {https://doi.org/10.1016/j.envsci.2011.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S1462901111000207},
author = {Ana Iglesias and Luis Garrote and Agustin Diz and Jeremy Schlickenrieder and Francisco Martin-Carrasco},
keywords = {Mediterranean, Climate change, Water policy, Adaptation and assessment},
abstract = {Water is scarce in Mediterranean countries: cities are crowded with increasing demand; food is produced with large amounts of water; ecosystems demand more water that is often available; drought affects all. As climate change impacts become more noticeable and costlier, some current water management strategies will not be useful. According to the findings of CIRCE, the areas with limited water resources will increase in the coming decades with major consequences for the way we produce food and we protect ecosystems. Based on these projections this paper discusses water policy priorities for climate change adaptation in the Mediterranean. We first summarise the main challenges to water resources in Mediterranean countries and outline the risks and opportunities for water under climate change based on previous studies. Recognising the difficulty to go from precipitation to water policy, we then present a framework to evaluate water availability in response to natural and management conditions, with an example of application in the Ebro basin that exemplifies other Mediterranean areas. Then we evaluate adaptive capacity to understand the ability of Mediterranean countries to face, respond and recover from climate change impacts on water resources. Social and economic factors are key drivers of inequality in the adaptive capacity across the region. Based on the assessment of impacts and adaptive capacity we suggest thresholds for water policy to respond to climate change and link water scarcity indicators to relevant potential adaptation strategies. Our results suggest the need to further prioritise socially and economically sensitive policies.}
}
@article{LI2024127497,
title = {Fully automated diagnosis of thyroid nodule ultrasound using brain-inspired inference},
journal = {Neurocomputing},
volume = {582},
pages = {127497},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.127497},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224002686},
author = {Guanghui Li and Qinghua Huang and Chunying Liu and Guanying Wang and Lingli Guo and Ruonan Liu and Longzhong Liu},
keywords = {Brain-inspired inference, TI-RADS, Deep learning, Knowledge tensor, Thyroid ultrasound},
abstract = {The interpretability of artificial intelligence (AI) based medical diagnostic systems is crucial to make the diagnosis adequately convincible. Deep learning has been extensively investigated and utilized in the area of medical assistance diagnosis in recent decades due to its outstanding performance and objective prediction. However, a huge semantic chasm dividing clinicians and unexplainable deep models emerges. Here we design a brain-inspired inference framework from medical images to explainable features, then to the final diagnostic conclusions. The fast thinking module is responsible for recognizing medical features in ultrasound (US) images, and the slow-thinking module builds a model for inferring from medical features to diagnostic results by constructing a knowledge graph of medical features with tensor decomposition. The whole model infers through intuition and thinking like a human being, and gives the recognized medical image features while inferring the diagnosis, which greatly improves the interpretability of the model. We conducted studies on thyroid cancer diagnoses using US images. The American College of Radiology (ACR) Thyroid Imaging Reporting and Data System (TI-RADS) characteristics are employed as medical features describing thyroid nodules. Our brain-inspired medical inference framework outperforms commonly used deep learning algorithms, with an AUC score of 0.963 (95% confidential interval (CI)=0.923–1.000) for thyroid US image diagnosis. Results indicate that our framework improves diagnostic objectivity and interpretability while providing performance that is better than deep models. Our proposed brain-inspired medical inference framework could improve the efficiency of diagnosis and our technique is performant, objective and interpretable.}
}
@article{KWOK2018461,
title = {Re-thinking Alzheimer's disease therapeutic targets using gene-based tests},
journal = {EBioMedicine},
volume = {37},
pages = {461-470},
year = {2018},
issn = {2352-3964},
doi = {https://doi.org/10.1016/j.ebiom.2018.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S2352396418304122},
author = {Man Ki Kwok and Shi Lin Lin and C. Mary Schooling},
keywords = {Alzheimer's disease, Genetics, Genetic drug targets, Gene-based test},
abstract = {Background
Alzheimer's disease (AD) is a devastating condition with no known effective drug treatments. Existing drugs only alleviate symptoms. Given repeated expensive drug failures, we assessed systematically whether approved and investigational AD drugs are targeting products of genes strongly associated with AD and whether these genes are targeted by existing drugs for other indications which could be re-purposed.
Methods
We identified genes strongly associated with late-onset AD from the loci of genetic variants associated with AD at genome-wide-significance and from a gene-based test applied to the most extensively genotyped late-onset AD case (n = 17,008)-control (n = 37,154) study, the International Genomics of Alzheimer's Project. We used three gene-to-drug cross-references, Kyoto Encyclopedia of Genes and Genomes, Drugbank and Drug Repurposing Hub, to identify genetically validated targets of AD drugs and any existing drugs or nutraceuticals targeting products of the genes strongly associated with late-onset AD.
Findings
A total of 67 autosomal genes (forming 9 gene clusters) were identified as strongly associated with late-onset AD, 28 from the loci of single genetic variants, 51 from the gene-based test and 12 by both methods. Existing approved or investigational AD drugs did not target products of any of these 67 genes. Drugs for other indications targeted 11 of these genes, including immunosuppressive disease-modifying anti-rheumatic drugs targeting PTK2B gene products.
Interpretation
Approved and investigational AD drugs are not targeting products of genes strongly associated with late-onset AD. However, other drugs targeting products of these genes exist and could perhaps be re-purposing to combat late-onset AD after further scrutiny.}
}
@article{HOLROYD2021316,
title = {The Best Laid Plans: Computational Principles of Anterior Cingulate Cortex},
journal = {Trends in Cognitive Sciences},
volume = {25},
number = {4},
pages = {316-329},
year = {2021},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2021.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S1364661321000103},
author = {Clay B. Holroyd and Tom Verguts},
keywords = {anterior cingulate cortex, computational models, artificial intelligence, hierarchical model-based hierarchical reinforcement learning, distributed representations, cognitive control},
abstract = {Despite continual debate for the past 30 years about the function of anterior cingulate cortex (ACC), its key contribution to neurocognition remains unknown. However, recent computational modeling work has provided insight into this question. Here we review computational models that illustrate three core principles of ACC function, related to hierarchy, world models, and cost. We also discuss four constraints on the neural implementation of these principles, related to modularity, binding, encoding, and learning and regulation. These observations suggest a role for ACC in hierarchical model-based hierarchical reinforcement learning (HMB-HRL), which instantiates a mechanism motivating the execution of high-level plans.}
}
@article{ELLIS2022581,
title = {Comparison of apnoeic oxygen techniques in term pregnant subjects: a computational modelling study},
journal = {British Journal of Anaesthesia},
volume = {129},
number = {4},
pages = {581-587},
year = {2022},
issn = {0007-0912},
doi = {https://doi.org/10.1016/j.bja.2022.06.021},
url = {https://www.sciencedirect.com/science/article/pii/S0007091222003221},
author = {Reena Ellis and Marianna Laviola and Daniel Stolady and Rebecca L. Valentine and Arani Pillai and Jonathan G. Hardman},
keywords = {apnoea, computer simulation, high-flow nasal oxygenation, low-flow nasal oxygenation, obesity in pregnancy, obstetrics},
abstract = {Background
Hypoxaemia during general anaesthesia can cause harm. Apnoeic oxygenation extends safe apnoea time, reducing risk during airway management. We hypothesised that low-flow nasal oxygenation (LFNO) would extend safe apnoea time similarly to high-flow nasal oxygenation (HFNO), whilst allowing face-mask preoxygenation and rescue.
Methods
A high-fidelity, computational, physiological model was used to examine the progression of hypoxaemia during apnoea in virtual models of pregnant women in and out of labour, with BMI of 24–50 kg m−2. Subjects were preoxygenated with oxygen 100% to reach end-tidal oxygen fraction (FE'O2) of 60%, 70%, 80%, or 90%. When apnoea started, HFNO or LFNO was commenced. To simulate varying degrees of effectiveness of LFNO, periglottic oxygen fraction (FgO2) of 21%, 60%, or 100% was configured. HFNO provided FgO2 100% and oscillating positive pharyngeal pressure.
Results
Application of LFNO (FgO2 100%) after optimal preoxygenation (FE'O2 90%) resulted in similar or longer safe apnoea times than HFNO FE'O2 80% in all subjects in labour. For BMI of 24, the time to reach SaO2 90% with LFNO was 25.4 min (FE'O2 90%/FgO2 100%) vs 25.4 min with HFNO (FE'O2 80%). For BMI of 50, the time was 9.9 min with LFNO (FE'O2 90%/FgO2 100%) vs 4.3 min with HFNO (FE'O2 80%). A similar finding was seen in subjects with BMI ≥40 kg m−2 not in labour.
Conclusions
There is likely to be clinical benefit to using LFNO, given that LFNO and HFNO extend safe apnoea time similarly, particularly when BMI ≥40 kg m−2. Additional benefits to LFNO include the facilitation of rescue face-mask ventilation and ability to monitor FE'O2 during preoxygenation.}
}
@article{MCANDREW2020300,
title = {Re-Thinking the Role of Statistics in Informing Heart Team Decisions: A Consensus Distribution Approach},
journal = {Structural Heart},
volume = {4},
number = {4},
pages = {300-301},
year = {2020},
issn = {2474-8706},
doi = {https://doi.org/10.1080/24748706.2020.1782550},
url = {https://www.sciencedirect.com/science/article/pii/S2474870622004997},
author = {Thomas McAndrew and Bjorn Redfors}
}
@article{SHAFIR1994403,
title = {Uncertainty and the difficulty of thinking through disjunctions},
journal = {Cognition},
volume = {50},
number = {1},
pages = {403-430},
year = {1994},
issn = {0010-0277},
doi = {https://doi.org/10.1016/0010-0277(94)90038-8},
url = {https://www.sciencedirect.com/science/article/pii/0010027794900388},
author = {Eldar Shafir},
abstract = {This paper considers the relationship between decision under uncertainty and thinking through disjunctions. Decision situations that lead to violations of Savage's sure-thing principle are examined, and a variety of simple reasoning problems that often generate confusion and error are reviewed. The common difficulty is attributed to people's reluctance to think through disjunctions. Instead of hypothetically traveling through the branches of a decision tree, it is suggested, people suspend judgement and remain at the node. This interpretation is applied to instances of decision making, information search, deductive and inductive reasoning, probabilistic judgement, games, puzzles and paradoxes. Some implications of the reluctance to think through disjunctions, as well as potential corrective procedures, are discussed.}
}
@article{CAETANO2020287,
title = {Computational design in architecture: Defining parametric, generative, and algorithmic design},
journal = {Frontiers of Architectural Research},
volume = {9},
number = {2},
pages = {287-300},
year = {2020},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2019.12.008},
url = {https://www.sciencedirect.com/science/article/pii/S2095263520300029},
author = {Inês Caetano and Luís Santos and António Leitão},
keywords = {Algorithmic design, Computer-aided design, Computational design, Generative design, Parametric design},
abstract = {Computation-based approaches in design have emerged in the last decades and rapidly became popular among architects and other designers. Design professionals and researchers adopted different terminologies to address these approaches. However, some terms are used ambiguously and inconsistently, and different terms are commonly used to express the same concept. This paper discusses computational design (CD) and proposes an improved and sound taxonomy for a set of key CD terms, namely, parametric, generative, and algorithmic design, based on an extensive literature review from which different definitions by various authors were collected, analyzed, and compared.}
}
@article{KUCUK2020100167,
title = {Students’ attitudes towards robotics and STEM: Differences based on gender and robotics experience},
journal = {International Journal of Child-Computer Interaction},
volume = {23-24},
pages = {100167},
year = {2020},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2020.100167},
url = {https://www.sciencedirect.com/science/article/pii/S2212868920300039},
author = {Sevda Kucuk and Burak Sisman},
keywords = {Secondary education, Gender studies, Educational robotics, STEM},
abstract = {In this study, Turkish secondary school students’ attitudes towards robotics and STEM were examined in terms of gender and robotics experience. Sample consisted of 240 secondary school students (98 females and 142 males; grades 5–7). Two scales were used to collect data: STEM Attitude Scale and Robotics Attitude Scale. The data were analyzed using a One-way MANOVA and through correlational methods. Results show that the students’ attitudes towards robotics and STEM were positive. Gender had no effect on STEM attitudes. However, in terms of robotics attitudes, female students had significantly less desire and less confidence to learn robotics than male students. There was no gender effect on computational thinking and teamwork. Implications were discussed in terms of theoretical insights, practices for educational robotics in STEM, and directions for further research.}
}
@article{BERNAL2015163,
title = {On the role of computational support for designers in action},
journal = {Design Studies},
volume = {41},
pages = {163-182},
year = {2015},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2015.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X15000551},
author = {Marcelo Bernal and John R. Haymaker and Charles Eastman},
keywords = {design knowledge, computer aided design, design automation, computer supported design, design technology},
abstract = {Designers' actions are high-level mechanisms based on heuristics and assumptions learned from professional experience. Significant research has been devoted to understanding these actions as well as finding ways to aid, automate, or augment them with computational support. However, representing and manipulating such tacit knowledge in computational environments remains an open area of research. In this paper, we map designers' actions and relationships to compare them with computational approaches for the generation, evaluation, and selection of design alternatives, and attempt to integrate all of the above. The analysis provides a more thorough understanding of the role of computational approaches in supporting designer actions and identifies challenges and areas of future research.}
}
@article{AIZAWA2010227,
title = {Computation in cognitive science: it is not all about Turing-equivalent computation},
journal = {Studies in History and Philosophy of Science Part A},
volume = {41},
number = {3},
pages = {227-236},
year = {2010},
note = {Computation and cognitive science},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2010.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S0039368110000452},
author = {Kenneth Aizawa},
keywords = {Circular causality, Computation, Cortical maps, Neural networks, Symbol manipulation, Turing-equivalent computation},
abstract = {It is sometimes suggested that the history of computation in cognitive science is one in which the formal apparatus of Turing-equivalent computation, or effective computability, was exported from mathematical logic to ever wider areas of cognitive science and its environs. This paper, however, indicates some respects in which this suggestion is inaccurate. Computability theory has not been focused exclusively on Turing-equivalent computation. Many essential features of Turing-equivalent computation are not captured in definitions of computation as (digital) symbol manipulation. Turing-equivalent computation did not play the role in McCulloch and Pitts’s early cybernetic work that is sometimes attributed to it. Finally, various segments of the neuroscientific community invoke a notion of computation that differs from the Turing-equivalent notion.}
}
@article{JOSHI2018740,
title = {Are you thinking what I'm thinking? Synchronization of resting fMRI time-series across subjects},
journal = {NeuroImage},
volume = {172},
pages = {740-752},
year = {2018},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2018.01.058},
url = {https://www.sciencedirect.com/science/article/pii/S1053811918300582},
author = {Anand A. Joshi and Minqi Chong and Jian Li and Soyoung Choi and Richard M. Leahy},
abstract = {We describe BrainSync, an orthogonal transform that allows direct comparison of resting fMRI (rfMRI) time-series across subjects. For this purpose, we exploit the geometry of the rfMRI signal space to propose a novel orthogonal transformation that synchronizes rfMRI time-series across sessions and subjects. When synchronized, rfMRI signals become approximately equal at homologous locations across subjects. The method is based on the observation that rfMRI data exhibit similar connectivity patterns across subjects, as reflected in the pairwise correlations between different brain regions. We show that if the data for two subjects have similar correlation patterns then their time courses can be approximately synchronized by an orthogonal transformation. This transform is unique, invertible, efficient to compute, and preserves the connectivity structure of the original data for all subjects. Analogously to image registration, where we spatially align structural brain images, this temporal synchronization of brain signals across a population, or within-subject across sessions, facilitates cross-sectional and longitudinal studies of rfMRI data. The utility of the BrainSync transform is illustrated through demonstrative simulations and applications including quantification of rfMRI variability across subjects and sessions, cortical functional parcellation across a population, timing recovery in task fMRI data, comparison of task and resting state data, and an application to complex naturalistic stimuli for annotation prediction.}
}
@article{IGAMBERDIEV2021104395,
title = {Mathematics in biological reality: The emergence of natural computation in living systems},
journal = {Biosystems},
volume = {204},
pages = {104395},
year = {2021},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2021.104395},
url = {https://www.sciencedirect.com/science/article/pii/S0303264721000526},
author = {Abir U. Igamberdiev and Joseph E. Brenner},
keywords = {Biological evolution, Biological code, Complexification, Computation, Epistemic cut, Hypercycle, Internal measurement, Relational biology, Univalent foundations},
abstract = {Mathematics is a powerful tool to express the computable part of the reality of the physical world. For living systems, mathematical relations emerge internally as an abstracting capacity in the course of development and adaptation to the external world. All living systems possess internal coding structures which represent their embedded description. They are anticipatory in the sense that the embedded description generates deterministic model of their behavior. If the model does not provide a correct result, they can evolve through the acquisition of new statements inside the embedded description that overcome limitations of the existing model. The newly generated statements acquire meaning in and from the changing environment. The growth of complexity, being a consequence of the internal active adaptation to externality performed by the systems, increases the amount of external work and generates the observed patterns of spatiotemporal structures of evolving systems. In living systems, the symbolic memory constraints are dynamic processes in themselves, co-evolving with the other components of biological systems. Separation of the symbolic memory and the dynamic laws (defined as the epistemic cut), required for self-replication of biological systems, forms the basis for their onto-epistemic relation to reality. In this regard, living systems possess their own internal abstracting capacity and invent mathematics. The digital structure of the genetic code is a manifestation of this mathematics.}
}
@article{ALONSOSANCHEZ202397,
title = {Language network self-inhibition and semantic similarity in first-episode schizophrenia: A computational-linguistic and effective connectivity approach},
journal = {Schizophrenia Research},
volume = {259},
pages = {97-103},
year = {2023},
note = {Language and Speech Analysis in Schizophrenia and Related Psychoses},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2022.04.007},
url = {https://www.sciencedirect.com/science/article/pii/S0920996422001608},
author = {María Francisca Alonso-Sánchez and Roberto Limongi and Joseph Gati and Lena Palaniyappan},
keywords = {Psychosis, Lexical access, fMRI, Spectral dynamic causal modelling, Broca's area, Disorganization, Formal thought disorder},
abstract = {Introduction
A central feature of schizophrenia is the disorganization and impoverishment of language. Recently, we observed higher semantic similarity in first-episode-schizophrenia (FES) patients. In this study, we investigate if this aberrant similarity relates to the ‘causal’ connectivity between two key nodes of the word production system: inferior frontal gyrus (IFG) and the semantic-hub at the ventral anterior temporal lobe (vATL).
Methods
Resting-state fMRI scans were collected from 60 participants (30 untreated FES and 30 healthy controls). The semantic distance was measured with the CoVec semantic tool based on GloVe. A spectral dynamic causal model with Parametrical Empirical Bayes was constructed modelling the intrinsic self-inhibitory and extrinsic-excitatory connections within the brain regions. We estimated the parameters of a fully connected model with the semantic distance as a covariate.
Results
FES patients chose words with higher semantic similarity when describing the pictures compared to the HC group. Among patients, an increased semantic similarity was related with an increase in intrinsic connections within both the vATL and IFG, suggesting that reduced ‘synaptic gain’ in these regions likely contribute to aberrant sampling of the semantic space during discourse in schizophrenia.
Conclusions
Lexical impoverishment relates to increased self-inhibition in both the IFG and vATL. The associated reduction in synaptic gain may relate to reduced precision of locally generated neural activity, forcing the choice of words that are already ‘activated’ in a lexical network. One approach to improve word sampling may be via promoting synaptic gain via supra-physiological stimulation within the Broca's-vATL network; this proposal needs verification.}
}
@article{BOOKER2004331,
title = {Solving black box computation problems using expert knowledge theory and methods},
journal = {Reliability Engineering & System Safety},
volume = {85},
number = {1},
pages = {331-340},
year = {2004},
note = {Alternative Representations of Epistemic Uncertainty},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2004.03.021},
url = {https://www.sciencedirect.com/science/article/pii/S0951832004000705},
author = {Jane M Booker and Laura A McNamara},
keywords = {Expert judgment, Elicitation, Probability theory, Epistemic uncertainty},
abstract = {The challenge problems for the Epistemic Uncertainty Workshop at Sandia National Laboratories provide common ground for comparing different mathematical theories of uncertainty, referred to as General Information Theories (GITs). These problems also present the opportunity to discuss the use of expert knowledge as an important constituent of uncertainty quantification. More specifically, how do the principles and methods of eliciting and analyzing expert knowledge apply to these problems and similar ones encountered in complex technical problem solving and decision making? We will address this question, demonstrating how the elicitation issues and the knowledge that experts provide can be used to assess the uncertainty in outputs that emerge from a black box model or computational code represented by the challenge problems. In our experience, the rich collection of GITs provides an opportunity to capture the experts' knowledge and associated uncertainties consistent with their thinking, problem solving, and problem representation. The elicitation process is rightly treated as part of an overall analytical approach, and the information elicited is not simply a source of data. In this paper, we detail how the elicitation process itself impacts the analyst's ability to represent, aggregate, and propagate uncertainty, as well as how to interpret uncertainties in outputs. While this approach does not advocate a specific GIT, answers under uncertainty do result from the elicitation.}
}
@article{LAMPRECHT20151927,
title = {Scientific Workflows with XMDD: A Way to Use Process Modeling in Computational Science Education},
journal = {Procedia Computer Science},
volume = {51},
pages = {1927-1936},
year = {2015},
note = {International Conference On Computational Science, ICCS 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.05.457},
url = {https://www.sciencedirect.com/science/article/pii/S187705091501265X},
author = {Anna-Lena Lamprecht and Tiziana Margaria},
keywords = {Process modeling, Scientific workflows, Computational science, Model-driven development},
abstract = {Process models are well suited to describe in a formal but still intuitive fashion what a system should do. They can thus play a central role in problem-based computational science education with regard to qualifying students for the design and implementation of software applications for their specific needs without putting the focus on the technical part of coding. eXtreme Model Driven Design (XMDD) is a software development paradigm that explicitly focuses on the What (solving problems) rather than on the How (the technical skills of writing code). In this paper we describe how we apply an XMDD-based process modeling and execution framework for scientific workflow projects in the scope of a computer science course for students with a background in natural sciences.}
}
@incollection{SCHLESINGER2020337,
title = {Computational Models of Development},
editor = {Janette B. Benson},
booktitle = {Encyclopedia of Infant and Early Childhood Development (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {337-346},
year = {2020},
isbn = {978-0-12-816511-9},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.23615-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245236158},
author = {Matthew Schlesinger},
keywords = {Computational model, Connectionist model, Artificial neural network, Learning algorithm, Symbolic versus sub-symbolic representations, Adaptive versus static, Learning mechanism, Rule-based model, Dynamic field theory model, Bayesian model, Developmental pattern},
abstract = {Conventional research methods for investigating development are powerful and diverse, but they also have their limits. Many of these limitations can be overcome or addressed through computer modeling. To help make this argument, the current chapter provides a broad, accessible overview to the study of computational models of learning and development. First, we explore the technical vocabulary of computational modeling research by reviewing a set of basic concepts, including the different kinds of representations that are employed by computational models, as well as the array of learning algorithms that are typically used. Next, we review four major types of models: connectionist models, dynamic field theory models, rule-based models, and Bayesian models. In the final section, we put these concepts and approaches into practice by surveying findings from models that simulate the development of object knowledge, language learning, and motor-skill acquisition.}
}
@article{WOLFENGAGEN2016306,
title = {Computational Model of the Tangled Web},
journal = {Procedia Computer Science},
volume = {88},
pages = {306-311},
year = {2016},
note = {7th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2016, held July 16 to July 19, 2016 in New York City, NY, USA},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.07.440},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916316969},
author = {Viacheslav E. Wolfengagen and Larisa Yu. Ismailova and Sergey Kosikov},
keywords = {event-driven computations, scripts, vulnerability, information security, computational model, tangled web},
abstract = {In this paper we attempt to build computational models of entanglement among the event-driven computations. The proposed model operates on the notion of dynamics of the events. This allows selection of entanglement zone that characterizes the area of risks where possible vulnerability and, as a consequence, security violations of web application arise. All constructions for objects are treated as virtual objects. The stated range of issues focuses on computational technologies used scripts, though other explanatory systems are admissible as well but within other appropriate contexts.}
}
@incollection{COUCLELIS2020357,
title = {Computational Human Geography},
editor = {Audrey Kobayashi},
booktitle = {International Encyclopedia of Human Geography (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {357-363},
year = {2020},
isbn = {978-0-08-102296-2},
doi = {https://doi.org/10.1016/B978-0-08-102295-5.10619-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780081022955106195},
author = {Helen Couclelis},
keywords = {Agent-based models, Ambient computing, Cellular automata, Computer modeling, Data revolution, GIS, Geocomputation, Simulation, Urban informatics, Visualization},
abstract = {Computational human geography refers to the use of computational methods and techniques to solve problems in human geography research and applications. The approach goes back to the beginnings of the quantitative revolution in geography and is philosophically related though methodologically distinct from it. Geographic information systems (GIS) and science are a big part of computational human geography, but the latter notion is considerably broader, encompassing spatial process modeling and simulation, the modeling of spatial decision and behavior, visualization techniques, spatial analysis, and an increasing number of new research areas and methods enabled by the most recent technological developments. The latter are discussed under the rubrics of The Data Revolution, Urban (Spatial) Informatics, and Ambient Computing. Two major thrusts have persisted throughout the years: the use of numerical techniques to solve large, complex quantitative problems; the development of models of complex spatial processes expressed directly in computational terms. Both have evolved with the times and continue to be central to computational human geography. Critiques originate from both within the field and from the humanities and social theory perspectives. These address epistemological and methodological problems as well as issues of ontology and representation.}
}
@article{ROLLWAGE2019820,
title = {What Underlies Political Polarization? A Manifesto for Computational Political Psychology},
journal = {Trends in Cognitive Sciences},
volume = {23},
number = {10},
pages = {820-822},
year = {2019},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2019.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S1364661319301810},
author = {Max Rollwage and Leor Zmigrod and Lee de-Wit and Raymond J. Dolan and Stephen M. Fleming},
keywords = {political psychology, computational modeling, cognitive styles, behavioral tasks, radicalism, polarization},
abstract = {Polarization is one of the biggest societal challenges of our time, yet its drivers are poorly understood. Here we propose a novel approach – computational political psychology – which uses behavioral tasks in combination with formal computational models to identify candidate cognitive processes underpinning susceptibility to polarized beliefs about political and societal issues.}
}
@incollection{MALEY2016271,
title = {Chapter 20 - Closed Loops in Neuroscience and Computation: What It Means and Why It Matters},
editor = {Ahmed {El Hady}},
booktitle = {Closed Loop Neuroscience},
publisher = {Academic Press},
address = {San Diego},
pages = {271-277},
year = {2016},
isbn = {978-0-12-802452-2},
doi = {https://doi.org/10.1016/B978-0-12-802452-2.00020-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128024522000202},
author = {C.J. Maley and G. Piccinini},
keywords = {Closed-loop neuroscience, Feedback, Neural computation, Digital computation, Finite-state automata, Turing machine, Persistent Turing machine},
abstract = {We compare the computational power of different classes of computational systems and relate it to whether they contain closed loops. Adding closed loops to the architecture of computational systems increases their computational power. Different computational models are apt for capturing the computational power of different classes of neural systems. We argue that while ordinary Turing machines (TMs) are a poor model for a kind of feedback that the closed-loop approach to neuroscience highlights, suitably modified TMs are a better fit.}
}
@incollection{JUNG2023198,
title = {Design-based education in STEM: for learners of the 21st century},
editor = {Robert J Tierney and Fazal Rizvi and Kadriye Ercikan},
booktitle = {International Encyclopedia of Education (Fourth Edition)},
publisher = {Elsevier},
edition = {Fourth Edition},
address = {Oxford},
pages = {198-206},
year = {2023},
isbn = {978-0-12-818629-9},
doi = {https://doi.org/10.1016/B978-0-12-818630-5.13077-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128186305130775},
author = {Yong Ju Jung and Gi Woong Choi and Soo Hyeon Kim},
keywords = {Design-based education, Design thinking, Digital media creation, Engineering design, Makerspaces, STEM+C education, STEM education, 21st century learning},
abstract = {This article aims to conceptualize design-based education (DBE) in STEM educational settings and provide examples of current DBE practices followed by discussing the gaps of current DBE. We define DBE as educational theory and practice that integrate and transform design processes and design thinking into learning experiences. DBE is well-aligned with the 21st century STEM education because it can enhance learner-centered pedagogy, learners' critical thinking, collaboration, interest-driven learning, and integrative STEM learning. More attention to concrete strategies for the integrative STEM education in DBE and systems of preparing educators for DBE is needed for better learning experiences.}
}
@article{DRUKARCH2018172,
title = {Thinking about the nerve impulse: A critical analysis of the electricity-centered conception of nerve excitability},
journal = {Progress in Neurobiology},
volume = {169},
pages = {172-185},
year = {2018},
issn = {0301-0082},
doi = {https://doi.org/10.1016/j.pneurobio.2018.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S0301008218300509},
author = {Benjamin Drukarch and Hanna A. Holland and Martin Velichkov and Jeroen J.G. Geurts and Pieter Voorn and Gerrit Glas and Henk W. {de Regt}},
keywords = {Nerve impulse, Action potential, Electromechanical pulse, Signal propagation, Hodgkin-Huxley model, Neuroscientific models},
abstract = {Nerve impulse generation and propagation are often thought of as solely electrical events. The prevalence of this view is the result of long and intense study of nerve impulses in electrophysiology culminating in the introduction of the Hodgkin-Huxley model of the action potential in the 1950s. To this day, this model forms the physiological foundation for a broad area of neuroscientific research. However, the Hodgkin-Huxley model cannot account for non-electrical phenomena that accompany nerve impulse propagation, for which there is nevertheless ample evidence. This raises the question whether the Hodgkin-Huxley model is a complete model of the nerve impulse. Several alternative models have been proposed that do take into account non-electrical aspects of the nerve impulse and emphasize their importance in gaining a more complete understanding of the nature of the nerve impulse. In our opinion, these models deserve more attention in neuroscientific research, since, together with the Hodgkin-Huxley model, they will help in addressing and solving a number of questions in basic and applied neuroscience which thus far have remained outside our grasp. Here we provide a historico-scientific overview of the developments that have led to the current conception of the action potential as an electrical phenomenon, discuss some major objections against this conception, and suggest a number of scientific factors which have likely contributed to the enduring success of the Hodgkin-Huxley model and should be taken into consideration whilst contemplating the formulation of a more extensive and complete conception of the nerve impulse.}
}
@article{AUGELLO201674,
title = {Artwork creation by a cognitive architecture integrating computational creativity and dual process approaches},
journal = {Biologically Inspired Cognitive Architectures},
volume = {15},
pages = {74-86},
year = {2016},
issn = {2212-683X},
doi = {https://doi.org/10.1016/j.bica.2015.09.007},
url = {https://www.sciencedirect.com/science/article/pii/S2212683X1500050X},
author = {Agnese Augello and Ignazio Infantino and Antonio Lieto and Giovanni Pilato and Riccardo Rizzo and Filippo Vella},
keywords = {Computational creativity, Cognitive architecture, Dual process theory, PSI model},
abstract = {The paper proposes a novel cognitive architecture (CA) for computational creativity based on the Psi model and on the mechanisms inspired by dual process theories of reasoning and rationality. In recent years, many cognitive models have focused on dual process theories to better describe and implement complex cognitive skills in artificial agents, but creativity has been approached only at a descriptive level. In previous works we have described various modules of the cognitive architecture that allows a robot to execute creative paintings. By means of dual process theories we refine some relevant mechanisms to obtain artworks, and in particular we explain details about resolution level of the CA dealing with different strategies of access to the Long Term Memory (LTM) and managing the interaction between S1 and S2 processes of the dual process theory. The creative process involves both divergent and convergent processes in either implicit or explicit manner. This leads to four activities (exploratory, reflective, tacit, and analytic) that, triggered by urges and motivations, generate creative acts. These creative acts exploit both the LTM and the WM in order to make novel substitutions to a perceived image by properly mixing parts of pictures coming from different domains. The paper highlights the role of the interaction between S1 and S2 processes, modulated by the resolution level which focuses the attention of the creative agent by broadening or narrowing the exploration of novel solutions, or even drawing the solution from a set of already made associations. An example of artificial painter is described in some experimentations by using a robotic platform.}
}
@article{BACELARALMEIDA2022100736,
title = {A formal treatment of the role of verified compilers in secure computation},
journal = {Journal of Logical and Algebraic Methods in Programming},
volume = {125},
pages = {100736},
year = {2022},
issn = {2352-2208},
doi = {https://doi.org/10.1016/j.jlamp.2021.100736},
url = {https://www.sciencedirect.com/science/article/pii/S2352220821000997},
author = {José Carlos {Bacelar Almeida} and Manuel Barbosa and Gilles Barthe and Hugo Pacheco and Vitor Pereira and Bernardo Portela},
keywords = {Secure multiparty computation, Secure compilation, Certified compilation, Formal verification, EasyCrypt, Computer-aided cryptography},
abstract = {Secure multiparty computation (SMC) allows for complex computations over encrypted data. Privacy concerns for cloud applications makes this a highly desired technology and recent performance improvements show that it is practical. To make SMC accessible to non-experts and empower its use in varied applications, many domain-specific compilers are being proposed. We review the role of these compilers and provide a formal treatment of the core steps that they perform to bridge the abstraction gap between high-level ideal specifications and efficient SMC protocols. Our abstract framework bridges this secure compilation problem across two dimensions: 1) language-based source- to target-level semantic and efficiency gaps, and 2) cryptographic ideal- to real-world security gaps. We link the former to the setting of certified compilation, paving the way to leverage long-run efforts such as CompCert in future SMC compilers. Security is framed in the standard cryptographic sense. Our results are supported by a machine-checked formalisation carried out in EasyCrypt.}
}
@article{LANDAU2024101463,
title = {Young children’s copying of block constructions: Significant constraints in a highly complex task},
journal = {Cognitive Development},
volume = {71},
pages = {101463},
year = {2024},
issn = {0885-2014},
doi = {https://doi.org/10.1016/j.cogdev.2024.101463},
url = {https://www.sciencedirect.com/science/article/pii/S0885201424000480},
author = {Barbara Landau and E. Emory Davis and Cathryn S. Cortesa and Zihan Wang and Jonathan D. Jones and Amy L. Shelton},
keywords = {Skilled action, Spatial skills, Spatial cognition, Development, Block construction, Intuitive physics},
abstract = {Block construction is ubiquitous in early development, yet is surprisingly complex, involving step-by-step sequenced actions to create specific structures. Here, we use novel analytic methods to characterize these action sequences in detail, including which individual parts of the structure (‘states’) are built and how these structures are combined, creating a fully specified build path towards the final structure. We find that, like adults tested in a previous study, 4- to 8-year-olds build by creating a small subset of possible individual states and full build paths, and that they prioritize building layer-by-layer. The individual states and build paths that children produce are strikingly similar to those of adults, resulting in structures that are more stable than other possible (but not attested) states and paths. Our approach serves as a lens into the cognitive processes underlying block building and suggests that children’s building is guided by significant cognitive constraints consistent with “computational thinking”.}
}
@article{DUNNE2013387,
title = {Insights from the application of computational neuroimaging to social neuroscience},
journal = {Current Opinion in Neurobiology},
volume = {23},
number = {3},
pages = {387-392},
year = {2013},
note = {Social and emotional neuroscience},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2013.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S095943881300055X},
author = {Simon Dunne and John P O’Doherty},
abstract = {A recent approach in social neuroscience has been the application of formal computational models for a particular social-cognitive process to neuroimaging data. Here we review preliminary findings from this nascent subfield, focusing on observational learning and strategic interactions. We present evidence consistent with the existence of three distinct learning systems that may contribute to social cognition: an observational-reward-learning system involved in updating expectations of future reward based on observing rewards obtained by others, an action-observational learning system involved in learning about the action tendencies of others, and a third system engaged when it is necessary to learn about the hidden mental-states or traits of another. These three systems appear to map onto distinct neuroanatomical substrates, and depend on unique computational signals.}
}
@article{VUQUOC20231069,
title = {Deep Learning Applied to Computational Mechanics: A Comprehensive Review, State of the Art, and the Classics},
journal = {CMES - Computer Modeling in Engineering and Sciences},
volume = {137},
number = {2},
pages = {1069-1343},
year = {2023},
issn = {1526-1492},
doi = {https://doi.org/10.32604/cmes.2023.028130},
url = {https://www.sciencedirect.com/science/article/pii/S1526149223002412},
author = {Loc Vu-Quoc and Alexander Humer},
keywords = {, breakthroughs, network architectures, backpropagation, stochastic optimization methods from classic to modern, recurrent neural networks, long short-term memory, gated recurrent unit, attention, transformer, kernel machines, Gaussian processes, libraries, Physics-Informed Neural Networks, state-of-the-art, history, limitations, challenges, , Finite-element matrix integration, improved Gauss quadrature, Multiscale geomechanics, fluid-filled porous media, Fluid mechanics, turbulence, proper orthogonal decomposition, , autoencoder, hyper-reduction using gappy data, control of large deformable beam},
abstract = {Three recent breakthroughs due to AI in arts and science serve as motivation: An award winning digital image, protein folding, fast matrix multiplication. Many recent developments in artificial neural networks, particularly deep learning (DL), applied and relevant to computational mechanics (solid, fluids, finite-element technology) are reviewed in detail. Both hybrid and pure machine learning (ML) methods are discussed. Hybrid methods combine traditional PDE discretizations with ML methods either (1) to help model complex nonlinear constitutive relations, (2) to nonlinearly reduce the model order for efficient simulation (turbulence), or (3) to accelerate the simulation by predicting certain components in the traditional integration methods. Here, methods (1) and (2) relied on Long-Short-Term Memory (LSTM) architecture, with method (3) relying on convolutional neural networks. Pure ML methods to solve (nonlinear) PDEs are represented by Physics-Informed Neural network (PINN) methods, which could be combined with attention mechanism to address discontinuous solutions. Both LSTM and attention architectures, together with modern and generalized classic optimizers to include stochasticity for DL networks, are extensively reviewed. Kernel machines, including Gaussian processes, are provided to sufficient depth for more advanced works such as shallow networks with infinite width. Not only addressing experts, readers are assumed familiar with computational mechanics, but not with DL, whose concepts and applications are built up from the basics, aiming at bringing first-time learners quickly to the forefront of research. History and limitations of AI are recounted and discussed, with particular attention at pointing out misstatements or misconceptions of the classics, even in well-known references. Positioning and pointing control of a large-deformable beam is given as an example.}
}
@article{ARBELAEZOSSA2023102458,
title = {A smarter perspective: Learning with and from AI-cases},
journal = {Artificial Intelligence in Medicine},
volume = {135},
pages = {102458},
year = {2023},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2022.102458},
url = {https://www.sciencedirect.com/science/article/pii/S093336572200210X},
author = {Laura {Arbelaez Ossa} and Michael Rost and Giorgia Lorenzini and David M. Shaw and Bernice Simone Elger},
keywords = {Medical education, Artificial intelligence, Case-based learning, Critical thinking, Ethics},
abstract = {Artificial intelligence (AI) has only partially (or not at all) been integrated into medical education, leading to growing concerns regarding how to train healthcare practitioners to handle the changes brought about by the introduction of AI. Programming lessons and other technical information into healthcare curricula has been proposed as a solution to support healthcare personnel in using AI or other future technology. However, integrating these core elements of computer science knowledge might not meet the observed need that students will benefit from gaining practical experience with AI in the direct application area. Therefore, this paper proposes a dynamic approach to case-based learning that utilizes the scenarios where AI is currently used in clinical practice as examples. This approach will support students' understanding of technical aspects. Case-based learning with AI as an example provides additional benefits: (1) it allows doctors to compare their thought processes to the AI suggestions and critically reflect on the assumptions and biases of AI and clinical practice; (2) it incentivizes doctors to discuss and address ethical issues inherent to technology and those already existing in current clinical practice; (3) it serves as a foundation for fostering interdisciplinary collaboration via discussion of different views between technologists, multidisciplinary experts, and healthcare professionals. The proposed knowledge shift from AI as a technical focus to AI as an example for case-based learning aims to encourage a different perspective on educational needs. Technical education does not need to compete with other essential clinical skills as it could serve as a basis for supporting them, which leads to better medical education and practice, ultimately benefiting patients.}
}
@article{SPREVAK2010260,
title = {Computation, individuation, and the received view on representation},
journal = {Studies in History and Philosophy of Science Part A},
volume = {41},
number = {3},
pages = {260-270},
year = {2010},
note = {Computation and cognitive science},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2010.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S0039368110000403},
author = {Mark Sprevak},
keywords = {Computation, Representation, Computational identity, Explanation, Narrow content, Physical computation},
abstract = {The ‘received view’ about computation is that all computations must involve representational content. Egan and Piccinini argue against the received view. In this paper, I focus on Egan’s arguments, claiming that they fall short of establishing that computations do not involve representational content. I provide positive arguments explaining why computation has to involve representational content, and how that representational content may be of any type (distal, broad, etc.). I also argue (contra Egan and Fodor) that there is no need for computational psychology to be individualistic. Finally, I draw out a number of consequences for computational individuation, proposing necessary conditions on computational identity and necessary and sufficient conditions on computational I/O equivalence of physical systems.}
}
@incollection{SHARMA2020123,
title = {Chapter 6 - Application of hybrid computational intelligence in health care},
editor = {Siddhartha Bhattacharyya and Václav Snášel and Deepak Gupta and Ashish Khanna},
booktitle = {Hybrid Computational Intelligence},
publisher = {Academic Press},
pages = {123-148},
year = {2020},
series = {Hybrid Computational Intelligence for Pattern Analysis and Understanding},
isbn = {978-0-12-818699-2},
doi = {https://doi.org/10.1016/B978-0-12-818699-2.00007-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012818699200007X},
author = {Moolchand Sharma and Suyash Agrawal and Suman Deswal},
keywords = {Computational intelligence, hybrid computational intelligence, healthcare systems, neural networks, genetic algorithms},
abstract = {The use of hybrid computational intelligence is currently broadening in the field of healthcare applications and research. Computational intelligence has played a vital role in health care for a significant period of time, but with the increased popularity and extensive use of these hybrid computational intelligent systems, a shift has been seen also in the field of health care. Hybrid computational intelligence can be implied in the field of decision making, remote monitoring, healthcare logistics, and modern information systems. Hybrid computational intelligence synergizes different computational intelligence techniques, such as the neural network, the fuzzy logic, the genetic algorithms, the evolutionary computation and the support vector machines, and have their application in the field of pattern recognition, system modeling, etc. In this chapter, we focus on the need for healthcare information technology, improvement of healthcare delivery systems, healthcare safety issues, and also various areas where it can be used.}
}
@article{ZHA2022104623,
title = {A mixed-method cluster analysis of physical computing and robotics integration in middle-grade math lesson plans},
journal = {Computers & Education},
volume = {190},
pages = {104623},
year = {2022},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2022.104623},
url = {https://www.sciencedirect.com/science/article/pii/S0360131522001944},
author = {Shenghua Zha and Yi Jin and Rebecca Wheeler and Erin Bosarge},
keywords = {Applications in subject areas, Improving classroom teaching, Secondary education},
abstract = {This study analyzed 281 lesson plans collected from the producers’ websites of 12 educational physical computing and robotics (ePCR) devices. We extracted and coded five variables from each lesson. They were ePCR functionality, coding skills, computational thinking skills, math knowledge, and activity design. First, a two-step cluster analysis was administered to find how three ePCR-related knowledge: ePCR functionality, coding skills, and computational thinking skills, were integrated to teach students ePCR technology in middle-grade math lessons. Results showed three types of lesson plans, including lessons to use basic ePCR functionality to teach students lower-level CT skills, lessons to teach students basic to intermediate coding skills, and lessons to use the technology at the advanced level. Next, we applied the Technological Pedagogical Content Knowledge (TPACK) framework and conducted a second two-step cluster analysis to identify how the technology (ePCR technology), content (math knowledge), and pedagogy (activity design) were integrated into those lesson plans. Results suggested ten clusters of lesson plans with distinct features. We summarized those ten lesson clusters into five categories: 1) ePCR technology lessons, 2) transdisciplinary problem-based learning lessons, 3) technology-assisted lessons, 4) lessons without real-world connections, and 5) lessons integrating middle-grade math learning into ePCR projects. Implications for educators and researchers were discussed at the end of the article.}
}
@article{WOLFRAM2020101132,
title = {What We’ve built Is a computational language (and that’s very important!)},
journal = {Journal of Computational Science},
volume = {46},
pages = {101132},
year = {2020},
note = {20 years of computational science},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2020.101132},
url = {https://www.sciencedirect.com/science/article/pii/S1877750320304336},
author = {Stephen Wolfram}
}
@article{PATON199363,
title = {Some computational models at the cellular level},
journal = {Biosystems},
volume = {29},
number = {2},
pages = {63-75},
year = {1993},
issn = {0303-2647},
doi = {https://doi.org/10.1016/0303-2647(93)90084-P},
url = {https://www.sciencedirect.com/science/article/pii/030326479390084P},
author = {Ray C. Paton},
keywords = {Computational models of the cell, Levels of organisation, Systemic metaphors},
abstract = {A number of viewpoints on how a cell can be modelled are discussed in this paper in light of the ability it has to process information. The paper begins with a very brief summary of four general types of computation: sequential, parallel, distributed, and emergent. These form the general framework from which a number of comparisons are made. Several metaphors are introduced to enable reflections to be made about cellular computational properties. The most important metaphor, namely the cell as a machine, is discussed, and then a number of other ideas are introduced that complement much current thinking in this area. The idea of networks or circuits in the cell is then developed, as this provides a means of describing the mechanisms within a machine. Following on from this, three further metaphors are applied in order to overcome certain limitations in current machine thinking, cell-as-society, cell-as-text, and cell-as-field.}
}
@incollection{SNYDER2011467,
title = {The Complex Dyanmics of the Climate System: Constraints on our Knowledge, Policy Implications and the Necessity of Systems Thinking},
editor = {Cliff Hooker},
booktitle = {Philosophy of Complex Systems},
publisher = {North-Holland},
address = {Amsterdam},
pages = {467-505},
year = {2011},
volume = {10},
series = {Handbook of the Philosophy of Science},
issn = {18789846},
doi = {https://doi.org/10.1016/B978-0-444-52076-0.50017-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780444520760500171},
author = {Carolyn W. Snyder and Michael D. Mastrandrea and Stephen H. Schneider},
abstract = {Publisher Summary
This chapter describes the contribution of complexity science to understanding of the climate system and the unique challenges its complex properties pose to climate predictions and policy analysis. First, it presents a brief exploration of the Earth's climate system through the lens of complexity science. Then, it introduces the data sources and modeling strategies that climate science uses to understand past behavior, to fingerprint causes of current climate changes, and to project future climate. The complex dynamics of the climate system constrain ability to gain knowledge about the climate system and add uncertainty to predictions of the impacts of human-induced climate change. It also investigates six case studies that illustrate the importance and development of key complexity themes in climate science: glacial-interglacial cycles, thermohaline ocean circulation, ice sheets, vegetation cover changes, extinction, and overshoot scenarios. In addition, it investigates the implications of the complexity of the Earth system for climate policy analysis. Assessments of the impacts of climate change are often disciplinary-based and not sufficiently integrative across important disciplinary subcomponents, producing misleading results that have potentially dangerous environmental consequences. The current framework of cost-benefit optimization is particularly flawed. Further, it describes how one should restructure climate policy analysis as an integrated assessment process, combining data and relationships from the physical, biological and social sciences, that includes robust assessments of potential risks within a vulnerability framework.}
}
@article{ZELENY1992563,
title = {An essay into a philosophy of MCDM: A way of thinking or another algorithm?},
journal = {Computers & Operations Research},
volume = {19},
number = {7},
pages = {563-566},
year = {1992},
note = {Implementing Multiobjective Optimization Methods: Behavioral and Computational Issues},
issn = {0305-0548},
doi = {https://doi.org/10.1016/0305-0548(92)90027-3},
url = {https://www.sciencedirect.com/science/article/pii/0305054892900273},
author = {Milan Zeleny},
abstract = {We have become accustomed to viewing MCDM as another OR/MS algorithm, characterized by a mere shift from k = 1 to k = n with respect to number k of objective functions or criteria. MCDM research and applications has therefore neglected the search for organizational embedding of MCDM: what types of organizations and under what conditions have the propensity to operate under multiple and which under single criteria? Organizations which derive their structure, strategy and motivation from the singleness of purpose will not and can not be conducive to the notions of multiple critera, no matter how skillfully or forcefully presented, or mathematically complete and computationally user-friendly. The organization, its structure and motivational culture have to change first. In short, traditional hierarchy of command, based on extreme specialization and little autonomy of employees and their departments will not be as open to the multiplicity of criteria as the self-managing teams of non-hierarchical companies which integrate task, labor and knowledge and which are only now starting to dominate certain business and management cultures.}
}
@article{HASSANNEZHAD2022116338,
title = {Virtual Net Propagator: A cloud-based computational tool for systemic decision propagation analysis},
journal = {Expert Systems with Applications},
volume = {191},
pages = {116338},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116338},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421016365},
author = {Mohammad Hassannezhad and Behzad Farahany and Fatemeh Barzegar},
keywords = {Change propagation, Complex networks, Computational intelligence, Systems design and analysis, Socio-technical systems, Web-based decision support system},
abstract = {Today’s organizations are witnessing a growing complexity in making interconnected decisions. Where individuals have a wider range of decisions to influence, the consequence of decisions far more propagate across the system, and the business environment continually influences the status of the system. Predicting the cascading effects of decisions in such situations would be very problematic yet can have several implications for managers and executives to think beyond organizational silos and make local decision with a bigger picture of emergent consequences in mind. A prominent challenge within this realm is the ever-increasing complexity of decision propagations, especially when incorporating the role and influence of people involved in decision-making. This paper tackles this challenge from an engineering change perspective, with the focus on computing the compound risk of decisions when their consequences concurrently propagate across the system. We introduce an interactive tool called Virtual Net Propagator, which incorporates organizational dynamics into decision analysis, with the aim to identify change opportunities and effective set of interventions. Illustrated by a field engineering case study, it is demonstrated that the proposed tool can provide detailed knowledge on how decisions are interconnected and how systemic (cascading) effects of a decision propagate through causal pathways, so highlighting key influencers along with role and influence of interfacing (hidden) players.}
}
@article{MARUYAMA20181037,
title = {Investigation into Parents’ Concerns about the Introduction of Programming Education into Japanese Primary School},
journal = {Procedia Computer Science},
volume = {126},
pages = {1037-1045},
year = {2018},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 22nd International Conference, KES-2018, Belgrade, Serbia},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.08.040},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918313188},
author = {Yukiko Maruyama},
keywords = {Programming education, primary school, parents’ concerns, computing thinking},
abstract = {The introduction of computational thinking into primary/secondary or K-12 education has been widely attempted. In Japan, programming education will be introduced into primary school in 2020. The role of parents in primary education is highly important, and their attitude towards education has a considerable influence on children’s attitudes. To investigate parents’ concerns regarding programming education in primary school, a preliminary questionnaire survey has been conducted as a first step of the study.}
}
@article{FLETCHER2023100061,
title = {Narrative creativity training: A new method for increasing resilience in elementary students},
journal = {Journal of Creativity},
volume = {33},
number = {3},
pages = {100061},
year = {2023},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2023.100061},
url = {https://www.sciencedirect.com/science/article/pii/S2713374523000201},
author = {Angus Fletcher and Patricia Enciso and Mike Benveniste},
keywords = {Narrative, Creativity, Education, Resilience, Self-efficacy, Counterfactual thinking},
abstract = {Narrative creativity training has recently shown promise as a tool for increasing self-efficacy and resilience in adult learners. The training employs dramatic and literary techniques such as perspective-shifting, counterfactual (i.e., what-if) thinking, and causal (i.e., why) thinking to improve real-world problem solving. To explore whether narrative creativity training could have similar benefits for younger populations, this study piloted a test on elementary students. A five-minute randomized controlled trial conducted with 32 third, fourth, and fifth grade students yielded increased self-efficacy and creative problem-solving, and a five-day longitudinal trial conducted with 28 students from the same population was associated with increased resilience. The results suggest the potential practical benefits of incorporating theater, literature, comics, and other story-based art into elementary school curricula.}
}
@article{TIKHONOV199898,
title = {The Sensing and Control Strategies of Thin-Film Growth Process Based on Visual Thinking Prototyping Cellular Neural Network},
journal = {IFAC Proceedings Volumes},
volume = {31},
number = {29, Supplement 1},
pages = {98-99},
year = {1998},
note = {7th IFAC Symposium on Artificial Intelligence in Real Time Control 1998. Extended Abstracts, Grand Canyon National Park, USA, 5-8 October},
issn = {1474-6670},
doi = {https://doi.org/10.1016/S1474-6670(17)38368-4},
url = {https://www.sciencedirect.com/science/article/pii/S1474667017383684},
author = {Nikolai I. Tikhonov}
}
@article{SUN2022102991,
title = {Lake algal bloom monitoring via remote sensing with biomimetic and computational intelligence},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {113},
pages = {102991},
year = {2022},
issn = {1569-8432},
doi = {https://doi.org/10.1016/j.jag.2022.102991},
url = {https://www.sciencedirect.com/science/article/pii/S1569843222001820},
author = {Zhibin Sun and Ni-Bin Chang and Chi-Farn Chen and Wei Gao},
keywords = {Eutrophication, Biomimetic intelligence, Computational intelligence, Ensemble learning, Food-water nexus, Decision level fusion, Water quality monitoring},
abstract = {Traditional supervised classifications for remote sensing-based water quality monitoring count on a set of classifiers to retrieve features and improve their prediction accuracies based on ground truth samples. However, many existing feature extraction methods in remote sensing are unable to exhibit multiple-instance nonlinear spatial pattern recognition at scales via ensemble learning. This paper designed for lake algal bloom monitoring presents intelligent feature extraction for harmonizing local and global features via tensor flow-based ensemble learning with integrated biomimetic and computational intelligence. To explore such complexity, an Integrated Biomimetic and Ensemble Learning Algorithm (IBELA) was developed to synthesize the contribution from different classifiers associated with the biomimetic philosophy of integrated bands. It leads to strengthened multiple-instance spatial pattern recognition in lake algal bloom monitoring via image fusion at the decision level. With the implementation of IBELA, a case study of a eutrophic freshwater lake, Lake Managua, for water quality monitoring leads to demonstrate six input visual senses showing different impacts on retrieving Chl-a concentrations in the dry and wet season, respectively. The input of total nitrogen from the watershed plays the most important role in water quality variations in both seasons in a watershed-based food–water nexus. Although ultraviolet and microwave bands are important in the dry season, Secchi disk depth is critical in the wet season for water quality monitoring.}
}
@incollection{SHAW2004295,
title = {Chapter 22 - The Spatial-Temporal Thinking Machine},
editor = {Gordon L. Shaw},
booktitle = {Keeping Mozart in Mind (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {San Diego},
pages = {295-299},
year = {2004},
isbn = {978-0-12-639061-2},
doi = {https://doi.org/10.1016/B978-012639061-2/50026-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780126390612500264},
author = {Gordon L. Shaw},
abstract = {Publisher Summary
This chapter discusses ideas and dreams of building a computer that can think and reason based on the spatial-temporal reasoning methods used in the brain. The enormous impact that electronic computers have had on our lives is well known. If one could combine the speed of the present computer with the ability of the brain to think using families of symmetry patterns developing in space and time, a whole new era would be here. Moreover, cortical columns are organized in a very highly structured manner to form a cortical area. It is this higher-level architecture that has been examined in order to explore the further consequences of the concepts concerning computation by symmetry operations. It is suggested that a hardware analog-digital implementation of this higher-level cortical area architecture of trion cortical columns should be “straightforward” owing to the localized and structured connectivity, and the discreteness of the firing levels. It is noted that, high-speed parallel computations would allow one to look for symmetry operations in a cortical area.}
}
@article{CSIZMADIA2024108765,
title = {Exploring the role of working memory gate opening process in creativity: An ERP study using the reference-back paradigm},
journal = {Biological Psychology},
volume = {187},
pages = {108765},
year = {2024},
issn = {0301-0511},
doi = {https://doi.org/10.1016/j.biopsycho.2024.108765},
url = {https://www.sciencedirect.com/science/article/pii/S0301051124000243},
author = {Petra Csizmadia and Boglárka Nagy and Lili Kővári and Zsófia Anna Gaál},
keywords = {Divergent/convergent thinking, Working memory, Reference-back paradigm, Gate opening, ERP},
abstract = {We investigated the relationship between the gate opening process of working memory and an individual's proficiency in divergent (DT) and convergent thinking (CT) using the reference-back paradigm. Event-related potentials and reaction times were measured across groups with varying DT (N = 40, 27.35 ± 5.05 years) and CT levels (N = 40, 27.88 ± 4.95 years). Based on the role of striatal dopamine in supporting cognitive flexibility, which facilitates DT, and considering the significance of phasic dopamine activity as the gate opening signal originating from the basal ganglia, we assumed that the gate opening process may contribute differently to DT and CT. Despite the absence of behavioural differences in gate opening costs, distinct neural patterns emerged. In the early time windows (P1, N1), gate opening effects were detected in both DT and CT groups, with a notable interaction influenced by the level of DT, resulting in significant effects within the lower DT group. The P2 component showed a gate opening effect only in the higher DT group. In the P3 time window, the process unfolded comparably in all groups. Our results suggest that groups with different levels of convergent thinking (based on Matrix reasoning) and those with lower DT (based on Creativity Index) tend to select and activate the prefrontal cortex representation containing the required task information at an earlier stage, compared to those with better DT. This could be beneficial especially in the early phase of idea generation, as more elements become available to create associations and original ideas.}
}
@article{AHMADI201627,
title = {Computational cognitive assistants for futures studies: Toward vision based simulation},
journal = {Futures},
volume = {81},
pages = {27-39},
year = {2016},
note = {Modelling and Simulation in Futures Studies},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2016.03.010},
url = {https://www.sciencedirect.com/science/article/pii/S0016328716300829},
author = {Meisam Ahmadi and Mohammadreza {Jahed Motlagh} and Adel Torkaman Rahmani and Mohammad Mahdi Zolfagharzadeh and Peyman Shariatpanahi},
keywords = {Futures studies, Quantitative and qualitative methods, HCI design, Cognitive architecture, Artificial intelligent agents},
abstract = {Many foresight researchers believe that quantitative simulations have a very restricted contribution in futures studies due to their simplicity and lack of creativity. While qualitative methods, taking advantage of the human cognitive system, have a great potential in addressing a wide range of problems in futures studies, this potential is mostly due to the human visual logic that can handle the task of imagining future scenarios much better than mathematical logic. On the other hand, computational methods benefit from the advantages of silicon-based systems namely speed, large memory, rapid networking, and communication. Hence, it would be extremely beneficial to come up with a solution that combines the positive sides of both qualitative and computational approaches. Cognitive artificial agents are computational units that make use of the human cognitive system. Their interaction with foresight and futures researchers can result in promising solutions for the problems addressed in futures studies. In addition, these agents can serve as a great source of inspiration for taking the first step towards vision based computers that can simulate humans’ imaginations of the future. This paper reviews some of the previous attempts in this field and finally sheds light on the main issues where methods in futures studies can play a key role in the future of Human Computer Interaction systems. Our suggested architecture for a future studies interactions-based system along with its justifications and specifications is provided in the form of a request for proposal.}
}
@article{HANI2023102968,
title = {Computational intelligence modeling of nanomedicine preparation using advanced processing: Solubility of fludrocortisone acetate in supercritical carbon dioxide},
journal = {Case Studies in Thermal Engineering},
volume = {45},
pages = {102968},
year = {2023},
issn = {2214-157X},
doi = {https://doi.org/10.1016/j.csite.2023.102968},
url = {https://www.sciencedirect.com/science/article/pii/S2214157X23002745},
author = {Umme Hani and Zainab {Ali Bu sinnah} and Ahmad J. Obaidullah and Bader Huwaimel and Muteb Alanazi and Tareq {Nafea Alharby} and Ahmed A. Lahiq and Abdullah {Ali Alshehri}},
keywords = {Nanomedicine, Multilayer perceptron, Support vector machine, Multi linear regression, Drug solubility},
abstract = {The method of green technology which is based on supercritical solvent has been studied in this work for analysis of nanomedicine preparation of solid dosage oral medications. Given that the poor drug solubility in aqueous media is a big challenge in pharmaceutical industry, nanomedicines would help improve the drug solubility in aqueous media. The solubility of fludrocortisone acetate in supercritical carbon dioxide is modelled in this research using various machine learning methods because it is a crucial aspect of the expansion of the pharmaceutical business. For this purpose, the accessible data have two input features: a pressure range of 120–300 (bar) and a temperature range of 308–338 (K). MLP, v-SVR and MLR are the basic models used in this research, but not their raw versions. They are improved for modeling drug solubility and coupled with the grey wolf optimization (GWO) in order to optimize the models. The models optimized by GWO showed acceptable results, but among these models, MLP regression has shown better results when coupled with this optimization algorithm. This model has the RMSE error rate of 2.98 × 10−2 and its R2 score is 0.9797 in correlating the solubility data of the medicine.}
}
@article{CHIARAMONTI2013101,
title = {Review of energy balance in raceway ponds for microalgae cultivation: Re-thinking a traditional system is possible},
journal = {Applied Energy},
volume = {102},
pages = {101-111},
year = {2013},
note = {Special Issue on Advances in sustainable biofuel production and use - XIX International Symposium on Alcohol Fuels - ISAF},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2012.07.040},
url = {https://www.sciencedirect.com/science/article/pii/S0306261912005624},
author = {David Chiaramonti and Matteo Prussi and David Casini and Mario R. Tredici and Liliana Rodolfi and Niccolò Bassi and Graziella Chini Zittelli and Paolo Bondioli},
keywords = {Microalgae, Biofuel, Raceway ponds, Head losses, Energy, Mixing},
abstract = {The present work addresses energy consumption in raceway ponds (RWPs). This kind of systems are today the most utilized industrial plant for outdoor algae cultivation. The problem has been addressed combining theoretical correlations and experimental data. Head losses for conventional raceway ponds were evaluated, and the results were compared with data available in literature. Computational fluid dynamics was used to support the theoretical analysis. This study suggested possible improvements to the traditional RWP design: an Innovative Raceway Pond (IRP II) was therefore designed, built and operated in parallel with a reference pilot RWP in a test site. Several modifications to traditional RWP design were implemented in the IRP II: the paddle wheel was substituted by a propeller, the water head was reduced and baffle boards were installed in the curves. To validate the new design, head losses and therefore energy consumption in the different systems were evaluated, during cultivation experiments, with two microalgae strains. The theoretical and experimental study allowed a validated calculation, which showed the importance of concentrated head losses towards distributed ones. The analysis highlighted how these losses weight at different pond scales, suggesting possible improvements of the RWP energy performance – as achieved in the IRP II – through revised design for optimized mixing.}
}
@article{DEPASQUALE2023631,
title = {The centrality of population-level factors to network computation is demonstrated by a versatile approach for training spiking networks},
journal = {Neuron},
volume = {111},
number = {5},
pages = {631-649.e10},
year = {2023},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2022.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S0896627322010807},
author = {Brian DePasquale and David Sussillo and L.F. Abbott and Mark M. Churchland},
keywords = {artificial neural networks, factor models, population dynamics, dimensionality reduction, spiking networks, recurrent neural networks, network training, FORCE learning, motor system, dynamical systems},
abstract = {Summary
Neural activity is often described in terms of population-level factors extracted from the responses of many neurons. Factors provide a lower-dimensional description with the aim of shedding light on network computations. Yet, mechanistically, computations are performed not by continuously valued factors but by interactions among neurons that spike discretely and variably. Models provide a means of bridging these levels of description. We developed a general method for training model networks of spiking neurons by leveraging factors extracted from either data or firing-rate-based networks. In addition to providing a useful model-building framework, this formalism illustrates how reliable and continuously valued factors can arise from seemingly stochastic spiking. Our framework establishes procedures for embedding this property in network models with different levels of realism. The relationship between spikes and factors in such networks provides a foundation for interpreting (and subtly redefining) commonly used quantities such as firing rates.}
}
@article{WALTERS199115,
title = {Critical thinking, rationality, and the vulcanization of students},
journal = {Journal of Accounting Education},
volume = {9},
number = {1},
pages = {15-31},
year = {1991},
issn = {0748-5751},
doi = {https://doi.org/10.1016/0748-5751(91)90020-R},
url = {https://www.sciencedirect.com/science/article/pii/074857519190020R},
author = {Kerry S. Walters}
}
@article{PATTON2022107263,
title = {Community implications for gun violence prevention during co-occurring pandemics; a qualitative and computational analysis study},
journal = {Preventive Medicine},
volume = {165},
pages = {107263},
year = {2022},
note = {Epidemiology and Prevention of Gun Violence},
issn = {0091-7435},
doi = {https://doi.org/10.1016/j.ypmed.2022.107263},
url = {https://www.sciencedirect.com/science/article/pii/S0091743522003127},
author = {Desmond U. Patton and Nathan Aguilar and Aviv Y. Landau and Chris Thomas and Rachel Kagan and Tianai Ren and Eric Stoneberg and Timothy Wang and Daniel Halmos and Anish Saha and Amith Ananthram and Kathleen McKeown},
keywords = {Gun violence, COVID-19, Black lives matter, Defund the police, Social media, Qualitative and computational analysis},
abstract = {This study provides insight into New York City residents' perceptions about violence after the outbreak of Coronavirus disease (COVID-19) based on information from communities in New York City Housing Authority (NYCHA) buildings. In this novel analysis, we used focus group and social media data to confirm or reject findings from qualitative interviews. We first used data from 69 in-depth, semi-structured interviews with low-income residents and community stakeholders to further explore how violence impacts New York City's low-income residents of color, as well as the role of city government in providing tangible support for violence prevention during co-occurring health (COVID-19) and social (anti-Black racism) pandemics. Residents described how COVID-19 and the Black Lives Matter movement impacted safety in their communities while offering direct recommendations to improve safety. Residents also shared recommendations that indirectly improve community safety by addressing long term systemic issues. As the recruitment of interviewees was concluding, researchers facilitated two focus groups with 38 interviewees to discuss similar topics. In order to assess the degree to which the themes discovered in our qualitative interviews were shared by the broader community, we developed an integrative community data science study which leveraged natural language processing and computer vision techniques to study text and images on public social media data of 12 million tweets generated by residents. We joined computational methods with qualitative analysis through a social work lens and design justice principles to most accurately and holistically analyze the community perceptions of gun violence issues and potential prevention strategies. Findings indicate valuable community-based insights that elucidate how the co-occurring pandemics impact residents' experiences of gun violence and provide important implications for gun violence prevention in a digital era.}
}
@article{LIU1996435,
title = {Is designing one search or two? A model of design thinking involving symbolism and connectionism},
journal = {Design Studies},
volume = {17},
number = {4},
pages = {435-449},
year = {1996},
note = {Special Issue: Design Cognition and Computation},
issn = {0142-694X},
doi = {https://doi.org/10.1016/S0142-694X(96)00018-X},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X9600018X},
author = {Yu-Tung Liu},
keywords = {design cognition, design process, symbolism, connectionism},
abstract = {In this paper, designing is interpreted as a combination of two searches: a shape restructuring search and a knowledge transforming search. During the first phase, designers or computer-aided design systems search for alternative ways to interpret for the current design state by restructuring shapes in terms of emergent subshapes; it is close to the connectionist processing which we can only slightly sense. During the second phase, designers or computer systems search for alternative rule applications in order to transform the interpreted current state into the next one that matches the formal and functional requirements; it is close to symbolic processing which we can sense, clearly and cognitively.}
}
@article{CAO20161940,
title = {Enhancing Computational Science Curriculum at Liberal Arts Institutions: A Case Study in the Context of Cybersecurity},
journal = {Procedia Computer Science},
volume = {80},
pages = {1940-1946},
year = {2016},
note = {International Conference on Computational Science 2016, ICCS 2016, 6-8 June 2016, San Diego, California, USA},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.05.510},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916309978},
author = {Paul Y. Cao and Iyad A. Ajwa},
keywords = {Computational Science, Cybersecurity, Liberal Arts, Curriculum Enhancement},
abstract = {Computational science curriculum developments and enhancements in liberal arts colleges can face unique challenges compared with larger institutions. We present a case study of computational science curriculum development at a medium sized liberal arts university in the context of cybersecurity. Three approaches, namely a cybersecurity minor, content infusion into existing courses, and a public forum are proposed to enrich the current computational science curriculum with cybersecurity contents.}
}
@article{SHAH2025e00881,
title = {Integration of phytochemical profiling and computational approaches to evaluate the neuroprotective potential of Nardostachys jatamansi in Alzheimer's disease},
journal = {Biotechnology Reports},
volume = {45},
pages = {e00881},
year = {2025},
issn = {2215-017X},
doi = {https://doi.org/10.1016/j.btre.2025.e00881},
url = {https://www.sciencedirect.com/science/article/pii/S2215017X25000086},
author = {Abdul Jalil Shah and Mohammad Younis Dar and Mohd Adnan and Tanmaykumar Varma and Dhairiya Agarwal and Prabha Garg and Reyaz Hassan Mir and Rampratap Meena and Mubashir Hussain Masoodi},
keywords = {, GCMS, Molecular docking, Network pharmacology, MD simulations},
abstract = {Despite broad spectrum utility of Nardostachys jatamansi (D. Don) DC, little is known about the molecular processes that underlie its anti-Alzheimer action. To investigate the molecular targets and therapeutic potential of N. jatamansi for Alzheimer's disease (AD), we used Gas Chromatography-Mass Spectrometry (GC-MS), ADMET analysis, network pharmacology, differential gene expression analysis, molecular docking, and molecular dynamics (MD) simulations. The STITCH database was used for network creation and protein-protein interaction analysis, while Cytoscape was used for network visualization and Kyoto Encyclopedia of Genes and Genomes (KEGG) pathway enrichment and Gene Ontology (GO) for term enrichment. Additionally, to investigate the intermolecular interactions between the active chemicals and target proteins, molecular docking experiments were conducted using the Blind docking on the Achilles server. The stability of the PS1 gene complex with Spirojatamol, was further evaluated using MD simulations. With Spirojatamol showing the highest binding energy scores against PS1 (−6.9 kcal/mol), molecular docking confirmed the activity of this metabolite against AD targets PS1 and Spirojatamol formed a stable complex at 100 nanoseconds, according to additional investigation using MD simulations. Significant ligand-protein interactions were verified by binding free energy calculations using the MM/GBSA technique. The PS1-Spirojatamol complex had a binding energy of ΔG: −36.95 ± 5.00 kcal/mol. By focusing on several genes and pathways, involved in AD, this work reveals the molecular underpinnings behind N. jatamansi possible use in the treatment of AD.}
}
@article{ZENGAFFINEN2023100159,
title = {“Computational analysis on verbal fluency reveals heterogeneity in subjective language interests and brain structure”},
journal = {Neuroimage: Reports},
volume = {3},
number = {1},
pages = {100159},
year = {2023},
issn = {2666-9560},
doi = {https://doi.org/10.1016/j.ynirp.2023.100159},
url = {https://www.sciencedirect.com/science/article/pii/S2666956023000041},
author = {Francilia Zengaffinen and Antje Stahnke and Stephan Furger and Roland Wiest and Thomas Dierks and Werner Strik and Yosuke Morishima},
keywords = {Language, SyNoPsis, Computational analysis, LSA, VBM, Healthy cohort, Psychosis},
abstract = {Language is an essential higher cognitive function in humans and is often affected by psychiatric and neurological disorders. Objective measures like the verbal fluency test are often used to determine language dysfunction. Recent applications of computational approaches broaden insights into language-related functions. In addition, individuals diagnosed with a psychiatric or neurological disorder also often report subjective difficulties in language-related functions. Therefore, we investigated the association between objective and subjective measures of language functioning, on the one hand, and inter-individual structural variations in language-related brain areas, on the other hand. We performed a Latent Semantic analysis (LSA) on a semantic verbal fluency task in 101 healthy adult participants. To investigate if these objective measures are associated with a subjective one, we examined assessed subjective natural tendency of interest in language-related activity with a study-specific questionnaire. Lastly, a voxel-based brain morphometry (VBM) was conducted to reveal associations between objective (LSA) measures and structural changes in language-related brain areas. We found a positive correlation between the LSA measure cosine similarity and the subjective interest in language. Furthermore, we found that higher cosine similarity corresponds to higher gray matter volume in the right cerebellum. The results suggest that people with higher interests in language access semantic knowledge in a more organized way exhibited by higher cosine similarity and have larger gray matter volume in the right cerebellum, when compared to people with lower interests. In conclusion, we demonstrate that there is inter-individual diverseness of accessing the semantic knowledge space and that it is associated with subjective language interests as well as structural differences in the right cerebellum.}
}
@article{CHEN2009191,
title = {Towards an explanatory and computational theory of scientific discovery},
journal = {Journal of Informetrics},
volume = {3},
number = {3},
pages = {191-209},
year = {2009},
note = {Science of Science: Conceptualizations and Models of Science},
issn = {1751-1577},
doi = {https://doi.org/10.1016/j.joi.2009.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S1751157709000236},
author = {Chaomei Chen and Yue Chen and Mark Horowitz and Haiyan Hou and Zeyuan Liu and Donald Pellegrino},
keywords = {Theory of scientific discovery, Transformative scientific discoveries, Theory of structural holes, Intellectual brokerage, Knowledge diffusion, Information foraging},
abstract = {We propose an explanatory and computational theory of transformative discoveries in science. The theory is derived from a recurring theme found in a diverse range of scientific change, scientific discovery, and knowledge diffusion theories in philosophy of science, sociology of science, social network analysis, and information science. The theory extends the concept of structural holes from social networks to a broader range of associative networks found in science studies, especially including networks that reflect underlying intellectual structures such as co-citation networks and collaboration networks. The central premise is that connecting otherwise disparate patches of knowledge is a valuable mechanism of creative thinking in general and transformative scientific discovery in particular. In addition, the premise consistently explains the value of connecting people from different disciplinary specialties. The theory not only explains the nature of transformative discoveries in terms of the brokerage mechanism but also characterizes the subsequent diffusion process as optimal information foraging in a problem space. Complementary to epidemiological models of diffusion, foraging-based conceptualizations offer a unified framework for arriving at insightful discoveries and optimizing subsequent pathways of search in a problem space. Structural and temporal properties of potentially high-impact scientific discoveries are derived from the theory to characterize the emergence and evolution of intellectual networks of a field. Two Nobel Prize winning discoveries, the discovery of Helicobacter pylori and gene targeting techniques, and a discovery in string theory demonstrated such properties. Connections to and differences from existing approaches are discussed. The primary value of the theory is that it provides not only a computational model of intellectual growth, but also concrete and constructive explanations of where one may find insightful inspirations for transformative scientific discoveries.}
}
@incollection{MAYER2023229,
title = {Problem solving},
editor = {Robert J Tierney and Fazal Rizvi and Kadriye Ercikan},
booktitle = {International Encyclopedia of Education (Fourth Edition)},
publisher = {Elsevier},
edition = {Fourth Edition},
address = {Oxford},
pages = {229-234},
year = {2023},
isbn = {978-0-12-818629-9},
doi = {https://doi.org/10.1016/B978-0-12-818630-5.14023-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128186305140230},
author = {Richard E. Mayer},
keywords = {Cognitive processing, Higher-order cognition, Insight, Problem representation, Problem solving, Reasoning, Rigidity in thinking, Solution plan, Thinking, Transfer},
abstract = {A problem occurs when a situation is in one state, the problem solver wants it to be in another state, and there are obstacles preventing a smooth transition from the given state to the goal state. Problem solving refers to cognitive processing aimed at overcoming a problem. This entry examines the definitions of key terms, types of problems, phases in problem solving, and types of knowledge involved in problem solving. This entry also explores findings about problem solving that are most relevant to education including research on rigidity in thinking, problem solving transfer, productive thinking, insight, computer simulation of problem solving, problem solving in realistic situations, and teaching of thinking.}
}
@article{CANBALOGLU202251,
title = {Computational modeling of organisational learning by self-modeling networks},
journal = {Cognitive Systems Research},
volume = {73},
pages = {51-64},
year = {2022},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2021.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S1389041721000978},
author = {Gülay Canbaloğlu and Jan Treur and Peter H.M.P. Roelofsma},
keywords = {Organisational learning, Network model, Mental model, Second-order adaptive, Control of adaptation},
abstract = {Within organisational learning literature, mental models are considered a vehicle for both individual learning and organizational learning. By learning individual mental models (and making them explicit), a basis for formation of shared mental models for the level of the organization is created, which after its formation can then be adopted by individuals. This provides mechanisms for organizational learning. These mechanisms have been used as a basis for an adaptive computational network model. The model is illustrated by a not too complex but realistic case study.}
}
@article{KVISTBORG2015591,
title = {Thinking Outside the Gate: Single-Cell Assessments in Multiple Dimensions},
journal = {Immunity},
volume = {42},
number = {4},
pages = {591-592},
year = {2015},
issn = {1074-7613},
doi = {https://doi.org/10.1016/j.immuni.2015.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S1074761315001351},
author = {Pia Kvistborg and Cécile Gouttefangeas and Nima Aghaeepour and Angelica Cazaly and Pratip K. Chattopadhyay and Cliburn Chan and Judith Eckl and Greg Finak and Sine Reker Hadrup and Holden T. Maecker and Dominik Maurer and Tim Mosmann and Peng Qiu and Richard H. Scheuermann and Marij J.P. Welters and Guido Ferrari and Ryan R. Brinkman and Cedrik M. Britten}
}
@article{YAO2022113,
title = {Symbols-Meaning-Value (SMV) space as a basis for a conceptual model of data science},
journal = {International Journal of Approximate Reasoning},
volume = {144},
pages = {113-128},
year = {2022},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2022.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X2200024X},
author = {Yiyu Yao},
keywords = {Three-way decision, Thinking in threes, Triadic thinking, Trilelvel thinking, Data science, Granular computing},
abstract = {By applying the principles of three-way decision as thinking in threes, in this paper I introduce a conceptual model of data science in three steps. First, I examine examples of triadic thinking in general and trilevel thinking in specific in data science. Then, based on Weaver's trilevel categorization of communications problems, I propose the concept of the symbols-meaning-value (SMV) space and discuss three perspectives on the SMV space from the viewpoints of information science and management science, cognitive science, and computer science. I label the operations on the SMV three levels metaphorically as seeing, knowing, and doing. Finally, I put forward a SMV-space-based conceptual model of data science, in which data are a resource, the power of data is the knowledge embedded in data, and the value of data is the wise decision and the best course of action supported by data. The goals and functions of data science at the SMV three levels are, respectively, making data available, making data meaningful, and making data valuable. To demonstrate the potential contributions of the conceptual model, I comment on some of its practical values and implications.}
}
@article{LOCKWOOD2020100783,
title = {A case for combinatorics: A research commentary},
journal = {The Journal of Mathematical Behavior},
volume = {59},
pages = {100783},
year = {2020},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2020.100783},
url = {https://www.sciencedirect.com/science/article/pii/S073231232030047X},
author = {Elise Lockwood and Nicholas H. Wasserman and Erik S. Tillema},
keywords = {Research commentary, Combinatorics, Discrete mathematics, Curricula},
abstract = {In this commentary, we make a case for the explicit inclusion of combinatorial topics in mathematics curricula, where it is currently essentially absent. We suggest ways in which researchers might inform the field’s understanding of combinatorics and its potential role in curricula. We reflect on five decades of research that has been conducted since a call by Kapur (1970) for a greater focus on combinatorics in mathematics education. Specifically, we discuss the following five assertions: 1) Combinatorics is accessible, 2) Combinatorics problems provide opportunities for rich mathematical thinking, 3) Combinatorics fosters desirable mathematical practices, 4) Combinatorics can contribute positively to issues of equity in mathematics education, and 5) Combinatorics is a natural domain in which to examine and develop computational thinking and activity. Ultimately, we make a case for the valuable and unique ways in which combinatorics might effectively be leveraged within K-16 curricula.}
}
@article{PSYCHARIS201490,
title = {The impact of the computational inquiry based experiment on metacognitive experiences, modelling indicators and learning performance},
journal = {Computers & Education},
volume = {72},
pages = {90-99},
year = {2014},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2013.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0360131513002789},
author = {Sarantos Psycharis and Evi Botsari and Panagiotis Mantas and Dionisios Loukeris},
keywords = {Metacognition, Modelling, Computational experiment, Inquiry based science education},
abstract = {Computational experiment approach considers modelling as the essential feature of Inquiry Based Science Education (IBSE), where the model and the computer take the place of the “classical” experimental set-up and simulation replaces the experiment (Landau, Pαez, & Bordeianu, 2008). Modelling, as a pedagogical tool, involves the model construction, the exploration of model characteristics and the model application to a specific problem, resembling authentic activities of scientists and mathematicians (Herbert, 2003). Recent developments in strategy instruction research suggest that learning in a particular discipline is enhanced by guiding students through the development of content-relevant metacognitive strategies (Wosnitza & Volet, 2009). Problem-solving is a complex process, which involves several cognitive operations such as collecting and selecting information, heuristic strategy and metacognition (De Corte, 2003, Garofalo and Lester, 1985, Schoenfeld, 1994). The purpose of this study was to explore the impact of the Computational Experiment Methodology on learners' cognitive performance, use of modelling indicators and shift of the metacognitive experiences during problem solving using computational models. Sixty prospective primary school teachers volunteered to participate in the study. Students were exposed by the Instructor to a number of computational experiments, while during the course they developed their own models of simulation. The results of the experiment show that the use of the computational experiment approach has a substantial effect on the metacognitive experiences and the use of modelling indicators.}
}
@article{GARCIA201325,
title = {A constructivist computational platform to support mathematics education in elementary school},
journal = {Computers & Education},
volume = {66},
pages = {25-39},
year = {2013},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2013.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S036013151300033X},
author = {I. Garcia and C. Pacheco},
keywords = {Elementary education, Constructivist theory, Interactive computational tools, Simulated environments, Process improvement},
abstract = {Many courses for elementary school are based upon teacher presentation and explanation of basic topics, rather than allowing students to develop their own knowledge. This traditional model may turn elementary-level lessons into an extremely theoretical, boring and non-effective process. In this context, research in mathematics elementary education in Mexico indicates the need to analyze alternative pedagogic practices and to find different ways to make mathematics education in early ages less difficult and more attractive. Constructivist theory can provide an alternative for developing pedagogic proposals. The objectives of this research were: (1) develop a computational platform to support the traditional Mexican method of education with practical mathematics problems simulated as part of the daily world environment and to increase the level of students' social involvement through direct collaboration, and (2) analyze how this computational tool affects student motivation, collaboration and discussion. An exploratory case study concerning dimensions of mathematics problem-solving using computer simulations was conducted with 6–8 year old elementary school children. After a theoretical class the children were involved in solving a series of verbal problems, using our computational platform. Sixty third-grade children participated in this case study and data were collected from their responses to questions and interviews in order to explore attitudes toward learning mathematics and assess self-efficacy in this area. The results obtained in this research indicate that the integration of computational tools into conventional method courses provides elements to improve student motivation, collaboration and discussion based on their own exploratory experiences. These results can assist other education programs to incorporate positive attitudes and their own knowledge creation from a constructivist approach using technology.}
}
@article{PANSKYI2019100593,
title = {Out-of-school assistance in the teaching of visual creative programming in the game-based environment – Case study: Poland},
journal = {Thinking Skills and Creativity},
volume = {34},
pages = {100593},
year = {2019},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2019.100593},
url = {https://www.sciencedirect.com/science/article/pii/S187118711930104X},
author = {Taras Panskyi and Zdzislawa Rowinska and Sebastian Biedron},
keywords = {Out-of-school education, Creative programming, Game-based learning, ICT},
abstract = {The paper presents effects of out-of-school teaching of computer science in a visual creative programming course (Scratch) for children aged 9–14, held at the Lodz University of Technology. The research was carrying out during 2016–2018 school years. The study sample consists of 265 primary and secondary students from Lodz Voivodeship (province) in central Poland. The results were obtained from anonymous questionnaires completed by 221 course participants and their parents. The answers confirm that this type of course becomes a new fascinating manner of spending spare time by children. Moreover, quantitative analysis of student’s finals projects also has been performed. In the process of creative programming in the game-based environment, children develop the computational thinking skills, problem-solving strategies, and abstract thinking. Moreover, children are supported by their parents, who notice how important these competences are and how great opportunities they will present for children in future. Authors continue to grow Scratch programming course to democratize access to new technologies and education, preparing future generation for a world in which computational and algorithmic thinking is a central part of problem-solving. Perhaps some of the course participants will continue their study of programming and make it a career for their life.}
}
@article{FENG2025100831,
title = {Construction of teaching game evaluation model based on ISSA-BPNN},
journal = {Entertainment Computing},
volume = {52},
pages = {100831},
year = {2025},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2024.100831},
url = {https://www.sciencedirect.com/science/article/pii/S187595212400199X},
author = {Bibo Feng and Lingli Zhang and Jing Yin and Rong Wang},
keywords = {Sparrow search algorithm, Back propagation neural network, Teaching games, Evaluating indicator},
abstract = {Teaching games are an effective teaching organization activity. In response to the evaluation and prediction problem of teaching games, a teaching game evaluation model based on improved sparrow search algorithm and back propagation neural network was studied and constructed. Firstly, a situational teaching game was designed and an evaluation index system was constructed. Then, a teaching game evaluation prediction model based on the improved method was established. Finally, the expert consultation method is adopted to collect opinions from experts in the field of education and construct an evaluation index system for teaching games. And based on the evaluation index system of teaching games, evaluate students’ mathematical thinking ability before and after experiencing teaching games to verify the application effect of teaching games. The scenario based teaching game designed in this study has a certain effect on improving students’ mathematical thinking ability. Students’ mathematical thinking has significantly improved (P<0.05), and the teaching effect is the same for students of different genders (P>0.1). The improved sparrow search algorithm has a faster convergence rate than other algorithms, and tends to be stable when iteration is about 100 when solving the single peak benchmark function. When solving the multimodal benchmark test function, it tends to stabilize when iteration is around 20. The teaching game evaluation prediction price model based on the improved method shows a trend of first increasing and then decreasing with hidden units increasing. When the hidden unit is 16, the area index under model curve is the highest, around 0.962, and its prediction accuracy is relatively high. In summary, the model constructed in this study is applicating good in teaching game evaluation prediction, and can promote education industry developing.}
}
@article{MCMILLAN2024101154,
title = {Connecting student development of use of grouping and mathematical properties},
journal = {The Journal of Mathematical Behavior},
volume = {74},
pages = {101154},
year = {2024},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2024.101154},
url = {https://www.sciencedirect.com/science/article/pii/S0732312324000312},
author = {Brandon G. McMillan},
keywords = {Algebraic properties, Children’s mathematical thinking, Grouping, Multiplication and division},
abstract = {Understanding algebraic properties is a key component of building mathematical thinking across grades K-8, yet less is known about the development of students' use of mathematical properties within their strategies. This article presents results from four conversations with 24 5th-grade students over a school year, that focus on examining the development of students grouping within strategies for multiplication and division problems. Findings add to previous research on student strategies within multiplication and division by detailing some of the nuances in students' use of grouping. Additionally, a focus on student strategies reveals students' progression in more explicit use of grouping underlies the development of more planful use of the distributive and associative properties of multiplication.}
}
@article{BIAN2019136,
title = {Statistical thinking, machine learning},
journal = {Journal of Clinical Epidemiology},
volume = {116},
pages = {136-137},
year = {2019},
issn = {0895-4356},
doi = {https://doi.org/10.1016/j.jclinepi.2019.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S0895435619304950},
author = {Jiang Bian and Iain Buchan and Yi Guo and Mattia Prosperi}
}
@article{GOOD201778,
title = {Programming language, natural language? Supporting the diverse computational activities of novice programmers},
journal = {Journal of Visual Languages & Computing},
volume = {39},
pages = {78-92},
year = {2017},
note = {Special Issue on Programming and Modelling Tools},
issn = {1045-926X},
doi = {https://doi.org/10.1016/j.jvlc.2016.10.008},
url = {https://www.sciencedirect.com/science/article/pii/S1045926X16301963},
author = {Judith Good and Kate Howland},
keywords = {Novice programming languages, Natural language, Design, Empirical evaluation},
abstract = {Given the current focus on teaching computational concepts to all from an early age, combined with the growing trend to empower end users to become producers of technology rather than mere consumers, we consider the issue of “computational notation”. Specifically, where the goal is to help individuals develop their understanding of computation and/or use computation in real world settings, we question whether natural language might be a preferred notation to traditional programming languages, given its familiarity and ubiquity. We describe three empirical studies investigating the use of natural language for computation in which we found that although natural language provides support for understanding computational concepts, it introduces additional difficulties when used for coding. We distilled our findings into a set of design guidelines for novice programming environments which consider the ways in which different notations, including natural language, can best support the various activities that comprise programming. These guidelines were embodied in Flip, a bi-modal programming language used in conjunction with the Electron toolset, which allows young people to create their own commercial quality, narrative based role- playing games. Two empirical studies on the use of Flip in three different real world contexts considered the extent to which the design guidelines support ease of use and an understanding of computation. The guidelines have potential to be of use both in analysing the use of natural language in existing novice programming environments, and in the design of new ones.}
}
@article{TUHKALA201954,
title = {Technology Comprehension — Combining computing, design, and societal reflection as a national subject},
journal = {International Journal of Child-Computer Interaction},
volume = {20},
pages = {54-63},
year = {2019},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2019.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S2212868918301016},
author = {Ari Tuhkala and Marie-Louise Wagner and Ole Sejer Iversen and Tommi Kärkkäinen},
keywords = {Technology comprehension, Digital fabrication, Making, Design, Computing, Computational thinking, Education, Teachers, National, Scaling, Subject},
abstract = {This article considers the implementation of a new learning subject ”Technology Comprehension” into lower secondary schools in Denmark, as part of an initiative by the Danish Ministry of Education. The subject consists of learning objectives related to computing, design, and societal reflection and was first introduced as an elective course in 13 schools to investigate how it could be integrated into the Danish education system. We present four key findings based on school visits, interviews, an electronical survey, two questionnaires, and workshops including theme discussions: (1) teachers did not perceive Technology Comprehension as a distinct subject, but rather as a set of skills that can be integrated into other subjects; (2) teachers pointed out that Technology Comprehension opens up for interdisciplinary and engaging learning activities, but they need more scaffolding and support; (3) Technology Comprehension challenges teachers’ existing competencies and there is a need for a framework that takes into account computing, design, and societal reflection as a whole; (4) Technology Comprehension appealed to various kind of students, not only those who are enthusiastic about technical matters. This study contributes to the previous research on making and digital fabrication by addressing how these endeavours are implemented on a national level through engaging with local teachers. We call for more research on scaffolding and supporting teachers to orchestrate meaningful learning activities to successfully integrate Technology Comprehension into the Danish national education.}
}
@article{FUGELSANG20051204,
title = {Brain-based mechanisms underlying complex causal thinking},
journal = {Neuropsychologia},
volume = {43},
number = {8},
pages = {1204-1213},
year = {2005},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2004.10.012},
url = {https://www.sciencedirect.com/science/article/pii/S002839320400274X},
author = {Jonathan A. Fugelsang and Kevin N. Dunbar},
keywords = {Scientific reasoning, Learning, Error detection, Conflict monitoring, fMRI},
abstract = {We use functional magnetic resonance imaging (fMRI) and behavioral analyses to study the neural roots of biases in causal reasoning. Fourteen participants were given a task requiring them to interpret data relative to plausible and implausible causal theories. Encountering covariation-based data during the evaluation of a plausible theory as opposed to an implausible theory selectively recruited neural tissue in the prefrontal and occipital cortices. In addition, the plausibility of a causal theory modulated the recruitment of distinct neural tissue depending on the extent to which the data were consistent versus inconsistent with the theory provided. Specifically, evaluation of data consistent with a plausible causal theory recruited neural tissue in the parahippocampal gyrus, whereas evaluating data inconsistent with a plausible theory recruited neural tissue in the anterior cingulate, left dorsolateral prefrontal cortex, and precuneus. We suggest that these findings provide a neural instantiation of the mechanisms by which working hypotheses and evidence are integrated in the brain.}
}
@article{DENG2025105224,
title = {Does ChatGPT enhance student learning? A systematic review and meta-analysis of experimental studies},
journal = {Computers & Education},
volume = {227},
pages = {105224},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2024.105224},
url = {https://www.sciencedirect.com/science/article/pii/S0360131524002380},
author = {Ruiqi Deng and Maoli Jiang and Xinlu Yu and Yuyan Lu and Shasha Liu},
keywords = {Teaching/learning strategies, Improve classroom teaching, Elementary education, Secondary education, Post-secondary education},
abstract = {Chat Generative Pre-Trained Transformer (ChatGPT) has generated excitement and concern in education. While cross-sectional studies have highlighted correlations between ChatGPT use and learning performance, they fall short of establishing causality. This review examines experimental studies on ChatGPT's impact on student learning to address this gap. A comprehensive search across five databases identified 69 articles published between 2022 and 2024 for analysis. The findings reveal that ChatGPT interventions are predominantly implemented at the university level, cover various subject areas focusing on language education, are integrated into classroom environments as part of regular educational practices, and primarily involve direct student use of ChatGPT. Overall, ChatGPT improves academic performance, affective-motivational states, and higher-order thinking propensities; it reduces mental effort and has no significant effect on self-efficacy. However, methodological limitations, such as the lack of power analysis and concerns regarding post-intervention assessments, warrant cautious interpretation of results. This review presents four propositions from the findings: (1) distinguish between the quality of ChatGPT outputs and the positive effects of interventions on academic performance by shifting from well-defined problems in post-intervention assessments to more complex, project-based assessments that require skill demonstration, adopting proctored assessments, or incorporating metrics such as originality alongside quality; (2) evaluate long-term impacts to determine whether the positive effects on affective-motivational states are sustained or merely owing to novelty effect; (3) prioritise objective measures to complement subjective assessments of higher-order thinking; and (4) use power analysis to determine adequate sample sizes to avoid Type II errors and provide reliable effect size estimates. This review provides valuable insights for researchers, instructors, and policymakers evaluating the effectiveness of generative AI integration in educational practice.}
}
@article{HADAS2024101549,
title = {Using large language models to evaluate alternative uses task flexibility score},
journal = {Thinking Skills and Creativity},
volume = {52},
pages = {101549},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101549},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124000877},
author = {Eran Hadas and Arnon Hershkovitz},
keywords = {Creativity, Divergent thinking, Alternative uses task, Flexibility, Large language models},
abstract = {In the Alternative Uses Task (AUT) test, a group of participants is asked to list as many uses as possible for a simple object. The test measures Divergent Thinking (DT), which involves exploring possible solutions in various semantic domains. In this study we employ a Machine Learning approach to automatically generate suitable categories for object uses and classify given responses into them. We show that the results yielded by this automated approach are correlated with results given by humans and can be used to predict expected behavior in the field. Educators and researchers may utilize this approach to address the limitations of subjective scoring, save time, and use the AUT as a tool for cultivating creativity.}
}
@incollection{ISMAIL2024219,
title = {Chapter 7 - High throughput screening of phytochemicals: Application of computational methods},
editor = {Satyajit D. Sarker and Lutfun Nahar},
booktitle = {Computational Phytochemistry (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
pages = {219-253},
year = {2024},
isbn = {978-0-443-16102-5},
doi = {https://doi.org/10.1016/B978-0-443-16102-5.00008-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780443161025000080},
author = {Fyaz M.D. Ismail and Lutfun Nahar and Satyajit D. Sarker},
keywords = {High throughput screening (HTS), Robotics, Dereplication, Liquid handling systems, Screening /, Natural product prototypes, Drug discovery and development, Machine learning, , , },
abstract = {This chapter examines the history and development of high-throughput screening (HTS) using the knowledge and expertise of the writers, who have worked as consultants or trainers for several pharmaceutical companies. It focuses on the function of HTS in drug development and screening for natural products (phytochemicals). It emphasizes the use of computational tools in HTS for phytochemicals. To guarantee that researchers can set up and effectively use HTS in their natural product research, common problems and solutions are covered along with a few ‘how to’ protocols. Also described are pertinent failures and accomplishments in finding intriguing natural products.}
}

@article{KHOSHNAM2022116686,
title = {A dual framework for implicit and explicit emotion recognition: An ensemble of language models and computational linguistics},
journal = {Expert Systems with Applications},
volume = {198},
pages = {116686},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.116686},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422001683},
author = {Fereshteh Khoshnam and Ahmad Baraani-Dastjerdi},
keywords = {Sentiment analysis (SA), Opinion mining, Explicit emotion recognition (EER), Implicit emotion recognition (IER), Language model (LM), Feature weighing, Dual framework, Ensemble method, Computational linguistics, Machine learning},
abstract = {One of the research domains in the field of sentiment analysis is automatic emotion recognition in texts which is a worthy topic in human-computer interaction. Text processing has always faced many challenges. The main one is the structural and semantic differences of sentences which have had a significant impact on the malfunction of auto-recognition systems. This problem becomes more prominent in short texts in which words and their concurrences are limited and insufficient. As a result of this, word frequency and TF-IDF weighing cannot well represent the relationship between words and the appropriate feature vector, leading to an undesirable accuracy of emotion recognition. Thus, different strategies should be applied to improve the feature vector and to formulate the features properly. The desired strategy should be able to identify the words that can distinguish between classes well and also to find the relationships between words and meaningful phrases using natural language processing concepts. In this paper, a combination of emotional models, categorical and hierarchical, are used for an emotional text recognition which could discover simultaneously explicit and implicit emotion in a short text. Our approach called DuFER, proposed a weighed method which improves the feature vector using language models and computational linguistics through applying a modified TF-IDF weighing to words as well as Maximum Likelihood Estimation weighing to expressions. Four implicit and explicit emotion datasets are used for the experiments. The results show that the accuracy of both implicit and explicit emotion recognition has increased and DuFER is actually the first successful dual framework in recognizing implicit and explicit emotions from text.}
}
@article{SKAGESTAD1993157,
title = {Thinking with machines: Intelligence augmentation, evolutionary epistemology, and semiotic},
journal = {Journal of Social and Evolutionary Systems},
volume = {16},
number = {2},
pages = {157-180},
year = {1993},
issn = {1061-7361},
doi = {https://doi.org/10.1016/1061-7361(93)90026-N},
url = {https://www.sciencedirect.com/science/article/pii/106173619390026N},
author = {Peter Skagestad}
}
@article{JIN2024e32590,
title = {Research hotspots and development trends of model and modelling education research: Bibliometric analysis based on CiteSpace},
journal = {Heliyon},
volume = {10},
number = {11},
pages = {e32590},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e32590},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024086213},
author = {Dongxue Jin and Min Jian},
keywords = {Model-based education research, Model and modelling, Bibliometric analysis, CiteSpace},
abstract = {Model-based learning and teaching are vital for addressing real-world challenges and are gaining research traction. This study, employing CiteSpace, analyses 583 articles, uncovering trends in authors, regions, and highly cited documents. Noteworthy focuses include learning achievements, technical support, and teaching approaches. Keyword analysis emphasises thinking cultivation and interdisciplinary integration. The study discusses current and future developments in modelling and modelling education research, particularly in learning evaluation and teacher professional development. Offering an international perspective, this analysis provides stakeholders with valuable insights. In summary, model-based learning's growth and influence are evident in the identified trends and future directions, guiding the field toward effective teaching strategies and solving complex problems. This research contributes to the broader understanding of modelling education's dynamics, facilitating informed decision-making for educators and policymakers.}
}
@article{DIAS2024103493,
title = {Artificial intelligence in the judiciary: A critical view},
journal = {Futures},
volume = {164},
pages = {103493},
year = {2024},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2024.103493},
url = {https://www.sciencedirect.com/science/article/pii/S0016328724001770},
author = {Stephanie Almeida de Jesus Dias and Renato Máximo Sátiro},
keywords = {Artificial Intelligence, Critical Theory, Judiciary},
abstract = {The main objective of this study is to raise questions about using artificial intelligence (AI) in the judiciary based on critical thinking. The essay approach used in this work aims to foster reflection and debate on the subject, presenting a review of theoretical perspectives with particular attention to the critical theory of the first generation of the Frankfurt School and theories that seek to analyze the relationship between humans and society/technology, such as the critical theory of technology, and stays away from the dominant currents of thinking in organizational studies to contribute unexplored perspectives. In this manner, it will go beyond existing benefits and applications, focusing on a critical view that identifies the elements that guide the technological choices that have been made, thus promoting a discussion that aggregates elements for future developments and improvements. Based on this theoretical context, this essay will raise questions and present three propositions summarizing the identified difficulties and directing future studies.}
}
@article{TAN2020109285,
title = {A fast and low computational memory algorithm for non-stochastic simulations in heterogeneous agent models},
journal = {Economics Letters},
volume = {193},
pages = {109285},
year = {2020},
issn = {0165-1765},
doi = {https://doi.org/10.1016/j.econlet.2020.109285},
url = {https://www.sciencedirect.com/science/article/pii/S0165176520301907},
author = {Eugene Tan},
keywords = {Numerical methods, Heterogeneous agent models, Non-stochastic simulation},
abstract = {Heterogeneous agent models in macroeconomics generally require numerical computation of the cross-sectional distribution of agents. The standard textbook approach is to fully approximate the Markov kernel that iterates the distribution forward in time as a Markov transition matrix, which can be costly in terms of computational time and memory when the state space is large. This note provides an alternative algorithm that is simple, requires much less computational memory, and is substantially faster than the standard algorithm.}
}
@article{MONTEJOLOPEZ20248615,
title = {Analysing the effect caused by increasing the molecular volume in M1-AChR receptor agonists and antagonists: a structural and computational study††Electronic supplementary information (ESI) available. See DOI: https://doi.org/10.1039/d3ra07380g},
journal = {RSC Advances},
volume = {14},
number = {13},
pages = {8615-8640},
year = {2024},
issn = {2046-2069},
doi = {https://doi.org/10.1039/d3ra07380g},
url = {https://www.sciencedirect.com/science/article/pii/S2046206924007459},
author = {Wilber Montejo-López and Raúl Sampieri-Cabrera and María Inés Nicolás-Vázquez and Juan Manuel Aceves-Hernández and Rodrigo Said Razo-Hernández},
abstract = {M1 muscarinic acetylcholine receptor (M1-AChR), a member of the G protein-coupled receptors (GPCR) family, plays a crucial role in learning and memory, making it an important drug target for Alzheimer's disease (AD) and schizophrenia. M1-AChR activation and deactivation have shown modifying effects in AD and PD preclinical models, respectively. However, understanding the pharmacology associated with M1-AChR activation or deactivation is complex, because of the low selectivity among muscarinic subtypes, hampering their therapeutic applications. In this regard, we constructed two quantitative structure–activity relationship (QSAR) models, one for M1-AChR agonists (total and partial), and the other for the antagonists. The binding mode of 59 structurally different compounds, including agonists and antagonists with experimental binding affinity values (pKi), were analyzed employing computational molecular docking over different structures of M1-AChR. Furthermore, we considered the interaction energy (Einter), the number of rotatable bonds (NRB), and lipophilicity (ilogP) for the construction of the QSAR model for agonists (R2 = 89.64, QLMO2 = 78, and Qext2 = 79.1). For the QSAR model of antagonists (R2 = 88.44, QLMO2 = 82, and Qext2 = 78.1) we considered the Einter, the fraction of sp3 carbons fCsp3, and lipophilicity (MlogP). Our results suggest that the ligand volume is a determinant to establish its biological activity (agonist or antagonist), causing changes in binding energy, and determining the affinity for M1-AChR.}
}
@article{KRUSE2023105975,
title = {Changes of creative ability and underlying brain network connectivity throughout the lifespan},
journal = {Brain and Cognition},
volume = {168},
pages = {105975},
year = {2023},
issn = {0278-2626},
doi = {https://doi.org/10.1016/j.bandc.2023.105975},
url = {https://www.sciencedirect.com/science/article/pii/S0278262623000325},
author = {Jordanna A. Kruse and Casey S. Martin and Noah Hamlin and Emma Slattery and Eibhlis M. Moriarty and Lucy K. Horne and Barbara Ozkalp-Poincloux and Anaelle Camarda and Stuart F. White and Jacob Oleson and Mathieu Cassotti and Gaelle E. Doucet},
keywords = {Creativity, Divergent thinking, Lifespan, rs-fMRI, ECN},
abstract = {Creativity, or divergent thinking, is essential to and supported by cognitive functions necessary for everyday tasks. The current study investigates divergent thinking and its neural mechanisms from adolescence to late adulthood. To do this, 180 healthy participants completed a creativity task called the egg task including 86 adolescents (mean age (SD) = 13.62 (1.98)), 52 young adults (24.92 (3.60), and 42 older adults (62.84 (7.02)). Additionally, a subsample of 111 participants completed a resting-state fMRI scan. After investigating the impact of age on different divergent thinking metrics, we investigated the impact of age on the association between divergent thinking and resting-state functional connectivity within and between major resting-state brain networks associated with creative thinking: the DMN, ECN, and SN. Adolescents tended to be less creative than both young and older adults in divergent thinking scores related to expansion creativity, and not in persistent creativity, while young and older adults performed relatively similar. We found that adolescents’ functional integrity of the executive control network (ECN) was positively associated with expansion creativity, which was significantly different from the negative association in both the young and older adults. These results suggest that creative performance and supporting brain networks change throughout the lifespan.}
}
@article{CALOFFI2023122351,
title = {Innovation intermediaries' types and functions: A computational analysis of the literature},
journal = {Technological Forecasting and Social Change},
volume = {189},
pages = {122351},
year = {2023},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2023.122351},
url = {https://www.sciencedirect.com/science/article/pii/S0040162523000367},
author = {Annalisa Caloffi and Ana Colovic and Valentina Rizzoli and Federica Rossi},
keywords = {Innovation intermediaries, Computational literature review, Open innovation intermediaries, Innovation system intermediaries, Transition intermediaries, Cluster intermediaries, KIBS, Incubators},
abstract = {Innovation intermediaries have become numerous and diverse. Faced with this growing heterogeneity, there is the need to advance understanding of the organisations that engage in innovation intermediation activities. To do so, we use a combination of text mining and bibliometric techniques, and we identify seven different streams of literature, six of which refer to distinct types of intermediaries that perform specific functions and often involve specific types of organisations. Looking at the evolution of the different streams of literature over time, we find that the early contributions focused on university incubators, science and technology parks, and the role they play within different types of innovation systems. More recently, the focus has shifted to the role of intermediaries in supporting sustainable transitions. Despite the differences between the various types of intermediaries and the literature streams that analyse them, the bibliographic coupling shows that all strands of literature have a common theoretical basis, which includes the open innovation approach and revolves around the role of science parks and incubators.}
}
@article{MICHELOYANNIS2005212,
title = {Neural networks involved in mathematical thinking: evidence from linear and non-linear analysis of electroencephalographic activity},
journal = {Neuroscience Letters},
volume = {373},
number = {3},
pages = {212-217},
year = {2005},
issn = {0304-3940},
doi = {https://doi.org/10.1016/j.neulet.2004.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0304394004012546},
author = {Sifis Micheloyannis and Vagelis Sakkalis and Michalis Vourkas and Cornelis J. Stam and Panagiotis G. Simos},
keywords = {Mathematics, Electroencephalography, Power spectrum, Coherence, Non-linear synchronization},
abstract = {Using linear and non-linear methods, electroencephalographic (EEG) signals were measured at various brain regions to provide information regarding patterns of local and coordinated activity during performance of three arithmetic tasks (number comparison, single-digit multiplication, and two-digit multiplication) and two control tasks that did not require arithmetic operations. It was hypothesized that these measures would reveal the engagement of local and increasingly complex cortical networks as a function of task specificity and complexity. Results indicated regionally increased neuronal signalling as a function of task complexity at frontal, temporal and parietal brain regions, although more robust task-related changes in EEG-indices of activation were derived over the left hemisphere. Both linear and non-linear indices of synchronization among EEG signals recorded from over different brain regions were consistent with the notion of more “local” processing for the number comparison task. Conversely, multiplication tasks were associated with a widespread pattern of distant signal synchronizations, which could potentially indicate increased demands for neural networks cooperation during performance of tasks that involve a greater number of cognitive operations.}
}
@article{WALSH2021143,
title = {Computational Cognitive Modeling of Human Calibration and Validity Response Scoring for the Graduate Record Examinations (GRE)},
journal = {Journal of Applied Research in Memory and Cognition},
volume = {10},
number = {1},
pages = {143-154},
year = {2021},
note = {Culture & Memory},
issn = {2211-3681},
doi = {https://doi.org/10.1016/j.jarmac.2020.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S2211368120300747},
author = {Matthew M. Walsh and Burcu Arslan and Bridgid Finn},
keywords = {Constructed response scoring, Graduate record examinations, Predictive performance equation, Skill decay},
abstract = {Most research on skill acquisition and retention focuses on the individual being tested. Yet sometimes another person is responsible for evaluating the individual’s performance. Here, we study the acquisition and retention of rater skill using data for the Graduate Record Examinations (GRE). Our work is based on the idea that response scoring, like other cognitive skills, will gradually improve with amount of practice, and decline with elapsed time since that practice occurred. These classic findings are the focus of a computational cognitive model called the Predictive Performance Equation (PPE). However, the generalizability of these findings to response scoring and the applicability of PPE to that domain have not yet been demonstrated. To address this issue, we leveraged a naturalistic dataset containing rating performance from over 23,000 sessions. Our analyses provide empirical support for PPE and establish a basis for using a model like PPE to personalize rater training requirements.}
}
@article{SMITH1990121,
title = {Writing, thinking, computing},
journal = {Poetics},
volume = {19},
number = {1},
pages = {121-142},
year = {1990},
issn = {0304-422X},
doi = {https://doi.org/10.1016/0304-422X(90)90033-2},
url = {https://www.sciencedirect.com/science/article/pii/0304422X90900332},
author = {John B. Smith and Catherine F. Smith},
abstract = {The computer has become the preferred tool for many writers. Over the next few years, it is likely to become the predominant tool. Since writing is fundamentally a mediated activity and since the tool inevitably affects the tool user, we need to consider how a tool as powerful as the computer is affecting writers. To address this issue, we consider the following questions: &#x02022;- What are writers saying about computers?&#x02022;- How are writers using computers?&#x02022;- What does this mean for the teaching of writing?&#x02022;- What does this mean for designers of future writing systems?&#x02022;- How does the computer affect writer's thinking? We are led to the conclusion that new, comprehensive writing environments are both needed and inevitable, and they, in turn, will lead to a form of enhanced, or amplified, thinking. But using these environments and developing this kind of thinking will also require new forms of instruction. Adapting to these changes will pose practical as well as intellectual challenges for the composition community. To meet these challenges tomorrow, we must begin considering the relationships among writing, thinking, and computing today.}
}
@article{DAKIN2009R851,
title = {Vision: Thinking Globally, Acting Locally},
journal = {Current Biology},
volume = {19},
number = {18},
pages = {R851-R854},
year = {2009},
issn = {0960-9822},
doi = {https://doi.org/10.1016/j.cub.2009.08.021},
url = {https://www.sciencedirect.com/science/article/pii/S0960982209015954},
author = {Steven C. Dakin},
abstract = {Summary
The global structure of images profoundly influences how we see their local detail, consistent with activity in primary visual cortex being disambiguated via feedback from later visual areas.}
}
@article{GARG201426,
title = {Modeling, analyzing and slicing periodic distributed computations},
journal = {Information and Computation},
volume = {234},
pages = {26-43},
year = {2014},
issn = {0890-5401},
doi = {https://doi.org/10.1016/j.ic.2013.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S0890540113001260},
author = {Vijay K. Garg and Anurag Agarwal and Vinit Ogale},
keywords = {Predicate detection, Liveness violation, d-Diagram, Recurrent computation},
abstract = {The earlier work on predicate detection has assumed that the given computation is finite. Detecting violation of a liveness predicate requires that the predicate be evaluated on an infinite computation. In this work, we develop the theory and associated algorithms for predicate detection in infinite runs. In practice, an infinite run can be determined in finite time if it consists of a recurrent behavior with some finite prefix. Therefore, our study is restricted to such runs. We introduce the concept of d-diagram, which is a finite representation of infinite directed graphs. Given a d-diagram that represents an infinite distributed computation, we solve the problem of determining if a global predicate ever became true in the computation. The crucial aspect of this problem is the stopping rule that tells us when to conclude that the predicate can never become true in future. We also provide an algorithm to provide vector timestamps to events in the computation for determining the dependency relationship between any two events in the infinite run. Finally, we give an algorithm to compute a slice of a d-diagram which concisely captures all the consistent global states of the computation satisfying the given predicate.}
}
@article{PSYCHARIS2013253,
title = {Examining the effect of the computational models on learning performance, scientific reasoning, epistemic beliefs and argumentation: An implication for the STEM agenda},
journal = {Computers & Education},
volume = {68},
pages = {253-265},
year = {2013},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2013.05.015},
url = {https://www.sciencedirect.com/science/article/pii/S0360131513001437},
author = {Sarantos Psycharis},
keywords = {Modelling, Computational experiment, Reasoning abilities, Epistemological beliefs, Argumentation},
abstract = {Computational experiment approach considers modelling as the essential feature of Inquiry-Based Science Education (IBSE) where the model and the computer take the place of the “classical” experimental set-up and simulation replaces the experiment (Landau, Páez, & Bordeianu, 2008). Modelling, as a pedagogical tool, involves the model construction, the exploration of model characteristics and the model application to a specific problem, resembling authentic activities of scientists and mathematicians (Herbert, 2003). Jonassen and Strobel (2006) state that in addition to modelling domain knowledge, learners can apply modelling skills in different ways: by modelling domain knowledge, by modelling problems (constructing problem spaces), by modelling systems and by modelling semantic structures. The purpose of this study was to explore the effects of the Computational Experiment Mathematical Modelling (CEMM) approach on University students': a) reasoning abilities, b) learning performance, c) epistemological beliefs, and d) argumentation. Students worked in a learning environment which contained applications in Physics created by the author and all of them were based on mathematical models, as the model was considered as the fundamental unit of instruction (Hestenes, 1999). Fifty (50) pre-service primary school university students participated in this project and results indicated a strong relationship between students' learning performance, performance in the scientific reasoning abilities test, epistemic beliefs and the ability to use arguments during computational experiments. This paper suggests an implementable integration strategy that uses mathematical models for physics phenomena that are developed using algorithms, aiming to deepen students' conceptual understanding and scientific reasoning. After completing the course, the mechanics baseline test (MBT) and a test on Heat were administered. The results indicated that there was a significant difference in problem-solving skill test mean scores, as measured by the MBT, and the test on Heat among concrete, formal and postformal reasoners. Overall, this study provides evidence that scientific reasoning has a strong impact to learning performance, scientific reasoning, epistemological beliefs and argumentation while the methodology of the Computational Experiment provides essential tools to students to implement Inquiry based scenario. Students developed their scenarios using an open source repository using the computational experiment approach and created their experiments using the Argument-Driven Inquiry (ADI) laboratory approach. Results have implications for the effectiveness of the computational experiment as a methodology to be included in the STEM agenda.}
}
@article{BELIK2023113555,
title = {Link on, Link off: Data-driven management of organizational networks for ambidexterity},
journal = {Journal of Business Research},
volume = {157},
pages = {113555},
year = {2023},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2022.113555},
url = {https://www.sciencedirect.com/science/article/pii/S0148296322010207},
author = {Ivan Belik and Eirik Sjåholm Knudsen},
keywords = {Organizational networks, Ambidexterity, Social networks, Knowledge flows, Network analysis, Data-driven},
abstract = {We examine how firms can intentionally design and manage their organizational networks to balance exploration and exploitation when a new exploration unit is established within an organization. We combine insights from the literature on social networks and structural ambidexterity and make two main arguments. First, a firm needs to ensure that the exploration unit is sufficiently connected to other parts of the organization where key complementary assets reside while minimizing the number of linkages to reduce the influence of the “old” way of thinking on new exploration efforts, to reduce coordination costs, and to increase adaptive ability. Second, the “ideal” level of connectedness for structural ambidexterity ultimately depends on the number of valuable complementary assets in a firm’s possession. We also show how managers can combine analytical methods from the computational literature on network analysis with managerial adjustments to do so in practice.}
}
@article{CHESHMEHZANGI2017102,
title = {Application of environmental performance analysis for urban design with Computational Fluid Dynamics (CFD) and EcoTect tools: The case of Cao Fei Dian eco-city, China},
journal = {International Journal of Sustainable Built Environment},
volume = {6},
number = {1},
pages = {102-112},
year = {2017},
issn = {2212-6090},
doi = {https://doi.org/10.1016/j.ijsbe.2017.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S2212609015300650},
author = {Ali Cheshmehzangi and Yan Zhu and Bo Li},
keywords = {Sustainability, Urban design, CFD, Optimisation, Environmental performance},
abstract = {This paper suggests a type of quantitative research method with the application of Computational Fluid Dynamics (CFD) and EcoTect tools for a sustainable urban design project. This paper is part of a funded research study and was completed in 2010. This study is part of the larger project for planning and development of Cao Fei Dian eco-city development in North-Eastern China; one of the first eco-city development projects in the first batch of pilot eco-cities in China. The research programme addresses the main aspects of good practice in terms of eco-design and sustainability. These aspects include wind flow analysis around buildings, insolation analysis of open spaces, pollutant dispersion in water systems and noise control on urban highways. This study aims to explore a range of research methods in order to enhance the performance of integrated design with a comprehensive planning stage. The integration in evaluation across professions and subject boundaries is emphasised to identify the key gaps between sustainability and design. The main method of this study is the application of CFD and EcoTect tools for environmental performance of a larger urban area than the common use for architectural interventions or immediate outdoor spaces of a project. This study suggests an integrated urban design model with the application of computational tools (i.e. CFD and EcoTect in here) and how these could inform, from a technical dimension, a more comprehensive approach to executing best practice in design and planning. The paper concludes by suggesting an integrated model of urban design to achieve urban sustainability.}
}
@article{RICHARDSON2021107607,
title = {TurboPy: A lightweight python framework for computational physics},
journal = {Computer Physics Communications},
volume = {258},
pages = {107607},
year = {2021},
issn = {0010-4655},
doi = {https://doi.org/10.1016/j.cpc.2020.107607},
url = {https://www.sciencedirect.com/science/article/pii/S0010465520302897},
author = {A.S. Richardson and D.F. Gordon and S.B. Swanekamp and I.M. Rittersdorf and P.E. Adamson and O.S. Grannis and G.T. Morgan and A. Ostenfeld and K.L. Phlips and C.G. Sun and G. Tang and D.J. Watkins},
keywords = {Framework, Physics, Computational physics, Python, Dynamic factory pattern, Resource sharing},
abstract = {Computational physics problems often have a common set of aspects to them that any particular numerical code will have to address. Because these aspects are common to many problems, having a framework already designed and ready to use will not only speed the development of new codes, but also enhance compatibility between codes. Some of the most common aspects of computational physics problems are: a grid, a clock which tracks the flow of the simulation, and a set of models describing the dynamics of various quantities on the grid. Having a framework that could deal with these basic aspects of the simulation in a common way could provide great value to computational scientists by solving various numerical and class design issues that routinely arise. This paper describes the newly developed computational framework that we have built for rapidly prototyping new physics codes. This framework, called turboPy, is a lightweight physics modeling framework based on the design of the particle-in-cell code turboWAVE. It implements a class (called Simulation) which drives the simulation and manages communication between physics modules, a class (called PhysicsModule) which handles the details of the dynamics of the various parts of the problem, and some additional classes such as a Grid class and a Diagnostic class to handle various ancillary issues that commonly arise.
Program summary
Program Title: TurboPy CPC Library link to program files: http://dx.doi.org/10.17632/rznn6s5myw.1 Developer’s repository link: https://github.com/NRL-Plasma-Physics-Division/turbopy Licensing provisions: CC0 1.0 Programming language: Python Nature of problem: Many computation physics problems have a common set of aspects to them that are often addressed in a custom way in every different code, which leads to lengthy and redundant development and testing, as well as introducing roadblocks to interoperability. Solution method: Implement a set of python classes as a lightweight framework that deals with these common problems, so that development time on new computational physics codes is reduced, and interoperability and reusability are increased. References: A.S. Richardson et al., TurboPy: A lightweight computational physics framework. NRL-Plasma-Physics-Division/turbopy (v2020.08.05). doi:10.5281/zenodo.3973693}
}
@article{MATSUMOTO2022116521,
title = {Forecasting US dollar exchange rate movement with computational models and human behavior},
journal = {Expert Systems with Applications},
volume = {194},
pages = {116521},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.116521},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422000227},
author = {Elia Yathie Matsumoto and Emilio Del-Moral-Hernandez and Claudia Emiko Yoshinaga and Afonso {de Campos Pinto}},
keywords = {Exchange rate, Behavioral finance, Ensemble models, Machine learning},
abstract = {Our research investigates the potential benefits of adding the Behavioral Finance approach to the Machine Learning and Big Data framework applied to the challenging problem of forecasting the US Dollar exchange rate. More specifically, we show how to improve existing voting-based ensemble models trained to predict the next-day exchange rate trend with no need for retraining or other costly computational tasks. We assume that calendar effects would constrain investors’ actions; furthermore, their constrained individual actions would collectively induce deterministic patterns in the financial time-series movement. Hence, financial time-series forecasting models could be prone to monthly repeat their performance patterns, and we could use this information to obtain better predictions and consistently achieve profit. To verify the effectiveness of our methodology, we predicted the sign of the US Dollar to Brazilian Real rate variation. Our proposed models generated a profit metric value 24% higher than the original voting-based ensemble models with 16% lower volatility, gathering two positive elements: higher return with lower risk. The experiments’ outcomes supported the hypothesis that there are considerable improvements with almost no extra computational effort by taking into account behavioral patterns in foreign exchange predictions.}
}
@article{BOTH201517,
title = {A generic computational model of mood regulation and its use to model therapeutical interventions},
journal = {Biologically Inspired Cognitive Architectures},
volume = {13},
pages = {17-34},
year = {2015},
issn = {2212-683X},
doi = {https://doi.org/10.1016/j.bica.2015.06.005},
url = {https://www.sciencedirect.com/science/article/pii/S2212683X15000328},
author = {Fiemke Both and Mark Hoogendoorn and Michel C.A. Klein and Jan Treur},
keywords = {Computational model, Mood, Depression, Analysis, Therapy, Intervention},
abstract = {As all living organisms, human beings aim at being in some kind of balance (or homeostasis) with their environment. Part of this challenge takes the form of keeping their mood within certain boundaries, and in particular avoiding (too) negative moods when facing negative events from time to time. In this paper a generic computational model for this regulative process is presented. The model serves as a framework or architecture in which various additional elements can be incorporated. To evaluate the suitability of this framework, the model has been extended by incorporating therapeutical interventions for four different types of therapy. The obtained intervention models have been used to model and compare different therapies for a variety of patient types by simulation experiments and by formal verification. Simulation experiments are reported showing that the mood regulation and depression indeed follow expected patterns when applying these therapies. These models form building block for intelligent therapy support systems.}
}
@article{YANG2024112150,
title = {Demand response strategy of user-side energy storage system and its application to reliability improvement},
journal = {Journal of Energy Storage},
volume = {92},
pages = {112150},
year = {2024},
issn = {2352-152X},
doi = {https://doi.org/10.1016/j.est.2024.112150},
url = {https://www.sciencedirect.com/science/article/pii/S2352152X24017365},
author = {Hejun Yang and Qiang Chen and Yue Liu and Yinghao Ma and Dabo Zhang},
keywords = {Power system reliability, Electricity pricing strategy, User-side energy storage system, Demand management},
abstract = {The time of use (TOU) strategy is being carried out in the power system for shifting load from peak to off-peak periods. For economizing the electricity bill of industry users, the trend on configuring user-side energy storage system (UES) by users will increase continuously. On the base of currently implemented TOU environment, designing an efficient and non-utility-dispatched guidance strategy for UES to realize the peak-shaving and valley-filling will have a great significance. Therefore, this paper firstly proposes a thinking based on a linear piecewise-shape pricing strategy for guiding UES to decrease the peak-valley difference although storage has not been dispatched by utility and always operates in its maximum benefit. In addition, benefit of user with UES has been guaranteed to be non-decreased compared to traditional TOU. Then, this paper establishes a planning-operation co-optimization model for UES to pursue its maximum net benefit, in which the proposed electricity pricing strategy has been incorporated. Thirdly, a linearized reliability improvement calculation method contributed by storage has been presented. Finally, the numerical results have verified the effectiveness of the proposed strategy, and in the designed case condition, there is an obvious improvement in the percentage of peak-valley difference and the reliability level.}
}
@article{LIU2023101339,
title = {Promoting primary school students’ creativity via reverse engineering pedagogy in robotics education},
journal = {Thinking Skills and Creativity},
volume = {49},
pages = {101339},
year = {2023},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2023.101339},
url = {https://www.sciencedirect.com/science/article/pii/S1871187123001086},
author = {Xiaohong Liu and Jianjun Gu and Li Zhao},
keywords = {Creativity, Reverse engineering pedagogy, Creative thinking, Robotics education, Creative self-efficacy},
abstract = {Creativity is an essential basic skill for students. In this study, the reverse engineering pedagogy (REP) was applied to primary school students’ robotics education course, with the aim of investigating the influence of REP and project-based pedagogy (PBP) on the cultivation of students' creativity. A quasi-experimental study that utilized a non-equivalent groups design was conducted with 91 fifth-grade students, comprising a control group (n = 46) who received the PBP intervention, and an intervention group (n = 45) who received the REP intervention. Creative self-efficacy, Torrance Tests of Creative Thinking Figural (TTCT-Figural), and assessment of the students’ robotic creative products were conducted to evaluate students’ creativity. In addition, t tests, ANCOVA, and ANOVA were used to analyze the data to determine whether REP could improve students’ creativity better than PBP. The results showed that REP could enhance students’ creative self-efficacy and their robotic creative products score more than PBP could, but not the TTCT-Figural score after the confounding effect of fluency was controlled for. In the intervention group, creative self-efficacy and creative thinking were improved after intervention. Overall, REP has more advantages than PBP for promoting primary school students' creativity. The findings of this study provide a reference and teaching strategies guidance for the cultivation of K-12 students' creativity in robotics education.}
}
@article{KLIMOVA20201,
title = {Artificial Intelligence as the Driver of Computational Science: preface to YSC’2020},
journal = {Procedia Computer Science},
volume = {178},
pages = {1-7},
year = {2020},
note = {9th International Young Scientists Conference in Computational Science, YSC2020, 05-12 September 2020},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920323735},
author = {Alexandra Klimova and Angelos Bilas and Vangelis Harmandaris and Vladimir Voevodin and Alexander Boukhanovsky},
keywords = {artificial intelligence, computational science},
abstract = {This volume presents selected papers of young scientists – participants of International Young Scientists Conference in Computational Science (YSC’2020). This annual event has been annually organized by ITMO University since 2012 and aims to develop a dialogue about the present and the future of computational science with a focus on applications of modeling and simulation to solve a wide range of problems in science, industry, and business. In this editorial we present retrospective analysis of scientific topics, which were presented during the YSC editions, and determine key trends of the conference, related to the interaction of computational and intelligent technologies.}
}
@article{VANBENTHEM2018519,
title = {Computation as social agency: What, how and who},
journal = {Information and Computation},
volume = {261},
pages = {519-535},
year = {2018},
note = {Strategic Reasoning 2015},
issn = {0890-5401},
doi = {https://doi.org/10.1016/j.ic.2017.09.009},
url = {https://www.sciencedirect.com/science/article/pii/S0890540117301669},
author = {Johan {van Benthem}},
keywords = {Computation, Logic, Epistemization, Gamification},
abstract = {Computation today is interactive agency in social networks. In this discussion paper, we look at this trend through the lens of logic, identifying two main lines. One is ‘epistemization’, making computational tasks refer explicitly to knowledge or beliefs of the agents performing them. The other line is using games as a model for computation, leading to ‘gamification’ of classical tasks, and computing by agents that may have preferences. This provides ingredients for a fundamental theory of computation that shifts from what is computed to how it is computed and by whom, moving from output to social behavior. The true impact of this shift is not in learning how to replace humans, but in creating new societies where humans and machines interact. While we do not offer a Turing-style account of this richer world, we discuss what becomes of three classical themes: the Universal Machine, Church's Thesis and the Turing Test.1}
}
@article{WINITZKY19921,
title = {Structure and process in thinking about classroom management: An exploratory study of prospective teachers},
journal = {Teaching and Teacher Education},
volume = {8},
number = {1},
pages = {1-14},
year = {1992},
issn = {0742-051X},
doi = {https://doi.org/10.1016/0742-051X(92)90036-3},
url = {https://www.sciencedirect.com/science/article/pii/0742051X92900363},
author = {Nancy Winitzky},
abstract = {Current research on teaching centers on teachers' thinking. What teachers know and, especially, how they reflect on their practice are considered central to understanding teaching. Part of the research on teachers' knowledge concerns cognitive structure (schemata), how teachers organize their knowledge; it is thought that complex, highly structured schemata are related to skillful teaching performance. While it is sensible to assume that schemata and reflection, structure and process, are linked, no data exist to support that assumption. In the present study, cognitive structure and reflection data were collected from 15 prospective teachers. The strength of the correlation between those variables was .48 (p = .05). Implications for theory, research, and practice are discussed.}
}
@article{PETSCHE199231,
title = {Thinking with images or thinking with language: a pilot EEG probability mapping study},
journal = {International Journal of Psychophysiology},
volume = {12},
number = {1},
pages = {31-39},
year = {1992},
issn = {0167-8760},
doi = {https://doi.org/10.1016/0167-8760(92)90040-I},
url = {https://www.sciencedirect.com/science/article/pii/016787609290040I},
author = {Hellmuth Petsche and Denis Lacroix and Klaus Lindner and Peter Rappelsberger and Eva Schmidt-Henrich},
keywords = {EEG probability mapping, Mental imagery, Thinking process, Cognitive activation, Sex difference},
abstract = {This pilot EEG mapping study was designed to explore thinking processes using complex mental imagery and thought processes. EEG was recorded with 19 electrodes (10/20 system against averaged ear lobe signals) while volunteers (n = 42) performed two separate tasks: visualization of an abstract concept and interpretation of a painting. Average spectral parameters such as amplitude, local and interhemispheric coherences were computed for five frequency bands (theta, alpha, beta 1, 2 and 3). Results indicate that the frontal regions are strongly involved during these tasks as evidenced by coherence changes. Changes are also present in temporal, parietal and occipital regions and are discussed in relation to information processing with the frontal regions considering the different cognitive functions required by the tasks.}
}
@article{CAIN2023197,
title = {Navigating Design, Data, and Decision in an Age of Uncertainty},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {9},
number = {2},
pages = {197-212},
year = {2023},
note = {The Future of Design Education: Rethinking Design Education for the 21st Century},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2023.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S2405872623000448},
author = {John Cain and Zach Pino},
keywords = {Data literacy, Design-driven data, Interconnected systems, Systemic implications, Uncertainty},
abstract = {The Future of Design Education working group on technical systems argues that the approach to handling data—the methods used, and the expectations for outcomes—can transform design practice. In contrast to design’s past defined by a lack of accessible data, today’s rapidly evolving age of data abundance informs the choices available—the decision space—with far-reaching consequences for organizational, social, and environmental well-being. The shifting design landscape requires new tools and techniques to navigate this data age effectively. This paper proposes a new curricular approach that intersects data, technology, and design to create an environment where students can evaluate their roles and impact, and interact effectively through data with humans and computational collaborators. This data-oriented curriculum includes foundational technical skills proficiency, data analytical skills, rhetorical skills for arguing with data, interdisciplinary design studies, and a focus on designing for society. It embraces the complexities and opportunities of the data age, and acknowledges the inherent uncertainty in this new landscape. The aim is to prepare the next generation of designers to create data-informed, human-centered, ethical, and sustainable designs, thereby fostering an inclusive, equitable, and sustainable future.}
}
@article{KING2014173,
title = {Re-discovering and re-creating African American historical accounts through mobile apps: The role of mobile technology in history education},
journal = {The Journal of Social Studies Research},
volume = {38},
number = {3},
pages = {173-188},
year = {2014},
note = {Research on technology in the social studies},
issn = {0885-985X},
doi = {https://doi.org/10.1016/j.jssr.2013.12.005},
url = {https://www.sciencedirect.com/science/article/pii/S0885985X14000242},
author = {LaGarrett J. King and Christina Gardner-McCune and Penelope Vargas and Yerika Jimenez},
keywords = {Mobile technology, Historical thinking, African American students, Plantation sites},
abstract = {This paper describes a case study of a program called WATCH: Workshop for Actively Thinking Computationally and Historically. The focus of the program and this paper was on using mobile application development to promote historical thinking using a plantation site visit as the focus of inquiry. WATCH was delivered during an academic enrichment youth program at a major research university in the Southeast and served a total of 30 African American and Latino high school students from low socio-economic backgrounds. Through the theoretical framework of historical thinking, this case study provides descriptions of the class sessions, students׳ perceptions of and interests in history and students level of historical thinking through their apps. We make suggestions about how the instructional activities could be adapted for classrooms, discuss the tensions of using technology and inquiry pedagogy to support and promote historical learning, and review the program׳s impact on students׳ agency as learners and critical consumers and producers of historical accounts.}
}
@incollection{KARACA202221,
title = {Chapter 3 - Multi-chaos, fractal and multi-fractional AI in different complex systems},
editor = {Yeliz Karaca and Dumitru Baleanu and Yu-Dong Zhang and Osvaldo Gervasi and Majaz Moonis},
booktitle = {Multi-Chaos, Fractal and Multi-Fractional Artificial Intelligence of Different Complex Systems},
publisher = {Academic Press},
pages = {21-54},
year = {2022},
isbn = {978-0-323-90032-4},
doi = {https://doi.org/10.1016/B978-0-323-90032-4.00016-X},
url = {https://www.sciencedirect.com/science/article/pii/B978032390032400016X},
author = {Yeliz Karaca},
keywords = {Chaotic systems, Complex order, Complexity, Computational complexity, Data ethics, Different complex systems, Dynamics of complex systems, Evolution, Fractional thinking, Nonlinearity and irregularity},
abstract = {Modern scientific thinking adopts the systemic properties and addresses them through revealing the spontaneous processes related to self-organization in a dynamical system in a state far from the equilibrium point and close to the disequilibrium point with no existence of external force acting upon the system. The modern way of thinking poses a challenge against the dichotomy between the natural world and social world, by taking into account the concepts around complexity, evolution and order. This study provides an overview encompassing multi-chaos, fractal, fractional and Artificial Intelligence (AI) way of thinking for the solution of the complex system problems concerned with natural and social sciences. Furthermore, ethical decision-making frameworks and strategies concerning big data and AI applications to provide assistance for the identification of the related problems in different settings and help thinking in a methodical manner with a deliberative compensating process so that tensions between conflicting aspects can be managed systematically. The values related to ethical issues, which are thorny in nature, point to being practical, flexible and problem-driven rather than purely theory-driven in order that dilemmas can be addressed and critical decision-making guided in a way beyond theoretical positions with a focus on applied aspects. Through the lenses of such transformative thinking along with mathematics-informed frameworks encompassing chaos, fractal and multi-fractional ways, the incorporation of technology, with Artificial Intelligence, as the most viable and far-reaching leg, is essentially required to be able to address and tackle complexity that has chaotic, nonlinear, and dynamic characteristics. Hence, optimized solutions can be conceived and implemented efficiently and in a facilitating way with some required degree of flexibility as well. Considering the impact and ubiquity of data technologies concerning all aspects of modern life, it becomes important to establish a balance between data use and ethical matters. Computational technologies in different complex systems based on mathematical-driven informed frameworks can enable the generation of more realistic and applicable adaptive models under transient, dynamic and ever-evolving conditions of different complex systems.}
}
@article{TEZDUYAR19971349,
title = {Parallel computational methods for 3D simulation of a parafoil with prescribed shape changes},
journal = {Parallel Computing},
volume = {23},
number = {9},
pages = {1349-1363},
year = {1997},
note = {Parallel computing methods in applied fluid mechanics},
issn = {0167-8191},
doi = {https://doi.org/10.1016/S0167-8191(97)00057-4},
url = {https://www.sciencedirect.com/science/article/pii/S0167819197000574},
author = {T. Tezduyar and V. Kalro and W. Garrard},
keywords = {Parallel finite elements, Parafoil dynamics, Space-time formulation, 3D simulation},
abstract = {In this paper we describe parallel computational methods for 3D simulation of the dynamics and fluid dynamics of a parafoil with prescribed, time-dependent shape changes. The mathematical model is based on the time-dependent, 3D Navier-Stokes equations governing the incompressible flow around the parafoil and Newton's law of motion governing the dynamics of the parafoil, with the aerodynamic forces acting on the parafoil calculated from the flow field. The computational methods developed for these 3D simulations include a stabilized space-time finite element formulation to accommodate for the shape changes, special mesh generation and mesh moving strategies developed for this purpose, iterative solution techniques for the large, coupled nonlinear equation systems involved, and parallel implementation of all these methods on scalable computing systems such as the Thinking Machines CM-5. As an example, we report 3D simulation of a flare maneuver in which the parafoil velocity is reduced by pulling down the flaps. This simulation requires solution of over 3.6 million coupled, nonlinear equations at every time step of the simulation.}
}
@article{HIBERTY1998237,
title = {Thinking and computing valence bond in organic chemistry1Dedicated to the memory of Professor Joseph Gerratt, in appreciation of his outstanding contributions to modern ab initio valence bond methodology.1},
journal = {Journal of Molecular Structure: THEOCHEM},
volume = {451},
number = {3},
pages = {237-261},
year = {1998},
issn = {0166-1280},
doi = {https://doi.org/10.1016/S0166-1280(98)00208-5},
url = {https://www.sciencedirect.com/science/article/pii/S0166128098002085},
author = {Philippe C. Hiberty},
keywords = {Valence bond, Hybridization, Symmetry breaking, Resonance energy, Breathing orbitals},
abstract = {This paper presents a short survey of some recent ab initio valence bond methods and their applications, and is aimed at justifying and encouraging a valence bond view of organic chemistry, as complementary to the molecular orbital approach. In the first section, the qualitative VB description of the elementary interactions is recalled and compared to the MO model. It is shown that the VB picture is fundamentally correct, even for the well-known cases of the low-lying states of dioxygen and the 4n/4n+2 aromaticity rule. The second section briefly discusses the classical VB method, which deals with atomic orbitals that are optimized for the free atoms and kept unchanged in molecules, then describes modern ab initio VB methods that all perform orbital optimization in molecular calculations. The generalized valence bond and spin-coupled theories both provide a one-configuration wavefunction. While the former is generally used with some time-saving restrictions such as the strong-orthogonality restriction and the perfect-pairing approximation, the latter releases any orthogonality constraint and allows all possible spin couplings. Multiconfiguration methods are also discussed, as well as methods using different orbitals for different structures. Some computational applications of these methods are presented in the last section. It is shown that if given full freedom to optimize its shape with the variational principle as a unique criterion, a one-configuration wavefunction spontaneously takes the form of a VB wavefunction displaying localized orbitals, and presents a picture in terms of hybrid orbitals and/or resonance between limiting structures, very close to the traditional qualitative picture. The concept of hybridization is firmly supported, as the unique outcome of the highest computational level still compatible with the orbital picture. The description of conjugated systems in terms of resonating Kekulé structures is also fully justified and shown to be the best framework for discussing questions such as the distortive tendencies of conjugated π-electronic systems, or violations of Hund's rules. The ab initio VB approach can be used for quantifying some traditional paradigms such as the role of the delocalization energy in the acidity of carboxylic acids and enols, or in the properties of the amide/thioamide functional group. It is also shown to be an elegant solution to some difficult computational problems like the symmetry-breaking artefact or the inclusion of dynamical correlation in the description of the chemical bond. Lastly, some of the methods presented here are shown to be appropriate for the calculation of diabatic potential surfaces, with applications to the Shaik–Pross reactivity model of the VB curve-crossing correlation diagrams.}
}
@article{IDEKER2009820,
title = {The Thinking Man's Cell},
journal = {Cell},
volume = {138},
number = {5},
pages = {820-821},
year = {2009},
issn = {0092-8674},
doi = {https://doi.org/10.1016/j.cell.2009.08.024},
url = {https://www.sciencedirect.com/science/article/pii/S0092867409010411},
author = {Trey Ideker}
}
@article{ABRAMS199569,
title = {New thinking about information technology security},
journal = {Computers & Security},
volume = {14},
number = {1},
pages = {69-81},
year = {1995},
issn = {0167-4048},
doi = {https://doi.org/10.1016/0167-4048(95)97027-8},
url = {https://www.sciencedirect.com/science/article/pii/0167404895970278},
author = {Marshall D. Abrams and Michael V. Joyce},
keywords = {Computer architecture, Security, Distributed systems, Access control, Policy, Trusted Computing Base, Applications, Separation},
abstract = {This is the last of three related papers exploring how contemporary computer architecture affects security. It brings together the concepts introduced in the earlier papers and presents a generalized approach to protection, isolation, and access control. We call this approach the Generalized Trusted Computing Base. Based upon the ‘divide and conquer’ approach) to achieving protection, understandability, and flexibility, the result is a more flexible solution than the rigid hierarchical organization identified in the Trusted Database Interpretation or the partitioning introduced in the Trusted Network Interpretation.}
}
@incollection{STERN2000246,
title = {THINKING SYSTEMS},
editor = {AUGUST STERN},
booktitle = {Quantum Theoretic Machines},
publisher = {North-Holland},
address = {Amsterdam},
pages = {246-264},
year = {2000},
isbn = {978-0-444-82618-3},
doi = {https://doi.org/10.1016/B978-044482618-3/50068-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780444826183500681},
author = {AUGUST STERN}
}
@article{STAHL199833,
title = {Is step-j thinking an arbitrary modelling restriction or a fact of human nature?},
journal = {Journal of Economic Behavior & Organization},
volume = {37},
number = {1},
pages = {33-51},
year = {1998},
issn = {0167-2681},
doi = {https://doi.org/10.1016/S0167-2681(98)00075-4},
url = {https://www.sciencedirect.com/science/article/pii/S0167268198000754},
author = {Dale O. Stahl},
abstract = {In `Boundedly Rational Rule Learning in a Guessing Game,' Games and Economic Behavior, 16 (1996), we combined Nagel's (1995) model of boundedly rational players with a `law of effect' learning model, and the synthesis outperformed alternative theories when confronting Nagel's data. In that model, there were four boundedly rational behavioral rules (step-j, j=0, 1, 2, 3), each corresponding to an integer level of depth of reasoning. It is legitimate to ask for a justification of the restriction to these `integer' rules. Why is it not reasonable to suppose that some player believes that 50% of the population is step-0, and 50% is step-1, and so himself adopts something like a step-1.5 rule? This paper constructs a tractable model with potentially infinitely many non-integer rules and conducts comparison tests. The main conclusion is that allowing for non-integer rules does not help to explain the data. Therefore, by Occam's Razor, the integer rule model is preferred. These results suggest that step-j thinking is a fact of human nature rather that an arbitrary modelling restriction.}
}
@incollection{ZHENG202483,
title = {Chapter Five - Middle vision: Computational Knowledge Vision for visual translation},
editor = {Wenbo Zheng and Fei-Yue Wang},
booktitle = {Computational Knowledge Vision},
publisher = {Academic Press},
pages = {83-113},
year = {2024},
isbn = {978-0-443-21619-0},
doi = {https://doi.org/10.1016/B978-0-44-321619-0.00012-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780443216190000121},
author = {Wenbo Zheng and Fei-Yue Wang},
keywords = {Computational Knowledge Vision, Visual computing, Just noticeable difference, Domain adaptation, Generative adversarial network},
abstract = {Based on the principles and paradigms of computational knowledge-based vision discussed in this chapter, we practice at the representational and algorithmic levels for the take of image-to-image translation. The image-to-image translation aims to learn the mapping between two visual domains. At the beginning of designing the existing image-to-image translation method, it was not considered whether the generated image is realistic or not. In this work, we present a novel approach to address the problem of generating fidelity in the area of image-to-image translation. In particular, humans judge whether an image is realistic or not with unique human vision's feeling rather than paying attention to the real-world semantics. Inspired by this, we propose an effective network loss to capture the pixel-level representations and human vision system information for verisimilar image-to-image translation. To enforce both structural and translation-model consistency during adaptation, we propose a novel Just-Noticeable-Difference loss based on a visual recognition task. The Just-Noticeable-Difference loss not only guides the overall representation to be discriminative but also enforces our cycle loss before and after mapping between domains. Experimental results show that our approach is able to generate realistic images using unpaired training data, on a wide range of tasks. Besides, we measure realism with Fréchet Inception Distance and diversity with the number of statistically-different bins, Jensen–Shannon divergence, and a perceptual distance metric. We also apply our approach to domain adaptation and show competitive performance when compared to others on several datasets.}
}
@article{ABUHAY2018193,
title = {Analysis of publication activity of computational science society in 2001–2017 using topic modelling and graph theory},
journal = {Journal of Computational Science},
volume = {26},
pages = {193-204},
year = {2018},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2018.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S1877750318302461},
author = {Tesfamariam M. Abuhay and Sergey V. Kovalchuk and Klavdiya Bochenina and Gali-Ketema Mbogo and Alexander A. Visheratin and George Kampis and Valeria V. Krzhizhanovskaya and Michael H. Lees},
keywords = {Topic modelling, Natural language processing, ICCS, Computational science, Graph theory, Collaboration networks},
abstract = {This paper presents the results of topic modelling and analysis of topic networks using the corpus of the International Conference on Computational Science (ICCS), which contains 5982 domain-specific papers over seventeen years 2001–2017. We discuss the topical structures of ICCS, and show how these topics have evolved over time in response to the topicality of various domains, technologies and methods, and how all these topics relate to one another. This analysis illustrates the multidisciplinary research and collaborations among scientific communities, by constructing static and dynamic networks from the topic modelling results and from the authors’ keywords. The results of this study provide insights regarding the past and future trends of core discussion topics in computational science and show how “computational thinking” has propagated across different fields of study. We used the Non-negative Matrix Factorization (NMF) topic modelling algorithm to discover topics. The resulting topics were then manually labelled and grouped hierarchically on three levels. Next, we applied trend analysis and Change Point Analysis (CPA) to study the evolution of topics over seventeen years and to identify the growing and disappearing topics. We used Gephi to examine the static networks of topics, and an R library called DyA to analyse the dynamic networks of topics. We also analysed the conference as a platform for potential collaboration development through the perspective of collaboration networks. The results show that authors of ICCS papers continue to actively collaborate after the conference − on average authors collaborate with three other ICCS authors, − which suggests that ICCS is a valuable platform for collaboration development.}
}
@incollection{ALIPPI2024251,
title = {13 - Computational intelligence in cyber-physical systems and the Internet of Things},
editor = {Robert Kozma and Cesare Alippi and Yoonsuck Choe and Francesco Carlo Morabito},
booktitle = {Artificial Intelligence in the Age of Neural Networks and Brain Computing (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
pages = {251-267},
year = {2024},
isbn = {978-0-323-96104-2},
doi = {https://doi.org/10.1016/B978-0-323-96104-2.00001-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780323961042000014},
author = {Cesare Alippi and Seiichi Ozawa},
keywords = {Intelligent systems, Embedded AI, Learning in nonstationary environments, Cybersecurity},
abstract = {The emergence of nontrivial embedded sensor units and cyber-physical systems and the Internet of Things has made possible the design and implementation of sophisticated applications where large amounts of real-time data are collected, possibly to constitute a big data picture as time passes. Within this framework, intelligence mechanisms based on machine learning, neural networks, and brain computing approaches play a key role to provide systems with advanced functionalities. Intelligent mechanisms are needed to guarantee appropriate performances within an evolving, time-variant environment, optimally harvest the available and manage the residual energy, reduce the energy consumption of the whole system, identify and mitigate the occurrence of faults, and provide shields against cyber-attacks. The chapter introduces the above aspects of intelligence, whose functionalities are needed to boost the next generation of cyber-physical and Internet of Things applications, a smart world generation whose footprint is already around us.}
}
@article{BUCHBERGER200424,
title = {Algorithm Synthesis by Lazy Thinking: Examples and Implementation in Theorema},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {93},
pages = {24-59},
year = {2004},
note = {Proceedings of the Mathematical Knowledge Management Symposium},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2003.12.027},
url = {https://www.sciencedirect.com/science/article/pii/S157106610400012X},
author = {Bruno Buchberger and Adrian Crăciun},
keywords = {algorithm invention, algorithm verification, program synthesis, algorithm correctness, re-usable algorithms, algorithm schemes, learning from failure, conjecture generation, lazy thinking, requirement engineering, didactics of programming, mathematical knowledge retrieval, mathematical knowledge management, sorting, merging, merge-sort, },
abstract = {Recently, we proposed a systematic method for top-down synthesis and verification of lemmata and algorithms called “lazy thinking method” as a part of systematic mathematical theory exploration (mathematical knowledge management). The lazy thinking method is characterized: •by using a library of theorem and algorithm schemes•and by using the information contained in failing attempts to prove the schematic theorem or the correctness theorem for the algorithm scheme for inventing lemmata or requirements for subalgorithms, respectively. In this paper, we give a couple of examples for algorithm synthesis using the lazy thinking paradigm. These examples illustrate how the synthesized algorithm depends on the algorithm scheme used. Also, we give details about the implementation of the lazy thinking algorithm synthesis method in the frame of the Theorema system. In this implementation, the synthesis of the example algorithms can be carried out completely automatically, i.e. without any user interaction.}
}
@article{BREA201661,
title = {Does computational neuroscience need new synaptic learning paradigms?},
journal = {Current Opinion in Behavioral Sciences},
volume = {11},
pages = {61-66},
year = {2016},
note = {Computational modeling},
issn = {2352-1546},
doi = {https://doi.org/10.1016/j.cobeha.2016.05.012},
url = {https://www.sciencedirect.com/science/article/pii/S2352154616301048},
author = {Johanni Brea and Wulfram Gerstner},
abstract = {Computational neuroscience is dominated by a few paradigmatic models, but it remains an open question whether the existing modelling frameworks are sufficient to explain observed behavioural phenomena in terms of neural implementation. We take learning and synaptic plasticity as an example and point to open questions, such as one-shot learning and acquiring internal representations of the world for flexible planning.}
}
@article{PATT2024108888,
title = {The sign effect in temporal discounting does not require the hippocampus},
journal = {Neuropsychologia},
volume = {199},
pages = {108888},
year = {2024},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2024.108888},
url = {https://www.sciencedirect.com/science/article/pii/S0028393224001039},
author = {Virginie M. Patt and Caroline Strang and Mieke Verfaellie},
keywords = {Hippocampus, Amnesia, intertemporal choice, Temporal discounting, Sign effect, Money loss versus gain},
abstract = {When considering future outcomes, humans tend to discount gains more than losses. This phenomenon, referred to as the temporal discounting sign effect, is thought to result from the greater anticipated emotional impact of waiting for a negative outcome (dread) compared to waiting for a positive outcome (mixture of savoring and impatience). The impact of such anticipatory emotions has been proposed to rely on episodic future thinking. We evaluated this proposal by examining the presence and magnitude of a sign effect in the intertemporal decisions of individuals with hippocampal amnesia, who are severely impaired in their ability to engage in episodic mental simulation, and by comparing their patterns of choices to those of healthy controls. We also measured loss aversion, the tendency to assign greater value to losses compared to equivalent gains, to verify that any reduction in the sign effect in the hippocampal lesion group could not be explained by a group difference in loss aversion. Results showed that participants with hippocampal amnesia exhibited a sign effect, with less discounting of monetary losses compared to gains, that was similar in magnitude to that of controls. Loss aversion, albeit greater in the hippocampal compared to the control group, did not account for the sign effect. These results indicate that the sign effect does not depend on the integrity of hippocampally mediated episodic processes. They suggest instead that the impact of anticipatory emotions can be factored into decisions via semantic future thinking, drawing on non-contextual knowledge about oneself.}
}
@article{CHAPLESKI2020101435,
title = {A Molecular-Scale Approach to Rare-Earth Beneficiation: Thinking Small to Avoid Large Losses},
journal = {iScience},
volume = {23},
number = {9},
pages = {101435},
year = {2020},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2020.101435},
url = {https://www.sciencedirect.com/science/article/pii/S2589004220306258},
author = {Robert C. Chapleski and Azhad U. Chowdhury and Anna K. Wanhala and Vera Bocharova and Santanu Roy and Philip C. Keller and Dylan Everly and Santa Jansone-Popova and Alexander Kisliuk and Robert L. Sacci and Andrew G. Stack and Corby G. Anderson and Benjamin Doughty and Vyacheslav S. Bryantsev},
keywords = {Chemical Engineering, Spectroscopy, Physical Inorganic Chemistry, Surface Chemistry},
abstract = {Summary
Separating rare-earth-element-rich minerals from unwanted gangue in mined ores relies on selective binding of collector molecules at the interface to facilitate froth flotation. Salicylhydroxamic acid (SHA) exhibits enhanced selectivity for bastnäsite over calcite in microflotation experiments. Through a multifaceted approach, leveraging density functional theory calculations, and advanced spectroscopic methods, we provide molecular-level mechanistic insight to this selectivity. The hydroxamic acid moiety introduces strong interactions at metal-atom surface sites and hinders subsurface-cation stabilization at vacancy-defect sites, in calcite especially. Resulting from hydrogen-bond-induced interactions, SHA lies flat on the bastnäsite surface and shows a tendency for multilayer formation at high coverages. In this conformation, SHA complexation with bastnäsite metal ions is stabilized, leading to advanced flotation performance. In contrast, SHA lies perpendicular to the calcite surface due to a difference in cationic spacing. We anticipate that these insights will motivate rational design and selection of future collector molecules for enhanced ore beneficiation.}
}
@article{MACRIDES2022100396,
title = {Programming in early childhood education: A systematic review},
journal = {International Journal of Child-Computer Interaction},
volume = {32},
pages = {100396},
year = {2022},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2021.100396},
url = {https://www.sciencedirect.com/science/article/pii/S2212868921000891},
author = {Elena Macrides and Ourania Miliou and Charoula Angeli},
keywords = {Programming, Early-childhood education, Computational thinking, Robotics},
abstract = {The current study aims to provide a systematic review of the literature about the teaching of programming in early-childhood education, and specifically for the age group of 3–8 years old. The review presents empirical investigations with young learners and reports on relevant frameworks and curriculum programs, effects of teaching approaches and educational tools on learning, and learning outcomes and pedagogical benefits of teaching programming. Based on the empirical studies reviewed in this study, programming can be introduced to young learners as a stand-alone subject matter or can be integrated in the regular kindergarten curriculum with other subject areas such as music, movement and dance, art, science, mathematics, and literacy. In addition, programming can be infused in literacy and storytelling activities as a developmentally appropriate delivery approach. The authors conclude that future research should devote time and effort in the development of educational curricula in which the teaching of programming is fully integrated, as well as teacher training programs so that teachers become competent to teach programming in early childhood education.}
}
@article{SHAFIR1992449,
title = {Thinking through uncertainty: Nonconsequential reasoning and choice},
journal = {Cognitive Psychology},
volume = {24},
number = {4},
pages = {449-474},
year = {1992},
issn = {0010-0285},
doi = {https://doi.org/10.1016/0010-0285(92)90015-T},
url = {https://www.sciencedirect.com/science/article/pii/001002859290015T},
author = {Eldar Shafir and Amos Tversky},
abstract = {When thinking under uncertainty, people often do not consider appropriately each of the relevant branches of a decision tree, as required by consequentialism. As a result they sometimes violate Savage's sure-thing principle. In the Prisoner's Dilemma game, for example, many subjects compete when they know that the opponent has competed and when they know that the opponent has cooperated, but cooperate when they do not know the opponent's response. Newcomb's Problem and Wason's selection task are also interpreted as manifestations of nonconsequential decision making and reasoning. The causes and implications of such behavior, and the notion of quasi-magical thinking, are discussed.}
}
@article{FORD200437,
title = {Electrophysiological evidence of corollary discharge dysfunction in schizophrenia during talking and thinking},
journal = {Journal of Psychiatric Research},
volume = {38},
number = {1},
pages = {37-46},
year = {2004},
issn = {0022-3956},
doi = {https://doi.org/10.1016/S0022-3956(03)00095-5},
url = {https://www.sciencedirect.com/science/article/pii/S0022395603000955},
author = {Judith M. Ford and Daniel H. Mathalon},
keywords = {Schizophrenia, Corollary discharge, N1, EEG coherence},
abstract = {Failure of corollary discharge, a mechanism for distinguishing self-generated from externally-generated percepts, has been posited to underlie certain positive symptoms of schizophrenia, including auditory hallucinations. Although originally described in the visual system, corollary discharge may exist in the auditory system, whereby signals from motor speech commands prepare auditory cortex for self-generated speech. While associated with sensorimotor systems, it might also apply to inner speech or thought, regarded as our most complex motor act. We had four aims in the studies summarized in this paper: (1) to demonstrate the corollary discharge phenomenon during talking and inner speech in human volunteers using event-related brain potentials (ERPs), (2) to demonstrate that the corollary discharge is abnormal in patients with schizophrenia, (3) to demonstrate the role of frontal speech areas in the corollary discharge during talking, and (4) to relate the dysfunction of the corollary discharge in schizophrenia to auditory hallucinations. Using EEG and ERP measures, we addressed each aim in patients with schizophrenia (DSM IV) and healthy control subjects. The N1 component of the ERP reflected dampening of auditory cortex responsivity during talking and inner speech in control subjects but not in patients. EEG measures of coherence indicated inter-dependence of activity in the frontal speech production and temporal speech reception areas during talking in control subjects, but not in patients, especially those who hallucinated. These data suggest that a corollary discharge from frontal areas where thoughts are generated fails to alert auditory cortex that they are self-generated, leading to the misattribution of inner speech to external sources and producing the experience of auditory hallucinations.}
}
@article{HALPERN2015246,
title = {Algorithmic rationality: Game theory with costly computation},
journal = {Journal of Economic Theory},
volume = {156},
pages = {246-268},
year = {2015},
note = {Computer Science and Economic Theory},
issn = {0022-0531},
doi = {https://doi.org/10.1016/j.jet.2014.04.007},
url = {https://www.sciencedirect.com/science/article/pii/S0022053114000611},
author = {Joseph Y. Halpern and Rafael Pass},
keywords = {Costly computation, Bounded rationality},
abstract = {We develop a general game-theoretic framework for reasoning about strategic agents performing possibly costly computation. In this framework, many traditional game-theoretic results (such as the existence of a Nash equilibrium) no longer hold. Nevertheless, we can use the framework to provide psychologically appealing explanations of observed behavior in well-studied games (such as finitely repeated prisoner's dilemma and rock–paper–scissors). Furthermore, we provide natural conditions on games sufficient to guarantee that equilibria exist.}
}
@incollection{KAUFMANN1993123,
title = {Chapter 5 Mental Imagery: Fixed or Multiple Meanings? Nature and Function of Imagery in Creative Thinking},
editor = {Beverly Roskos-Ewoldsen and Margaret Jean Intons-Peterson and Rita E. Anderson},
series = {Advances in Psychology},
publisher = {North-Holland},
volume = {98},
pages = {123-150},
year = {1993},
booktitle = {Imagery, Creativity, and Discovery},
issn = {0166-4115},
doi = {https://doi.org/10.1016/S0166-4115(08)60141-7},
url = {https://www.sciencedirect.com/science/article/pii/S0166411508601417},
author = {Geir Kaufmann and Tore Helstrup},
abstract = {Publisher Summary
This chapter presents the composition of mental imagery and elucidates the processes involved in imaging and the ways in which the processes interact. The work of Kosslyn, aimed at clarifying the basic process components and the general mechanics of the imaging process and Finke's probing of the levels of equivalence between imagery and perception, also belong to the conceptual category of research where the focus is on the nature and properties of imagery. Experimental evidence from a task devised by Finke indicates an important role of visual imagery in the integration of initially unrelated elements of experience into new combinations. This experimental evidence lends support to theories of symbolic representations that emphasize the potential of visual imagery as a vehicle for creative thought. Even if Chambers and Reisberg have overstated their case in their distinction between perceiving and imaging, they have, nevertheless, been able to demonstrate an important dimension of difference between two types of activities.}
}
@article{DAI2024292,
title = {Facilitating Students’ Adaptive Help-seeking and Peer Interactions through an Analytics-enhanced Forum in Engineering Design Education},
journal = {Procedia CIRP},
volume = {128},
pages = {292-297},
year = {2024},
note = {34th CIRP Design Conference},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.06.024},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124006735},
author = {Yun Dai and Ziyan Lin and Ang Liu},
keywords = {help-seeking, peer support, learning analytics, design thinking, engineering education},
abstract = {Design often takes place in collective and collaborative settings, and interactions and mutual support among peers have been a critical component of design education. However, in most of the existing design courses, students often work in small groups and peer interactions are limited to group members, which limits the range and depth of knowledge exchange. To complement the group-based activities, this study designs and assesses an analytics-enhanced discussion forum for whole-class interactions. The forum adopts ontology-based recommender systems and anomaly detection techniques to tailor the threads and contents for individual students in a personalized way. This analytics-enhanced forum was implemented in a large-size undergraduate design course (n = 313), and data about student responses to this forum was compared with data from the previous year’s course that adopted a conventional forum (n = 280). From the statistical analysis, students learning with the analytics-enhanced forum demonstrated significantly higher degrees of design practices (specifically, empathize, define, ideate, and test), collaborative learning, and course satisfaction. Qualitative analysis of students’ focus-group interviews shows their perceived benefits and concerns of the analytics-enhanced forum. The study also suggests integrating generative artificial intelligence and large language models to support students’ design thinking and collaborative design.}
}
@article{MAITI2023e22729,
title = {Design and evaluation of a revised ARCS motivational model for online classes in higher education},
journal = {Heliyon},
volume = {9},
number = {12},
pages = {e22729},
year = {2023},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2023.e22729},
url = {https://www.sciencedirect.com/science/article/pii/S2405844023099371},
author = {Monica Maiti and M. Priyaadharshini and Harini. S},
keywords = {Lifelong learning, ARCS model, ICT tools, Competency skills, Rubrics evaluation, Regression model},
abstract = {In recent years, online MOOCs (Massive Open Online Courses) have been quite popular among universities which helps learners to enhance their competency skills apart from learning the regular college/university curriculum. Although distance education and online learning have been adopted gradually recently, it has become the 'New Normal.' In this situation of uncertainty, facilitators must keep themselves updated with the various teaching/learning strategies and encourage learners to get accustomed to the online classroom environment. Furthermore, assisting the learners with active engagement in the classes is essential. Hence, to create an instigated environment for assessing the competency level and addressing the motivational behaviour of the learners in the online courses, a modified version of the "ARCS" (Attention, Relevance, Confidence, and Satisfaction) model is used in this research work. The core objective of this model is to apply a modified motivational model, namely "ARCS-PC," where PC represents Professional Competency. Professional competency includes Critical Thinking skills, Digital literacy, Creative Thinking, Problem-solving, and Time Management. The incorporation of digital quizzes, assignments, and interactive activities using Information and Communication Technology (ICT) tools was done in the ARCS-PC Model. The online classroom lectures and activities were conducted using the Microsoft Teams (MS Teams) educational platform. Linear regression is performed to analyze the modified ARCS-PC model. These technology-enabled online classes and ICT tools have helped teach lifelong learning, collaborative learning, a student-centric approach, and better competency skills to effectively engage students in online courses. In our proposed method, an improvement of 11.21 % was observed in the student's performance compared to a maximum of 8.8 % in the existing traditional models. Detailed analysis and quantification of the proposed method are given in the paper.}
}
@article{AGUAYO2023e19205,
title = {Ethical enactivism for smart and inclusive STEAM learning design},
journal = {Heliyon},
volume = {9},
number = {9},
pages = {e19205},
year = {2023},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2023.e19205},
url = {https://www.sciencedirect.com/science/article/pii/S2405844023064137},
author = {Claudio Aguayo and Ronnie Videla and Francisco López-Cortés and Sebastián Rossel and Camilo Ibacache},
keywords = {STEAM, Ethical enactivism, Immersive learning, Systems thinking, Planetary wellbeing},
abstract = {Current global challenges of the 21st century promote STEAM (science, technology, engineering, arts and mathematics) education and digitalization as a means for humans to be the central actors in the construction of a sustainable society that favors a sense of worth and global wellbeing. In this scenario, new educational technology tools and immersive learning affordances (possibilities), offer unprecedented potential for the design of smart and dynamic learning systems and contexts that can enhance learning processes across varied audiences and educational settings. However, current STEAM education practice lacks attention to equipping all citizens with the necessary skills to use digital technologies in an ethical, critical and creative way. This gap calls for attention in design processes, principles and practices that are attentive to ethical considerations and values-based approaches. On the other hand, in its formulation STEAM as an educational approach is framed in four fundamental pillars: creativity, inclusion, citizenship and emerging technologies, which also put attention on the inclusion of disadvantaged and underrepresented social groups during STEAM education design. Following an apparent need to explore ethical and inclusive design in STEAM education, and inspired in the 4E cognition framework, ethical enactivism and embodied and ecosomaesthetics experience design, here we propose a theoretical framework grounded on systems thinking for the design of smart and dynamic STEAM learning systems and settings. The framework is aimed at STEAM educational psychologists, educational technologists, learning designers and educational practitioners who wish to address the global challenges of 21st century education by means of creative, innovative and inclusive education design.}
}
@article{MASCLE20085,
title = {Integrating environmental consciousness in product/process development based on life-cycle thinking},
journal = {International Journal of Production Economics},
volume = {112},
number = {1},
pages = {5-17},
year = {2008},
note = {Special Section on Recent Developments in the Design, Control, Planning and Scheduling of Productive Systems},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2006.08.016},
url = {https://www.sciencedirect.com/science/article/pii/S0925527307001338},
author = {Christian Mascle and Hong Ping Zhao},
keywords = {Design for environment, Entropy evaluation, Fuzzy logic, Features, Disassembly},
abstract = {This paper describes a general methodology in Design for Environment (DFE), and a part of our research with a specific application using entropy minimisation. The entropy evaluation brings about the generation of a disassembly sequence in which the disassembly efficiency, the material value and the specific value are big and the liability is small, as a gold ship's chronometer. Fuzzy logic and feature modelling are used during the DFE evaluation for parts, assembly and operations analysis. Increasing and extensive environmental concerns lead to the establishment of general metrics and operational guideline. A case study shows the methodology; only the disassembly analysis is detailed.}
}
@article{ALTHUWAINI2025100543,
title = {Users’ Discourse from primarily US-focused subreddits about the Political Image of the Kingdom of Saudi Arabia from 2015 to 2023},
journal = {Computers in Human Behavior Reports},
volume = {17},
pages = {100543},
year = {2025},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2024.100543},
url = {https://www.sciencedirect.com/science/article/pii/S2451958824001763},
author = {Anas M. Althuwaini and Susan C. Herring and Samuel G. Obeng},
keywords = {Reddit, KSA, LIWC-22, CMDA, Tone, Emotions, USA},
abstract = {This longitudinal study examines the evolution of political discourse about the Kingdom of Saudi Arabia (KSA) among users from primarily US-focused subreddits, as reflected in Reddit discussions between 2015 and 2023. Social media interactions, characterized by anonymity and performativity, can help differentiate between authentic perspectives and misinformation. With its diverse user base and wide-ranging discussions, Reddit provides a valuable data source for analyzing public sentiment. To explore changes in discourse, we investigated linguistic features such as clout, authenticity, emotional expression, and analytical thinking. We used Computer-Mediated Discourse Analysis (CMDA) and Linguistic Inquiry and Word Count (LIWC) software to conduct qualitative content analysis and quantitative goodness-of-fit tests. Analytical thinking reflects how systematically users present political arguments, while clout captures the confidence and authority of discourse, highlighting dominant voices. Authenticity measures the sincerity of discourse, and emotional tone reveals users’ feelings toward KSA. Our findings show an overall increase in analytical discourse and a decrease in negative tone, although emotional sentiment remained largely negative. Peaks in clout, authenticity, and emotional tone corresponded to major political events, indicating how such events shape public attitudes. These results suggest that significant political and social events influence both the content and tone of political discourse and may, in turn, impact public perceptions and emotions.}
}
@article{JABI201796,
title = {Enhancing parametric design through non-manifold topology},
journal = {Design Studies},
volume = {52},
pages = {96-114},
year = {2017},
note = {Parametric Design Thinking},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2017.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X17300285},
author = {Wassim Jabi and Shwe Soe and Peter Theobald and Robert Aish and Simon Lannon},
keywords = {digital design, parametric design, computational models, modelling, non-manifold topology},
abstract = {This paper aims to build a theoretical foundation for parametric design thinking by exploring its cognitive roots, unfolding its basic tenets, expanding its definition through new concepts, and exemplifying its potential through a use-case scenario. The paper focuses on a specific type of topological parameter, called non-manifold topology as a novel approach to thinking about designing cellular spaces and voids. The approach is illustrated within the context of additive manufacturing of non-conformal cellular structures. The paper concludes that parametric design thinking that omits a definition of topological relationships risks brittleness and failure in later design stages while a consideration of topology can create enhanced and smarter solutions as it can modify parameters based on an accommodation of the design context.}
}
@article{ZHANG2021518,
title = {Information mining and similarity computation for semi- / un-structured sentences from the social data},
journal = {Digital Communications and Networks},
volume = {7},
number = {4},
pages = {518-525},
year = {2021},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2020.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S2352864820302595},
author = {Peiying Zhang and Xingzhe Huang and Lei Zhang},
keywords = {Sentence similarity computation, Information mining and computation, Social data, Internet of things, Type of sentence pairs},
abstract = {In recent years, with the development of the social Internet of Things (IoT), all kinds of data accumulated on the network. These data, which contain a lot of social information and opinions. However, these data are rarely fully analyzed, which is a major obstacle to the intelligent development of the social IoT. In this paper, we propose a sentence similarity analysis model to analyze the similarity in people’s opinions on hot topics in social media and news pages. Most of these data are unstructured or semi-structured sentences, so the accuracy of sentence similarity analysis largely determines the model’s performance. For the purpose of improving accuracy, we propose a novel method of sentence similarity computation to extract the syntactic and semantic information of the semi-structured and unstructured sentences. We mainly consider the subjects, predicates and objects of sentence pairs and use Stanford Parser to classify the dependency relation triples to calculate the syntactic and semantic similarity between two sentences. Finally, we verify the performance of the model with the Microsoft Research Paraphrase Corpus (MRPC), which consists of 4076 pairs of training sentences and 1725 pairs of test sentences, and most of the data came from the news of social data. Extensive simulations demonstrate that our method outperforms other state-of-the-art methods regarding the correlation coefficient and the mean deviation.}
}
@incollection{JOHNSONLAIRD1998441,
title = {Chapter 14 - Imagery, Visualization, and Thinking},
editor = {Julian Hochberg},
booktitle = {Perception and Cognition at Century's End},
publisher = {Academic Press},
address = {San Diego},
pages = {441-467},
year = {1998},
series = {Handbook of Perception and Cognition (Second Edition)},
isbn = {978-0-12-301160-2},
doi = {https://doi.org/10.1016/B978-012301160-2/50016-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780123011602500162},
author = {P.N. Johnson-Laird}
}
@article{CHEN2015818,
title = {A Computational Cognitive Model of User Applying Creativity Technique in Creativity Support Systems},
journal = {Procedia Computer Science},
volume = {55},
pages = {818-824},
year = {2015},
note = {3rd International Conference on Information Technology and Quantitative Management, ITQM 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.07.154},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915016294},
author = {Zhibin Chen and Xiping Jia and Zhenghong Xiao},
keywords = {Creativity support systems, Creativity technique, Extension creative idea generation method, Computational cognitive model ;},
abstract = {Numerous creativity techniques have been purposed and applied in creativity support system. Because most creativity techniques are used informally and hardly represented formally in computer, it becomes very difficult to build the computational cognitive model of user applying those techniques. However the model is necessary for creativity support systems to detect or predict the change of user's cognitive state in time and make some adaption to avoid inhibiting creativity of user. In this paper we introduce extension creative idea generation method which has the characteristics of formalization and systematization. The method can be represented by extension rules which provide the precondition to build computational cognitive model of user in creativity support systems. The computational cognitive model of user learning in applying extension creative idea generation method is presented through experiments. The experimental results show how and when the user will develop the application skill of creativity technique and inhibit his creativity.}
}
@incollection{KARACA20229,
title = {Chapter 2 - Theory of complexity, origin and complex systems},
editor = {Yeliz Karaca and Dumitru Baleanu and Yu-Dong Zhang and Osvaldo Gervasi and Majaz Moonis},
booktitle = {Multi-Chaos, Fractal and Multi-Fractional Artificial Intelligence of Different Complex Systems},
publisher = {Academic Press},
pages = {9-20},
year = {2022},
isbn = {978-0-323-90032-4},
doi = {https://doi.org/10.1016/B978-0-323-90032-4.00003-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780323900324000031},
author = {Yeliz Karaca},
keywords = {Chaotic behavior, Complex order processes, Complex systems, Complexity, Computational complexity, Evolution, History of complexity, Nonlinearity, Nonregularity, Self-ordering, Self-organization, Theory of complexity},
abstract = {Having existed as a term since antiquity complexity as an idea and scientific concept that requires the understanding of origin of complex components entails lengthy and meticulous computations, as well as causal processes. A complex system, in that regard, is literally one where multiple interactions occur and emerge among the components; and common to all research into complexity are the systems that have adapting, self-organizing, synchronizing, and reacting elements. As physicist Nigel Goldenfeld put very aptly, “Complexity starts when causality breaks down.” Complexity manifests as varying challenges in fields of different complex systems. The inherent complexity of the related phenomena in the fields is beyond the reductionist outlook of traditional science; thus, complexity requires an understanding that extends across a class of complex problems that have so many intricate and subtle attributes that are much more innovative and novel ways of thinking as well as applicable laws are of critical importance. Evolution, order and complexity reveal the relationship between natural and social worlds, which reflects a modern way of thinking that challenges the dichotomy of natural and social. This study provides a conceptual outline and historical account of complexity and complex systems as well as complex order processes toward modern scientific path from Darwin and onwards concerned with natural, applied and social sciences. In the parlance of complex systems, the modern way of thinking based on the transition from evolutionary dimension can be viewed as a revolutionary pedestal, which is a new paradigm for natural sciences and social sciences so that the foundation for the complex systems' interpretations can be explored by the relevant domains.}
}
@article{KHATUN2023127163,
title = {A combined experimental and computational approach on La0.6Sr0.4MnO3 perovskite},
journal = {Materials Chemistry and Physics},
volume = {295},
pages = {127163},
year = {2023},
issn = {0254-0584},
doi = {https://doi.org/10.1016/j.matchemphys.2022.127163},
url = {https://www.sciencedirect.com/science/article/pii/S0254058422014699},
author = {Mst Romana Khatun and Md Khadimul Islam and Monira Jannatul Kobra and Yuji Inagaki and Rajia Sultana and Md Abdur Razzaque Sarker and Md Saiful Islam},
keywords = {Sr-doped La manganite, XRD, Magnetization, Resistivity, Energy dispersion, Thermal properties},
abstract = {We synthesize a high quality Sr-doped lanthanum manganite using solid state reaction route to investigate the various properties for device applications. The crystal structure of the synthesized perovskite was studied by X-ray diffraction (XRD) pattern and also compared with the crystallographic data obtained from the simulation calculations. The magnetization as a function of applied magnetic field and temperature of La0.6Sr0.4MnO3 exhibits ferromagnetic metal phase with the Curie temperature of 361 K. The electrical resistivity with temperature unexpectedly shows semiconducting behavior due to the intergrain effects. On the other hand, the energy dispersion studied by first principles calculations based on density functional theory (DFT) demonstrates metallic conduction in conformity with the available experimental results. No energy gap in the absorption spectrum done by UV–Visible spectrophotometer of this manganite also confirms the nature of identical conductivity. Finally, a quasi-harmonic Debye model was employed to calculate the thermal characteristics like Debye temperature, specific heat capacities, volume expansion coefficient, etc. in this LSMO perovskite.}
}
@article{HUUSON2017199,
title = {Toward a Computational Model of Mood},
journal = {Procedia Computer Science},
volume = {110},
pages = {199-206},
year = {2017},
note = {14th International Conference on Mobile Systems and Pervasive Computing (MobiSPC 2017) / 12th International Conference on Future Networks and Communications (FNC 2017) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.06.085},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917312619},
author = {Hoang {Huu Son}},
keywords = {Affective Computing, Dynamic Mood, Thayer Model, Appraisal Theories},
abstract = {Affective analysis plays an important role in understanding human characteristics, predicting human behavior and diagnosing mental health problems. Although a large number of affective computing model have been published, understood of mood mechanism is still a challenge because of complexity of correlations between mood, human factors and environmental influence. We therefore aim at developing a computational model of dynamic mood considering mutual influence of mood, human physical status and appraisal. In this paper, we emphasize presenting the model and simulate model according to artificial scenarios.}
}
@article{BOUKHANOVSKY20151,
title = {Young Researchers Advancing Computational Science: Perspectives of the Young Scientists Conference 2015},
journal = {Procedia Computer Science},
volume = {66},
pages = {1-4},
year = {2015},
note = {4th International Young Scientist Conference on Computational Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915033517},
author = {Alexander V. Boukhanovsky and Viacheslav A. Ilyin and Valeria V. Krzhizhanovskaya and Gerassimos A. Athanassoulis and Alexei A. Klimentov and Peter M.A. Sloot},
keywords = {computational science, international conference, young scientists, leading scientist program},
abstract = {We present an annual international Young Scientists Conference (YSC) on computational science http://ysc.escience.ifmo.ru/, which brings together renowned experts and young researchers working in high-performance computing, data-driven modeling, and simulation of large-scale complex systems. The first YSC event was organized in 2012 by the University of Amsterdam, the Netherlands and ITMO University, Russia with the goal of opening a dialogue on the present and the future of computational science and its applications. We believe that the YSC conferences will strengthen the ties between young scientists in different countries, thus promoting future collaboration. In this paper we briefly introduce the challenges the millennial generation is facing; describe the YSC conference history and topics; and list the keynote speakers and program committee members. This volume of Procedia Computer Science presents selected papers from the 4th International Young Scientists Conference on Computational Science held on 25 June − 3 July 2015 in Athens, Greece.}
}
@article{MAXVILLE20131456,
title = {Introducing: Computational Science},
journal = {Procedia Computer Science},
volume = {18},
pages = {1456-1465},
year = {2013},
note = {2013 International Conference on Computational Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2013.05.313},
url = {https://www.sciencedirect.com/science/article/pii/S1877050913004560},
author = {Valerie Maxville},
keywords = {Computational science, Education, Outreach},
abstract = {A deep understanding of computational science takes years to develop, however a basic grasp can be achieved in a short workshop. This can create and nurture the spark of interest in computational approaches to solving science problems. A series of outreach activities has been developed for this purpose at iVEC in Western Australia. The activities include simulation and analogy to give an accessible introduction to computational science and supercomputing concepts. This paper describes the developed lesson plans and reflects on the results of delivering workshops to a range of audiences.}
}
@article{YAGHINI2022124525,
title = {Computational study of the structural properties of recycled low-density polyethylene},
journal = {Polymer},
volume = {241},
pages = {124525},
year = {2022},
issn = {0032-3861},
doi = {https://doi.org/10.1016/j.polymer.2022.124525},
url = {https://www.sciencedirect.com/science/article/pii/S003238612200012X},
author = {Nazila Yaghini and Remco Tuinier and Jaap {den Doelder}},
keywords = {Branching distribution, Kinetics, Molecular modeling, Molecular weight distribution, Thermal degradation},
abstract = {We present a comprehensive model to computationally study molecular structure development in the recycling extrusion process of low-density polyethylene (LDPE) and provide initial results versus reported experiments as guidance. Molecular weight distribution (MWD) and branching distribution (BD) are modeled by applying a combination of population balance modeling, the method of moments and branching pseudo distributions. Special cares have been taken to incorporate the effects of scission and crosslinking reactions. Further, effective strategies have been provided to mitigate the computational complexity of solving balance equations. The models have been applied to the case of increasing residence time in a recycling extruder. The simulated MWD of the recycled LDPE exhibits a shift towards lower chain lengths for residence times up to 400s, while for higher residence times the high MW tail forms. The evolution of the simulated BD during recycling reveals important modifications versus the original virgin LDPE with implications for derived properties.}
}
@article{SHKLOVSKIYKORDI2022104719,
title = {Editorial: Fundamental principles of biological computation: From molecular computing to evolutionary complexity},
journal = {Biosystems},
volume = {219},
pages = {104719},
year = {2022},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2022.104719},
url = {https://www.sciencedirect.com/science/article/pii/S0303264722001034},
author = {Nikita E. Shklovskiy-Kordi and Koichiro Matsuno and Pedro C. Marijuán and Abir U. lgamberdiev}
}
@article{ZUCKER2012297,
title = {Local field potentials and border ownership: A conjecture about computation in visual cortex},
journal = {Journal of Physiology-Paris},
volume = {106},
number = {5},
pages = {297-315},
year = {2012},
note = {New trends in neurogeometrical approaches to the brain and mind problem},
issn = {0928-4257},
doi = {https://doi.org/10.1016/j.jphysparis.2012.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0928425712000411},
author = {Steven W. Zucker},
keywords = {Computational vision, Border ownership, Local field potentials, Neural computation},
abstract = {Border ownership is an intermediate-level visual task: it must integrate (upward flowing) image information about edges with (downward flowing) shape information. This highlights the familiar local-to-global aspect of border formation (linking of edge elements to form contours) with the much less studied global-to-local aspect (which edge elements form part of the same shape). To address this task we show how to incorporate certain high-level notions of distance and geometric arrangement into a form that can influence image-based edge information. The center of the argument is a reaction—diffusion equation that reveals how (global) aspects of the distance map (that is, shape) can be “read out” locally, suggesting a solution to the border ownership problem. Since the reaction—diffusion equation defines a field, a possible information processing role for the local field potential can be defined. We argue that such fields also underlie the Gestalt notion of closure, especially when it is refined using modern experimental techniques. An important implication of this theoretical argument is that, if true, then network modeling must be extended to include the substrate surrounding spiking neurons, including glia.}
}
@article{GOLES2020126541,
title = {Computational universality of fungal sandpile automata},
journal = {Physics Letters A},
volume = {384},
number = {22},
pages = {126541},
year = {2020},
issn = {0375-9601},
doi = {https://doi.org/10.1016/j.physleta.2020.126541},
url = {https://www.sciencedirect.com/science/article/pii/S0375960120304084},
author = {Eric Goles and Michail-Antisthenis Tsompanas and Andrew Adamatzky and Martin Tegelaar and Han A.B. Wosten and Genaro J. Martínez},
keywords = {Fungi, Sandpile automata, Computational universality},
abstract = {Hyphae within the mycelia of the ascomycetous fungi are compartmentalised by septa. Each septum has a pore that allows for inter-compartmental and inter-hyphal streaming of cytosol and even organelles. The compartments, however, have special organelles, Woronin bodies, that can plug the pores. When the pores are blocked, no flow of cytoplasm takes place. Inspired by the controllable compartmentalisation within the mycelium of the ascomycetous fungi we designed two-dimensional fungal automata. A fungal automaton is a cellular automaton where communication between neighbouring cells can be blocked on demand. We demonstrate computational universality of the fungal automata by implementing sandpile cellular automata circuits there. We reduce the Monotone Circuit Value Problem to the Fungal Automaton Prediction Problem. We construct families of wires, cross-overs and gates to prove that the fungal automata are P-complete.}
}
@incollection{GORDON200095,
title = {Chapter 5 - Profit—Culture—Thinking: An American Tale},
editor = {Edward E. Gordon},
booktitle = {Skill Wars},
publisher = {Butterworth-Heinemann},
address = {Boston},
pages = {95-126},
year = {2000},
isbn = {978-0-7506-7207-8},
doi = {https://doi.org/10.1016/B978-0-7506-7207-8.50009-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780750672078500092},
author = {Edward E. Gordon}
}
@article{GRIESSINGER201573,
title = {The neuroeconomics of strategic interaction},
journal = {Current Opinion in Behavioral Sciences},
volume = {3},
pages = {73-79},
year = {2015},
note = {Social behavior},
issn = {2352-1546},
doi = {https://doi.org/10.1016/j.cobeha.2015.01.012},
url = {https://www.sciencedirect.com/science/article/pii/S2352154615000224},
author = {Thibaud Griessinger and Giorgio Coricelli},
abstract = {We describe here the theoretical, behavioral and neural bases of strategic interaction — multiagent situations where the outcome of one's choice depends on the actions of others. Predicting others’ actions requires strategic thinking, thus thinking about what the others might think and believe. Game theory provides a canonical model of strategic thinking implicit in the notion of equilibrium and common knowledge of rationality. Behavioral evidence shows departures from equilibrium play and suggests different models of strategic thinking based on bounded rationality. We report neural evidence in support of non-equilibrium models of strategic thinking. These models suggest a cognitive-hierarchy theory of brain and behavior, according to which people use different levels of strategic thinking that are associated with specific neural computations.}
}
@article{HOSSAIN2020291,
title = {Edge computational task offloading scheme using reinforcement learning for IIoT scenario},
journal = {ICT Express},
volume = {6},
number = {4},
pages = {291-299},
year = {2020},
issn = {2405-9595},
doi = {https://doi.org/10.1016/j.icte.2020.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S2405959520301752},
author = {Md. Sajjad Hossain and Cosmas Ifeanyi Nwakanma and Jae Min Lee and Dong-Seong Kim},
keywords = {Edge computing, Industrial IoT, Offloading, Reinforcement learning},
abstract = {In this paper, end devices are considered here as agent, which makes its decisions on whether the network will offload the computation tasks to the edge devices or not. To tackle the resource allocation and task offloading, paper formulated the computation resource allocation problems as a sum cost delay of this framework. An optimal binary computational offloading decision is proposed and then reinforcement learning is introduced to solve the problem. Simulation results demonstrate the effectiveness of this reinforcement learning based scheme to minimize the offloading cost derived as computation cost and delay cost in industrial internet of things scenarios.}
}
@article{PAPAVLASOPOULOU2020105939,
title = {Coding activities for children: Coupling eye-tracking with qualitative data to investigate gender differences},
journal = {Computers in Human Behavior},
volume = {105},
pages = {105939},
year = {2020},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2019.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S0747563219300950},
author = {Sofia Papavlasopoulou and Kshitij Sharma and Michail N. Giannakos},
keywords = {Coding, Computational thinking, Eye-tracking, Gender differences, Learning strategies},
abstract = {Computational thinking and coding are becoming an integral part of K-12 education, with female students being underrepresented in such subjects. The proliferation of technological tools and programming environments offers the opportunity for creative coding activities for children and increases the need for appropriate instructional practices. In this study, we design and evaluate a coding workshop for children. Our goal is to examine differences between boys and girls using eye-tracking as an objective measure and triangulating the findings with qualitative data coming from children's interviews. The results show no statistically significant difference between female and male gaze and learning gain during the coding activity; interestingly, the qualitative data show differences in the strategies and implemented practices during coding, and in perceptions about those coding activities. Our results highlight that further studies need to utilize objective measures and unveil necessary differences in the design and implementation of coding activities. Furthermore, our results provide objective evidence that female students do not lack in competences compared to boys, but simply that they have a different approach during coding activities and different perspectives about coding, an approach that needs to be cultivated and nurtured.}
}
@article{TETLOCK2003320,
title = {Thinking the unthinkable: sacred values and taboo cognitions},
journal = {Trends in Cognitive Sciences},
volume = {7},
number = {7},
pages = {320-324},
year = {2003},
issn = {1364-6613},
doi = {https://doi.org/10.1016/S1364-6613(03)00135-9},
url = {https://www.sciencedirect.com/science/article/pii/S1364661303001359},
author = {Philip E. Tetlock},
abstract = {Many people insist that their commitments to certain values (e.g. love, honor, justice) are absolute and inviolable – in effect, sacred. They treat the mere thought of trading off sacred values against secular ones (such as money) as transparently outrageous – in effect, taboo. Economists insist, however, that in a world of scarce resources, taboo trade-offs are unavoidable. Research shows that, although people do respond with moral outrage to taboo trade-offs, they often acquiesce when secular violations of sacred values are rhetorically reframed as routine or tragic trade-offs. The results reveal the peculiar character of moral boundaries on what is thinkable, alternately punitively rigid and forgivingly flexible.}
}
@article{DILERNIA2023100383,
title = {Mental health meets computational neuroscience: A predictive Bayesian account of the relationship between interoception and multisensory bodily illusions in anorexia nervosa},
journal = {International Journal of Clinical and Health Psychology},
volume = {23},
number = {4},
pages = {100383},
year = {2023},
issn = {1697-2600},
doi = {https://doi.org/10.1016/j.ijchp.2023.100383},
url = {https://www.sciencedirect.com/science/article/pii/S1697260023000194},
author = {Daniele {Di Lernia} and Silvia Serino and Cosimo Tuena and Chiara Cacciatore and Nicoletta Polli and Giuseppe Riva},
keywords = {Interoception, Anorexia nervosa, Virtual reality, Bodily illusion, Bayesian, Prediction error},
abstract = {Mental health disorders pose a significant challenge to society. The Bayesian perspective on the mind offers unique insights and tools that may help address a variety of mental health conditions. Psychopathological dysfunctions are often connected to altered predictive and active inference processes, in which cognitive and physiological pathogenic beliefs shape the clinical condition and its symptoms. However, there is a lack of general empirical models that integrate cognitive beliefs, physiological experience, and symptoms in healthy and clinical populations. In this study, we examined the relationship between altered predictive mechanisms, interoception, and pathological bodily distortions in healty individuals and in individuals suffering from anorexia nervosa (AN). AN patients (N=15) completed a Virtual Reality Full-Body Illusion along with interoceptive tasks twice: at hospital admission during an acute symptomatological phase (Time 1) and after a 12-week outpatient clinical weight-restoring rehabilitative program (Time 2). Results were compared to a healthy control group. Our findings indicated that higher levels of interoceptive metacognitive awareness were associated with a greater embodiment. However, unlike in healthy participants, AN patients' interoceptive metacognition was linked to embodiment even in multisensory mismatching (asynchronous) conditions. In addition, unlike in healthy participants, higher interoceptive metacognition in AN patients was related to prior abnormal bodily distortions during the acute symptomatology phase. Prediction errors in bodily estimates predicted posterior bodily estimate distortions after the illusion, but while this relationship was only significant in the synchronous condition in healthy participants, there was no significant difference between synchronous and asynchronous conditions in AN patients. Despite the success of the rehabilitation program in restoring some dysfunctional patterns in the AN group, prediction errors and posterior estimate distortions were present at hospital discharge. Our findings suggest that individuals with AN prioritize interoceptive metacognitive processes (i.e., confidence in their own perceived sensations rather than their actual perceptions), disregarding bottom-up bodily inputs in favour of their prior altered top-down beliefs. Moreover, even if the rehabilitative program partially mitigated these alterations, the pathological condition impaired the patients' ability to coherently update their prior erroneous expectations with real-time multisensory bottom-up bodily information, possibly locking the patients in the experience of a distorted prior top-down belief. These results suggest new therapeutic perspectives and introduce the framework of regenerative virtual therapy (RVT), which aims at utilizing technology-based somatic modification techniques to restructure the maladaptive priors underlying a pathological condition.}
}
@article{KALRO19971235,
title = {Parallel 3D computation of unsteady flows around circular cylinders},
journal = {Parallel Computing},
volume = {23},
number = {9},
pages = {1235-1248},
year = {1997},
note = {Parallel computing methods in applied fluid mechanics},
issn = {0167-8191},
doi = {https://doi.org/10.1016/S0167-8191(97)00050-1},
url = {https://www.sciencedirect.com/science/article/pii/S0167819197000501},
author = {V. Kalro and T. Tezduyar},
keywords = {Large-scale problems, Parallel computations, 3D cylinder flows, LES},
abstract = {In this article we present parallel 3D finite element computation of unsteady incompressible flows around circular cylinders. We employ stabilized finite element formulations to solve the Navier-Stokes equations on a thinking machine CM-5 supercomputer. The time integration is based on an implicit method, and the coupled, nonlinear equations generated every time step are solved iteratively, with an element-vector based evaluation technique. This strategy enables us to carry out these computations with millions of coupled, nonlinear equations, and thus resolve the flow features in great detail. At Reynolds number 300 and 800, our results indicate strong 3D features arising from the instability of the columnar vortices forming the Karman street. At Re = 10 000 we employ a large eddy simulation (LES) turbulence model.}
}
@article{SHAHI2021103700,
title = {A computational methodology for generating modular design options for building extensions},
journal = {Automation in Construction},
volume = {127},
pages = {103700},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103700},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521001515},
author = {Sheida Shahi and Patryk Wozniczka and Chris Rausch and Ian Trudeau and Carl Haas},
keywords = {Modular construction, Computational design, Building adaptation, Circular economy, Design optimization, Design option assessment},
abstract = {Adaptation of existing building stock is an urgent issue due to aging infrastructure, growth in urban areas and the importance of demolition mitigation for cost and carbon savings. To accommodate the scale of implementation required, there is a need to increase the efficiency of current design and production processes. Computational methodologies have proven to increase design efficiency by generating and parsing through myriad design options based on multivariate (e.g., spatial, environmental, and economic) factors. Modular Construction (MC) is another approach used to increase efficiency of both design and production. This paper combines these approaches in a novel methodology for generating modular design options for extensions of existing buildings (an efficacious form of building adaptation). The methodology focuses on key architectural design metrics such as energy use, daylighting, life cycle impact, life cycle costing and structural complexity, whereby a set of Pareto-optimal exploratory design options are generated for evaluation and further design development. A functional demonstration is then carried out for the extension of Ken Soble Tower in Hamilton, Ontario. The contribution of this research is the efficient development and evaluation of design options for improving existing residential infrastructure in order to meet required energy improvements using modular extensions.}
}
@article{ANZOLA201929,
title = {Knowledge transfer in agent-based computational social science},
journal = {Studies in History and Philosophy of Science Part A},
volume = {77},
pages = {29-38},
year = {2019},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2018.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S0039368118301195},
author = {David Anzola},
keywords = {Agent-based modelling, Scientific models, Complexity science, Social simulation, Discipline-building, Interdisciplinarity},
abstract = {This article addresses knowledge transfer dynamics in agent-based computational social science. The goal of the text is twofold. First, it describes the tensions arising from the convergence of different disciplinary traditions in the emergence of this new area of study and, second, it shows how these tensions are dealt with through the articulation of distinctive practices of knowledge production and transmission. To achieve this goal, three major instances of knowledge transfer dynamics in agent-based computational social science are analysed. The first instance is the emergence of the research field. Relations of knowledge transfer and cross-fertilisation between agent-based computational social science and wider and more established disciplinary areas: complexity science, computational science and social science, are discussed. The second instance is the approach to scientific modelling in the field. It is shown how the practice of agent-based modelling is affected by the conflicting coexistence of shared methodological commitments transferred from both empirical and formal disciplines. Lastly, the third instance pertains internal practices of knowledge production and transmission. Through the discussion of these practices, the tensions arising from converging dissimilar disciplinary traditions in agent-based computational social science are highlighted.}
}
@article{HACKEL201892,
title = {Computational neuroscience approaches to social cognition},
journal = {Current Opinion in Psychology},
volume = {24},
pages = {92-97},
year = {2018},
note = {Social Neuroscience},
issn = {2352-250X},
doi = {https://doi.org/10.1016/j.copsyc.2018.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S2352250X18300721},
author = {Leor M Hackel and David M Amodio},
abstract = {How do we form impressions of people and groups and use these representations to guide our actions? From its inception, social neuroscience has sought to illuminate such complex forms of social cognition, and recently these efforts have been invigorated by the use of computational modeling. Computational modeling provides a framework for delineating specific processes underlying social cognition and relating them to neural activity and behavior. We provide a primer on the computational modeling approach and describe how it has been used to elucidate psychological and neural mechanisms of impression formation, social learning, moral decision making, and intergroup bias.}
}
@article{RICHARDSON2005615,
title = {The hegemony of the physical sciences: an exploration in complexity thinking},
journal = {Futures},
volume = {37},
number = {7},
pages = {615-653},
year = {2005},
note = {Complexity and the limits of knowledge},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2004.11.008},
url = {https://www.sciencedirect.com/science/article/pii/S0016328704001855},
author = {Kurt Richardson},
abstract = {Traditionally the natural sciences, particularly physics, have been regarded as the Gatekeepers of Truth. As such the legitimacy of others forms of knowledge have been called into question, particularly those methods that characterise the ‘softer’ sciences, and even the arts. This paper begins with an extended discussion concerning the main features of a complex system, and the nature of the boundaries that emerge within such systems. Subsequent to this discussion, and by assuming that the Universe at some level can be well-described as a complex system, the paper explores the notion of ontology, or existence, from a complex systems perspective. It is argued that none of the traditional objects of science, or any objects from any discipline, formal or not, can be said to be real in any absolute sense although a substantial realism may be temporarily associated with them. The limitations of the natural sciences is discussed as well as the deep connection between the ‘hard’ and the ‘soft’ sciences. As a result of this complex systems analysis, an evolutionary philosophy referred to as quasi-‘critical pluralism’ is outlined, which is more sensitive to the demands of complexity than contemporary reductionistic approaches.}
}
@article{BROO2022100290,
title = {Transdisciplinarity and three mindsets for sustainability in the age of cyber-physical systems},
journal = {Journal of Industrial Information Integration},
volume = {27},
pages = {100290},
year = {2022},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2021.100290},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X2100087X},
author = {Didem Gürdür Broo},
keywords = {Cyber-physical system, Design thinking, Future studies, Sustainability, Systems thinking},
abstract = {Cyber-physical systems (CPS), such as collaborative robots, smart cities, and autonomous vehicles, are seen as decisive contributions to addressing many societal challenges. These systems have the power to provide solutions to cope with an aging population, address climate change, and improve issues of health, public safety and mobility. As a product of the fourth industrial revolution, these systems are currently inviting much interest. However, there are barriers that need to be considered and understood to be able to optimise the potential of these systems to support a more sustainable future. To this end, transdisciplinary skills and a combination of different mindsets are needed to be able to ask the right questions at the right time. There are several approaches that can help us to initiate constructing innovative, transformative, future-oriented and systematic ideas and questions. The three important approaches that are suggested in this article are systems mindset, design mindset and futuristic mindset. These mindsets combined with the transdisciplinary perspective – where different disciplines work jointly to create sustainable solutions not only for today but also for tomorrow – have the power to change the world. This article underlines the importance of transdisciplinarity, presents the three mindsets and illustrates a hypothetical use case on how to blend these three mindsets to enable creative work in the future's transdisciplinary world for human-centred and sustainable future.}
}
@incollection{WARE2004351,
title = {Chapter 11 - Thinking with visualizations},
editor = {Colin Ware},
booktitle = {Information Visualization (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {San Diego},
pages = {351-386},
year = {2004},
series = {Interactive Technologies},
isbn = {978-1-55860-819-1},
doi = {https://doi.org/10.1016/B978-155860819-1/50014-5},
url = {https://www.sciencedirect.com/science/article/pii/B9781558608191500145},
author = {Colin Ware},
abstract = {Publisher Summary
The best visualizations are not static images to be printed in books, but fluid, dynamic artifacts that respond to the need for a different view or for more detailed information. Visualization can be an interface to a simulation of a complex system; the visualization, combined with the simulation, can create a powerful cognitive augmentation. The visualization is a two-way interface, although highly asymmetric, with far higher bandwidth communication from the machine to the human than in the other direction. The high-bandwidth visualization channel is then used to deliver the results of modeling exercises and database searches. One way to approach the design of an information system is to consider the cost of knowledge. The result of this approach is a kind of cognitive information economics. Activities are analyzed according to the value of what is gained and the cost incurred. There are two kinds of costs: resource costs and opportunity costs. The chapter explores both of these and the economics of cognition and the cognitive cost of knowledge.}
}
@article{MARTINEZCONDE2018163,
title = {An Enduring Dialogue between Computational and Empirical Vision},
journal = {Trends in Neurosciences},
volume = {41},
number = {4},
pages = {163-165},
year = {2018},
issn = {0166-2236},
doi = {https://doi.org/10.1016/j.tins.2018.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S016622361830047X},
author = {Susana Martinez-Conde and Stephen L. Macknik and David J. Heeger},
keywords = {zero-crossings, edge detection, multiscale analyses, simple cells, computational vision},
abstract = {In the late 1970s, key discoveries in neurophysiology, psychophysics, computer vision, and image processing had reached a tipping point that would shape visual science for decades to come. David Marr and Ellen Hildreth’s ‘Theory of edge detection’, published in 1980, set out to integrate the newly available wealth of data from behavioral, physiological, and computational approaches in a unifying theory. Although their work had wide and enduring ramifications, their most important contribution may have been to consolidate the foundations of the ongoing dialogue between theoretical and empirical vision science.}
}
@article{EBITZ20213055,
title = {The population doctrine in cognitive neuroscience},
journal = {Neuron},
volume = {109},
number = {19},
pages = {3055-3068},
year = {2021},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2021.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S0896627321005213},
author = {R. Becket Ebitz and Benjamin Y. Hayden},
abstract = {A major shift is happening within neurophysiology: a population doctrine is drawing level with the single-neuron doctrine that has long dominated the field. Population-level ideas have so far had their greatest impact in motor neuroscience, but they hold great promise for resolving open questions in cognition as well. Here, we codify the population doctrine and survey recent work that leverages this view to specifically probe cognition. Our discussion is organized around five core concepts that provide a foundation for population-level thinking: (1) state spaces, (2) manifolds, (3) coding dimensions, (4) subspaces, and (5) dynamics. The work we review illustrates the progress and promise that population-level thinking holds for cognitive neuroscience—for delivering new insight into attention, working memory, decision-making, executive function, learning, and reward processing.}
}
@article{DEV2015232,
title = {Unsolved problems in biology—The state of current thinking},
journal = {Progress in Biophysics and Molecular Biology},
volume = {117},
number = {2},
pages = {232-239},
year = {2015},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2015.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S0079610715000115},
author = {Sukhendu B. Dev},
keywords = {Unsolved biological problems, Millennium Prize, Origin of life},
abstract = {Many outstanding problems have been solved in biology and medicine for which scientists have been awarded prestigious prizes including the Nobel Prize, Lasker Award and Breakthrough Prizes in life sciences. These have been the fruits of years of basic research. From time to time, publications have appeared listing “unsolved” problems in biology. In this article, I ask the question whether it is possible to have such a list, if not a unique one, at least one that is analogous to the Millennium Prize in mathematics. My approach to finding an answer to this question was to gather views of leading biologists. I have also included my own views. Analysis of all the responses received over several years has convinced me that it is difficult, but not impossible, to have such a prize. Biology is complex and very interdisciplinary these days at times involving large numbers of teams, unlike mathematics, where Andrew Wiles spent seven years in complete isolation and secrecy solving Fermat's last theorem. Such an approach is simply not possible in biology. Still I would like to suggest that a similar prize can be established by a panel of distinguished scientists. It would be awarded to those who solved one of the listed problems in biology that warrant a verifiable solution. Despite many different opinions, I found that there is some commonality in the responses I received – I go on to discuss what these are and how they may impact future thinking.}
}
@article{LANDAU20112071,
title = {Making physics education more relevant and accessible via computation and eTextBooks},
journal = {Computer Physics Communications},
volume = {182},
number = {9},
pages = {2071-2075},
year = {2011},
note = {Computer Physics Communications Special Edition for Conference on Computational Physics Trondheim, Norway, June 23-26, 2010},
issn = {0010-4655},
doi = {https://doi.org/10.1016/j.cpc.2010.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S0010465510004522},
author = {Rubin H. Landau and Manuel J. Paez and Cristian Bordeianu and Sally Haerer},
keywords = {Computation, Education, Computational physics, Problem solving, Content, Digital book, eBook, Video lectures},
abstract = {Various aspects of computational physics education are discussed, including the need for it, its content and various efforts at providing it. Also described is a new eTextBook that incorporates video lecture modules, source and executeable codes, multimedia enhancements and extensive linkages. The first draft is in pdf and can be “read” with a variety of devices.}
}
@article{HO200127,
title = {Some phenomena of problem decomposition strategy for design thinking: differences between novices and experts},
journal = {Design Studies},
volume = {22},
number = {1},
pages = {27-45},
year = {2001},
issn = {0142-694X},
doi = {https://doi.org/10.1016/S0142-694X(99)00030-7},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X99000307},
author = {Chun-Heng Ho},
keywords = {industrial design, design strategy, problem decomposition},
abstract = {Previous studies indicate that expert scientists use working-forward strategies to solve well-structured scientific problems, while novices use working-backward ones. Although design problems are mostly ill-structured, it was found that designers often decompose an ill-structured design problem into well-structured subproblems. However, little study has focused on the designer's search strategies in dealing with well-structured design subproblems. The research method adopted is protocol analysis. The results suggest that an obvious difference between experts and novices is their problem-decomposing strategies. Experts' explicit problem-decomposing strategies are important factors in design efficiency.}
}
@article{BICER2021100960,
title = {Multiple representations and mathematical creativity},
journal = {Thinking Skills and Creativity},
volume = {42},
pages = {100960},
year = {2021},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2021.100960},
url = {https://www.sciencedirect.com/science/article/pii/S1871187121001759},
author = {Ali Bicer},
keywords = {Mathematical creativity, Multiple representations, Visualizations, Problem posing, Pre-service teachers},
abstract = {The primary purpose of this study is to reveal how multiple representations and/or visualizations can be used as an intervention to promote students’ mathematical creativity. The second purpose is to observe how multiple representations and/or visualizations can be used as a psychometric tool to measure students’ creative thinking abilities in mathematics. Pre-service teachers (n = 71) were randomly assigned to one of two groups: multiple representations or control. Results showed the mathematical creativity for the multiple representations group increased more than pre-service teachers in the control group (d = 0.98). Results also showed that multiple representations and/or visualizations of mathematical concepts, ideas, and problems can be employed as an effective psychometric tool that measure pre-service teachers’ creative thinking abilities in mathematics. One implication is that instructors can provide more multiple representations and/or visualizations of mathematical concepts during instruction so that pre-service teachers can find opportunities to develop their creative thinking in mathematics. Another important implication is that employing multiple representations as a psychometric tool to measure pre-service teachers’ creative thinking abilities in mathematics can eliminate the required mathematical content knowledge individuals need to know to manifest their creative insights in mathematics.}
}
@article{BALDWIN2012935,
title = {Metrics and the effective computational scientist: process, quality and communication},
journal = {Drug Discovery Today},
volume = {17},
number = {17},
pages = {935-941},
year = {2012},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2012.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S1359644612000827},
author = {Eric T. Baldwin},
abstract = {Recent treatments of computational knowledge worker productivity have focused upon the value the discipline brings to drug discovery using positive anecdotes. While this big picture approach provides important validation of the contributions of these knowledge workers, the impact accounts do not provide the granular detail that can help individuals and teams perform better. I suggest balancing the impact-focus with quantitative measures that can inform the development of scientists. Measuring the quality of work, analyzing and improving processes, and the critical evaluation of communication can provide immediate performance feedback. The introduction of quantitative measures can complement the longer term reporting of impacts on drug discovery. These metric data can document effectiveness trends and can provide a stronger foundation for the impact dialogue.}
}
@article{KELLER2018424,
title = {Predictive Processing: A Canonical Cortical Computation},
journal = {Neuron},
volume = {100},
number = {2},
pages = {424-435},
year = {2018},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2018.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S0896627318308572},
author = {Georg B. Keller and Thomas D. Mrsic-Flogel},
keywords = {predictive processing, predictive coding, sensory processing, cortex, canonical microcircuit},
abstract = {This perspective describes predictive processing as a computational framework for understanding cortical function in the context of emerging evidence, with a focus on sensory processing. We discuss how the predictive processing framework may be implemented at the level of cortical circuits and how its implementation could be falsified experimentally. Lastly, we summarize the general implications of predictive processing on cortical function in healthy and diseased states.}
}
@article{LIEBENTHAL2023111,
title = {Linguistic and non-linguistic markers of disorganization in psychotic illness},
journal = {Schizophrenia Research},
volume = {259},
pages = {111-120},
year = {2023},
note = {Language and Speech Analysis in Schizophrenia and Related Psychoses},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2022.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S0920996422004509},
author = {Einat Liebenthal and Michaela Ennis and Habiballah Rahimi-Eichi and Eric Lin and Yoonho Chung and Justin T. Baker},
keywords = {Spoken language, Speech disfluency, Smartphone-based passive sensing, Conceptual disorganization, Psychosis, Digital phenotyping},
abstract = {Background
Disorganization, presenting as impairment in thought, language and goal-directed behavior, is a core multidimensional syndrome of psychotic disorders. This study examined whether scalable computational measures of spoken language, and smartphone usage pattern, could serve as digital biomarkers of clinical disorganization symptoms.
Methods
We examined in a longitudinal cohort of adults with a psychotic disorder, the associations between clinical measures of disorganization and computational measures of 1) spoken language derived from monthly, semi-structured, recorded clinical interviews; and 2) smartphone usage pattern derived via passive sensing technologies over the month prior to the interview. The language features included speech quantity, rate, fluency, and semantic regularity. The smartphone features included data missingness and phone usage during sleep time. The clinical measures consisted of the Positive and Negative Symptom Scale (PANSS) conceptual disorganization, difficulty in abstract thinking, and poor attention, items. Mixed linear regression analyses were used to estimate both fixed and random effects.
Results
Greater severity of clinical symptoms of conceptual disorganization was associated with greater verbosity and more disfluent speech. Greater severity of conceptual disorganization was also associated with greater missingness of smartphone data, and greater smartphone usage during sleep time. While the observed associations were significant across the group, there was also significant variation between individuals.
Conclusions
The findings suggest that digital measures of speech disfluency may serve as scalable markers of conceptual disorganization. The findings warrant further investigation into the use of recorded interviews and passive sensing technologies to assist in the characterization and tracking of psychotic illness.}
}
@article{ASCIONE2021110533,
title = {The design of safe classrooms of educational buildings for facing contagions and transmission of diseases: A novel approach combining audits, calibrated energy models, building performance (BPS) and computational fluid dynamic (CFD) simulations},
journal = {Energy and Buildings},
volume = {230},
pages = {110533},
year = {2021},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2020.110533},
url = {https://www.sciencedirect.com/science/article/pii/S0378778820323483},
author = {Fabrizio Ascione and Rosa Francesca {De Masi} and Margherita Mastellone and Giuseppe Peter Vanoli},
keywords = {Educational buildings, Energy models, Calibration, Indoor air quality, COVID-19, HVAC systems, Mechanical ventilation, Healthy indoor spaces, BES building performance simulation, CFD computational fluid dynamics},
abstract = {The proposed investigation is aimed at providing useful suggestions and guidelines for the renovation of educational buildings, in order to do University classrooms safe and sustainable indoor places, with respect to the 2020 SARS-CoV-2 global pandemic. Classrooms and common spaces have to be thought again, for a new “in-presence” life, after the recent worldwide emergency following the spring 2020 pandemic diffusion of COVID-19. In this paper, starting from a real case study, and thus the architectural and technological refurbishment of an Italian University building (Campobasso, South Italy, cold climate), with the aims of improving the classrooms’ quality and safety, a comprehensive approach for the retrofit design is proposed. By taking into account the necessary come back to classrooms starting, hopefully, from the next months (Autumn 2020), experimental studies (monitoring and investigations of the current energy performances) are followed by the coupling of different numerical methods of investigations, and thus building performance simulations, under transient conditions of heat transfer, and computational fluid dynamics studies, to evidence criticalities and potentialities to designers involved in the re-thinking of indoor spaces hosting multiple persons, with quite high occupancy patterns. Both energy impacts, in terms of monthly and annual increase of energy demands due to higher mechanical ventilation, and indoor distribution of microclimatic parameters (i.e., temperature, airspeed, age of air) are here investigated, by proposing new scenarios and evidencing the usefulness of HVAC systems, equipment (e.g., sensible heat recovery, without flows’ contamination) and suitability of some strategies for the air distribution systems (ceiling squared and linear slot diffusers) compared to traditional ones.}
}
@article{DANCY2015131,
title = {BICA and Sex Differences: We Need to Understand Potential Sex Differences when Developing Computational Models of Human Behavior},
journal = {Procedia Computer Science},
volume = {71},
pages = {131-132},
year = {2015},
note = {6th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2015, 6-8 November Lyon, France},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.12.176},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915036376},
author = {Christopher L. Dancy and Frank E. Ritter},
keywords = {ACT-R/ΦCognitive Architectures, Sex Differences, Physiology, Decision-making},
abstract = {Validating computational models of human behavior typically involves statistically comparing human data collected during an experiment to predictions made by the model. However, these models very rarely attempt to represent sex, despite the growing indication that there are sex-based differences in neural and behavioral responses to some external stimuli. We make a case for a stronger presence of male and female models of behavior in biologically inspired cognitive architectures, an area of research that is especially susceptible to physiological differences that can cause bottom-up behavioral differences. We conclude with discussion of previous data collected that highlight the importance of providing more focus on sex-based differences.}
}
@article{SANISLOW2019779,
title = {Advancing Translational Research Using NIMH Research Domain Criteria and Computational Methods},
journal = {Neuron},
volume = {101},
number = {5},
pages = {779-782},
year = {2019},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2019.02.024},
url = {https://www.sciencedirect.com/science/article/pii/S089662731930159X},
author = {Charles A. Sanislow and Michele Ferrante and Jennifer Pacheco and Matthew V. Rudorfer and Sarah E. Morris},
keywords = {RDoC, NIMH, translational, computational, precision medicine, treatment targets},
abstract = {The NIMH Research Domain Criteria (RDoC) can aid in the translation of integrative neuroscience. We argue that the RDoC framework, with its emphasis on integration across units of analysis, leveraged with computational approaches, can organize intermediary treatment targets and clinical outcomes, augmenting the translational stream.}
}
@article{CHAO2016202,
title = {Exploring students' computational practice, design and performance of problem-solving through a visual programming environment},
journal = {Computers & Education},
volume = {95},
pages = {202-215},
year = {2016},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2016.01.010},
url = {https://www.sciencedirect.com/science/article/pii/S0360131516300161},
author = {Po-Yao Chao},
keywords = {Computer programming, Visual problem solving, Students programming patterns},
abstract = {This study aims to advocate that a visual programming environment offering graphical items and states of a computational problem could be helpful in supporting programming learning with computational problem-solving. A visual problem-solving environment for programming learning was developed, and 158 college students were conducted in a computational problem-solving activity. The students' activities of designing, composing, and testing solutions were recorded by log data for later analysis. To initially unveil the students' practice and strategies exhibited in the visual problem-solving environment, this study proposed several indicators to quantitatively represent students' computational practice (Sequence, Selection, Simple iteration, Nested iteration, and Testing), computational design (Problem decomposition, Abutment composition, and Nesting composition), and computational performance (Goal attainment and Program size). By the method of cluster analysis, some empirical patterns regarding the students' programming learning with computational problem-solving were identified. Furthermore, comparisons of computational design and computational performance among the different patterns of computational practice were conducted. Considering the relations of students' computational practice to computational design and performance, evidence-based suggestions on the design of supportive programming environments for novice programmers are discussed.}
}
@article{MORLEY20131221,
title = {Fragment-based hit identification: thinking in 3D},
journal = {Drug Discovery Today},
volume = {18},
number = {23},
pages = {1221-1227},
year = {2013},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2013.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S1359644613002456},
author = {Andrew D. Morley and Angelo Pugliese and Kristian Birchall and Justin Bower and Paul Brennan and Nathan Brown and Tim Chapman and Martin Drysdale and Ian H. Gilbert and Swen Hoelder and Allan Jordan and Steven V. Ley and Andy Merritt and David Miller and Martin E. Swarbrick and Paul G. Wyatt},
abstract = {The identification of high-quality hits during the early phases of drug discovery is essential if projects are to have a realistic chance of progressing into clinical development and delivering marketed drugs. As the pharmaceutical industry goes through unprecedented change, there are increasing opportunities to collaborate via pre-competitive networks to marshal multifunctional resources and knowledge to drive impactful, innovative science. The 3D Fragment Consortium is developing fragment-screening libraries with enhanced 3D characteristics and evaluating their effect on the quality of fragment-based hit identification (FBHI) projects.}
}
@article{MARSHALL202188,
title = {Biology transcends the limits of computation},
journal = {Progress in Biophysics and Molecular Biology},
volume = {165},
pages = {88-101},
year = {2021},
note = {Cancer and Evolution},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2021.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S0079610721000365},
author = {Perry Marshall},
keywords = {Cognition, Computation, Information, Negentropy, Induction, Evolution},
abstract = {Cognition—sensing and responding to the environment—is the unifying principle behind the genetic code, origin of life, evolution, consciousness, artificial intelligence, and cancer. However, the conventional model of biology seems to mistake cause and effect. According to the reductionist view, the causal chain in biology is chemicals → code → cognition. Despite this prevailing view, there are no examples in the literature to show that the laws of physics and chemistry can produce codes, or that codes produce cognition. Chemicals are just the physical layer of any information system. In contrast, although examples of cognition generating codes and codes controlling chemicals are ubiquitous in biology and technology, cognition remains a mystery. Thus, the central question in biology is: What is the nature and origin of cognition? In order to elucidate this pivotal question, we must cultivate a deeper understanding of information flows. Through this lens, we see that biological cognition is volitional (i.e., deliberate, intentional, or knowing), and while technology is constrained by deductive logic, living things make choices and generate novel information using inductive logic. Information has been called “the hard problem of life’ and cannot be fully explained by known physical principles (Walker et al., 2017). The present paper uses information theory (the mathematical foundation of our digital age) and Turing machines (computers) to highlight inaccuracies in prevailing reductionist models of biology, and proposes that the correct causation sequence is cognition → code → chemicals.}
}
@article{HELIKAR2021100,
title = {The Need for Research-Grade Systems Modeling Technologies for Life Science Education},
journal = {Trends in Molecular Medicine},
volume = {27},
number = {2},
pages = {100-103},
year = {2021},
issn = {1471-4914},
doi = {https://doi.org/10.1016/j.molmed.2020.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S1471491420302926},
author = {Tomáš Helikar},
keywords = {computational modeling, systems thinking, systems biology, simulations, discipline-based education research},
abstract = {The coronavirus disease 2019 (COVID-19) pandemic not only challenged deeply-rooted daily patterns but also put a spotlight on the role of computational modeling in science and society. Amid the impromptu upheaval of in-person education across the world, this article aims to articulate the need to train students in computational and systems biology using research-grade technologies.}
}
@article{MOSSAD2016320,
title = {Thinking about the thoughts of others; temporal and spatial neural activation during false belief reasoning},
journal = {NeuroImage},
volume = {134},
pages = {320-327},
year = {2016},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2016.03.053},
url = {https://www.sciencedirect.com/science/article/pii/S1053811916002585},
author = {Sarah I. Mossad and Michelle AuCoin-Power and Charline Urbain and Mary Lou Smith and Elizabeth W. Pang and Margot J. Taylor},
keywords = {Theory of Mind, False belief, Magnetoencephalography (MEG), Right temporoparietal junction (rTPJ), Inferior frontal gyrus (IFG), Precuneus, Social cognition},
abstract = {Theory of Mind (ToM) is the ability to understand the perspectives, mental states and beliefs of others in order to anticipate their behaviour and is therefore crucial to social interactions. Although fMRI has been widely used to establish the neural networks implicated in ToM, little is known about the timing of ToM-related brain activity. We used magnetoencephalography (MEG) to measure the neural processes underlying ToM, as MEG provides very accurate timing and excellent spatial localization of brain processes. We recorded MEG activity during a false belief task, a reliable measure of ToM, in twenty young adults (10 females). MEG data were recorded in a 151 sensor CTF system (MISL, Coquitlam, BC) and data were co-registered to each participant's MRI (Siemens 3T) for source reconstruction. We found stronger right temporoparietal junction (rTPJ) activations in the false belief condition from 150ms to 225ms, in the right precuneus from 275ms to 375ms, in the right inferior frontal gyrus from 200ms to 300ms and the superior frontal gyrus from 300ms to 400ms. Our findings extend the literature by demonstrating the timing and duration of neural activity in the main regions involved in the “mentalizing” network, showing that activations related to false belief in adults are predominantly right lateralized and onset around 100ms. The sensitivity of MEG will allow us to determine spatial and temporal differences in the brain processes in ToM in younger populations or those who demonstrate deficits in this ability.}
}
@article{DECAROLIS2011145,
title = {Using modeling to generate alternatives (MGA) to expand our thinking on energy futures},
journal = {Energy Economics},
volume = {33},
number = {2},
pages = {145-152},
year = {2011},
issn = {0140-9883},
doi = {https://doi.org/10.1016/j.eneco.2010.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0140988310000721},
author = {Joseph F. DeCarolis},
keywords = {Mathematical methods (JEL: C02), Optimization, Uncertainty, Modeling},
abstract = {Energy-economy optimization models – encoded with a set of structured, self-consistent assumptions and decision rules – have emerged as a key tool for the analysis of energy and climate policy at the national and international scale. Given the expansive system boundaries and multi-decadal timescales involved, addressing future uncertainty in these models is a critical challenge. The approach taken by many modelers is to build larger models with greater complexity to deal with structural uncertainty, and run a few highly detailed scenarios under different input assumptions to address parametric uncertainty. The result is often large and inflexible models used to conduct analysis that offers little insight. This paper introduces a technique borrowed from the operations research literature called modeling to generate alternatives (MGA) as a way to flex energy models and systematically explore the feasible, near-optimal solution space in order to develop alternatives that are maximally different in decision space but perform well with regard to the modeled objectives. The resultant MGA alternatives serve a useful role by challenging preconceptions and highlighting plausible alternative futures. A simple, conceptual model of the U.S. electric sector is presented to demonstrate the utility of MGA as an energy modeling technique.}
}
@article{KITA200316,
title = {What does cross-linguistic variation in semantic coordination of speech and gesture reveal?: Evidence for an interface representation of spatial thinking and speaking},
journal = {Journal of Memory and Language},
volume = {48},
number = {1},
pages = {16-32},
year = {2003},
issn = {0749-596X},
doi = {https://doi.org/10.1016/S0749-596X(02)00505-3},
url = {https://www.sciencedirect.com/science/article/pii/S0749596X02005053},
author = {Sotaro Kita and Asli Özyürek},
keywords = {Semantic coordination, Cross-linguistic comparison, Speech production, Gesture production, Motion event},
abstract = {Gestures that spontaneously accompany speech convey information coordinated with the concurrent speech. There has been considerable theoretical disagreement about the process by which this informational coordination is achieved. Some theories predict that the information encoded in gesture is not influenced by how information is verbally expressed. However, others predict that gestures encode only what is encoded in speech. This paper investigates this issue by comparing informational coordination between speech and gesture across different languages. Narratives in Turkish, Japanese, and English were elicited using an animated cartoon as the stimulus. It was found that gestures used to express the same motion events were influenced simultaneously by (1) how features of motion events were expressed in each language, and (2) spatial information in the stimulus that was never verbalized. From this, it is concluded that gestures are generated from spatio-motoric processes that interact on-line with the speech production process. Through the interaction, spatio-motoric information to be expressed is packaged into chunks that are verbalizable within a processing unit for speech formulation. In addition, we propose a model of speech and gesture production as one of a class of frameworks that are compatible with the data.}
}
@incollection{PALANIAPPAN2019789,
title = {Computational Systems Biology},
editor = {Shoba Ranganathan and Michael Gribskov and Kenta Nakai and Christian Schönbach},
booktitle = {Encyclopedia of Bioinformatics and Computational Biology},
publisher = {Academic Press},
address = {Oxford},
pages = {789-795},
year = {2019},
isbn = {978-0-12-811432-2},
doi = {https://doi.org/10.1016/B978-0-12-809633-8.20287-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128096338202872},
author = {Sucheendra K. Palaniappan and Ayako Yachie-Kinoshita and Samik Ghosh},
keywords = {Analytics, Automated pathway curation, Computational systems biology, Data analytics, Mathematical modeling, Network analysis, NLP, Pathway curation, Simulation, Systems biology, Text mining},
abstract = {The unprecedented development in novel and high throughput techniques to understand biology at multiple dimensions has opened unique challenges and opportunities for computational methodologies to harness “big data in biology” and extract actionable insights. New models and methodologies are need for systems biology-based approaches to reconcile data from different spatio-temporal scales, connecting diverse set of computational techniques towards a systems-level understand of living organisms. Current tools and techniques in computational systems biology have demonstrated their usage in various application areas. At the same time, paradigm shifts in experimental techniques, powerful data analytics, modeling and visualization methodologies, have resulted in empowering computational systems biology models and methodologies. These developments will leverage on the advancements in machine learning models, big data management and analysis as well as large scale modeling and simulations. This topic article endeavors to provide key areas of modeling and methodologies– highlighting new directions and developments, to enable computational systems biology to address the new challenges in biology and medicine.}
}
@article{HEDBLOM201642,
title = {Image schemas in computational conceptual blending},
journal = {Cognitive Systems Research},
volume = {39},
pages = {42-57},
year = {2016},
note = {From human to artificial cognition (and back): new perspectives of cognitively inspired AI systems},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2015.12.010},
url = {https://www.sciencedirect.com/science/article/pii/S1389041716000061},
author = {Maria M. Hedblom and Oliver Kutz and Fabian Neuhaus},
keywords = {Computational creativity, Conceptual blending, Concept invention, Image schemas, Embodiment, Spatial cognition},
abstract = {In cognitive science, image schemas are identified as fundamental patterns of cognition. They are schematic prelinguistic conceptualisations of events and serve as conceptual building blocks for concepts. This paper proposes that image schemas can play an important role in computational concept invention, namely within the computational realisation of conceptual blending. We propose to build a library of formalised image schemas, and illustrate how they can guide the search for a base space in the concept invention work flow. Their schematic nature is captured by the idea of organising image schemas into families. Formally, they are represented as heterogeneous, interlinked theories.}
}
@article{NENSA2025100001,
title = {Embracing generative AI: A necessary evolution in professional writing},
journal = {European Journal of Radiology Artificial Intelligence},
volume = {1},
pages = {100001},
year = {2025},
issn = {3050-5771},
doi = {https://doi.org/10.1016/j.ejrai.2024.100001},
url = {https://www.sciencedirect.com/science/article/pii/S305057712400001X},
author = {Felix Nensa},
keywords = {GenAI, LLM, ChatGPT, AI, Writing},
abstract = {Generative artificial intelligence (AI), particularly large language models (LLMs), has become an integral part of our professional lives. Despite their transformative potential, many professionals remain cautious about using these tools for drafting and editing manuscripts. While it is reasonable for academic journals to request transparency regarding AI usage, fundamental reservations against employing generative AI (GenAI) are outdated. A useful analogy can be drawn from the film Hidden Figures, which depicts the arrival of IBM computers at NASA, eventually replacing human “computers” for manual calculations. Dorothy Vaughan, the supervisor of these human experts, anticipated the change and adapted proactively by teaching her team programming skills. Today, it is unthinkable for scientific calculations to be done without software, just as it will soon be unthinkable to draft professional texts without AI assistance. GenAI should be seen as a tool that enhances human creativity rather than replacing it. By handling mundane aspects of writing, it allows authors to focus on critical thinking and idea generation. Transparency in AI use fosters trust and maintains ethical standards. Authors are encouraged to use GenAI under supervision and disclose its use openly. This will not only improve manuscript quality but also help authors allocate more time to innovation and creative thinking. Embracing GenAI is not merely an option; it represents an essential evolution in the way we approach writing.}
}
@article{YANG2014754,
title = {Computational Optimization, Modelling and Simulation: Past, Present and Future},
journal = {Procedia Computer Science},
volume = {29},
pages = {754-758},
year = {2014},
note = {2014 International Conference on Computational Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.05.067},
url = {https://www.sciencedirect.com/science/article/pii/S1877050914002440},
author = {Xin-She Yang and Slawomir Koziel and Leifur Leifsson},
keywords = {algorithm, computational optimization, data-intensive method, large-scale optimization, metaheuristic, nonlinear optimization, surrogate-based optimization, simulation.},
abstract = {An integrated part of modern design practice in both engineering and industry is simulation and optimization. Significant challenges still exist, though huge progress has been made in the last few decades. This 5th workshop on Computational Optimization, Modelling and Simulation (COMS 2014) at ICCS 2014 will summarize the latest developments of optimization and modelling and their applications in science, engineering and industry. This paper reviews the past developments, the state-of-the-art present and the future trends, while highlighting some challenging issues in these areas. It can be expected that future research should focus on the data intensive applications, approximations for computationally expensive methods, combinatorial optimization, and large-scale applications.}
}

@article{KRINGELBACH2020108128,
title = {Brain States and Transitions: Insights from Computational Neuroscience},
journal = {Cell Reports},
volume = {32},
number = {10},
pages = {108128},
year = {2020},
issn = {2211-1247},
doi = {https://doi.org/10.1016/j.celrep.2020.108128},
url = {https://www.sciencedirect.com/science/article/pii/S2211124720311177},
author = {Morten L. Kringelbach and Gustavo Deco},
abstract = {Summary
Within the field of computational neuroscience there are great expectations of finding new ways to rebalance the complex dynamic system of the human brain through controlled pharmacological or electromagnetic perturbation. Yet many obstacles remain between the ability to accurately predict how and where best to perturb to force a transition from one brain state to another. The foremost challenge is a commonly agreed definition of a given brain state. Recent progress in computational neuroscience has made it possible to robustly define brain states and force transitions between them. Here, we review the state of the art and propose a framework for determining the functional hierarchical organization describing any given brain state. We describe the latest advances in creating sophisticated whole-brain computational models with interacting neuronal and neurotransmitter systems that can be studied fully in silico to predict and design novel pharmacological and electromagnetic interventions to rebalance them in disease.}
}
@article{SUI2022377,
title = {Data-driven based four examinations in TCM: a survey},
journal = {Digital Chinese Medicine},
volume = {5},
number = {4},
pages = {377-385},
year = {2022},
issn = {2589-3777},
doi = {https://doi.org/10.1016/j.dcmed.2022.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S258937772200074X},
author = {Dong SUI and Lei ZHANG and Fei YANG},
keywords = {Traditional Chinese medicine (TCM), Four examinations, Data-driven, Machine learning, Computational intelligence},
abstract = {Traditional Chinese medicine (TCM) diagnosis is a unique disease diagnosis method with thousands of years of TCM theory and effective experience. Its thinking mode in the process is different from that of modern medicine, which includes the essence of TCM theory. From the perspective of clinical application, the four diagnostic methods of TCM, including inspection, auscultation and olfaction, inquiry, and palpation, have been widely accepted by TCM practitioners worldwide. With the rise of artificial intelligence (AI) over the past decades, AI based TCM diagnosis has also grown rapidly, marked by the emerging of a large number of data-driven deep learning models. In this paper, our aim is to simply but systematically review the development of the data-driven technologies applied to the four diagnostic approaches, i.e. the four examinations, in TCM, including data sets, digital signal acquisition devices, and learning based computational algorithms, to better analyze the development of AI-based TCM diagnosis, and provide references for new research and its applications in TCM settings in the future.}
}
@article{CAMERON2017131,
title = {Lateral thinking – Interocular symmetry and asymmetry in neurovascular patterning, in health and disease},
journal = {Progress in Retinal and Eye Research},
volume = {59},
pages = {131-157},
year = {2017},
issn = {1350-9462},
doi = {https://doi.org/10.1016/j.preteyeres.2017.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S135094621630091X},
author = {James R. Cameron and Roly D. Megaw and Andrew J. Tatham and Sarah McGrory and Thomas J. MacGillivray and Fergus N. Doubal and Joanna M. Wardlaw and Emanuele Trucco and Siddharthan Chandran and Baljean Dhillon},
keywords = {Interocular symmetry, Asymmetry, Retina, Retinal imaging, Retinal vasculature, Patterning},
abstract = {No biological system or structure is likely to be perfectly symmetrical, or have identical right and left forms. This review explores the evidence for eye and visual pathway asymmetry, in health and in disease, and attempts to provide guidance for those studying the structure and function of the visual system, where recognition of symmetry or asymmetry may be essential. The principal question with regards to asymmetry is not ‘are the eyes the same?’, for some degree of asymmetry is pervasive, but ‘when are they importantly different?’. Knowing if right and left eyes are ‘importantly different’ could have significant consequences for deciding whether right or left eyes are included in an analysis or for examining the association between a phenotype and ocular parameter. The presence of significant asymmetry would also have important implications for the design of normative databases of retinal and optic nerve metrics. In this review, we highlight not only the universal presence of asymmetry, but provide evidence that some elements of the visual system are inherently more asymmetric than others, pointing to the need for improved normative data to explain sources of asymmetry and their impact on determining associations with genetic, environmental or health-related factors and ultimately in clinical practice.}
}
@article{SCOTT2020107269,
title = {CPC’s 50th Anniversary: Celebrating 50 years of open-source software in computational physics},
journal = {Computer Physics Communications},
volume = {252},
pages = {107269},
year = {2020},
issn = {0010-4655},
doi = {https://doi.org/10.1016/j.cpc.2020.107269},
url = {https://www.sciencedirect.com/science/article/pii/S0010465520300886},
author = {N.S. Scott and A. Hibbert and J. Ballantyne and S. Fritzsche and A.L. Hazel and D.P. Landau and D.W. Walker and Z. Was},
keywords = {Computer Physics Communications, CPC Program Library, Collaborative Computational Project, Mendeley Data repository, Platform for Advanced Scientific Computing, Code Ocean},
abstract = {To celebrate the leading role Computer Physics Communications (CPC) has played in publishing open-source software in computational physics for over 50 years the editors are delighted to announce this Virtual Special Issue. Since 2018, coinciding with the 50th anniversary of the start of the CPC venture, thirty-two invited articles have been published. Each has been peer reviewed and each bears the header ‘CPC 50th anniversary article’. The special issue is in keeping with CPC’s ethos: it is focused on computational physics software and is accompanied by twenty-five software systems. The introduction to the collection also includes a personal reflection on Phil Burke, CPC’s founder, by Alan Hibbert, a lifelong colleague, who joined Queen’s University with Phil in the autumn of 1967. The distinctive feature of CPC is its Program Library which houses and distributes over 3500 open-source programs in computational physics. The introduction concludes with a description of key events in the history of the Program Library, its association with Queen’s University Belfast and its transfer to Elsevier’s Mendeley Data repository.}
}
@article{TAUB201510,
title = {The effect of computer science on physics learning in a computational science environment},
journal = {Computers & Education},
volume = {87},
pages = {10-23},
year = {2015},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2015.03.013},
url = {https://www.sciencedirect.com/science/article/pii/S0360131515000913},
author = {Rivka Taub and Michal Armoni and Esther Bagno and Mordechai (Moti) Ben-Ari},
keywords = {Interdisciplinary projects, Programming and programming languages, Secondary education, Simulations, Teaching/learning strategies},
abstract = {College and high-school students face many difficulties when dealing with physics formulas, such as a lack of understanding of their components or of the physical relationships between the two sides of a formula. To overcome these difficulties some instructors suggest combining simulations' design while learning physics, claiming that the programming process forces the students to understand the physical mechanism activating the simulation. This study took place in a computational-science course where high-school students programmed simulations of physical systems, thus combining computer science (CS) and mathematics with physics learning. The study explored the ways in which CS affected the students' conceptual understanding of the physics behind formulas. The major part of the analysis process was qualitative, although some quantitative analysis was applied as well. Findings revealed that a great amount of the time was invested by the students on representing their physics knowledge in terms of computer science. Three knowledge domains were found to be applied: structural, procedural and systemic. A fourth domain which enabled reflection on the knowledge was found as well, the domain of execution. Each of the domains was found to promote the emergence of knowledge integration processes (Linn & Eylon, 2006, 2011), thus promoting students’ physics conceptual understanding. Based on these findings, some instructional implications are discussed.}
}
@article{GISSEL201661,
title = {A case of fixed asset accounting: Initial and subsequent measurement},
journal = {Journal of Accounting Education},
volume = {37},
pages = {61-66},
year = {2016},
issn = {0748-5751},
doi = {https://doi.org/10.1016/j.jaccedu.2016.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0748575116300422},
author = {Jodi L. Gissel},
keywords = {Fixed asset acquisition, Depreciation, Interest capitalization, Nonmonetary exchange, Impairment, IFRS},
abstract = {This instructional case integrates multiple accounting concepts relating to fixed asset acquisition and subsequent measurement. You must apply accounting knowledge, professional judgment, and critical thinking skills to evaluate fixed assets and make recommendations. You must also analyze differences between fixed asset accounting under US generally accepted accounting principles and IFRS. As a student, you generally understand basic application of asset cost computation that simply recognizes the amount of cash paid for acquiring the asset. However, determining asset cost becomes challenging when you encounter more complex situations. You must consider initial measurement issues relating to a land purchase (demolition of existing building and a special assessment expenditure), interest capitalization for a self-constructed building, a nonmonetary asset exchange, and an asset retirement obligation. The case also considers subsequent measurement issues in terms of depreciation (straight-line and accelerated methods), replacement of an asset component, and impairment. The case structure is flexible and the teaching notes include alternatives for using scaled-down versions.}
}
@incollection{PHIPPEN2025125,
title = {Digital Literacy},
editor = {David Baker and Lucy Ellis},
booktitle = {Encyclopedia of Libraries, Librarianship, and Information Science (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {125-132},
year = {2025},
isbn = {978-0-323-95690-1},
doi = {https://doi.org/10.1016/B978-0-323-95689-5.00097-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780323956895000973},
author = {Andy Phippen},
keywords = {AI literacy, Critical thinking, Data literacy, Digital literacy, Digital wellbeing, DQ standard, Education for a connected world, Information literacy, Media literacy, Online safety, Social media literacy, Stakeholders},
abstract = {Digital literacy is a crucial skill set in the contemporary era, encompassing technical proficiency, information and media literacy, data literacy, and more. There are further disciplines that are incorporated into the broad concept of digital literacy, including cybersecurity, online safety, and responsible communication. The importance of critical thinking in digital contexts and the emerging field of digital wellbeing are addressed. There are challenges in achieving digital literacy including the lack of common frameworks and diverse barriers such as access to technology, affordability, and cultural differences. Ultimately digital literacy is something that requires the input of various stakeholders, including educators, governments, technology providers, and community organizations. There is a clear need for a collaborative, multi-pronged approach to address these challenges and the need for common agreement on what digital literacy is.}
}
@article{CHANG2014335,
title = {Computational architecture: Connecting the physical and virtual worlds},
journal = {Frontiers of Architectural Research},
volume = {3},
number = {4},
pages = {335-336},
year = {2014},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2014.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S2095263514000624},
author = {Teng-Wen Chang and Weixin Huang}
}
@incollection{COMBA2021241,
title = {2.14 - Computational Coordination Chemistry},
editor = {Edwin C. Constable and Gerard Parkin and Lawrence {Que Jr}},
booktitle = {Comprehensive Coordination Chemistry III},
publisher = {Elsevier},
address = {Oxford},
pages = {241-255},
year = {2021},
isbn = {978-0-08-102689-2},
doi = {https://doi.org/10.1016/B978-0-08-102688-5.00023-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780081026885000234},
author = {Peter Comba},
keywords = {Ab-initio quantum mechanics, Catalytic cycle, Charge distribution, Complex stability, DFT, Electronic structure, Ligand field theory, Molecular magnetism, Molecular mechanics, Molecular structure, Quantum chemistry, Reaction mechanism, Redox potential, Spectroscopy, Transition state},
abstract = {The computational modeling of metal complexes has been developed to an extent where a large variety of spectroscopic properties, reactivities and stabilities of mono- and oligonuclear complexes can be efficiently and reliably computed. There is a large arsenal of computational methods for the modeling of coordination compounds, spanning a wide range of scales in terms of theoretical basis, accuracy of the data in comparison with experiment, and accessibility in terms of computer power. Relevant current approaches and their limits and possible pitfalls that are discussed include ab-initio and DFT-based quantum-chemical, molecular mechanical, ligand-field-based methods and various combinations thereof, as well as approaches related to machine-learning, artificial intelligence, molecular docking and empirical structure-property correlations.}
}
@article{LETONSAARI2017131,
title = {Modeling computational algorithms using nonlinear storytelling methods of computer game design},
journal = {Procedia Computer Science},
volume = {119},
pages = {131-138},
year = {2017},
note = {6th International Young Scientist Conference on Computational Science, YSC 2017, 01-03 November 2017, Kotka, Finland},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.11.169},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917323797},
author = {Mika Letonsaari and Jukka Selin},
keywords = {Twine, visual programming, rapid prototyping, algorithm design, digital storytelling},
abstract = {Computational algorithms can be described in many methods and implemented in many languages. Here we present an approach using storytelling methods of computer game design in modeling some finite-state machine algorithms and applications requiring user interaction. An open source software Twine is used for the task. Interactive nonlinear stories created with Twine are applications that can be executed in a web browser. Storytelling approach provides an easy-to-understand view on computational algorithms allowing communication with people with no computer science education. It also allows rapid prototyping and testing in mixed background work teams.}
}
@article{CESARI2017361,
title = {Frailty and Multimorbidity: Different Ways of Thinking About Geriatrics},
journal = {Journal of the American Medical Directors Association},
volume = {18},
number = {4},
pages = {361-364},
year = {2017},
issn = {1525-8610},
doi = {https://doi.org/10.1016/j.jamda.2016.12.086},
url = {https://www.sciencedirect.com/science/article/pii/S1525861017300348},
author = {Matteo Cesari and Mario Ulises Pérez-Zepeda and Emanuele Marzetti},
keywords = {Diseases, comprehensive geriatric assessment, aging, public health},
abstract = {The terms multimorbidity and frailty are increasingly used in the medical literature to measure the risk profile of an older individual in order to support clinical decisions and design ad hoc interventions. The construct of multimorbidity was initially developed and used in nongeriatric settings. It generates a monodimensional nosological risk profile, grounding its roots in the somewhat inadequate framework of disease. On the other hand, frailty is a geriatric concept that implies a more exhaustive and comprehensive assessment of the individual and his/her environment, facilitating the implementation of multidimensional and tailored interventions. This article aims to promote among geriatricians the use of terms that may better enhance their background and provide more value to their unrivaled expertise in caring for biologically aged persons.}
}
@article{EDELMAN201791,
title = {Language and other complex behaviors: Unifying characteristics, computational models, neural mechanisms},
journal = {Language Sciences},
volume = {62},
pages = {91-123},
year = {2017},
issn = {0388-0001},
doi = {https://doi.org/10.1016/j.langsci.2017.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S0388000117300128},
author = {Shimon Edelman},
abstract = {Similar to other complex behaviors, language is dynamic, social, multimodal, patterned, and purposive, its purpose being to promote desirable actions or thoughts in others and self (Edelman, 2017b). An analysis of the functional characteristics shared by complex sequential behaviors suggests that they all present a common overarching computational problem: dynamically controlled constrained navigation in concrete or abstract situation spaces. With this conceptual framework in mind, I compare and contrast computational models of language and evaluate their potential for explaining linguistic behavior and for elucidating the brain mechanisms that support it.}
}
@article{SRIHARI20141083,
title = {Role of automation in the examination of handwritten items},
journal = {Pattern Recognition},
volume = {47},
number = {3},
pages = {1083-1095},
year = {2014},
note = {Handwriting Recognition and other PR Applications},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2013.09.032},
url = {https://www.sciencedirect.com/science/article/pii/S0031320313004044},
author = {Sargur N. Srihari and Kirsten Singer},
keywords = {Handwriting examination, Forensic document examination, Writer verification, Writer identification, Computational forensics, Expert system validation},
abstract = {Several automation tools have been developed over the years for forensic document examination (FDE) of handwritten items. Integrating the developed tools into a unified framework is considered and the essential role of the human in the process is discussed. The task framework is developed by considering the approach of computational thinking whose components are abstraction, algorithms, mathematical models and ability to scale. Beginning with the human FDE procedure expressed in algorithmic form, mathematical and software implementations of individual steps of the algorithm are described. Advantages of the framework are discussed, including efficiency (ability to scale to tasks with many handwritten items), reproducibility and validation/improvement of existing manual procedures. It is indicated that as with other expert systems, such as for medical diagnosis, current automation tools are useful only as part of a larger manually intensive procedure. This viewpoint is illustrated with a well-known FDE case, concerning the Lindbergh kidnapping with a new hypothesis – in this case, there are multiple questioned documents, possibility of multiple writers of the same document, determining whether the writing is disguised, known writing is formal while questioned writing is informal, etc. Observations are made for future developments, where human examiners provide handwriting characteristics while computational methods provide the necessary statistical analysis.}
}
@article{FEHER201498,
title = {Computational approaches to mapping allosteric pathways},
journal = {Current Opinion in Structural Biology},
volume = {25},
pages = {98-103},
year = {2014},
note = {Theory and simulation / Macromolecular machines},
issn = {0959-440X},
doi = {https://doi.org/10.1016/j.sbi.2014.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S0959440X14000190},
author = {Victoria A Feher and Jacob D Durrant and Adam T {Van Wart} and Rommie E Amaro},
abstract = {Allosteric signaling occurs when chemical and/or physical changes at an allosteric site alter the activity of a primary orthosteric site often many Ångströms distant. A number of recently developed computational techniques, including dynamical network analysis, novel topological and molecular dynamics methods, and hybrids of these methods, are useful for elucidating allosteric signaling pathways at the atomistic level. No single method prevails as best to identify allosteric signal propagation path(s), rather each has particular strengths in characterizing signals that occur over specific timescale ranges and magnitudes of conformational fluctuation. With continued improvement in accuracy and predictive power, these computational techniques aim to become useful drug discovery tools that will allow researchers to identify allostery critical residues for subsequent pharmacological targeting.}
}
@article{KAUFFMAN201525,
title = {Infinite computations and the generic finite},
journal = {Applied Mathematics and Computation},
volume = {255},
pages = {25-35},
year = {2015},
note = {Special issue devoted to the international conference ‘‘Numerical computations: Theory and Algorithms’’ June 17–23, 2013, Falerna, Italy},
issn = {0096-3003},
doi = {https://doi.org/10.1016/j.amc.2014.06.054},
url = {https://www.sciencedirect.com/science/article/pii/S009630031400890X},
author = {Louis H. Kauffman},
keywords = {Grossone, , Finite, Infinite, Generic finite, Category},
abstract = {This paper introduces the concept of a generic finite set and points out that a consistent and significant interpretation of the grossone, ① notation of Sergeyev is that ① takes the role of a generic natural number. This means that ① is not itself a natural number, yet it can be treated as one and used in the generic expression of finite sets and finite formulas, giving a new power to algebra and algorithms that embody this usage. In this view,N={1,2,3,…,①-2,①-1,①}is not an infinite set, it is a symbolic structure representing a generic finite set. We further consider the concept of infinity in categories. An object A in a given category C is infinite relative to that category if and only if there is a injection J:A⟶A in C that is not a surjection. In the category of sets this recovers the usual notion of infinity. In other categories, an object may be non-infinite (finite) while its underlying set (if it has one) is infinite. The computational methodology due to Sergeyev for executing numerical calculations with infinities and infinitesimals is considered from this categorical point of view.}
}
@incollection{LOURDUSAMY202091,
title = {7 - Computational intelligence using ontology—A case study on the knowledge representation in a clinical decision support system},
editor = {Jitendra Kumar Verma and Sudip Paul and Prashant Johri},
booktitle = {Computational Intelligence and Its Applications in Healthcare},
publisher = {Academic Press},
pages = {91-104},
year = {2020},
isbn = {978-0-12-820604-1},
doi = {https://doi.org/10.1016/B978-0-12-820604-1.00007-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128206041000078},
author = {Ravi Lourdusamy and Xavierlal J. Mattam},
keywords = {Clinical decision support systems, Knowledge representation, Computational semantics, Ontology, Ontological engineering},
abstract = {Computational intelligence has been traditionally associated with neural networks, fuzzy systems, and genetic algorithms. Over the years there have been many developments in computational intelligence. At present, many other fields are part of the study and research in computational intelligence. With advances in cognitive sciences, more techniques of information processing by machines that show characteristics closely associated with human intelligence are being found. Some of these techniques have been studied for a long time, but in recent years there has been some maturity in the understanding and use of these techniques. One such technique is the use of semantics in computational intelligence. There has been a long-drawn-out philosophical debate between lingualism, which claims that there is no human thought without language, and “language of thought” theories, which believe that natural language is inessential to private thought. In an attempt to create intelligent machines, the use of semantics for knowledge representation and knowledge-based creation in a system follows the philosophy of lingualism. Different knowledge representations are used in a knowledge-based clinical decision support system. This chapter makes a study of various knowledge representations. The different theories behind the techniques used in the knowledge representations are discussed. The philosophy of lingualism and the use of semantics in computational intelligence are explained, while a study on semantic knowledge representation in clinical decision support systems is made. The conclusion is the explanation as to how ontological engineering can be used to create computational intelligence.}
}
@incollection{BYRNE1997105,
title = {Cognitive Processes in Counterfactual Thinking about what Might Have Been},
editor = {Douglas L. Medin},
series = {Psychology of Learning and Motivation},
publisher = {Academic Press},
volume = {37},
pages = {105-154},
year = {1997},
issn = {0079-7421},
doi = {https://doi.org/10.1016/S0079-7421(08)60501-0},
url = {https://www.sciencedirect.com/science/article/pii/S0079742108605010},
author = {Ruth M.J. Byrne}
}
@article{NITYANANDA2020R159,
title = {Insect Neurobiology: Divergent Neural Computations in Predatory Insects},
journal = {Current Biology},
volume = {30},
number = {4},
pages = {R159-R161},
year = {2020},
issn = {0960-9822},
doi = {https://doi.org/10.1016/j.cub.2019.12.035},
url = {https://www.sciencedirect.com/science/article/pii/S0960982219316689},
author = {Vivek Nityananda},
abstract = {Summary
A comparative approach to neuroscience can greatly increase our understanding of how mechanisms map onto behaviour. A new study comparing two predatory insects demonstrates how neurons that are homologous can nonetheless mediate different computations and behaviour.}
}
@incollection{2009339,
title = {Appendix A - Thinking in MATLAB},
editor = {Pascal Wallisch and Michael Lusignan and Marc Benayoun and Tanya I. Baker and Adam S. Dickey and Nicholas G. Hatsopoulos},
booktitle = {Matlab for Neuroscientists},
publisher = {Academic Press},
address = {London},
pages = {339-344},
year = {2009},
isbn = {978-0-12-374551-4},
doi = {https://doi.org/10.1016/B978-0-12-374551-4.00034-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780123745514000348}
}
@article{CHI20111937,
title = {Teaching Computing to STEM Students via Visualization Tools},
journal = {Procedia Computer Science},
volume = {4},
pages = {1937-1943},
year = {2011},
note = {Proceedings of the International Conference on Computational Science, ICCS 2011},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2011.04.211},
url = {https://www.sciencedirect.com/science/article/pii/S1877050911002699},
author = {Hongmei Chi and Harsh Jain},
keywords = {Visualization, ChemSketch, ParaView, Computation ;STEM education},
abstract = {Information technology is evolving fast and steady over the years providing more and more tools for society to use. There is an increasing need and implementation of computation in the conduct of modern scientific research and experimentation. Computational thinking has been scarcely understood by STEM undergraduates if their majors are not computer sciences. We explore computation projects into existing courses via visualization computational tools to increase the number of STEM students who graduate with discipline specific computational skills. The goal of this paper was to report our efforts for increasing the number of students with experience using computation in science. Discipline specific tools were chosen and implemented in the respective courses, for example Chemsketch in chemistry. Hands-on labs were designed to familiarize instructors and students so it can be helpful to smooth the learning curve in STEM undergraduate students}
}
@article{SAID2015396,
title = {Exploiting Computational Intelligence Paradigms in e-Technologies and Activities},
journal = {Procedia Computer Science},
volume = {65},
pages = {396-405},
year = {2015},
note = {International Conference on Communications, management, and Information technology (ICCMIT'2015)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.09.101},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915029312},
author = {Hanaa M. Said and Abdel-Badeeh M. Salem},
keywords = {Machine Learning, Intelligent Data Analysis, E- Technologies government, Neural Networks, Fuzzy Logic, Genetic algorithm, Case based reasoning, SVM, Swarm intelligence, computational intelligence;},
abstract = {Computational intelligence (CI) has emerged as a powerful paradigm in e-Science, providing the researchers an immense volume of intelligent computing techniques and algorithms. CI provides knowledge engineers to develop a robust techniques and intelligent tools for e-government applications and tasks. This paper presents a comparative analysis of some techniques used in e-activities and e-government systems. The study includes the following paradigms; artificial neural networks, fuzzy logic, genetic algorithms, case-based reasoning, support vector machines, and swarm intelligence. Additionally, this study found that such paradigms offer many business benefits and advantages; e.g. (a) the ability to acquire, represent, manage and structure the knowledge in the domain under study, (b) the ability to optimize resources, (c) the ability to perform efficient performance, and (d) the ability to conduct planning, budgeting, and forecasting.}
}
@article{BICER2024101462,
title = {Mathematical creativity in upper elementary school mathematics curricula},
journal = {Thinking Skills and Creativity},
volume = {51},
pages = {101462},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101462},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124000014},
author = {Ali Bicer and Helen Aleksani and Chuck Butler and Traci Jackson and Tricia Dawn Smith and Michael Bostick},
keywords = {Creativity in mathematics, Creativity-directed tasks, Curriculum},
abstract = {Textbooks should promote creative tasks for teachers to enhance students' math skills through creative thinking, instead of relying on memorization of step-by-step procedures. The aim of this study is to analyze elementary school mathematics curricula commonly employed in the U.S., namely GoMath, enVision Math, Math Connects, MyMath, and Investigations. The selection of these curricula is based on their widespread usage, and the analysis seeks to evaluate their effectiveness in fostering the development of students' creative thinking skills. We employed Bicer et al.'s (2021) framework for creativity-directed tasks to analyze 1,000 mathematical tasks within each curriculum. The analysis unveiled that Eureka, followed by Investigations, incorporated a higher proportion of creativity-directed tasks compared to the remaining three curricula. For some categories and subcategories of creativity-directed tasks (e.g., communication, connection), the results are less varied across five curricula. The present study enables school districts, schools, and classroom teachers to know what curricula support the development of creative thinking of students by including various options of creativity-directed tasks in their upper elementary mathematics textbooks.}
}
@article{SOSA2018157,
title = {Innovation Teams and Organizational Creativity: Reasoning with Computational Simulations},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {4},
number = {2},
pages = {157-170},
year = {2018},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2018.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S240587261730076X},
author = {Ricardo Sosa and Andy Connor},
keywords = {Organizational climate, Agent-based simulation, Creative teams, Leadership},
abstract = {A computational social simulation encourages systematic reasoning about the management of innovation teams and organizational creativity. This article draws upon historical literature to identify a potential dilemma faced by business organizations: Is it better to promote creative behavior across a whole organization or focus on the development of small and highly creative teams? We formulate the dilemma from the literature on organizational creativity, and explore it using a multi-agent simulation. Our study models creative behavior abstractly, as the ability to introduce novelty. By varying the scale and scope of non-conformist behavior in the simulation, our research supports the systematic study of the breadth vs. depth dilemma. The results of this study invite an informed examination of strategies to sustain innovation based on the introduction of either a small number of significantly novel ideas, or a large number of novel but more familiar ideas. Results from this study on change agency also indicate that there is a possible trade-off between a highly creative team and its creative efficiency, drawing attention to the importance of a creative critical mass in an organization. We also discuss the implications of these results and our research approach.}
}
@article{GJORGJIEVA2021iii,
title = {Editorial overview: Theoretical and computational approaches to decipher brain function from molecules to behavior},
journal = {Current Opinion in Neurobiology},
volume = {70},
pages = {iii-vii},
year = {2021},
note = {Computational Neuroscience},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2021.11.010},
url = {https://www.sciencedirect.com/science/article/pii/S0959438821001379},
author = {Julijana Gjorgjieva and Ila Fiete}
}
@article{LEE20152858,
title = {The Benin experience: How computational modeling can assist major vaccine policy changes in low and middle income countries},
journal = {Vaccine},
volume = {33},
number = {25},
pages = {2858-2861},
year = {2015},
issn = {0264-410X},
doi = {https://doi.org/10.1016/j.vaccine.2015.04.022},
url = {https://www.sciencedirect.com/science/article/pii/S0264410X15004752},
author = {Bruce Y. Lee and Benjamin Schreiber and Angela R. Wateska and Diana L. Connor and Hamadou M. Dicko and Philippe Jaillard and Mercy Mvundura and Carol Levin and Mélanie Avella and Leila A. Haidari and Shawn T. Brown},
keywords = {Benin, Vaccine, Supply chain, Computational modeling},
abstract = {While scientific studies can show the need for vaccine policy or operations changes, translating scientific findings to action is a complex process that needs to be executed appropriately for change to occur. Our Benin experience provided key steps and lessons learned to help computational modeling inform and lead to major policy change. The key steps are: engagement of Ministry of Health, identifying in-country “champions,” directed and efficient data collection, defining a finite set of realistic scenarios, making the study methodology transparent, presenting the results in a clear manner, and facilitating decision-making and advocacy. Generating scientific evidence is one component of policy change. Enabling change requires orchestration of a coordinated set of steps that heavily involve key stakeholders, earn their confidence, and provide them with relevant information. Our Benin EVM+CCEM+HERMES Process led to a decision to enact major changes and could serve as a template for similar approaches in other countries.}
}
@article{ZILCHAMANO2025100478,
title = {Contrasting individual-specific resilience and compensation personalization frameworks: The case of rumination},
journal = {Biological Psychiatry Global Open Science},
pages = {100478},
year = {2025},
issn = {2667-1743},
doi = {https://doi.org/10.1016/j.bpsgos.2025.100478},
url = {https://www.sciencedirect.com/science/article/pii/S2667174325000321},
author = {Sigal Zilcha-Mano},
keywords = {Rumination, compensation, resilience, complementing, capitalization, personalized treatment, mechanism of change},
abstract = {Background
Rumination has been identified as a potential mechanism of therapeutic change, particularly in directive and focused psychotherapies for depression. Previous research has predominantly centered on either trait-like individual differences or state-like changes in rumination, without integrating these aspects. The present study proposes a computational approach to investigate whether rumination serves as a compensatory or resilience mechanism by integrating both trait-like and state-like effects.
Method
Rumination and depressive symptoms were assessed (in N=100) pre-treatment and repeatedly throughout treatment. Mixed-level models were used to examine whether pre-treatment trait-like rumination interacted with a time-variant variable of in-treatment state-like changes in rumination to predict subsequent changes in treatment outcomes. These models were used to determine whether individuals with higher or lower pre-treatment trait-like levels of rumination benefited more from state-like reductions in rumination, thus contrasting the compensatory and resilience theoretical frameworks.
Results
As hypothesized, the findings support the compensatory framework: individuals with higher pre-treatment trait-like levels of rumination benefited most from greater state-like reductions in rumination during treatment, as evidenced by greater subsequent symptom reduction (p=.04).
Conclusion
The findings refine our understanding of rumination as an individual-specific mechanism of therapeutic change, dependent on the individual's trait-like levels of rumination. The proposed computational approach enabled an empirical comparison of the two main theoretical frameworks of treatment personalization, compensatory and resilience, offering new insights into mechanisms driving therapeutic change. Future studies could leverage the paradigm proposed here to examine for which patients and in what contexts mechanisms of change function as compensatory versus resilience mechanisms.}
}
@article{ANDREJCZUK2019104799,
title = {Synergistic team composition: A computational approach to foster diversity in teams},
journal = {Knowledge-Based Systems},
volume = {182},
pages = {104799},
year = {2019},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2019.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S0950705119302746},
author = {Ewa Andrejczuk and Filippo Bistaffa and Christian Blum and Juan A. Rodríguez-Aguilar and Carles Sierra},
keywords = {Team composition, Exact algorithms, Heuristic algorithms, Optimisation, Coalition formation},
abstract = {Co-operative learning in heterogeneous teams refers to learning methods in which teams are organised both to accomplish academic tasks and for individuals to gain knowledge. Competencies, personality and the gender of team members are key factors that influence team performance. Here, we introduce a team composition problem, the so-called synergistic team composition problem (STCP), which incorporates such key factors when arranging teams. Thus, the goal of the STCP is to partition a set of individuals into a set of synergistic teams: teams that are diverse in personality and gender and whose members cover all required competencies to complete a task. Furthermore, the STCP requires that all teams are balanced in that they are expected to exhibit similar performances when completing the task. We propose two efficient algorithms to solve the STCP. Our first algorithm is based on a linear programming formulation and is appropriate to solve small instances of the problem. Our second algorithm is an anytime heuristic that is effective for large instances of the STCP. Finally, we thoroughly study the computational properties of both algorithms in an educational context when grouping students in a classroom into teams using actual-world data.}
}
@article{DOLAN2023,
title = {Using Shopping Data to Improve the Diagnosis of Ovarian Cancer: Computational Analysis of a Web-Based Survey},
journal = {JMIR Cancer},
volume = {9},
year = {2023},
issn = {2369-1999},
doi = {https://doi.org/10.2196/37141},
url = {https://www.sciencedirect.com/science/article/pii/S2369199923000174},
author = {Elizabeth H Dolan and James Goulding and Laila J Tata and Alexandra R Lang},
keywords = {carcinoma, ovarian epithelial, ovarian neoplasms, self-medication, diagnostic errors, symptom assessment, machine learning, nonprescription drugs, over-the-counter, pharmaceutical, symptom, ovary, ovarian cancer, oncology, cancer},
abstract = {Background
Shopping data can be analyzed using machine learning techniques to study population health. It is unknown if the use of such methods can successfully investigate prediagnosis purchases linked to self-medication of symptoms of ovarian cancer.
Objective
The aims of this study were to gain new domain knowledge from women’s experiences, understand how women’s shopping behavior relates to their pathway to the diagnosis of ovarian cancer, and inform research on computational analysis of shopping data for population health.
Methods
A web-based survey on individuals’ shopping patterns prior to an ovarian cancer diagnosis was analyzed to identify key knowledge about health care purchases. Logistic regression and random forest models were employed to statistically examine how products linked to potential symptoms related to presentation to health care and timing of diagnosis.
Results
Of the 101 women surveyed with ovarian cancer, 58.4% (59/101) bought nonprescription health care products for up to more than a year prior to diagnosis, including pain relief and abdominal products. General practitioner advice was the primary reason for the purchases (23/59, 39%), with 51% (30/59) occurring due to a participant’s doctor believing their health problems were due to a condition other than ovarian cancer. Associations were shown between purchases made because a participant’s doctor believing their health problems were due to a condition other than ovarian cancer and the following variables: health problems for longer than a year prior to diagnosis (odds ratio [OR] 7.33, 95% CI 1.58-33.97), buying health care products for more than 6 months to a year (OR 3.82, 95% CI 1.04-13.98) or for more than a year (OR 7.64, 95% CI 1.38-42.33), and the number of health care product types purchased (OR 1.54, 95% CI 1.13-2.11). Purchasing patterns are shown to be potentially predictive of a participant’s doctor thinking their health problems were due to some condition other than ovarian cancer, with nested cross-validation of random forest classification models achieving an overall in-sample accuracy score of 89.1% and an out-of-sample score of 70.1%.
Conclusions
Women in the survey were 7 times more likely to have had a duration of more than a year of health problems prior to a diagnosis of ovarian cancer if they were self-medicating based on advice from a doctor rather than having made the decision to self-medicate independently. Predictive modelling indicates that women in such situations, who are self-medicating because their doctor believes their health problems may be due to a condition other than ovarian cancer, exhibit distinct shopping behaviors that may be identifiable within purchasing data. Through exploratory research combining women sharing their behaviors prior to diagnosis and computational analysis of these data, this study demonstrates that women’s shopping data could potentially be useful for early ovarian cancer detection.}
}
@article{NEILL2024100870,
title = {Designer delectables; exploring the design practice of haute couture and haute cuisine},
journal = {International Journal of Gastronomy and Food Science},
volume = {35},
pages = {100870},
year = {2024},
issn = {1878-450X},
doi = {https://doi.org/10.1016/j.ijgfs.2024.100870},
url = {https://www.sciencedirect.com/science/article/pii/S1878450X24000039},
author = {Lindsay Neill and Nigel Hemmington and Christine McDonald and Francesca Zampollo},
keywords = {Design practice, Haute couture, Haute cuisine, Designerly thinking},
abstract = {This study explores design practice across two domains: haute couture (fashion), and haute cuisine (food). A case study approach was taken using the voice of practitioners as the focus through in-depth qualitative interviews. The cross-domain approach revealed similarities in design practice through four design themes: visualization, ‘conversations’ with materials, co-creation and ‘pushing boundaries’. The data also revealed innovations within the four themes that could apply to other design domains, for example visualization (haute couture) and co-creation (haute cuisine). The practitioners also provided valuable and nuanced insights into their design practice – ‘You have to live something to do it’. These insights from practitioners and their practice reveal how the two domains hold similarities in design practice and provide a deeper understanding of design processes, and designerly thinking, from which creativity and innovation can emerge.}
}
@article{GHAVANLOO20231,
title = {Experimental and computational physics of fullerenes and their nanocomposites: Synthesis, thermo-mechanical characteristics and nanomedicine applications},
journal = {Physics Reports},
volume = {996},
pages = {1-116},
year = {2023},
note = {Experimental and computational physics of fullerenes and their nanocomposites: Synthesis, thermo-mechanical characteristics and nanomedicine applications},
issn = {0370-1573},
doi = {https://doi.org/10.1016/j.physrep.2022.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S0370157322003775},
author = {Esmaeal Ghavanloo and Hashem Rafii-Tabar and Ayesha Kausar and Georgios I. Giannopoulos and S. Ahmad Fazelzadeh},
keywords = {Fullerene molecules, Nanocomposites, Synthesis, Computational modeling, Thin films, Mechanical properties, Thermal properties, Vibrational properties, Molecular dynamics, Molecular mechanics, Micromechanics, Nanomedicine, Nanoneuroscience application},
abstract = {It is an established paradigm in the emerging fields of nanoscience, nanotechnology and molecular engineering that a very important domain of fundamental research is associated with carbon-based materials. Ever since the discovery of the first member of the fullerene family (C60) in 1985, and the subsequent discovery of the other members, fullerenes as a nanoscopic allotrope of carbon with anticipated extensive applications in all areas of nanoscience and nanotechnology (both industrial and medical), materials science and engineering, condensed matter physics and chemistry have occupied a central position in research activities across the globe. Detailed investigations, both experimental and theoretical/computational, into their morphology, mechanical, thermal, chemical, biological, electronic, optical and structural properties have led to the emergence of a well-established and independent science of fullerenes, providing very valuable information both in basic and applied sciences. A comprehensive review of these properties of fullerenes, particularly their applications in the above fields will provide valuable up-to-date and essential background information for engaging in new research in this field and also be able to develop new concepts and applications of these exotic carbon structures. For instance, a recent development is their applications in the emerging field of nanoneuroscience, a field interfacing nanoscience and neuroscience. In this extensive, albeit selective survey, related mainly to the C60 fullerenes, the processes involving their experimental synthesis, theoretical formulation of their geometrical structures, their mechanical and thermal properties and nanomedical applications have been reviewed and summarized both within the experimental and theoretical/computational domains. Essential theoretical concepts, ranging from discrete atomistic molecular dynamics and molecular mechanics methods to continuum-based methods have been expounded in order to facilitate the pursuance of the reviewed literature and also to aid in the development of further research in this field.}
}
@article{MCCLELLAND1993209,
title = {Computational approaches to cognition: top-down approaches},
journal = {Current Opinion in Neurobiology},
volume = {3},
number = {2},
pages = {209-216},
year = {1993},
issn = {0959-4388},
doi = {https://doi.org/10.1016/0959-4388(93)90212-H},
url = {https://www.sciencedirect.com/science/article/pii/095943889390212H},
author = {James L. McClelland and David C. Plaut},
abstract = {Computational models are useful tools for exploring the nature of human cognitive processes. In particular, connectionist models are providing researchers with new ways of thinking about the basic nature of cognition and its implementation in the brain. They support novel explanations of important aspects of perception, memory, language, thought and cognitive development, and allow cognitive processes to be linked with the underlying physiological mechanisms. The models also aid our understanding of how disorders of brain function lead to disorders of cognition.}
}
@article{QUINLAN2007413,
title = {Re-thinking stages of cognitive development: An appraisal of connectionist models of the balance scale task},
journal = {Cognition},
volume = {103},
number = {3},
pages = {413-459},
year = {2007},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2006.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S0010027706000552},
author = {Philip T. Quinlan and Han L.J. {van der Maas} and Brenda R.J. Jansen and Olaf Booij and Mark Rendell},
keywords = {Connectionist models, Balance scale task, Latent class analysis},
abstract = {The present paper re-appraises connectionist attempts to explain how human cognitive development appears to progress through a series of sequential stages. Models of performance on the Piagetian balance scale task are the focus of attention. Limitations of these models are discussed and replications and extensions to the work are provided via the Cascade-Correlation algorithm. An application of multi-group latent class analysis for examining performance of the networks is described and these results reveal fundamental functional characteristics of the networks. Evidence is provided that strongly suggests that the networks are unable to acquire a mastery of torque and, although they do recover certain rules of operation that humans do, they also show a propensity to acquire rules never previously seen.}
}
@article{KONG2023100126,
title = {Complementary role of large language models in educating undergraduate design of distillation column: Methodology development},
journal = {Digital Chemical Engineering},
volume = {9},
pages = {100126},
year = {2023},
issn = {2772-5081},
doi = {https://doi.org/10.1016/j.dche.2023.100126},
url = {https://www.sciencedirect.com/science/article/pii/S2772508123000443},
author = {Zong Yang Kong and Vincentius Surya Kurnia Adi and Juan Gabriel Segovia-Hernández and Jaka Sunarso},
keywords = {ChatGPT, Chemical engineering education, Large language models, Distillation, Industry 4.0, Mass transfer},
abstract = {This paper explores the integration of large language models (LLMs), such as ChatGPT, in chemical engineering education, departing from conventional practices that may not be universally accepted. While there is ongoing debate surrounding the acceptance of LLMs, driven by concerns over computational instability and potential inconsistencies, their inevitability in shaping our communication and interaction with technology cannot be ignored. As educators, we are positioned to play a vital role in guiding students toward the responsible, effective, and synergetic use of LLMs. Focusing specifically on distillation column design in undergraduate mass-transfer courses, this study demonstrates how ChatGPT can be utilized as an auxiliary tool to create interactive learning environments and simulate real-world engineering thinking processes. It emphasizes the need for students to develop critical thinking skills and a thorough understanding of LLM principles, taking responsibility for their use and creations. While ChatGPT should not be solely relied upon, its integration with fundamental principles of chemical engineering is crucial. The effectiveness and limitations of ChatGPT are exemplified through two case studies, showcasing the importance of manual calculations and established simulation software as primary tools for guiding and validating engineering results and analyses. This paper also addresses the pedagogical implications of integrating LLMs into mass transfer courses, encompassing curriculum integration, facilitation, guidance, and ethical considerations. Recommendations are provided for incorporating LLMs effectively into the curriculum. Overall, this study contributes to the advancement of chemical engineering education by examining the benefits and limitations of LLMs as educational aids in the design process.}
}
@incollection{CAPELLI2023105,
title = {4 - 3D-printed and computational models: a combined approach for patient-specific studies},
editor = {Deepak M. Kalaskar},
booktitle = {3D Printing in Medicine (Second Edition)},
publisher = {Woodhead Publishing},
edition = {Second Edition},
pages = {105-125},
year = {2023},
series = {Woodhead Publishing Series in Biomaterials},
isbn = {978-0-323-89831-7},
doi = {https://doi.org/10.1016/B978-0-323-89831-7.00011-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780323898317000110},
author = {Claudio Capelli and Michele Bertolini and Silvia Schievano},
keywords = {Patient-specific models, cardiovascular models, segmentation, 3D printing, finite element analyses, computational fluid dynamics, validation},
abstract = {Three-dimensional printed models have been increasingly used in many fields of medicine. The most common benefits include a better understanding of anatomical details, an improved communication between clinicians and patients, a more accurate planning of treatments, and new opportunities for procedural training. In the cardiovascular field, this technology has contributed to improve the management of complex cases, in particular congenital heart disease, by fostering personalized preprocedural planning and increasing medical trainees’ confidence. Cardiovascular structures, however, are extremely challenging to replicate using materials compatible with current 3D printing technologies. Hence, patient-specific computational models, generated from the same set of medical images as printed ones, can be combined to 3D printing technology to simulate different conditions and identify the optimal treatment for each specific patient. A further step forward is represented by the integration of advanced visualization techniques like augmented and virtual reality, to close still existing loopholes. In this chapter, we review the current possibilities associated with the use of patient-specific models, in the context of cardiovascular applications.}
}
@article{FIELDS2025256,
title = {Thoughts and thinkers: On the complementarity between objects and processes},
journal = {Physics of Life Reviews},
volume = {52},
pages = {256-273},
year = {2025},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2025.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S1571064525000089},
author = {Chris Fields and Michael Levin},
keywords = {Active inference, Cognitive light cone, Emergence, Evo/devo/eco, Multiscale competency architecture, Niche construction, Semantics},
abstract = {We argue that “processes versus objects” is not a useful dichotomy. There is, instead, substantial theoretical utility in viewing “objects” and “processes” as complementary ways of describing persistence through time, and hence the possibility of observation and manipulation. This way of thinking highlights the role of memory as an essential resource for observation, and makes it clear that “memory” and “time” are also mutually inter-defined, complementary concepts. We formulate our approach in terms of the Free Energy Principle (FEP) of Friston and colleagues and the fundamental idea from quantum theory that physical interactions can be represented by linear operators. Following Levin (2024) [30], we emphasize that memory is, first and foremost, an interpretative function, from which the idea of memory as a record, at some level of accuracy, of past events is derivative. We conclude that the distinction between objects and processes is always contrived, and always misleading, and that science would be better served by abandoning it entirely.}
}
@article{SAW2025111884,
title = {Current status and future directions of explainable artificial intelligence in medical imaging},
journal = {European Journal of Radiology},
volume = {183},
pages = {111884},
year = {2025},
issn = {0720-048X},
doi = {https://doi.org/10.1016/j.ejrad.2024.111884},
url = {https://www.sciencedirect.com/science/article/pii/S0720048X24006004},
author = {Shier Nee Saw and Yet Yen Yan and Kwan Hoong Ng},
keywords = {Artificial intelligence, Interpretability, Explainability, Medical imaging, Medical information systems},
abstract = {The inherent “black box” nature of AI algorithms presents a substantial barrier to the widespread adoption of the technology in clinical settings, leading to a lack of trust among users. This review begins by examining the foundational stages involved in the interpretation of medical images by radiologists and clinicians, encompassing both type 1 (fast thinking − ability of the brain to think and act intuitively) and type 2 (slow analytical − slow analytical, laborious approach to decision-making) decision-making processes. The discussion then delves into current Explainable AI (XAI) approaches, exploring both inherent and post-hoc explainability for medical imaging applications and highlighting the milestones achieved. XAI in medicine refers to AI system designed to provide transparent, interpretable, and understandable reasoning behind AI predictions or decisions. Additionally, the paper showcases some commercial AI medical systems that offer explanations through features such as heatmaps. Opportunities, challenges and potential avenues for advancing the field are also addressed. In conclusion, the review observes that state-of-the-art XAI methods are not mature enough for implementation, as the explanations they provide are challenging for medical experts to comprehend. Deeper understanding of the cognitive mechanisms by medical professionals is important in aiming to develop more interpretable XAI methods.}
}
@article{GAMAL20241319,
title = {A computational sustainable approach for energy storage systems performance evaluation based on spherical-fuzzy MCDM with considering uncertainty},
journal = {Energy Reports},
volume = {11},
pages = {1319-1341},
year = {2024},
issn = {2352-4847},
doi = {https://doi.org/10.1016/j.egyr.2023.12.058},
url = {https://www.sciencedirect.com/science/article/pii/S2352484723016529},
author = {Abduallah Gamal and Mohamed Abdel-Basset and Ibrahim M. Hezam and Karam M. Sallam and Ahmad M. Alshamrani and Ibrahim A. Hameed},
keywords = {Energy storage systems, Sustainable, Uncertainty, MCDM, SF-AHP, SF-MACONT, Sensitivity analysis},
abstract = {Incorporating energy storage systems (ESSs) can mitigate the intermittency of renewable energy sources. There are a variety of ESSs for renewable energy with vastly different characteristics. The problem of diversity of characteristics in selecting the most appropriate ESS can be approached as a multi-criteria decision-making (MCDM) problem. This research evaluates sustainable ESSs through a case study in Egypt. A sustainable computational approach is presented through which experts can use verbal expressions to express their opinions in determining the priorities of the dimensions that affect the selection of ESSs. Determining the appropriate energy storage system requires consideration of several main dimensions such as the technology dimension, environmental dimension, economic dimension, and social-political dimension and, in addition to the sub-indicators. Hence, this research applies a hybrid MCDM approach that deals with different indicators and characteristics. Also, uncertainty in applying the proposed approach was dealt with by a spherical fuzzy (SF) environment and by using the spherical fuzzy numbers (SFNs). At first, the SF analytical hierarchy process (SF-AHP) method was used to assess the priorities of the four main dimensions and their sub-indicators. Then, the SF mixed aggregation by comprehensive normalization technique (SF-MACONT) was applied to evaluate and rank the ESSs selected for analysis through research. An illustrative case study was presented that included seven ESSs out of the eighteen systems listed in the research to confirm the feasibility of the developed approach. Sensitivity analysis was carried out by changing some parameters like λ, μ, δ, and ϑ based on the SF-MACONT method and changing the weights of some main dimensions. A comparative analysis with some MCDM approaches was conducted to show the advantages of the developed approach through its flexibility and built-in parameters. The findings show that the technology dimension is the most influential in choosing a sustainable ESS, while the economic dimension is the least influential. Also, the results of the evaluation and ranking of the seven selected ESSs indicate that the "Pumped Hydro" system is the most suitable system for energy storage in Egypt.}
}
@article{TIRADORAMOS2010855,
title = {Fourth Workshop on Teaching Computational Science (WTCS 2010)},
journal = {Procedia Computer Science},
volume = {1},
number = {1},
pages = {855-856},
year = {2010},
note = {ICCS 2010},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2010.04.093},
url = {https://www.sciencedirect.com/science/article/pii/S1877050910000943},
author = {A. Tirado-Ramos and A.B. Shiflet},
keywords = {Teaching, Computational science, Modeling, Simulation},
abstract = {The Workshop on Teaching Computational Science (WTCS), taking place within the International Conference on Computational Science (ICCS), is a platform for discussing innovations in teaching computational science in its various aspects, e.g. modeling and simulation, at all levels and contexts. Innovations may cover the context of formal courses or self-directed learning, involving, for example, curriculum development, introductory programming, service courses, specialist undergraduate and postgraduate topics, as well as industry-related short courses. This editorial provides an introduction to the work presented during the sessions in Amsterdam.}
}
@incollection{SHARMA202353,
title = {Chapter 2 - Computational approaches in drug discovery and design},
editor = {Rupesh Kumar Gautam and Mohammad Amjad Kamal and Pooja Mittal},
booktitle = {Computational Approaches in Drug Discovery, Development and Systems Pharmacology},
publisher = {Academic Press},
pages = {53-93},
year = {2023},
isbn = {978-0-323-99137-7},
doi = {https://doi.org/10.1016/B978-0-323-99137-7.00009-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780323991377000095},
author = {Priyanka Sharma and Kalicharan Sharma and Mukesh Nandave},
keywords = {Molecular modeling, Molecular docking, Molecular dynamics simulation, QSAR, Bioinformatics},
abstract = {Drug development is a costly and time-consuming procedure. The medicine must meet certain characteristics such as nontoxicity, bioavailability, and potency. Establishing a better drug-like compound has now become a difficult and error-prone endeavor in light of ever-increasing expectations for effectiveness, intensity, and stability. The emergence of conformations of chemical therapeutic targets, as well as developments in computational techniques and bioinformatics, have accelerated the use of molecular modeling in pharmaceutical research. Numerous molecular modeling methodologies used in recent pharmacological studies are reviewed in this chapter. Structure- and ligand-based drug design, protein modeling and visualization molecular docking, virtual screening, molecular dynamics simulation, pharmacophore modeling, and QSAR techniques have all been discussed. In addition, we make key database resources and tools available to the researchers and scientists for future prospects.}
}
@article{YOUSEF2024137753,
title = {Biological and computational assessment of new synthesized nicotinamides as potential immunomodulatory VEGFR-2 inhibitors},
journal = {Journal of Molecular Structure},
volume = {1305},
pages = {137753},
year = {2024},
issn = {0022-2860},
doi = {https://doi.org/10.1016/j.molstruc.2024.137753},
url = {https://www.sciencedirect.com/science/article/pii/S002228602400276X},
author = {Reda G. Yousef and Alaa Elwan and Abdallah E. Abdallah and Hazem Elkady and Ahmed B.M. Mehany and Mariam Ali Abo-Saif and Mohamed M. Radwan and Mahmoud A. ElSohly and Ibrahim M. Ibrahim and Mohamed A. Elkady and Mohamed Ayman El-Zahabi and Ibrahim H. Eissa},
keywords = {Nicotinamides, Anticancer, VEGFR-2, Apoptosis, Immunomodulatory, Computational studies},
abstract = {As an extension to our preceding studies on nicotinamide derivatives as anticancer agents, new nicotinamide-based candidates were designed and synthesized as VEGFR-2 inhibitors. The in vitro cytotoxic activity of the synthesized compounds was evaluated against three human cancer cell lines (MCF-7, HepG-2 and HCT-116). The IC50 values for compound 17 were 2.61± 0.01, 3.20 ± 0.02, and 2.46 ± 0.01 µM, respectively, compared to sorafenib (4.21±0.03, 3.40 ± 0.02, and 5.30 ± 0.04 µM) against MCF-7, HePG-2, and HCT-116. This indicated that compound 17 possess double strength relative to sorafenib against both MCF-7 and HCT-116. Compound 17 was the most promising VEGFR-2 inhibitor with IC50 value of 0.34 μM that was slightly better than that of sorafenib (0.38 μM). Further studies displayed the ability of compound 17 to arrest the growth of HCT-116 cells at the Pre-G1 and S phases. Additionally, compound 17 induced a significant increase in the total apoptosis rate of HCT-116 cells from 1.82 % to 26.69 %. Moreover, it showed high selectivity indices against HCT-116, HepG2, and MCF-7 cancer cells. Furthermore, compound 17 showed potent inhibitory activities on TNF-α and IL-6 and showed a notable rise in caspase-3 level. In addition, the potentiality of the designed derivatives to bind with and inhibit the VEGFR-2 enzyme was indicated by molecular docking assessments. MD simulation studies revealed the stability of compound 17 in the active site of VEGFR-2 for 100 ns. Based on the previous findings, compound 17 appears to be a promising apoptotic VEGFR-2 inhibitor and could potentially direct future efforts towards the development of novel anticancer medications.}
}
@article{COSTA201227,
title = {Systems pathology: A critical review},
journal = {Molecular Oncology},
volume = {6},
number = {1},
pages = {27-32},
year = {2012},
issn = {1574-7891},
doi = {https://doi.org/10.1016/j.molonc.2011.11.007},
url = {https://www.sciencedirect.com/science/article/pii/S1574789111001438},
author = {Jose Costa},
keywords = {Systems biology, Systems pathology, Translational research},
abstract = {The technological advances of the last twenty years together with the dramatic increase in computational power have injected new life into systems-level thinking in Medicine. This review emphasizes the close relationship of Systems Pathology to Systems Biology and delineates the differences between Systems Pathology and Clinical Systems Pathology. It also suggests an algorithm to support the application of systems-level thinking to clinical research, proposes applying systems-level thinking to the health care systems and forecasts an acceleration of preventive medicine as a result of the coupling of personal genomics with systems pathology.}
}
@article{LERON2014126,
title = {Functions via everyday actions: Support or obstacle?},
journal = {The Journal of Mathematical Behavior},
volume = {36},
pages = {126-134},
year = {2014},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2014.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S073231231400056X},
author = {Uri Leron and Tamar Paz},
keywords = {Functions, Composition of functions, Intuitive thinking, Analytical thinking, Dual-process theory, Actions on objects, Changing-the-input misconception},
abstract = {The general context of this paper is the power of intuitive thinking, and how it can help or hinder analytical thinking. The research literature in cognitive psychology teems with tasks where intuitive thinking leads subjects to “non-normative” answers, including tasks for which they have all the knowledge necessary for the normative answer. The best explanation to date for such phenomena is dual-process theory, which stipulates the activation of a quick automatic intuitive process (System 1), together with the failure of the heavy, lazy, and computationally expensive analytical process (System 2) to intervene and correct the intuitive response. In an earlier paper, we have documented a clash between intuitive and analytical thinking concerning functions, which we have termed the changing-the-input phenomenon. The discovery of the changing-the-input phenomenon, however, left us with a puzzle: Why has this phenomenon concerning functions – a purely mathematical concept – been observed in computer science classes but not in mathematics ones? The purpose of the present paper is to address this puzzle. More generally we ask, under what conditions the changing-the-input phenomenon will or will not be manifested? Still more generally, in learning about functions, when is the intuitive scaffolding of functions via actions-on-tangible-objects helpful, and when does it get in the way of deeper understanding?}
}
@article{HAN20241,
title = {Ground threat prediction-based path planning of unmanned autonomous helicopter using hybrid enhanced artificial bee colony algorithm},
journal = {Defence Technology},
volume = {32},
pages = {1-22},
year = {2024},
issn = {2214-9147},
doi = {https://doi.org/10.1016/j.dt.2023.04.010},
url = {https://www.sciencedirect.com/science/article/pii/S2214914723001071},
author = {Zengliang Han and Mou Chen and Haojie Zhu and Qingxian Wu},
keywords = {UAH, Path planning, Ground threat prediction, Hybrid enhanced, Collaborative thinking},
abstract = {Unmanned autonomous helicopter (UAH) path planning problem is an important component of the UAH mission planning system. Aiming to reduce the influence of non-complete ground threat information on UAH path planning, a ground threat prediction-based path planning method is proposed based on artificial bee colony (ABC) algorithm by collaborative thinking strategy. Firstly, a dynamic threat distribution probability model is developed based on the characteristics of typical ground threats. The dynamic no-fly zone of the UAH is simulated and established by calculating the distribution probability of ground threats in real time. Then, a dynamic path planning method for UAH is designed in complex environment based on the real-time prediction of ground threats. By adding the collision warning mechanism to the path planning model, the flight path could be dynamically adjusted according to changing no-fly zones. Furthermore, a hybrid enhanced ABC algorithm is proposed based on collaborative thinking strategy. The proposed algorithm applies the leader-member thinking mechanism to guide the direction of population evolution, and reduces the negative impact of local optimal solutions caused by collaborative learning update strategy, which makes the optimization performance of ABC algorithm more controllable and efficient. Finally, simulation results verify the feasibility and effectiveness of the proposed ground threat prediction path planning method.}
}
@article{KU2021114105,
title = {Computational linguistic analysis applied to a semantic fluency task: A replication among first-episode psychosis patients with and without derailment and tangentiality},
journal = {Psychiatry Research},
volume = {304},
pages = {114105},
year = {2021},
issn = {0165-1781},
doi = {https://doi.org/10.1016/j.psychres.2021.114105},
url = {https://www.sciencedirect.com/science/article/pii/S0165178121004029},
author = {Benson S. Ku and Luca Pauselli and Michael A. Covington and Michael T. Compton},
keywords = {Derailment, First-episode psychosis, Formal thought disorder, Loose associations, Psychosis, Schizophrenia, Semantic fluency tasks},
abstract = {Automated tools do not yet exist to measure formal thought disorder, including derailment and tangentiality, both of which can be subjectively rated using the Scale for the Assessment of Positive Symptoms after a clinical research interview. CoVec, a new automated tool, measures the semantic similarity among words averaged in a five- and ten-word window (Coherence-5 and Coherence-10, respectively). One prior report demonstrated that this tool was able to differentiate between patients with those types of thought disorder and patients without them (and controls). Here, we attempted a replication of the initial findings using data from a different sample of patients hospitalized for initial evaluation of first-episode psychosis. Participants were administered a semantic fluency task and the animal lists were analyzed with CoVec. In this study, we partially replicated the prior findings, showing that first-episode patients with derailment had significantly lower Coherence-5 and Coherence-10 compared with patients without derailment. Further research is warranted on this and other highly reliable and objective methods of detecting formal thought disorder through simple assessments such as semantic fluency tasks.}
}
@article{FABRY2018793,
title = {Turing redux: Enculturation and computation},
journal = {Cognitive Systems Research},
volume = {52},
pages = {793-808},
year = {2018},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2018.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S1389041718301724},
author = {Regina E. Fabry},
keywords = {Enculturation, Mathematical cognition, Computation, Hybrid cognition, Neural plasticity, Embodied cognition},
abstract = {Many of our cognitive capacities are shaped by enculturation. Enculturation is the acquisition of cognitive practices such as symbol-based mathematical practices, reading, and writing during ontogeny. Enculturation is associated with significant changes to the organization and connectivity of the brain and to the functional profiles of embodied actions and motor programs. Furthermore, it relies on scaffolded cultural learning in the cognitive niche. The purpose of this paper is to explore the components of symbol-based mathematical practices. Phylogenetically, these practices are the result of concerted organism-niche interactions that have led from approximate number estimations to the emergence of discrete, symbol-based mathematical operations. Ontogenetically, symbol-based mathematical practices are associated with plastic changes to neural circuitry, action schemata, and motor programs. It will be suggested that these practices rely on previously acquired capacities such as subitizing and counting. With these considerations in place, I will argue that computations, understood in the sense of Turing (1936), are a specific kind of symbol-based mathematical practices that can be realized by human organisms, machines, or by hybrid organism-machine systems. In sum, this paper suggests a new way to think about mathematical cognition and computation.}
}
@article{20167,
title = {What Is the Key Best Practice for Collaborating with a Computational Biologist?},
journal = {Cell Systems},
volume = {3},
number = {1},
pages = {7-11},
year = {2016},
issn = {2405-4712},
doi = {https://doi.org/10.1016/j.cels.2016.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S240547121630223X}
}
@article{BRYANT201034,
title = {Thinking inside the box: A participatory, computer-assisted approach to scenario discovery},
journal = {Technological Forecasting and Social Change},
volume = {77},
number = {1},
pages = {34-49},
year = {2010},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2009.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S004016250900105X},
author = {Benjamin P. Bryant and Robert J. Lempert},
keywords = {Scenario Discovery, Scenario planning, Robust decision making},
abstract = {Scenarios provide a commonly used and intuitively appealing means to communicate and characterize uncertainty in many decision support applications, but can fall short of their potential especially when used in broad public debates among participants with diverse interests and values. This paper describes a new approach to participatory, computer-assisted scenario development that we call scenario discovery, which aims to address these challenges. The approach defines scenarios as a set of plausible future states of the world that represent vulnerabilities of proposed policies, that is, cases where a policy fails to meet its performance goals. Scenario discovery characterizes such sets by helping users to apply statistical or data-mining algorithms to databases of simulation-model-generated results in order to identify easy-to-interpret combinations of uncertain model input parameters that are highly predictive of these policy-relevant cases. The approach has already proved successful in several high impact policy studies. This paper systematically describes the scenario discovery concept and its implementation, presents statistical tests to evaluate the resulting scenarios, and demonstrates the approach on an example policy problem involving the efficacy of a proposed U.S. renewable energy standard. The paper also describes how scenario discovery appears to address several outstanding challenges faced when applying traditional scenario approaches in contentious public debates.}
}
@article{BARGMANN20242999,
title = {Cori Bargmann},
journal = {Neuron},
volume = {112},
number = {18},
pages = {2999-3002},
year = {2024},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2024.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S0896627324006561},
author = {Cori Bargmann},
abstract = {In an interview with Neuron, Cori Bargmann discusses C. elegans as a model organism, the importance of considering the animal’s own world (thinking like a worm), choosing a scientific problem, and her experience as head of science at the Chan Zuckerberg Initiative and co-chair of the BRAIN Initiative.}
}
@article{WATFORD2019114707,
title = {Progress in data interoperability to support computational toxicology and chemical safety evaluation},
journal = {Toxicology and Applied Pharmacology},
volume = {380},
pages = {114707},
year = {2019},
issn = {0041-008X},
doi = {https://doi.org/10.1016/j.taap.2019.114707},
url = {https://www.sciencedirect.com/science/article/pii/S0041008X19303151},
author = {Sean Watford and Stephen Edwards and Michelle Angrish and Richard S. Judson and Katie {Paul Friedman}},
keywords = {Data Interoperability, Computational Toxicology, Bioinformatics, Databases, Applications},
abstract = {New approach methodologies (NAMs) in chemical safety evaluation are being explored to address the current public health implications of human environmental exposures to chemicals with limited or no data for assessment. For over a decade since a push toward “Toxicity Testing in the 21st Century,” the field has focused on massive data generation efforts to inform computational approaches for preliminary hazard identification, adverse outcome pathways that link molecular initiating events and key events to apical outcomes, and high-throughput approaches to risk-based ratios of bioactivity and exposure to inform relative priority and safety assessment. Projects like the interagency Tox21 program and the US EPA ToxCast program have generated dose-response information on thousands of chemicals, identified and aggregated information from legacy systems, and created tools for access and analysis. The resulting information has been used to develop computational models as viable options for regulatory applications. This progress has introduced challenges in data management that are new, but not unique, to toxicology. Some of the key questions require critical thinking and solutions to promote semantic interoperability, including: (1) identification of bioactivity information from NAMs that might be related to a biological process; (2) identification of legacy hazard information that might be related to a key event or apical outcomes of interest; and, (3) integration of these NAM and traditional data for computational modeling and prediction of complex apical outcomes such as carcinogenesis. This work reviews a number of toxicology-related efforts specifically related to bioactivity and toxicological data interoperability based on the goals established by Findable, Accessible, Interoperable, and Reusable (FAIR) Data Principles. These efforts are essential to enable better integration of NAM and traditional toxicology information to support data-driven toxicology applications.}
}
@article{THEODOROPOULOS2021100335,
title = {Augmented Reality and programming education: A systematic review},
journal = {International Journal of Child-Computer Interaction},
volume = {30},
pages = {100335},
year = {2021},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2021.100335},
url = {https://www.sciencedirect.com/science/article/pii/S2212868921000544},
author = {Anastasios Theodoropoulos and George Lepouras},
keywords = {Augmented Reality (AR), Programming learning, Coding learning, CS education, Review study},
abstract = {In recent years, Augmented Reality (AR) usage in the learning process has been growing. AR tools and environments lead to a variety of positive outcomes and impacts for educational purposes. Similarly, AR is changing the learning process in the Computer Science (CS) Education domain. There are numerous studies that adopt the immersive AR technology in order to improve Computational Thinking (CT) or programming skills, in several contexts. However, there are not sufficient studies that analyze the meaningful characteristics or the advantages and disadvantages of AR in the field. In order to better understand the impact of AR in programming education we performed a systematic literature review. This review analyzes 31 studies in the field. It explores the evolution of this developing technology, the challenges and issues that AR offers and discusses how this work can benefit student learning and further research.}
}
@article{LIU2021107410,
title = {A new computational method for acquiring effect knowledge to support product innovation},
journal = {Knowledge-Based Systems},
volume = {231},
pages = {107410},
year = {2021},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.107410},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121006729},
author = {Hongwei Liu and Wenqiang Li and Yan Li},
keywords = {TRIZ, Product innovation design, Effect knowledge representation, Functional Basis, IPC},
abstract = {Effect provides a scientific principle-level means for product function realization. The unexpected or new application of effects can create high-level innovations enabling products long-term technical advantages and market competitiveness. Acquiring design knowledge is the vital first step of conducting product innovation activities. In order to capture the effect knowledge that can efficiently aid high-level product innovation, this article proposes a new computational method. The method stems from a novel effect knowledge representation considering both functional and technical area features, and utilizes functional-flow terms of Functional Basis and technical area categories of international patent classification (IPC) respectively to standardize the modelling of the two kinds of features. Based on such representation, the method reasonably combines syntactic analysis, WordNet and word vector technologies to extract the desired effect knowledge from IPC text. To evaluate the method, this article first compares the acquired knowledge with those in a comprehensive human-compiled effect database, and then applies the knowledge to aid the innovation design of several mechanical products with different technical backgrounds. Evaluation results and the discussion based on them suggest the feasibility and potential of the proposed method in automatically acquiring well-organized effect knowledge system, as well as in aiding high-level product innovation.}
}
@article{ARFE2020103807,
title = {The effects of coding on children's planning and inhibition skills},
journal = {Computers & Education},
volume = {148},
pages = {103807},
year = {2020},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2020.103807},
url = {https://www.sciencedirect.com/science/article/pii/S0360131520300099},
author = {Barbara Arfé and Tullio Vardanega and Lucia Ronconi},
keywords = {Coding, Computational thinking, Executive function, Primary school children, Problem-solving},
abstract = {Computational thinking (CT) and the coding element of it are progressively entering in the primary school curriculum worldwide. Yet, little is known about the effects of these skills on children's cognitive development. In a cluster-randomized controlled trial, we examined how 1st-grade children's gains in coding skills that follow instructional intervention transfer to two important executive functions (EFs): planning and response inhibition. One-hundred seventy-nine (179) first graders from 5 schools and 10 class groups, with no prior experience of coding, were randomly assigned to an experimental (coding, 5 classes) or control (standard STEM, 5 classes) instructional condition. The experimental intervention involved 8 h of coding activities (two weekly lessons for 4 weeks), through the Code.org platform. Children in the control group were exposed to standard STEM instruction. Four coding tasks drawn from Code.org, two standardized planning tasks (Elithorn maze test and Tower of London, ToL, test) and two standardized response inhibition tasks (NEPSY-II inhibition subtest and numerical Stroop), were used to assess children's skills at the pretest and posttest (after the instructional intervention). To measure retention, the same skills were also assessed for 44 children from the experimental group 5 weeks from the posttest (follow up). The results show that practice with coding through Code.org not only improved measurably children's ability to solve coding problems, but also their EFs, increasing the time children spent planning, their ability to solve standardized planning tasks, and to inhibit prepotent responses. Such findings add to the still limited literature on the cognitive effects of coding, deepening our understanding of the positive implications of introducing Computational Thinking early in the school curriculum.}
}
@article{ANDERSEN2024100697,
title = {Infrastructuring digital literacy in K-12 education: A national case study},
journal = {International Journal of Child-Computer Interaction},
volume = {42},
pages = {100697},
year = {2024},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2024.100697},
url = {https://www.sciencedirect.com/science/article/pii/S2212868924000667},
author = {Lars Bo Andersen and Ditte Amund Basballe and Lillian Buus and Christian Dindler and Thomas Illum Hansen and Mikkel Hjorth and Ole Sejer Iversen and Christian Mosbæk Johannessen and Katrine Holm Kanstrup and Rasmus Fink Lorentzen and Morten Misfeldt and Line Have Musaeus and Camilla Balslev Nielsen and Marianne Graves Petersen and Vibeke Schrøder and Marie Falkesgaard Slot},
keywords = {Technology comprehension, Digital literacy, Infrastructuring, Strategy},
abstract = {While much CCI research has dealt with the educational challenge of providing children with knowledge and skills for a digital society, little work has dealt with the strategic challenge of developing and implementing a digital literacy subject in K-12 education. In this paper, we explore how to develop, implement, and sustain a national program on technology comprehension by analyzing the newly established Danish knowledge center for digital technology comprehension. We draw on the concept of infrastructuring to shed light on how to create and sustain the social, material, political and organizational structures that form the basis for introducing the new national initiative. Based on our case, we distill seven propositions that describe more generally how to work strategically with this challenge.}
}
@article{WINTER20181,
title = {The art of the Wunderlich cube and the development of spatial abilities},
journal = {International Journal of Child-Computer Interaction},
volume = {18},
pages = {1-7},
year = {2018},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2018.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S2212868917301010},
author = {Victor Winter and Betty Love and Cindy Corritore},
keywords = {Spatial reasoning, Mathematical analysis, Coding, 3D printing},
abstract = {This paper advocates for a future where the teaching of math and art are harmoniously intertwined as they were in the days of da Vinci. In this future, code provides the “brush” that enables the expression of artistic ideas and mathematical structures in digital and digitally-fabricated mediums. This educational idea is motivated by (1) literature supporting the position that visual thinking and spatial reasoning significantly impact STEAM disciplines, and (2) Piaget’s theory of cognitive development in which children, in the concrete operational stage, solve problems relating to physical objects (i.e., they learn-by-making). A project is then described involving the creation of a 3D artifact we call a Wunderlich cube — a mathematical artifact that embodies numerous spatial reasoning puzzles. An understanding of the properties of the Wunderlich cube is developed through manual construction using LEGO®, mathematical analysis, computational thinking, coding, and 3D printing.}
}
@article{PRADO2019727,
title = {Towards an Extensible Architecture for Ideation},
journal = {Procedia Computer Science},
volume = {159},
pages = {727-735},
year = {2019},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 23rd International Conference KES2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.09.228},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919314140},
author = {Hércules A. do Prado and Elaine Coutinho Marcial and Aluizio Haendchen Filho and Edilson Ferneda and Roseane Salvio},
keywords = {design thinking, ideation, debates, sentiment analysis, foresight, Studies of Future},
abstract = {Ideation is an important activity of Design Thinking, a process that may benefit from different levels of automation in its activities. Preceded by Immersion and Analysis activities, Ideation can be enhanced by computational approaches like debate synthesis and mediation, sentiment analysis, and so on. In this paper an architecture for an extensible platform for ideation is addressed. Initially, it comprises a set of components to cope with those functionalities. The extensibility of this platform is in the sense that it shall allow the inclusion of new components like creation of domain ontologies for integration of different studies in the same domain. The general purpose of this platform is to support the creation of ideas by (i) constructing consensus among specialists and (ii) managing dissents in order to keep in track of marginal ideas that can become dominant ones as the discussion advances. It can be applied to many fields, like innovation, Studies of Future, definition of complex diagnoses, etc. Actually, this proposal came up from an experience with a study of future in which some experts had tried to envision trends for some years ahead in order to propose strategic actions for reaching a desired status for Brazil as a successful, fair, and inclusive country. The proposal includes an open and interactive computational environment to enable (i) structuring debates in threads of discussion; (ii) the gathering of ideas about topics of interest; (iii) the debate on the ideas put forward in order to identify the most relevant ones; (iv) synthesis of a debate (anytime summarization); (v) identification of the prevailing sentiments in a debate; and (vi) identification of variables relevant for the sake of the debate target.}
}
@article{KITA202021,
title = {Computational design of generalized centrifugal puzzles},
journal = {Computers & Graphics},
volume = {90},
pages = {21-28},
year = {2020},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2020.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S009784932030056X},
author = {Naoki Kita and Takafumi Saito},
keywords = {Computational design, Digital fabrication, Puzzles},
abstract = {Mechanical puzzles have fascinated many people for a long time. While some puzzles require complex procedures to solve, there are puzzles that can be solved easily if the solver understands the underlying mechanism. In this paper, we focus on mechanical puzzles that can be solved by spin such that centrifugal force is applied to the internal mechanical core to unlock the locked state. While traditional centrifugal puzzles are limited to simple shapes, we propose a computational design method to generalize such puzzles by embedding the mechanical core into 3D models. We parameterize the internal core mechanism and optimize the design under several design constraints, and we generate a support structure that helps users solve puzzles easily because generalized puzzles cannot always be spun steadily and easily due to complex surfaces and non-flat contact areas. Additionally, we embed multiple cores into a model. To solve a multi-core puzzle, the user must follow certain orders to unlock each locking mechanism. We fabricate a variety of designed puzzles and demonstrate whether they can be physically unlocked.}
}
@article{BAGGIO2020100005,
title = {Computational modelling and simulations in tourism: A primer},
journal = {Annals of Tourism Research Empirical Insights},
volume = {1},
number = {1},
pages = {100005},
year = {2020},
issn = {2666-9579},
doi = {https://doi.org/10.1016/j.annale.2020.100005},
url = {https://www.sciencedirect.com/science/article/pii/S2666957920300057},
author = {Rodolfo Baggio},
keywords = {Complex systems, Modelling, Simulations, Numerical and computational methods},
abstract = {The aim of this contribution is to briefly sketch and discuss the main issues that concern the activities of modelling and simulating complex phenomena and systems. The focus is on numerical and computational techniques. We discuss the validity of these methods and examine the different steps to be taken for ensuring a correct, accurate and reliable implementation. The approach is essentially of general methodological nature, regardless of specific techniques or tools.}
}
@article{MOTOMURA20103,
title = {Multi-aspect data analysis for investigating human computation mechanism},
journal = {Cognitive Systems Research},
volume = {11},
number = {1},
pages = {3-15},
year = {2010},
note = {Brain Informatics},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2008.08.010},
url = {https://www.sciencedirect.com/science/article/pii/S1389041708000521},
author = {Shinichi Motomura and Ning Zhong},
keywords = {Multi-aspect data analysis, Brain informatics methodology, Human computation mechanism, EEG and fMRI},
abstract = {In the paper, we present a multi-aspect data analysis approach for investigating human computation mechanism. Multi-aspect analysis in multiple human brain data sources is an important methodology in Brain Informatics, which emphasizes on a systematic way for investigating human information processing mechanisms, including measuring, collecting, modeling, transforming, managing, and mining multiple human brain data obtained from various cognitive experiments by using powerful equipments, such as fMRI and EEG. After giving an outline of Brain Informatics methodology, we describe how to design cognitive experiments of mental arithmetic task with multiple difficulty levels for obtaining multiple EEG and fMRI data sources, and how to analyze such data for investigating the spatiotemporal characteristics and flow of human computation processing. Such an investigation can be regarded as a case study using Brain Informatics methodology. Experimental results show the usefulness of our approach.}
}
@article{VANCOUVER201456,
title = {Change one can believe in: Adding learning to computational models of self-regulation},
journal = {Organizational Behavior and Human Decision Processes},
volume = {124},
number = {1},
pages = {56-74},
year = {2014},
issn = {0749-5978},
doi = {https://doi.org/10.1016/j.obhdp.2013.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0749597813001180},
author = {Jeffrey B. Vancouver and Justin M. Weinhardt and Ronaldo Vigo},
keywords = {Computational model, Motivation, Dynamics, Learning},
abstract = {Theories of self-regulation describe motivation as a dynamic process of goal choice and goal striving. To facilitate those processes, individuals learn about themselves and their environment, which is an internal dynamic process. However, the precise nature of the relationship between these learning and motivational processes is not well specified. This article integrates formal models of learning, goal choice, and goal striving using a single information processing structure found in self-regulatory models of motivation. Results from two published studies (DeShon and Rench, 2009, Schmidt and DeShon, 2007) validate the model. In both cases, the integrated model accounts for findings that previous theories of self-regulation could not explain. Discussion focuses on additional tests to validate the model and on the value of incorporating formal models from the cognitive, learning, and motivational literatures to account for behavior in complex settings and over time.}
}
@article{MULATTI2023100040,
title = {Perceived lack of control promotes creativity},
journal = {Journal of Creativity},
volume = {33},
number = {1},
pages = {100040},
year = {2023},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2022.100040},
url = {https://www.sciencedirect.com/science/article/pii/S2713374522000231},
author = {Claudio Mulatti and Barbara Treccani},
keywords = {Creativity, Divergent creativity, Lack of control, Compensatory control theory, Semantic control},
abstract = {The sense of lack of control has been shown to foster illusory pattern perception, superstition, conspiracy and religious beliefs. In two identical experiments we investigated whether the feeling of lacking control (vs. control) can also foster creative thinking, which we operationalized as the ability to produce associative and dissociative combinations of either related and unrelated concepts. Participants were asked to think about an incident in their life wherein they felt either to be in control or to lose control of the situation. Immediately afterwards, they had to perform a set of tasks tapping (divergent) creative thinking. In both experiments, we observed higher scores in all creativity tasks for participants who recalled loss-of-control events than for those recalling in-control events. Our findings suggest that compensatory processes, triggered by experiencing lack of control, can promote divergent thinking. We propose an account situated within current models of semantic control.}
}
@article{LEE2025100890,
title = {Generative ecodesign for mechanical products: A design workflow},
journal = {Cleaner Engineering and Technology},
volume = {24},
pages = {100890},
year = {2025},
issn = {2666-7908},
doi = {https://doi.org/10.1016/j.clet.2025.100890},
url = {https://www.sciencedirect.com/science/article/pii/S2666790825000138},
author = {Amos Wei Lun Lee and Kevin Kai Wern Seah and Bing Feng Ng and Ee Teng Zhang and Wen Feng Lu and Jonathan Sze Choong Low},
keywords = {Carbon emission, Generative design, Product design, Environmental sustainability, Ecodesign},
abstract = {Harnessing advancements in artificial intelligence, generative design holds great potential to support designers in their ecodesign efforts by enabling them to explore design solutions beyond the limits of their imagination and expertise. However, a systematic literature review on the application of generative design in ecodesign reveals a clear underrepresentation, highlighting a missed opportunity in the field. To bridge this gap, a seven-component generative ecodesign workflow for mechanical products was developed. This workflow combines generative design algorithms, typically used for geometry lightweighting, with life cycle thinking. It facilitates the generation, evaluation, and identification of design solutions by considering the design tri-factor: material choice, manufacturing process, and geometry. This represents the first reported product ecodesign tool to integrate generative design with ecodesign principles while simultaneously addressing all three elements of the design tri-factor. To showcase its utility, environmentally optimal design alternatives were created for a mountain bicycle's handlebar stem.}
}
@article{COONS2015126,
title = {Grease pencils and the persistence of individuality in computationally produced custom objects},
journal = {Design Studies},
volume = {41},
pages = {126-136},
year = {2015},
note = {Special Issue: Computational Making},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2015.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X15000599},
author = {ginger “all-lower-case” coons and Matt Ratto},
keywords = {computer aided design, design tools, participatory design, social design, computational craft},
abstract = {This article explores the relationship between an established craft production method and a computational adaptation of that method. In looking at a specific tool, the grease pencils used in the fitting and production of prosthetic limbs, we examine the ways in which complexity, tacit understandings, and human movement are translated into a collection of variables and considerations manipulable in a digital environment. We discuss, briefly, the persistent individuality of objects like prosthetic sockets, and the ways in which their materiality and necessarily custom nature push back against assumptions that computational production is generalizing, disembodied, and abstract.}
}
@article{KARSAKOV2015730,
title = {Improving Visualization Courses in Russian Higher Education in Computational Science and High Performance Computing},
journal = {Procedia Computer Science},
volume = {66},
pages = {730-739},
year = {2015},
note = {4th International Young Scientist Conference on Computational Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.11.083},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915034328},
author = {Andrey Karsakov and Anna Bilyatdinova and Alexey Bezgodov},
keywords = {Visualization course, Computational science, Higher education},
abstract = {In order to keep up with the fast-paced and widespread technologies and applications of visualization, worldwide education community is actively implementing visualization courses in curricula of undergraduate and graduate programs. A study of the state of the art in the teaching visualization in Russian higher education shows the necessity to improve the quality and breadth of knowledge of the visualization courses. In this paper we propose our approach to overcome the national and historical challenges in teaching visualization in Russian STEM higher education on the example of Computational Science and High Performance Computing double degree Master's programs in ITMO University. We offer a smooth transition to the modern relevant syllabus content by presenting two courses’ designs with same width but with various depth in knowledge that should to be studied. At the end of the paper we give some discussions about future works in development visualization courses in Russia.}
}
@incollection{COUCLELIS2009245,
title = {Computational Human Geography},
editor = {Rob Kitchin and Nigel Thrift},
booktitle = {International Encyclopedia of Human Geography},
publisher = {Elsevier},
address = {Oxford},
pages = {245-250},
year = {2009},
isbn = {978-0-08-044910-4},
doi = {https://doi.org/10.1016/B978-008044910-4.00669-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780080449104006696},
author = {H. Couclelis},
keywords = {Agent-based models, Cellular automata, Geocomputation, Geo(infor)matics, GIS, Location-based services, Models/modeling, Public participation GIS, Spatial analysis},
abstract = {Computational human geography refers to the use of computational methods and techniques to solve problems in human geography research and applications. Geographic information systems (GIS) and science are a big part of computational human geography but the notion is considerably broader, encompassing spatial process modeling and simulation, the modeling of spatial decision and behavior, visualization techniques, most aspects of spatial analysis, and an increasing number of other areas. Computation in human geography goes back to the beginnings of the quantitative revolution and is philosophically related though methodologically distinct from it. Two major thrusts have persisted through the years: the use of numerical techniques to solve large, complex quantitative problems; and the development of models of complex spatial processes expressed directly in computational terms. Typical exponents of the latter kinds of applications are cellular automata models of urban and environmental processes, and agent-based models of spatial decision and behavior. More recent developments involve applications of mobile and portable computing. Critiques of computational human geography originate from both within the field and from the humanistic and social theory perspectives. The former address a number of epistemological and methodological problems while the latter tend to focus on issues of ontology and representation.}
}
@article{PETZSCHNER2017421,
title = {Computational Psychosomatics and Computational Psychiatry: Toward a Joint Framework for Differential Diagnosis},
journal = {Biological Psychiatry},
volume = {82},
number = {6},
pages = {421-430},
year = {2017},
note = {Computational Psychiatry},
issn = {0006-3223},
doi = {https://doi.org/10.1016/j.biopsych.2017.05.012},
url = {https://www.sciencedirect.com/science/article/pii/S0006322317315846},
author = {Frederike H. Petzschner and Lilian A.E. Weber and Tim Gard and Klaas E. Stephan},
keywords = {Allostasis, Cybernetics, Hierarchical Bayesian model, Homeostasis, Inference, Metacognition, Prediction error},
abstract = {This article outlines how a core concept from theories of homeostasis and cybernetics, the inference-control loop, may be used to guide differential diagnosis in computational psychiatry and computational psychosomatics. In particular, we discuss 1) how conceptualizing perception and action as inference-control loops yields a joint computational perspective on brain-world and brain-body interactions and 2) how the concrete formulation of this loop as a hierarchical Bayesian model points to key computational quantities that inform a taxonomy of potential disease mechanisms. We consider the utility of this perspective for differential diagnosis in concrete clinical applications.}
}
@article{REN2021105428,
title = {Computational fluid dynamics simulation of adsorption process in a liquid-solids fluidized bed},
journal = {Journal of Environmental Chemical Engineering},
volume = {9},
number = {4},
pages = {105428},
year = {2021},
issn = {2213-3437},
doi = {https://doi.org/10.1016/j.jece.2021.105428},
url = {https://www.sciencedirect.com/science/article/pii/S221334372100405X},
author = {Panfeng Ren and Wenbin Li and Kuotsung Yu},
keywords = {Liquid-solids fluidized bed (LSFB), Computational fluid dynamics (CFD) simulation, Turbulent mass diffusivity, Hydrodynamics, Protein adsorption},
abstract = {For simultaneously predicting the hydrodynamics and protein adsorption process in a liquid-solids fluidized bed (LSFB), a computational fluid dynamics (CFD) model is established by combining the two-fluid model (TFM) for the liquid-particles two-phase fluidization system with the c2¯−εc model for the turbulent mass transfer. In terms of hydrodynamics, the kl−εl−kp−εp−Θ equations are adopted to describe phases turbulence. The simulations of hydrodynamics using various drag models and different modelling parameters are conducted to test their sensitivity. Then for the adsorption process, the recently developed formulations of the c2¯−εc model are adopted to characterize rigorously the turbulent mass diffusion in LSFB. With the proposed model, the velocity field as well as the concentration field can be acquired. Simulated results are compared with the experimental data and a good agreement between them is found.}
}
@article{FLETCHER1998747,
title = {Computational fluid dynamics modelling of an entrained flow biomass gasifier},
journal = {Applied Mathematical Modelling},
volume = {22},
number = {10},
pages = {747-757},
year = {1998},
issn = {0307-904X},
doi = {https://doi.org/10.1016/S0307-904X(98)10025-2},
url = {https://www.sciencedirect.com/science/article/pii/S0307904X98100252},
author = {D.F. Fletcher and B.S. Haynes and J. Chen and S.D. Joseph},
abstract = {A mathematical model, based on the Computational Fluid Dynamics package CFX4, has been developed to study the flow within an entrained flow biomass gasifier. The gasifier is designed to convert sawdust and chopped cotton gin trash into a low calorific value gas which can be burned in a modified engine to run a generator. Calculations of the flowfield are performed using the standard k–ϵ model and a Differential Reynolds Stress Model (DSM). In line with current thinking, it is shown that the k–ϵ model gives unphysical results for complex swirling flows, whereas the DSM model performs well. Particle tracking was performed to determine typical trajectories for the biomass and char and the results used to determine means of avoiding slagging in the gasifier base. The simulations have proved to be very useful to the designers who are now using the model to optimise the design.}
}
@article{LOOSEN2020631,
title = {Towards a computational psychiatry of juvenile obsessive-compulsive disorder},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {118},
pages = {631-642},
year = {2020},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2020.07.021},
url = {https://www.sciencedirect.com/science/article/pii/S014976342030484X},
author = {Alisa M. Loosen and Tobias U. Hauser},
keywords = {Juvenile obsessive-compulsive disorder, Adolescence, Neuropsychology, Computational psychiatry, Neuroimaging},
abstract = {Obsessive-Compulsive Disorder (OCD) most often emerges during adolescence, but we know little about the aberrant neural and cognitive developmental mechanisms that underlie its emergence during this critical developmental period. To move towards a computational psychiatry of juvenile OCD, we review studies on the computational, neuropsychological and neural alterations in juvenile OCD and link these findings to the adult OCD and cognitive neuroscience literature. We find consistent difficulties in tasks entailing complex decision making and set shifting, but limited evidence in other areas that are altered in adult OCD, such as habit and confidence formation. Based on these findings, we establish a neurocomputational framework that illustrates how cognition can go awry and lead to symptoms of juvenile OCD. We link these possible aberrant neural processes to neuroimaging findings in juvenile OCD and show that juvenile OCD is mainly characterised by disruptions of complex reasoning systems.}
}
@article{FRISTON2014148,
title = {Computational psychiatry: the brain as a phantastic organ},
journal = {The Lancet Psychiatry},
volume = {1},
number = {2},
pages = {148-158},
year = {2014},
issn = {2215-0366},
doi = {https://doi.org/10.1016/S2215-0366(14)70275-5},
url = {https://www.sciencedirect.com/science/article/pii/S2215036614702755},
author = {Karl J Friston and Klaas Enno Stephan and Read Montague and Raymond J Dolan},
abstract = {Summary
In this Review, we discuss advances in computational neuroscience that relate to psychiatry. We review computational psychiatry in terms of the ambitions of investigators, emerging domains of application, and future work. Our focus is on theoretical formulations of brain function that put subjective beliefs and behaviour within formal (computational) frameworks—frameworks that can be grounded in neurophysiology down to the level of synaptic mechanisms. Understanding the principles that underlie the brain's functional architecture might be essential for an informed phenotyping of psychopathology in terms of its pathophysiological underpinnings. We focus on active (Bayesian) inference and predictive coding. Specifically, we show how basic principles of neuronal computation can be used to explain psychopathology, ranging from impoverished theory of mind in autism to abnormalities of smooth pursuit eye movements in schizophrenia.}
}
@article{KUMAR20223122,
title = {Experimental Spectroscopic, Quantum Computational, Hirshfeld Surface, Molecular Docking, and Electronic Excitation Studies on an Antibiotic Agent: SDZ},
journal = {Polycyclic Aromatic Compounds},
volume = {43},
number = {4},
pages = {3122-3146},
year = {2022},
issn = {1040-6638},
doi = {https://doi.org/10.1080/10406638.2022.2063909},
url = {https://www.sciencedirect.com/science/article/pii/S1040663822010284},
author = {Mukesh Kumar and Aysha Fatima and Meenakshi Singh and Indresh Verma and Ghazala Khanum and S. Muthu and Khaled Althubeiti and khamael M. Abualnaja and Musheer Ahmad and Nazia Siddiqui and Saleem Javed},
keywords = {DFT, NBO, EDD and HDD, molecular docking},
abstract = {In this report sulfadiazine (SDZ) has been experimentally and quantum chemically investigated. Computational analysis was carried out theoretically using the density functional theory (DFT) approach/B3LYP and 6-311++G(d,p) level to obtain optimized geometrical structure and vibrational modes analysis and other various calculations. A detailed description of the intermolecular interactions of the crystal surface were carried out by means of Hirshfeld surface analysis and fingerprint plots. Exploration of electron excitation from occupied to unoccupied orbitals in a single electron pair occurs, with dimethyl sulfoxide (DMSO) and MeOH as solvents and electron density distribution (EDD) and hole density distribution (HDD) maps were drawn in an excited state. The molecule reactivity region MEP, molecular stability, natural bond orbital (NBO), HOMO–LUMO, dipole moment (μ), polarizability (α), and hyperpolarizability (β) nonlinear optical (NLO), have all been taken into account. NBO analysis was carried out and the hybridization of atoms that form bonds was evaluated. The charge transfer of the title molecule has been examined by TD-DFT method The UV–Vis spectrum was obtained by employing the TDDFT/PCM method and compared with experimental spectra. Calculated HOMO→LUMO energy gap and charge transfer in the molecule was investigated. Chemical descriptors indicate the reactivity of the molecule as a whole, and Fukui function calculations were used to examine the reactive locations of the compound. The electrophilicity index was calculated and the bio-activity of the molecule was studied. However, biological research like drug-likeness and molecular docking are also done on the molecule.}
}
@article{FINDLAY1988165,
title = {Thinking creatively about creative thinking},
journal = {Journal of Social and Biological Structures},
volume = {11},
number = {1},
pages = {165-175},
year = {1988},
issn = {0140-1750},
doi = {https://doi.org/10.1016/0140-1750(88)90059-0},
url = {https://www.sciencedirect.com/science/article/pii/0140175088900590},
author = {C.Scott Findlay and Charles J. Lumsden}
}
@article{VARGASROJAS2022110093,
title = {Prescriptive comprehensive approach for the engineering of products made with composites centered on the manufacturing process and structured design methods: Review study performed on filament winding},
journal = {Composites Part B: Engineering},
volume = {243},
pages = {110093},
year = {2022},
issn = {1359-8368},
doi = {https://doi.org/10.1016/j.compositesb.2022.110093},
url = {https://www.sciencedirect.com/science/article/pii/S1359836822004693},
author = {Erik Vargas-Rojas},
keywords = {Composites thinking, Design method, Filament winding, Product engineering, TRIZ},
abstract = {At first, this research seeks to develop the technology required to fabricate two surfaces of revolution via filament winding: a concavity and a convexity. Concerning mandrels technology, the detachable mandrel concept is chosen among others. Their engineering is conducted conventionally based on free-thinking design approaches, as well as expertise and overconfidence. Consequently, the demoulding process of the concave surface is inefficient due to the lack of adequate dismantling functions of the respective mandrel, leading to damage of the composite material during demoulding, mandrel rework and delays. These inconveniences motivated a reexamination of the mandrels design process. Thus, three structured design methods were incorporated: Design for Manufacturing and Assembly (DFMA), Functional Analysis (FA) and Theory of Inventive Problem Solving (TIPS, a.k.a. TRIZ). Their synergistic implementation allowed the correct demoulding of the concave surface of revolution. In a second stage, this experience serves as reference for proposing a comprehensive, iterative, prescriptive and unified approach aimed at filament-wound products. It focuses on the base material (composites) and the manufacturing process (filament winding), being applicable to other fabrication processes of composite products. It is based on three models reported in the literature: one for metals, one for composites and one for filament-wound composites. Each of its steps is carried out with well-known structured design methods employed in products and systems engineering, including but not limited to DFMA, FA and TRIZ. As regards results, at the level of the design problem of the mandrels, the importance of the correct establishment of mechanical functions – dismantling in this case – is observed. In particular, how the lack of demoulding functions impacts unfavorably the quality of the final product. As respects the comprehensive approach, a significant outcome is the “filament winding thinking,” as an evolution of other schemes such as “metals” or “composites thinking” followed to generically develop products according to the nature of their base material.}
}
@incollection{SEJNOWSKI2015480,
title = {Computational Neuroscience},
editor = {James D. Wright},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {480-484},
year = {2015},
isbn = {978-0-08-097087-5},
doi = {https://doi.org/10.1016/B978-0-08-097086-8.55011-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780080970868550119},
author = {Terrence J. Sejnowski},
keywords = {Algorithms, Computational models, Neural systems},
abstract = {The goal of computational neuroscience is to understand how brains generate behaviors using computational approaches. Computational models of the brain explore how populations of highly interconnected neurons are formed during development and how they represent, process, store, act upon, and become altered by information present in the body and the environment. Techniques from physics, computer science, and mathematics are used to simulate and analyze these computational models and provide links between the wide range of levels that brains are investigated, from molecular interactions to large-scale systems. Models are also used for interpreting experimental data and providing a conceptual framework for the dynamical properties of neural systems, which should lead to more comprehensive theories of brain function.}
}
@article{ESCOLAGASCON2022e11303,
title = {'Feeling' or 'sensing' the future? Testing for anomalous cognitions in clinical versus healthy populations},
journal = {Heliyon},
volume = {8},
number = {11},
pages = {e11303},
year = {2022},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2022.e11303},
url = {https://www.sciencedirect.com/science/article/pii/S2405844022025919},
author = {Álex Escolà-Gascón and Abigail C. Wright and James Houran},
keywords = {Boundary functioning, Emotional intelligence, Parapsychology, Premonitions, Schizophrenia, Thinking styles},
abstract = {In the study and treatment of psychosis, emotional intelligence (EI) and thinking styles are important patient characteristics for successful outcomes in clinical intervention. Anticipation of unpredictable stimuli (AUS) may be understood as an anomalous perception and anomalous cognition in which an individual supposedly senses and recognizes future stimuli in an unexpected way, also referred to as “hunches or premonitions.” This examined the roles of EI and thinking styles in AUSs in convenience samples of healthy participants (n = 237) versus patients diagnosed with psychosis (n = 118). We adjusted several quadratic and exponential regression models according to the obtained functions. Group means were also compared to examine differences in EI scores for participants with psychosis compared to healthy participants. In the healthy group, EI predicted AUSs with a weight between 42% and 58%. Thinking styles were not correlated with AUSs. However, EI was not correlated with AUSs in the clinical group. Patients with psychosis tended to score higher on AUSs and lower on EI and thinking styles compared to participants in the healthy group. We discuss EI as a variable that can contextualize some anomalous perceptions which are otherwise difficult to classify or measure within the classic psychosis continuum model.}
}
@article{ANDREWS2019102188,
title = {Black hole as a model of computation},
journal = {Results in Physics},
volume = {13},
pages = {102188},
year = {2019},
issn = {2211-3797},
doi = {https://doi.org/10.1016/j.rinp.2019.102188},
url = {https://www.sciencedirect.com/science/article/pii/S2211379719304036},
author = {G.R. Andrews},
keywords = {Black hole computation, Kerr/CFT correspondence, Holographic principle, Information theory, Gamma-ray spectroscopy, Shannon entropy},
abstract = {This paper focuses on an alternative, more physically realistic model of computation than Etesi and Németi’s relativistic computer in a Malament-Hogarth spacetime (2002) that uses the black hole itself combined with an external observer equipped with a source and some method of measurement of gamma-rays, as opposed to sending a classical computer into a black hole and exploiting the properties of the spacetime to achieve hypercomputation. The source of output, Hawking radiation, is considered along with the constraints imposed by the holographic principle which limit the number of degrees of freedom in the system and consequently the maximum usable information. The Bekenstein-Hawking entropy is converted from the traditional form in terms of the horizon area to that of the Shannon entropy, establishing an analogy between the physical and computational perspectives of the system. Next examples are considered to establish the approximate order of the necessary excitation energy and the resulting gamma-ray interactions which form the input from the observer. Finally, the Turing completeness of the language for this model is considered through a simulation of the Turing machine. The goal is to introduce a model of computation that can later be used to study the relationship between computability and physical systems.}
}
@article{JAY201976,
title = {Intensional computation with higher-order functions},
journal = {Theoretical Computer Science},
volume = {768},
pages = {76-90},
year = {2019},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2019.02.016},
url = {https://www.sciencedirect.com/science/article/pii/S0304397519301227},
author = {Barry Jay},
keywords = {Intensional computation, Higher-order functions, SF-calculus, Foundations of computation},
abstract = {Intensional computations are those that query the internal structure of their arguments. In a higher-order setting, such queries perform program analysis. This is beyond the expressive power of traditional term rewriting systems, such as lambda-calculus or combinatory logic, as they are extensional. In such settings it has been necessary to encode or quote the program before analysis. However, there are intensional calculi, specifically confluent term rewriting systems, that can analyse higher-order programs within the calculus proper, without quotation; there are even programs that produce the Goedel numbers of their program argument. This paper summarizes the current situation. Highlights include the following observations. We have known since 2011 that the simplest intensional calculus, SF-calculus, supports arbitrary queries of closed normal forms, including equality, pattern-matching, searching and self-interpretation. Recent work, verified using the Coq proof assistant, has shown that all recursive programs can be represented as closed normal forms in SF-calculus, and even in combinatory logic. Thus, we can here deduce that SF-calculus (but not combinatory logic) can define queries of programs. These results are compatible with direct support for lambda-abstraction. Although these results conflict with the traditional understanding of expressive power of combinatory logic and λ-calculus, as developed by Church and Kleene, our recent publication has shown that their approach is compromised by its reliance on encodings. To drive the point home, this paper uses a non-standard encoding to lambda-define a trivial solution of the Halting Problem.}
}
@article{GURSOY201529,
title = {Visualizing making: Shapes, materials, and actions},
journal = {Design Studies},
volume = {41},
pages = {29-50},
year = {2015},
note = {Special Issue: Computational Making},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2015.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X15000617},
author = {Benay Gürsoy and Mine Özkar},
keywords = {material computing, computational models, design activity, parametric design, reasoning},
abstract = {The increasing interest in materiality currently challenges the long existing traditions that consider visual thinking as the primary actor in design creativity. Shape grammars offer a formalism to represent visual reasoning in design, which is never purely limited to the visual aspects of design processes. Aiming to develop ways to explicitly include material manipulation in a computational formalism, we report on an ongoing exploration of how shape computation extends beyond abstract visual shapes to incorporate material shapes that have a physical existence. We present a materially informed process with shape rules and show that we can apply these rules creatively to explore the physical character of the material.}
}
@article{VELUPILLAI201440,
title = {Computable and computational complexity theoretic bases for Herbert Simon’s cognitive behavioral economics},
journal = {Cognitive Systems Research},
volume = {29-30},
pages = {40-52},
year = {2014},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2013.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S1389041713000405},
author = {K.Vela Velupillai and Ying-Fang Kao},
keywords = {Bounded rationality, Satisficing, Heuristics, Computability, Computational complexity},
abstract = {This paper aims to interpret and formalize Herbert Simon’s cognitive notions of bounded rationality, satisficing and heuristics in terms of computability theory and computational complexity theory. Simon’s theory of human problem solving is analyzed in the light of Turing’s work on Solvable and Unsolvable Problems. It is suggested here that bounded rationality results from the fact that the deliberations required for searching computationally complex spaces exceed the actual complexity that human beings can handle. The immediate consequence is that satisficing becomes the general criterion of decision makers and heuristics are the procedures used for achieving their goals. In such decision problems, it is demonstrated that bounded rationality and satisficing are more general than orthodox, non-cognitive, Olympian rationality and optimization, respectively, and not the other way about.}
}
@article{KACERJA2023101035,
title = {Values in preservice mathematics teachers’ discussions of the Body Mass Index - A critical perspective},
journal = {The Journal of Mathematical Behavior},
volume = {70},
pages = {101035},
year = {2023},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2023.101035},
url = {https://www.sciencedirect.com/science/article/pii/S0732312323000056},
author = {Suela Kacerja and Cyril Julie},
keywords = {Values, Critical thinking, Preservice teachers, Mathematics in society, Critical mathematics education},
abstract = {This article explores the values that come to the fore when preservice mathematics teachers (PTs) 11In the remaining parts of the text, we will refer to preservice teachers as PTs. engage in critical discussions about the role of mathematical models in society. The specific model that was discussed was the Body Mass Index (BMI) 22From now on, the Body Mass Index will be referred to as BMI and is calculated as mass (m) divided by the square of height (h).. From the analysis of the PTs’ discussions of the BMI from a mathematical and societal point of view several mathematical and mathematics educational values were identified such as openness, rationalism, progress, reasoning, evaluating, and problematizing the instrumental understanding of mathematics. In addition, critical thinking about mathematics in society as emphasized in curricula in the three countries involved in the study, was identified with four categories of complementary pairs. Knowing the mathematical and mathematics educational values underpinning PTs’ discussions and their connection to critical thinking is important for successfully engaging with the role of mathematics in society.}
}
@article{MAYER2017107,
title = {Understanding scientists’ computational modeling decisions about climate risk management strategies using values-informed mental models},
journal = {Global Environmental Change},
volume = {42},
pages = {107-116},
year = {2017},
issn = {0959-3780},
doi = {https://doi.org/10.1016/j.gloenvcha.2016.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S0959378016306197},
author = {Lauren A. Mayer and Kathleen Loa and Bryan Cwik and Nancy Tuana and Klaus Keller and Chad Gonnerman and Andrew M. Parker and Robert J. Lempert},
keywords = {Values-informed mental models, Climate change, Risk management, Decision making under uncertainty},
abstract = {When developing computational models to analyze the tradeoffs between climate risk management strategies (i.e., mitigation, adaptation, or geoengineering), scientists make explicit and implicit decisions that are influenced by their beliefs, values and preferences. Model descriptions typically include only the explicit decisions and are silent on value judgments that may explain these decisions. Eliciting scientists’ mental models, a systematic approach to determining how they think about climate risk management, can help to gain a clearer understanding of their modeling decisions. In order to identify and represent the role of values, beliefs and preferences on decisions, we used an augmented mental models research approach, namely values-informed mental models (ViMM). We conducted and qualitatively analyzed interviews with eleven climate risk management scientists. Our results suggest that these scientists use a similar decision framework to each other to think about modeling climate risk management tradeoffs, including eight specific decisions ranging from defining the model objectives to evaluating the model’s results. The influence of values on these decisions varied between our scientists and between the specific decisions. For instance, scientists invoked ethical values (e.g., concerns about human welfare) when defining objectives, but epistemic values (e.g., concerns about model consistency) were more influential when evaluating model results. ViMM can (i) enable insights that can inform the design of new computational models and (ii) make value judgments explicit and more inclusive of relevant values. This transparency can help model users to better discern the relevance of model results to their own decision framing and concerns.}
}
@article{HUIJSER2018170,
title = {The wandering self: Tracking distracting self-generated thought in a cognitively demanding context},
journal = {Consciousness and Cognition},
volume = {58},
pages = {170-185},
year = {2018},
issn = {1053-8100},
doi = {https://doi.org/10.1016/j.concog.2017.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S1053810017301927},
author = {Stefan Huijser and Marieke K. {van Vugt} and Niels A. Taatgen},
keywords = {Self-generated thought, Mind wandering, Self-referential processing, Task demand, Computational cognitive modeling, Eye-tracking},
abstract = {We investigated how self-referential processing (SRP) affected self-generated thought in a complex working memory task (CWM) to test the predictions of a computational cognitive model. This model described self-generated thought as resulting from competition between task- and distracting processes, and predicted that self-generated thought interferes with rehearsal, reducing memory performance. SRP was hypothesized to influence this goal competition process by encouraging distracting self-generated thinking. We used a spatial CWM task to examine if SRP instigated such thoughts, and employed eye-tracking to examine rehearsal interference in eye-movement and self-generated thinking in pupil size. The results showed that SRP was associated with lower performance and higher rates of self-generated thought. Self-generated thought was associated with less rehearsal and we observed a smaller pupil size for mind wandering. We conclude that SRP can instigate self-generated thought and that goal competition provides a likely explanation for how self-generated thoughts arises in a demanding task.}
}
@article{SUN2009124,
title = {Theoretical status of computational cognitive modeling},
journal = {Cognitive Systems Research},
volume = {10},
number = {2},
pages = {124-140},
year = {2009},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2008.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S1389041708000429},
author = {Ron Sun},
keywords = {Cognitive modeling, Cognitive architecture, Theory, Simulation, Validation},
abstract = {This article explores the view that computational models of cognition may constitute valid theories of cognition, often in the full sense of the term “theory”. In this discussion, this article examines various (existent or possible) positions on this issue and argues in favor of the view above. It also connects this issue with a number of other relevant issues, such as the general relationship between theory and data, the validation of models, and the practical benefits of computational modeling. All the discussions point to the position that computational cognitive models can be true theories of cognition.}
}
@article{ALEXANDRU20221,
title = {Theories of life and computation: Special issue on the occasion of the 65th birthday of Professor Gabriel Ciobanu},
journal = {Theoretical Computer Science},
volume = {926},
pages = {1-2},
year = {2022},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2022.06.041},
url = {https://www.sciencedirect.com/science/article/pii/S0304397522004157},
author = {Andrei Alexandru and Bogdan Aman and Ross Horne}
}
@article{OERS199051,
title = {The development of mathematical thinking in school: a comparison of the action- psychological and information-processing approaches},
journal = {International Journal of Educational Research},
volume = {14},
number = {1},
pages = {51-66},
year = {1990},
issn = {0883-0355},
doi = {https://doi.org/10.1016/0883-0355(90)90016-2},
url = {https://www.sciencedirect.com/science/article/pii/0883035590900162},
author = {Bert Van Oers},
abstract = {The learning and teaching of mathematics can be analyzed from different psychological points of view. Information-processing theories focus on the various information-processing mechanisms underlying mathematical competence and try to foster the development of these mechanisms in order to stimulate the growth of mathematical competence. In the action-psychological approach of the cultural-historical school, mathematics is viewed as a kind of culturally developed human activity governed by the rules that mathematicians themselves follow while doing their job. Consequently, the development of mathematical competence is regarded as the formation of a system of meaningful mathematical actions that constitute that activity. At a general theoretical level these approaches can be shown to be basically different and even incompatible. With regard to mathematics education the differences are illustrated with respect to several themes such as task-analysis, automatization, and the learning of elementary arithmetic. Considering insight and meaningful and sophisticated problem-solving as the core of mathematical thinking, the action-psychological approach appears to be the more promising candidate as an aid in the design of future mathematics education.}
}
@article{ADAMATZKY2017469,
title = {East-West paths to unconventional computing},
journal = {Progress in Biophysics and Molecular Biology},
volume = {131},
pages = {469-493},
year = {2017},
note = {Integral Biomathics 2017: The Necessary Conjunction of Western and Eastern Thought Traditions for Exploring the Nature of Mind and Life},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2017.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S0079610717301177},
author = {Andrew Adamatzky and Selim Akl and Mark Burgin and Cristian S. Calude and José Félix Costa and Mohammad Mahdi Dehshibi and Yukio-Pegio Gunji and Zoran Konkoli and Bruce MacLennan and Bruno Marchal and Maurice Margenstern and Genaro J. Martínez and Richard Mayne and Kenichi Morita and Andrew Schumann and Yaroslav D. Sergeyev and Georgios Ch. Sirakoulis and Susan Stepney and Karl Svozil and Hector Zenil},
keywords = {Unconventional computing, East, West, Spirituality},
abstract = {Unconventional computing is about breaking boundaries in thinking, acting and computing. Typical topics of this non-typical field include, but are not limited to physics of computation, non-classical logics, new complexity measures, novel hardware, mechanical, chemical and quantum computing. Unconventional computing encourages a new style of thinking while practical applications are obtained from uncovering and exploiting principles and mechanisms of information processing in and functional properties of, physical, chemical and living systems; in particular, efficient algorithms are developed, (almost) optimal architectures are designed and working prototypes of future computing devices are manufactured. This article includes idiosyncratic accounts of ‘unconventional computing’ scientists reflecting on their personal experiences, what attracted them to the field, their inspirations and discoveries.}
}
@article{THANATIPANONDA202138,
title = {A multi-computational exploration of some games of pure chance},
journal = {Journal of Symbolic Computation},
volume = {104},
pages = {38-68},
year = {2021},
issn = {0747-7171},
doi = {https://doi.org/10.1016/j.jsc.2020.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S0747717120300183},
author = {Thotsaporn “Aek” Thanatipanonda and Doron Zeilberger},
keywords = {Experimental mathematics, Games of pure chance, Symbolic computation},
abstract = {In the spirit of “multi-culturalism”, we use four kinds of computations: simulation, numeric, symbolic, and “conceptual”, to explore some “games of pure chance” inspired by children board games like “Snakes and Ladders” (aka “Chutes and Ladders”) and “gambler's ruin with unlimited credit”. Even more interesting than the many computer-generated specific results described in this paper and its web-site extension, is our broad-minded, ecumenical approach, not favoring, a priori, any one of the above four kinds of computation, but showing that, a posteriori, symbolic computation is the most important one, since (except for simulation) numerics can be made more efficient with the help of symbolics (in the “downward” direction), and, (in the “upward” direction) the mere existence of certain symbolic-computational algorithms imply interesting “qualitative” results, that certain numbers are always rational, or always algebraic, and certain sequences are always polynomial, or C-recursive, or algebraic, or holonomic. This article is accompanied by four Maple packages, and numerous input and output files, that readers can use as templates for their own investigations.}
}
@article{NIKOLIC2023107820,
title = {Where is the mind within the brain? Transient selection of subnetworks by metabotropic receptors and G protein-gated ion channels},
journal = {Computational Biology and Chemistry},
volume = {103},
pages = {107820},
year = {2023},
issn = {1476-9271},
doi = {https://doi.org/10.1016/j.compbiolchem.2023.107820},
url = {https://www.sciencedirect.com/science/article/pii/S1476927123000117},
author = {Danko Nikolić},
keywords = {Scaling problem, Explanatory gap, Connectionism, Metabotropic receptors, G protein-gated ion channels, Practopoiesis},
abstract = {Perhaps the most important question posed by brain research is: How the brain gives rise to the mind. To answer this question, we have primarily relied on the connectionist paradigm: The brain’s entire knowledge and thinking skills are thought to be stored in the connections; and the mental operations are executed by network computations. I propose here an alternative paradigm: Our knowledge and skills are stored in metabotropic receptors (MRs) and the G protein-gated ion channels (GPGICs). Here, mental operations are assumed to be executed by the functions of MRs and GPGICs. As GPGICs have the capacity to close or open branches of dendritic trees and axon terminals, their states transiently re-route neural activity throughout the nervous system. First, MRs detect ligands that signal the need to activate GPGICs. Next, GPGICs transiently select a subnetwork within the brain. The process of selecting this new subnetwork is what constitutes a mental operation – be it in a form of directed attention, perception or making a decision. Synaptic connections and network computations play only a secondary role, supporting MRs and GPGICs. According to this new paradigm, the mind emerges within the brain as the function of MRs and GPGICs whose primary function is to continually select the pathways over which neural activity will be allowed to pass. It is argued that MRs and GPGICs solve the scaling problem of intelligence from which the connectionism paradigm suffers.}
}
@article{PINE2017385,
title = {Clinical Advances From a Computational Approach to Anxiety},
journal = {Biological Psychiatry},
volume = {82},
number = {6},
pages = {385-387},
year = {2017},
note = {Computational Psychiatry},
issn = {0006-3223},
doi = {https://doi.org/10.1016/j.biopsych.2016.09.020},
url = {https://www.sciencedirect.com/science/article/pii/S0006322316328669},
author = {Daniel S. Pine}
}
@incollection{ERICSSON199437,
title = {CHAPTER 2 - Contemporary Approaches to the Study of Thinking and Problem Solving},
editor = {Robert J. Sternberg},
booktitle = {Thinking and Problem Solving},
publisher = {Academic Press},
address = {San Diego},
pages = {37-79},
year = {1994},
volume = {2},
series = {Handbook of Perception and Cognition},
isbn = {978-0-08-057299-4},
doi = {https://doi.org/10.1016/B978-0-08-057299-4.50008-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780080572994500086},
author = {K. Anders Ericsson and Reid Hastie},
abstract = {Publisher Summary
This chapter discusses the contemporary approaches to the study of thinking and problem solving. The modal approach to create a comprehensive theory of thinking strives to identify simple conditions under which a given type of thinking can be reliably reproduced. Following the successful example of experimenters in many of the natural sciences, the goal of this approach is to discover general laws and invariant constraints in well-defined tasks that do not require access to complex knowledge and experience. The most popular alternative approach to the study of thinking starts by examining performance in everyday life and identifying stable and reproducible phenomena. Of particular interest is expert performance, because it offers the highest levels of performance and also the largest stable individual differences in performance when compared with that of beginners. An understanding of thinking is incomplete unless it provides an account of how the elements of adult thought—such as concepts, representations, and skills—are acquired. Research on learning and skill acquisition on the whole range of activities ranging from performance on simple laboratory tasks to complex life-long efforts to attain expert performance shows that effective learning is not an automatic consequence of extended experience.}
}
@article{1999209,
title = {99/02041 Strategic thinking about nuclear energy: implications of the emerging market structure in electric generation: Bodde, D. L. Energy Policy, 1998, 26, (12), 957–962},
journal = {Fuel and Energy Abstracts},
volume = {40},
number = {3},
pages = {209},
year = {1999},
issn = {0140-6701},
doi = {https://doi.org/10.1016/S0140-6701(99)97811-6},
url = {https://www.sciencedirect.com/science/article/pii/S0140670199978116}
}
@article{GIORGI2023101151,
title = {Conceptual development from the perspective of a brain-inspired robotic architecture},
journal = {Cognitive Systems Research},
volume = {82},
pages = {101151},
year = {2023},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2023.101151},
url = {https://www.sciencedirect.com/science/article/pii/S1389041723000797},
author = {Ioanna Giorgi and Bruno Golosio and Massimo Esposito and Angelo Cangelosi and Giovanni Luca Masala},
keywords = {Brain-inspired model, Cognitive architecture, Robotic model, High-level cognition, Human language, Concepts, Categorisation, Conceptual development, Understanding},
abstract = {Concepts are central to reasoning and intelligent behaviour. Scientific evidence shows that conceptual development is fundamental for the emergence of high-cognitive phenomena. Here, we model such phenomena in a brain-inspired cognitive robotic model and examine how the robot can learn, categorise, and abstract concepts to voluntary control behaviour. The paper argues that such competence arises with sufficient conceptual content from physical and social experience. Hence, senses, motor abilities and language, all contribute to a robot’s intelligent behaviour. To this aim, we devised a method for attaining concepts, which computationally reproduces the steps of the inductive thinking strategy of the Concept Attainment Model (CAM). Initially, the robot is tutor-guided through socio-centric cues to attain concepts and is then tested consistently to use these concepts to solve complex tasks. We demonstrate how the robot uses language to create new categories by abstraction in response to human language-directed instructions. Linguistic stimuli also change the representations of the robot’s experiences and generate more complex representations for further concepts. Most notably, this work shows that this competence emerges from the robot’s ability to understand the concepts similarly to human understanding. Such understanding was also maintained when concepts were expressed in multilingual lexicalisations showing that labels represent concepts that allowed the model to adapt to unfamiliar contingencies in which it did not have directly related experiences. The work concludes that language is an essential component of conceptual development, which scaffolds the cognitive continuum of a robot from low-to-high cognitive skills, including its skill to understand.}
}
@article{BERNARD20153982,
title = {Developing a Capability to Elicit and Structure Psychosocial Decision Information within Computational Models},
journal = {Procedia Manufacturing},
volume = {3},
pages = {3982-3989},
year = {2015},
note = {6th International Conference on Applied Human Factors and Ergonomics (AHFE 2015) and the Affiliated Conferences, AHFE 2015},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2015.07.945},
url = {https://www.sciencedirect.com/science/article/pii/S2351978915009464},
author = {Michael L. Bernard},
keywords = {Knowledge elicitation, Knowledge structure, Cognitive modeling, Social modeling, Systems modeling, Country assessments},
abstract = {There is a recognized need to develop computational models that can represent and simulate the decision making process of various groups across socio-cultural domains [5]. Yet, developing such models can be greatly hampered by the need to acquire and represent information pertaining to the psychological and social aspects of decision-making within these groups. Currently, there are numerous techniques and tools to help facilitate the elicitation and structuring of knowledge within expert-type systems—particularly those that focus on technical processes such as mechanical troubleshooting [3]. However, few techniques and tools have been developed for models that are intended to represent and assess the decision making of groups within different societies—particularly including cultural elements within these societies. This paper seeks to help address this challenge by discussing an approach to eliciting and structuring cross-cultural psychosocial and behavioral-economic elements within a theory-based assessment model. This work was developed to address the needs of Sandia National Laboratories’ Behavioral Influence Assessment modeling capability, which assesses decision-making within societies. The main component of the knowledge engineering effort is what we call the “knowledge structure.” The knowledge structure acts as scaffolding for the organization of psychosocial processes underlying decision-making, as well as the actual content of that knowledge with respect to a modeled society.}
}
@article{LIU2023340,
title = {Research on the standardization strategy of granular computing},
journal = {International Journal of Cognitive Computing in Engineering},
volume = {4},
pages = {340-348},
year = {2023},
issn = {2666-3074},
doi = {https://doi.org/10.1016/j.ijcce.2023.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S2666307423000323},
author = {Donghang Liu and Xuekui Shangguan and Keyu Wei and Chensi Wu and Xiaoying Zhao and Qifeng Sun and Yaoyu Zhang and Ruijun Bai},
keywords = {Granular computing, Standardization strategy, Methodology, Standard system},
abstract = {As intelligent systems continue to evolve, problems are becoming increasingly complex. The constant abundance of data puts a higher demand on the value of data utilization. Granular computing is a new computational paradigm for complex problem-solving. It takes structured thinking, structured problem-solving methods, and structured information processing patterns as its research objects and belongs to the scope of higher-level human cognitive mechanism research. The development and application of granular computing must be more standardized and unified. The granular computing standardization strategy is the most direct means to promote the regularization of granular computing. In this paper, we first sort out the main applications of granular computing in standards. According to the characteristics of granular computing, a framework of its standard system is proposed to provide a reference for the subsequent research of granular computing standards. The next direction of the granular computing standards strategy is discussed, and solutions are given.}
}
@article{ROWAN2024171672,
title = {Digital technologies to unlock safe and sustainable opportunities for medical device and healthcare sectors with a focus on the combined use of digital twin and extended reality applications: A review},
journal = {Science of The Total Environment},
volume = {926},
pages = {171672},
year = {2024},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2024.171672},
url = {https://www.sciencedirect.com/science/article/pii/S004896972401814X},
author = {Neil J. Rowan},
keywords = {Medical devices, Digital transformation, Design thinking, Sterilization, Sustainability, Circularity},
abstract = {Medical devices have increased in complexity where there is a pressing need to consider design thinking and specialist training for manufacturers, healthcare and sterilization providers, and regulators. Appropriately addressing this consideration will positively inform end-to-end supply chain and logistics, production, processing, sterilization, safety, regulation, education, sustainability and circularity. There are significant opportunities to innovate and to develop appropriate digital tools to help unlock efficiencies in these important areas. This constitutes the first paper to create an awareness of and to define different digital technologies for informing and enabling medical device production from a holistic end-to-end life cycle perspective. It describes the added-value of using digital innovations to meet emerging opportunities for many disposable and reusable medical devices. It addresses the value of accessing and using integrated multi-actor HUBs that combine academia, industry, healthcare, regulators and society to help meet these opportunities. Such as cost-effective access to specialist pilot facilities and expertise that converges digital innovation, material science, biocompatibility, sterility assurance, business model and sustainability. It highlights the marked gap in academic R&D activities (PRISMA review of best publications conducted between January 2010 and January 2024) and the actual list of U.S. FDA's approved and marketed artificial intelligence/machine learning (AI/ML), and augmented reality/virtual reality (AR/VR) enabled-medical devices for different healthcare applications. Bespoke examples of benefits underlying future use of digital tools includes potential implementation of machine learning for supporting and enabling parametric release of sterilized products through efficient monitoring of critical process data (complying with ISO 11135:2014) that would benefit stakeholders. This paper also focuses on the transformative potential of combining digital twin with extended reality innovations to inform efficiencies in medical device design thinking, supply chain and training to inform patient safety, circularity and sustainability.}
}
@article{20161,
title = {Credit for Computation},
journal = {Cell Systems},
volume = {3},
number = {1},
pages = {1-2},
year = {2016},
issn = {2405-4712},
doi = {https://doi.org/10.1016/j.cels.2016.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S2405471216302289}
}
@article{LEIRMO2024761,
title = {Digital Twins for Industry 5.0: Unlocking the Human Potential},
journal = {Procedia CIRP},
volume = {130},
pages = {761-766},
year = {2024},
note = {57th CIRP Conference on Manufacturing Systems 2024 (CMS 2024)},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.10.161},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124013180},
author = {Torbjørn L. Leirmo},
keywords = {Digital twin, Human aspect, Industry 5.0},
abstract = {The holy grail of Industry 5.0 resides in the intersection of the three dimensions; sustainable, resilient, and human-centric manufacturing. While the Industry 4.0 paradigm addresses resiliency and sustainability through increased flexibility and efficiency, the human component of manufacturing systems has been largely neglected. Despite rapid developments in artificial intelligence, human intelligence remains superior in terms of creative and critical thinking. Digital twins have emerged as a concept that effectively merges the physical and the digital worlds in cyber-physical production systems. The computational power of digital systems is leveraged to collect and aggregate data that are analyzed and presented to a human decision-maker. Taking a human-centric perspective, the digital twin should be designed to enhance human capabilities, accommodate the needs of people, and mitigate shortcomings of the human mind. This paper addresses these issues by discussing how humans may utilize and better interact with digital twins. A conceptual framework for a human-centric digital twin is proposed with use cases for various interfaces for operators, engineers, and managers.}
}
@article{HAN2020382,
title = {A computational approach for using social networking platforms to support creative idea generation},
journal = {Procedia CIRP},
volume = {91},
pages = {382-387},
year = {2020},
note = {Enhancing design through the 4th Industrial Revolution Thinking},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2020.02.190},
url = {https://www.sciencedirect.com/science/article/pii/S2212827120308374},
author = {Ji Han and Dongmyung Park and Hannah Forbes and Dirk Schaefer},
keywords = {Creativity, Social Media, Idea Generation, Social Networking, Ideation},
abstract = {Good design relies upon the generation of good ideas, but producing ideas, especially creative ones, is increasingly challenging. This may be due to limited relevant information, lack of creative skills, design fixation, or as a result of too many previously existing ideas. Conventional creativity tools, such as brainstorming and TRIZ, as well as advanced methods, such as design-by-analogy, are often employed by designers for idea generation to alleviate some of these challenges. In recent years, computational creativity tools have emerged to support creative idea generation. However, most of these computational tools are data-driven, and thereby employ various databases, for example, existing databases such as the ConceptNet containing past common-sense knowledge, and customized ones containing limited information. The limitations of these databases have constrained the capability of the computational creativity tools. Social media platforms, such as Twitter and Wikipedia, which allow users to create web-based content, have been reported to have billions of users. It can be considered a huge ‘unorganized’ database of information created by a crowd. However, to date little work has been done on the utilization of such crowd-generated knowledge from social media to support actual design activities, especially during the early stages of the design process. In this paper, the authors propose a computational approach to retrieve, process, and reuse the textual knowledge from social networks to prompt designers’ creative mind in producing ideas for new product design and development. They also propose a novel approach to construct crowd knowledge databases, which can be employed by computational tools, as well as used individually, for supporting creative idea generation. A case study involving the use of an existing social media analysis tool to construct a crowd database for helping designers produce ideas has been conducted to provide insights on implementing the proposed approach for creative idea generation.}
}
@incollection{HORWITZ2023265,
title = {8 - Improved force models for Euler–Lagrange computations},
editor = {Shankar Subramaniam and S. Balachandar},
booktitle = {Modeling Approaches and Computational Methods for Particle-Laden Turbulent Flows},
publisher = {Academic Press},
pages = {265-298},
year = {2023},
series = {Computation and Analysis of Turbulent Flows},
isbn = {978-0-323-90133-8},
doi = {https://doi.org/10.1016/B978-0-32-390133-8.00015-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780323901338000153},
author = {Jeremy A.K. Horwitz},
keywords = {undisturbed fluid velocity, two-way coupling, Euler–Lagrange, spherical particle equation of motion, drag, lift, unsteady effects, wall-bounded flows, multi-particle effects},
abstract = {This chapter focuses on force models governing spherical particle motion which are used in Euler–Lagrange methods. These forces also represent a momentum exchange and are important for modeling how fluid dynamics change in the presence of particles. A survey of widely used drag and lift correlations for single- and multiple-particle systems will be presented along with some physical discussion as to their origins. Our focus is on incompressible applications though a few compressible force formulations will be mentioned. A central quantity that arises in these force correlations is the notion of the undisturbed fluid velocity. Seldom taught in fluid mechanics curricula and often confused with “free-stream” velocity, the undisturbed fluid velocity is discussed in detail to develop the reader's intuition. Modeling of the undisturbed fluid velocity is addressed in the context of two-way coupled correction schemes.}
}
@article{NAGURNEY19953,
title = {Massively parallel computation of spatial price equilibrium problems as dynamical systems},
journal = {Journal of Economic Dynamics and Control},
volume = {19},
number = {1},
pages = {3-37},
year = {1995},
issn = {0165-1889},
doi = {https://doi.org/10.1016/0165-1889(93)00772-V},
url = {https://www.sciencedirect.com/science/article/pii/016518899300772V},
author = {Anna Nagurney and Takashi Takayama and Ding Zhang},
keywords = {Spatial price equilibrium, Dynamical systems, Variational inequalities, Massively parallel computation},
abstract = {In this paper we introduce a dynamical system for the formulation and computation of spatial price equilibrium problems in quantity variables. The set of stationary points of the system corresponds to the set of solutions of the variational inequality problem governing the problem. We propose the Euler-type method for the computation of the equilibrium pattern and provide convergence results. We then demonstrate that the algorithm can be implemented on a massively parallel architecture and illustrate its performance on the Thinking Machine's CM-2 architecture. This research represents the first implementation of a massively parallel approach for the computation of either dynamical systems or variational inequality problems arising in economics.}
}
@article{JOLLY20171,
title = {Computational systems biology of epithelial-hybrid-mesenchymal transitions},
journal = {Current Opinion in Systems Biology},
volume = {3},
pages = {1-6},
year = {2017},
note = {• Mathematical modelling • Mathematical modelling, Dynamics of brain activity at the systems level • Clinical and translational systems biology},
issn = {2452-3100},
doi = {https://doi.org/10.1016/j.coisb.2017.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S2452310016300191},
author = {Mohit Kumar Jolly and Herbert Levine},
keywords = {Metastasis, Epithelial–mesenchymal plasticity, Hybrid epithelial/mesenchymal, Cancer stem cells, Computational modeling},
abstract = {Metastasis accounts for more than 90% of cancer-related deaths, and is fueled by fine-tuned transitions among many cellular phenotypes. Transitions among epithelial (strong cell–cell adhesion, no or little migration), mesenchymal (no cell–cell adhesion, high migration), and hybrid epithelial/mesenchymal (both cell–cell adhesion and cell migration) phenotypes are considered to be a hallmark of metastasis. Recent years have witnessed rapid progress in mapping the regulatory networks underlying these transitions. This progress has enabled the capability to develop computational systems biology models to characterize how various intracellular and extracellular signals can drive these transitions. Here, we discuss how different mathematical models have contributed to elucidating the underlying principles of these transitions and guided further experiments to address key unanswered questions concerning metastasis.}
}

@article{FUCHS2023103688,
title = {A post-Cartesian economic and Buddhist view on tourism},
journal = {Annals of Tourism Research},
volume = {103},
pages = {103688},
year = {2023},
issn = {0160-7383},
doi = {https://doi.org/10.1016/j.annals.2023.103688},
url = {https://www.sciencedirect.com/science/article/pii/S0160738323001615},
author = {Matthias Fuchs},
keywords = {Economic growth ideology, Post-Cartesian ontology, Post-mechanistic economic theory, Buddhist philosophy, Transformative tourism},
abstract = {Insuperable socio-economic and ecological crises demonstrate the need to challenge economic growth ideology that is often embedded in contemporary tourism science. By borrowing from Buddhist philosophy this essay describes inconsistencies in economic theorizing due to its adoption of the Cartesian ontology implying a mechanistic thinking form. Following philosopher Brodbeck (2014), economic science is neither an empirically exact science nor value-free but represents an implicit ethics. To build on this, the elements of a post-mechanistic economic theory are sketched (Brodbeck, 2001). The applicability of this concept is corroborated by instances of current tourism research. After reinterpreting the homo economicus and the nature of money an agenda for a transformative tourism science building upon post-Cartesian economic thinking and Buddhist philosophy is elaborated.}
}
@incollection{DELLANGELO2022299,
title = {13 - Computational chemistry and the study and design of catalysts},
editor = {Liliana Mammino},
booktitle = {Green Chemistry and Computational Chemistry},
publisher = {Elsevier},
pages = {299-332},
year = {2022},
series = {Advances in Green and Sustainable Chemistry},
isbn = {978-0-12-819879-7},
doi = {https://doi.org/10.1016/B978-0-12-819879-7.00010-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128198797000106},
author = {David Dell’Angelo},
keywords = {CO capture, conversion and utilization, Energy storage, Free energy techniques, Metal-organic frameworks (MOFs), Nanohazard simulations, Photocatalysis technologies, Roles of catalysis in green chemistry, Simulation methods in molecular modelling, Solvent effects on chemical reactivity, Zeolites and catalysis},
abstract = {Several theoretical and computational chemistry works may yield results that prove useful for a better understanding of phenomena relevant to green chemistry, or may specifically focus on addressing green chemistry issues. This chapter presents an overview of results of this type, considering their various application areas. At the same time, it devotes particular attention to the roles that computationally obtained information may play for an efficient design of catalysts and for a better understanding of catalytic processes. This particular attention is motivated by the fundamental roles of catalysis in the design of ‘greener’ processes, where ‘greener’ may refer to a variety of aspects, such as the use of safer reactants and products, the use of benign solvents, the increase in energy efficiency and other features that make a process more environmentally friendly.}
}
@article{SUO2024109268,
title = {A review of three-way decision: Triadic understanding, organization, and perspectives},
journal = {International Journal of Approximate Reasoning},
volume = {173},
pages = {109268},
year = {2024},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2024.109268},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X24001555},
author = {Langwangqing Suo and Han Yang and Qiaoyi Li and Hai-Long Yang and Yiyu Yao},
keywords = {Three-way decision, Triadic thinking, Three-way literature review,  method, Three-way bibliometrics analytics},
abstract = {A theory of three-way decision is about thinking, problem-solving, and computing in threes or through triads. In this paper, we review fifteen years of research on three-way decision by using the philosophy-theory-application triad and the who-what-when triad. First, we discuss the philosophy, theory, and application of three-way decision. At the philosophy level, we delve into the philosophical roots and fundamental nature of three-way decision to reveal the underlying philosophical thinking. At the theory level, we provide an insightful analysis of the theory and methodology of three-way decision. At the application level, we examine the integration of three-way decision with other theories and their applications and effectiveness in real-world scenarios. Second, we focus on bibliometrics analytics by using the who-what-when triad, which attempts to answer a fundamental question of “who did what when”. We propose a 3×3 model by applying the 3×3 method of three-way decision. The first 3 is the author-topic-time triad. The second 3 represents a three-level analysis for each of the first three: (1) categorizing authors into the three levels of prolific authors, frequent authors, and occasional authors, (2) classifying topics into the three levels of the core topics, emerging topics, and to-be-explored topics, and (3) dividing articles into the three levels of initial investigations, further developments, and most recent studies. Finally, we perform a bibliometrics analysis of three-way decision articles by using the 3×3 model of three-way decision. The results not only reveal the current status and trend of three-way decision research but also provide a road map for future research.}
}
@article{FERGUSON2024286,
title = {Social uncertainty in the digital world},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {4},
pages = {286-289},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S1364661324000329},
author = {Amanda M. Ferguson and Georgia Turner and Amy Orben},
keywords = {Bayesian inference, digital affordances, social media, social uncertainty},
abstract = {The social world is inherently uncertain. We present a computational framework for thinking about how increasingly popular online environments modulate the social uncertainty we experience, depending on the type of social inferences we make. This framework draws on Bayesian inference, which involves combining multiple informational sources to update our beliefs.}
}
@article{YERION20151967,
title = {An Introductory Course in the Computational Modeling of Nature},
journal = {Procedia Computer Science},
volume = {51},
pages = {1967-1976},
year = {2015},
note = {International Conference On Computational Science, ICCS 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.05.461},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915012697},
author = {Kathie A. Yerion},
keywords = {Modeling, Agent-based, System-dynamics},
abstract = {This introductory course in computational modeling of nature contains the development of three kinds of models of phenomena in nature -- agent-based models and simple finite difference models using the environment of the NetLogo language and complex finite difference models using the language of C++. No prior programming experience is assumed. The natural phenomena modeled include some standard ones (e.g. ants following pheromone trails, the interaction of sheep and wolves) and some non-standard ones (the creation of the world, 3 dogs playing games, and formation of stripes and spots in the skins of animals). The emphasis of the course is on the modeling process. A distinguishing feature is that students are able to compare and critique these models.}
}
@article{BOERS2025100095,
title = {Exploring cognitive strategies in human-AI interaction: ChatGPT's role in creative tasks},
journal = {Journal of Creativity},
volume = {35},
number = {1},
pages = {100095},
year = {2025},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2025.100095},
url = {https://www.sciencedirect.com/science/article/pii/S2713374525000020},
author = {Jelle Boers and Terra Etty and Martine Baars and Kim {van Boekhoven}},
keywords = {Human-AI interaction, Cognitive strategies, Creativity, Higher education},
abstract = {This study investigated the cognitive strategies employed by dyads when utilizing ChatGPT's examples to generate ideas in creative tasks. Fourteen university students generated ideas for both function-first and form-first creative tasks in interaction with ChatGPT. Their 591 turns were analyzed using both self-reports and coded transcripts to categorize cognitive strategies such as conceptual combination, inspiration, improvement, and repetition. The results indicated that students less frequently employ cognitive strategies focusing on human-AI interaction (e.g., inspiration, improve, combine), but that most of the ideas were produced by repeating ChatGPT's idea. This tendency suggests that, when given freedom, students may rely heavily on AI-generated suggestions rather than actively engaging in more complex cognitive processes. A key practical implication of these findings is the importance of educating students on different cognitive strategies they can adopt in collaboration with AI tools. By guiding students to employ more diverse and active cognitive strategies, ChatGPT has the potential to become a more effective tool for enhancing creative thinking in higher education.}
}
@article{LIU20111907,
title = {The effect of simulation games on the learning of computational problem solving},
journal = {Computers & Education},
volume = {57},
number = {3},
pages = {1907-1918},
year = {2011},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2011.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S0360131511000832},
author = {Chen-Chung Liu and Yuan-Bang Cheng and Chia-Wen Huang},
keywords = {Game-based learning, Problem solving, Simulation, Flow experience},
abstract = {Simulation games are now increasingly applied to many subject domains as they allow students to engage in discovery processes, and may facilitate a flow learning experience. However, the relationship between learning experiences and problem solving strategies in simulation games still remains unclear in the literature. This study, thus, analyzed the feedback and problem solving behaviors of 117 students in a simulation game, designed to assist them to learn computational problem solving. It was found that students when learning computational problem solving with the game were more likely to perceive a flow learning experience than in traditional lectures. The students’ intrinsic motivation was also enhanced when they learned with the simulation game. In particular, the results of the study found a close association between the students’ learning experience states and their problem solving strategies. The students who perceived a flow experience state frequently applied trial-and-error, learning-by-example, and analytical reasoning strategies to learn the computational problem solving skills. However, a certain portion of students who experienced states of boredom and anxiety did not demonstrate in-depth problem solving strategies. For instance, the students who felt anxious in the simulation game did not apply the learning-by-example strategy as frequently as those in the flow state. In addition, the students who felt bored in the simulation game only learned to solve the problem at a superficial level.}
}
@article{HAWTHORNE2022100931,
title = {Reconceptualizing a mathematical domain on the basis of student reasoning: Considering teachers’ perspectives about integers},
journal = {The Journal of Mathematical Behavior},
volume = {65},
pages = {100931},
year = {2022},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2021.100931},
url = {https://www.sciencedirect.com/science/article/pii/S0732312321000924},
author = {Casey Hawthorne and Randolph A. Philipp and Lisa L. Lamb and Jessica P. Bishop and Ian Whitacre and Bonnie P. Schappelle},
keywords = {Integers, Student thinking, Mathematical knowledge for teaching},
abstract = {Integers have historically been approached as a system of rules. However, to teach any mathematical domain for understanding, teachers must conceptualize it as comprised of more than procedures. Using as a lens the four types of integer reasoning identified by Bishop et al. (2014a, 2014b), we interviewed 7th-grade teachers to investigate their own integer reasoning and how this corresponds to their approaches to teaching integers and to their interpretations of students’ reasoning. The teachers not only correctly solved integer tasks but also most reasoned using more than rules, demonstrating a flexibility of strategies. Additionally, although they attempted to introduce integers in meaningful ways, most teachers viewed teaching integers as helping their students apply procedures, an orientation that constrained their understanding of students’ integer reasoning. Results indicate that teachers possess productive conceptual resources but need a structure to leverage their understandings to teach integers as more than a set of rules.}
}
@article{LIU2024100642,
title = {A systematic review on how educators teach AI in K-12 education},
journal = {Educational Research Review},
volume = {45},
pages = {100642},
year = {2024},
issn = {1747-938X},
doi = {https://doi.org/10.1016/j.edurev.2024.100642},
url = {https://www.sciencedirect.com/science/article/pii/S1747938X24000514},
author = {Xiaofan Liu and Baichang Zhong},
keywords = {K-12 education, AI education, AI literacy, Research design, Teaching practice},
abstract = {Developing Artificial Intelligence (AI) education in K-12 contexts, i.e., teaching students about AI, is critical to promote students' AI literacy. However, the state-of-the-art of AI education is not clear enough. To this end, this study reviewed 45 high-quality empirical studies on K-12 AI education over the past decade from both research and instruction perspectives. Regarding the research design, this study revealed the relationship between publication year, sample size, learning stage, educational setting, research method, research focus and duration. Regarding the instruction design, this study revealed the relationship between learning stage, pedagogical strategy, learning tool, learning activity, learning content, assessment method and learning effect. Besides, this study also derived recommendations for research (i.e., time allocation, samples selection, longitudinal design, rigorous methodology and technical democracy) and instruction (i.e., group learning, authentic context, teacher involvement, triangular evidence and learning scaffolding). Overall, the main findings indicate that K-12 AI education has the potential to develop students’ AI literacy, which contains AI knowledge, AI affectivity, and AI thinking. However, deficiencies in research and instructional design still remain, including short durations, small sample sizes, non-standardized research methods, lack of long-term and cross-age AI curriculum, etc. This study also discussed several critical topics for future research and instruction.}
}
@incollection{IACOBONI2000523,
title = {17 - Mapping Human Cognition: Thinking, Numerical Abilities, Theory of Mind, Consciousness},
editor = {Arthur W. Toga and John C. Mazziotta},
booktitle = {Brain Mapping: The Systems},
publisher = {Academic Press},
address = {San Diego},
pages = {523-534},
year = {2000},
isbn = {978-0-12-692545-6},
doi = {https://doi.org/10.1016/B978-012692545-6/50019-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780126925456500192},
author = {Marco Iacoboni},
abstract = {Publisher Summary
This chapter discusses the mapping the brain activity associated with complex cognitive functions—problem solving, reasoning, numerical processing, and consciousness. One of the most widely used tasks in brain mapping studies of problem solving is the Raven's progressive matrices. The role of frontoparietal circuits in numerical cognition has been confirmed by a positron emission tomography (PET) investigation of number multiplication and number comparison, in which bilateral frontoparietal networks are activated during both tasks. Various other regions are also found activated in this investigation, in which an exploratory, hypotheses-generating approach determined relatively “liberal” statistical thresholds. The consciousness of action is an important component of consciousness. However, the most common approach to the study of consciousness and its neural counterpart in cognitive neuroscience is via perception and visual awareness. A variety of brain mapping techniques, from PET and functional magnetic resonance imaging to electrical scalp recording, have been already used in investigations directly addressing visual awareness in normal subjects and patients with neurological disorders. A paradigm that is extremely suitable for the examination of conscious perception is binocular rivalry. A different mapping approach to the study of conscious perception is the mapping of temporal neural events.}
}
@article{SHENGLAI20124318,
title = {Study on Simulation Modeling and Approximate Synchronous Computation Technology for the Active Structural Stiffness Design},
journal = {Procedia Engineering},
volume = {29},
pages = {4318-4324},
year = {2012},
note = {2012 International Workshop on Information and Electronics Engineering},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2012.01.664},
url = {https://www.sciencedirect.com/science/article/pii/S1877705812006741},
author = {Xia Shenglai and He Jingwu and Chu Hongyu and Yang Xuan},
keywords = {active structural stiffness design (ASSD), stiffness criterion, simulation modeling, computation analysis, section stiffness},
abstract = {In the past, structure design mainly adopted strength criterion. At the same time, many problems occurred due to structural stiffness deficiency. In order to resolve many practical problems resulted from structural stiffness in aircraft structure, and draw out structural potential better, the design idea of active structural stiffness, namely, the method of active structural stiffness design (ASSD) is put forward at the beginning of the structure design. For ASSD, there are three key factors should be considered, that is, stiffness criterion, simulation modeling and computation analysis. In this paper, stiffness criterion, which is important at the preliminary stage of structural design, will be researched; Simulation modeling adopts parametric modeling technology; computation analysis is based on engineering beam theory, which is compiled and embedded into CATIA to compute structural stiffness. Using simulation modeling and computation analysis technologies, ASSD can be achieved quickly and conveniently.}
}
@article{FIGLIOLIA2020102968,
title = {An FPGA multiprocessor architecture for Bayesian online change point detection using stochastic computation},
journal = {Microprocessors and Microsystems},
volume = {74},
pages = {102968},
year = {2020},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2019.102968},
url = {https://www.sciencedirect.com/science/article/pii/S0141933119304727},
author = {Tomas Figliolia and Andreas G. Andreou},
keywords = {Changepoint analysis, Changepoint detection, Image segmentation, Bayesian inference, On-line algorithm, Stochastic processing, Precision on demand, ASIC, VHDL, Probabilistic event representation},
abstract = {In this paper we report on an event-based stochastic architecture for the Adams/McKay Bayesian Online Change Point Detection algorithm (BOCPD) [1]. In the stochastic computational structures, probabilities are represented natively as stochastic events and computation is carried out directly with these probabilities and not probability density functions. A fully programmable BOCPD processor is synthesized in VHDL. The BOCPD algorithm with on-line learning, to perform foreground/background image segmentation with online learning. Running on a single Kintex 7 FPGA (Opal Kelly XEM7350-K410T) the architecture is capable of real-time processing a 160 × 120 pixels image, at 10 frames per second.}
}
@article{GRIGORIADIS2022618,
title = {Computational and conceptual blends: Material considerations and agency in a multi-material design workflow},
journal = {Frontiers of Architectural Research},
volume = {11},
number = {4},
pages = {618-629},
year = {2022},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2022.04.005},
url = {https://www.sciencedirect.com/science/article/pii/S2095263522000449},
author = {Kostas Grigoriadis},
keywords = {Digital design, Multi-materials, Computer simulation, Material agency, Materially anchored conceptual blends},
abstract = {The assimilation of functionally graded (or multi-) materials into architecture is deemed to enable the rethinking of current architectural design practice and bring back material considerations at the heart of the early design process. In response, the paper outlines a functionally graded material (FGM) design workflow that departs from standard early-stage CAD, which is typically performed via computer elements devoid of materiality. It then analyses this workflow from a theoretical perspective, namely through Edwin Hutchins' materially anchored conceptual blending, Lambros Malafouris' Material Engagement Theory (MET) and John Searle's concepts of intentionality. The aim is to demonstrate that due to the superimposition of material considerations that precede and succeed the CAD operation, working with material-less entities during early-stage FGM design is not logically sustainable. Additionally, multi-materiality allows for the questioning of authorship in the design process and leads to a repositioning of agency from the subject to the locus of engagement with digital materials and their affordances.}
}
@article{LI2024108089,
title = {Population characteristic exploitation-based multi-orientation multi-objective gene selection for microarray data classification},
journal = {Computers in Biology and Medicine},
volume = {170},
pages = {108089},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.108089},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524001732},
author = {Min Li and Rutun Cao and Yangfan Zhao and Yulong Li and Shaobo Deng},
keywords = {Gene selection, Microarray data, Multi-orientation, Multi-objective, Reverse thinking},
abstract = {Gene selection is a process of selecting discriminative genes from microarray data that helps to diagnose and classify cancer samples effectively. Swarm intelligence evolution-based gene selection algorithms can never circumvent the problem that the population is prone to local optima in the process of gene selection. To tackle this challenge, previous research has focused primarily on two aspects: mitigating premature convergence to local optima and escaping from local optima. In contrast to these strategies, this paper introduces a novel perspective by adopting reverse thinking, where the issue of local optima is seen as an opportunity rather than an obstacle. Building on this foundation, we propose MOMOGS-PCE, a novel gene selection approach that effectively exploits the advantageous characteristics of populations trapped in local optima to uncover global optimal solutions. Specifically, MOMOGS-PCE employs a novel population initialization strategy, which involves the initialization of multiple populations that explore diverse orientations to foster distinct population characteristics. The subsequent step involved the utilization of an enhanced NSGA-II algorithm to amplify the advantageous characteristics exhibited by the population. Finally, a novel exchange strategy is proposed to facilitate the transfer of characteristics between populations that have reached near maturity in evolution, thereby promoting further population evolution and enhancing the search for more optimal gene subsets. The experimental results demonstrated that MOMOGS-PCE exhibited significant advantages in comprehensive indicators compared with six competitive multi-objective gene selection algorithms. It is confirmed that the “reverse-thinking" approach not only avoids local optima but also leverages it to uncover superior gene subsets for cancer diagnosis.}
}
@article{THABTAH2018112,
title = {A new computational intelligence approach to detect autistic features for autism screening},
journal = {International Journal of Medical Informatics},
volume = {117},
pages = {112-124},
year = {2018},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2018.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S1386505618300546},
author = {Fadi Thabtah and Firuz Kamalov and Khairan Rajab},
keywords = {Accuracy, Autism Spectrum Disorder, Behaviour science, Classifiers, Computational intelligence, Data mining, Feature analysis, Machine learning, Sensitivity, Specificity},
abstract = {Autism Spectrum Disorder (ASD) is one of the fastest growing developmental disability diagnosis. General practitioners (GPs) and family physicians are typically the first point of contact for patients or family members concerned with ASD traits observed in themselves or their family member. Unfortunately, some families and adult patients are unaware of ASD traits that may be exhibited and as a result do not seek out necessary diagnostic services or contact their GP. Therefore, providing a quick, accessible, and simple tool utilizing items related to ASD to these families may increase the likelihood they will seek professional assessment and is vital to the early detection and treatment of ASD. This study aims at identifying fewer, albeit influential, features in common ASD screening methods in order to achieve efficient screening as demands on evaluating the items’ influences on ASD within existing tools is urgent. To achieve this aim, a computational intelligence method called Variable Analysis (Va) is proposed that considers feature-to-class correlations and reduces feature-to-feature correlations. The results of the Va have been verified using two machine learning algorithms by deriving automated classification systems with respect to specificity, sensitivity, positive predictive values (PPVs), negative predictive values (NPVs), and predictive accuracy. Experimental results using cases and controls related to items in three common screening methods, along with features related to individuals, have been analysed and compared with results obtained from other common filtering methods. The results exhibited that Va was able to derive fewer numbers of features from adult, adolescent, and child screening methods yet maintained competitive predictive accuracy, sensitivity, and specificity rates.}
}
@article{MARTIN2000195,
title = {What do animals do all day?: The division of labor, class bodies, and totemic thinking in the popular imagination},
journal = {Poetics},
volume = {27},
number = {2},
pages = {195-231},
year = {2000},
issn = {0304-422X},
doi = {https://doi.org/10.1016/S0304-422X(99)00025-X},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X9900025X},
author = {John Levi Martin},
keywords = {Animals, Totemism, Class body, Busytown, Symbolic domination, Division of labor},
abstract = {This article uses relatively new methods of the analysis of qualitative data to investigate the socio-logical relation between animal species and occupation in the popular imagination, specifically in the world of children's literature, in order to test a claim that the class habitus that naturalizes the division of labor, erasing the contingent nature of class domination, does not simply arise via the internalization of objective social divisions into a subjective social vision, but rather begins with the application of a totemic logic which maps differences between people onto differences between animals, thereby exaggerating and naturalizing them. Children are evidently instructed in the reality of class bodies and the logic of social structure before they have any first-hand acquaintance with these social processes; indeed, by working the embodied relations of class domination into the role play and role learning of the pre-school years, we make it difficult for them to have any unmediated first-hand experience that would militate against these habitual distinctions.}
}
@article{SADEGHIPOUR2012213,
title = {Gesture processing as grounded motor cognition: Towards a computational model},
journal = {Procedia - Social and Behavioral Sciences},
volume = {32},
pages = {213-223},
year = {2012},
note = {The 4th International Conference of Cognitive Science},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2012.01.032},
url = {https://www.sciencedirect.com/science/article/pii/S187704281200033X},
author = {Amir Sadeghipour and Stefan Kopp},
keywords = {Motor Cognition, embodiment, grounded cognition, gestures, social interaction, computational model, embodied conversational agents},
abstract = {In this paper, we present an approach to treat and model the processing (i.e. recognition and production) of communicative gestures as grounded motor cognition. We first review cognitive theories and neuropsychological studies on human motor cognition. On this basis, we propose a computational framework that connects the sensorimotor processing of hand gestures in representational structures of meaning (visuospatial imagery), other modalities (language), and communicative intentions. We present an implementation that enables an embodied virtual agent to engage in gesture-based interaction with a human user.}
}
@article{ZAROUALI2024108024,
title = {Personality and susceptibility to political microtargeting: A comparison between a machine-learning and self-report approach},
journal = {Computers in Human Behavior},
volume = {151},
pages = {108024},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2023.108024},
url = {https://www.sciencedirect.com/science/article/pii/S0747563223003758},
author = {Brahim Zarouali and Tom Dobber and Jurrian Schreuder},
keywords = {Political microtargeting, Persuasion, Personality, Social media, Algorithms},
abstract = {Based on recent technological advances, campaigners and political actors can use psychographic-based political marketing. Yet, empirical evidence about its effectiveness is still very limited. Based on self-congruity theory, a pre-registered experiment (N = 280) investigated the persuasion effects of personality-congruent political microtargeting on the attitude toward the political party and voting intentions of citizens. More precisely, the focus was on the thinking vs feeling personality dimension (MBTI), and it was tested whether this personality “interacts” with exposure to a matching advertising appeal: rational vs. emotional political ad. To do so, two different methodological approaches were used: 1) a machine learning approach; 2) a self-report survey measure of personality. Results revealed significant “congruence effects” between personality and ad appeal, and showed that perceived ad relevance was serving as the underlying mechanism (mediator). However, these results were only found when the self-report measure of personality was used. When the algorithmic approach was used, no significant results were found. These findings feed into timely societal, methodological, and theoretical contributions.}
}
@article{LIU20121773,
title = {ACE - A Model Centered REU Program Standing on the Three Legs of CSE: Analysis, Computation and Experiment},
journal = {Procedia Computer Science},
volume = {9},
pages = {1773-1782},
year = {2012},
note = {Proceedings of the International Conference on Computational Science, ICCS 2012},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2012.04.195},
url = {https://www.sciencedirect.com/science/article/pii/S187705091200316X},
author = {Hong P. Liu and Andrei Ludu},
keywords = {CSE Education, REU, Project-Oriented Pedagogy},
abstract = {Enhancing REU (research experience for undergraduates) has become a popular strategy for many selective universities to enhance quality of undergraduate education and recruit gifted new students. The university that the authors are affiliated has set REU as one of the major outcomes for our QEP (quality enhancement program) for next 5 years. This paper presents a model centered REU program entitled as ACE standing for Analysis, Computation and Experiment. As a work in progress, the program is planned to run for the next 5 years and to serve for 20-30 undergraduate students who are gifted in mathematics and computing annually. ACE is to use interdisciplinary research projects, the guided exploration based on sound pedagogical practice and the top niche analogical and virtual dual lab facility bring measurable impacts to over a hundred of gifted undergraduates.}
}
@article{YANG2012852,
title = {Computational Optimization, Modelling and Simulation: Smart Algorithms and Better Models},
journal = {Procedia Computer Science},
volume = {9},
pages = {852-856},
year = {2012},
note = {Proceedings of the International Conference on Computational Science, ICCS 2012},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2012.04.091},
url = {https://www.sciencedirect.com/science/article/pii/S1877050912002128},
author = {Xin-She Yang and Slawomir Koziel and Leifur Leifsson},
keywords = {algorithm, black-box modelling, computational optimization, derivative-free method, optimization algorithm, modelling, nonlinear optimization, surragate-based optimization, simulation},
abstract = {Computational optimization is becoming a standard tool that is widely used in engineering design and industrial applications. Products and services are often concerned with the maximization of profits and reduction of cost, but also aim at being more energy-efficient, environment-friendly and safety-ensured; at the same time they are limited by resources, time and money. Despite of increasing computer power and availability of better simulation packages, there are a number of challenges remaining when applying numerical optimization methods for real-world engineering problems. Also, new challenges emerge when attempting to attack problems whose solution by means of simulation-based optimization was not even possible in the past. This third workshop on Computational Optimization, Modelling and Simulation (COMS 2012) at ICCS 2012 will further summarize the latest developments of optimization and modelling and their applications in science, engineering and industry.}
}
@article{KOKOLAKIS2023110732,
title = {Bounded rational Dubins vehicle coordination for target tracking using reinforcement learning},
journal = {Automatica},
volume = {149},
pages = {110732},
year = {2023},
issn = {0005-1098},
doi = {https://doi.org/10.1016/j.automatica.2022.110732},
url = {https://www.sciencedirect.com/science/article/pii/S0005109822005982},
author = {Nick-Marios T. Kokolakis and Kyriakos G. Vamvoudakis},
keywords = {Game theory, Target tracking, Bounded rationality, Reinforcement learning, Switched systems, Target allocation},
abstract = {In this paper, we address the problem of cooperative tracking of multiple heterogeneous targets by deploying multiple and heterogeneous pursuers exhibiting different decision-making capabilities. Initially, under infinite resources, we formulate a game between the evader and the pursuing team, with an evader being the maximizing player and the pursuing team being the minimizing one. Subsequently, we relax the perfect rationality assumption via the use of a level-k thinking framework that allows the evaders to not exhibit the same levels of rationality. Such rationality policies are computed by using a reinforcement learning-based architecture and are proven to form Nash policies as the thinking levels increase. Finally, in the case of multiple pursuers against multiple targets, we develop a switched learning scheme with multiple convergence sets by assigning the most intelligent pursuers to the most intelligent evaders.}
}
@article{CALVIN20241192,
title = {ShopMe: a mobile app to introduce Indonesian local MSMEs},
journal = {Procedia Computer Science},
volume = {245},
pages = {1192-1201},
year = {2024},
note = {9th International Conference on Computer Science and Computational Intelligence 2024 (ICCSCI 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.349},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924031570},
author = {Jeremiah Calvin and Yudhistya Ayu Kusumawati and Asri Radhitanti},
keywords = {Economic Inequality, MSMEs, Income, Platform, Poverty},
abstract = {The poverty rate in Malang Raya is decreasing, although this is a good thing, another problem is emerging, namely economic inequality. Economic inequality impacts many parties, both rich and poor. This problem started with the COVID-19 pandemic, with uncertain economic stability. With this reality, one of the factors that will have an impact on the current economy is MSMEs. Moreover, with the increasing economic inequality in Malang, MSMEs will have minimal income and if MSMEs do not run as they should, the country's economy will not be good. be good. This research aims to find a solution by creating a platform to unite MSMEs that are under the radar to improve their playing field, especially F&B MSMEs, with the main benefits being given to MSMEs. To understand this problem, this research uses a design thinking process, with interviews and questionnaires as the main research, as well as a literature review as the method for conducting this research. The result of this research is the development of a mobile app which can be a bridge for MSMEs to become better known to the public. With the publication of this research, it is hoped that it will be an inspiration for the public to find ways to overcome these problems.}
}
@article{KNIGHT20151,
title = {Computational making},
journal = {Design Studies},
volume = {41},
pages = {1-7},
year = {2015},
note = {Special Issue: Computational Making},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2015.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X15000721},
author = {Terry Knight and Theodora Vardouli}
}
@article{JONCZYK2024120752,
title = {Operating in a second language lowers cognitive interference during creative idea generation: Evidence from brain oscillations in bilinguals},
journal = {NeuroImage},
volume = {297},
pages = {120752},
year = {2024},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2024.120752},
url = {https://www.sciencedirect.com/science/article/pii/S1053811924002490},
author = {Rafał Jończyk and Iga Krzysik and Olga Witczak and Katarzyna Bromberek-Dyzman and Guillaume Thierry},
keywords = {Creativity, Bilingualism, EEG, Alternate uses task, Alpha frequency, Beta frequency},
abstract = {Tasks measuring human creativity overwhelmingly rely on both language comprehension and production. Although most of the world's population is bilingual, few studies have investigated the effects of language of operation on creative output. This is surprising given that fluent bilinguals master inhibitory control, a mechanism also at play in creative idea evaluation. Here, we compared creative output in the two languages of Polish(L1)-English(L2) bilinguals engaged in a cyclic adaptation of the Alternative Uses Task increasing the contribution of idea evaluation (convergent thinking). We show that Polish-English bilinguals suffer less cognitive interference when generating unusual uses for common objects in the L2 than the L1, without incurring a significant drop in idea originality. Right posterior alpha oscillation power, known to reflect creative thinking, increased over cycles. This effect paralleled the increase in originality ratings over cycles, and lower alpha power (8–10 Hz) was significantly greater in the L1 than the L2. Unexpectedly, we found greater beta (16.5–28 Hz) desynchronization in the L2 than the L1, suggesting that bilingual participants suffered less interference from competing mental representations when performing the task in the L2. Whereas creative output seems unaffected by language of operation overall, the drop in beta power in the L2 suggests that bilinguals are not subjected to the same level of semantic flooding in the second language as they naturally experience in their native language.}
}
@incollection{RAMOS2018720,
title = {8.36 - Bioinformatics and Computational Biology in Toxicology: Gateways for Precision Medicine☆},
editor = {Charlene A. McQueen},
booktitle = {Comprehensive Toxicology (Third Edition)},
publisher = {Elsevier},
edition = {Third Edition},
address = {Oxford},
pages = {720-728},
year = {2018},
isbn = {978-0-08-100601-6},
doi = {https://doi.org/10.1016/B978-0-12-801238-3.99176-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128012383991761},
author = {K.S. Ramos and M. Martin and I.N. Ramos and G.A. Rempala},
keywords = {Bioinformatics, Computational biology, Precision medicine, Systems biology},
abstract = {The National Center for Biotechnology Information (NCBI) defines bioinformatics as “… the field of science in which biology, computer science, and information technology merge to form a single discipline”. As such, the field of bioinformatics includes computer scientists who develop algorithms for sequence analysis, biostatisticians who develop and implement methods of analyses for large clinical datasets, mathematicians or physical scientists who develop models to describe the interactions of genes, proteins, and small molecules within cells, and all those engaged in the development of software and databases for manipulation, storage, and retrieval of information in support of their research. This chapter focuses on how computational biology has been enabled by molecular informatics to provide the basis for in silico studies that facilitate the collection, organization, and analysis of datasets that explain biological phenomena and that help to drive biological discovery with applications in precision medicine.}
}
@article{ZENDEHROUH2015112,
title = {A new computational account of cognitive control over reinforcement-based decision-making: Modeling of a probabilistic learning task},
journal = {Neural Networks},
volume = {71},
pages = {112-123},
year = {2015},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2015.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608015001604},
author = {Sareh Zendehrouh},
keywords = {Cognitive control, Reinforcement learning, Goal-directed behavior, Dual system theory, Cost function, Probabilistic learning task},
abstract = {Recent work on decision-making field offers an account of dual-system theory for decision-making process. This theory holds that this process is conducted by two main controllers: a goal-directed system and a habitual system. In the reinforcement learning (RL) domain, the habitual behaviors are connected with model-free methods, in which appropriate actions are learned through trial-and-error experiences. However, goal-directed behaviors are associated with model-based methods of RL, in which actions are selected using a model of the environment. Studies on cognitive control also suggest that during processes like decision-making, some cortical and subcortical structures work in concert to monitor the consequences of decisions and to adjust control according to current task demands. Here a computational model is presented based on dual system theory and cognitive control perspective of decision-making. The proposed model is used to simulate human performance on a variant of probabilistic learning task. The basic proposal is that the brain implements a dual controller, while an accompanying monitoring system detects some kinds of conflict including a hypothetical cost-conflict one. The simulation results address existing theories about two event-related potentials, namely error related negativity (ERN) and feedback related negativity (FRN), and explore the best account of them. Based on the results, some testable predictions are also presented.}
}
@article{VARNER2017170,
title = {Computational models of airway branching morphogenesis},
journal = {Seminars in Cell & Developmental Biology},
volume = {67},
pages = {170-176},
year = {2017},
note = {Extracellular Vesicles Cellular Mechanisms of Morphogenesis},
issn = {1084-9521},
doi = {https://doi.org/10.1016/j.semcdb.2016.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S1084952116301653},
author = {Victor D. Varner and Celeste M. Nelson},
keywords = {Quantitative models, Morphodynamics, Mechanobiology, Turing patterns},
abstract = {The bronchial network of the mammalian lung consists of millions of dichotomous branches arranged in a highly complex, space-filling tree. Recent computational models of branching morphogenesis in the lung have helped uncover the biological mechanisms that construct this ramified architecture. In this review, we focus on three different theoretical approaches – geometric modeling, reaction-diffusion modeling, and continuum mechanical modeling – and discuss how, taken together, these models have identified the geometric principles necessary to build an efficient bronchial network, as well as the patterning mechanisms that specify airway geometry in the developing embryo. We emphasize models that are integrated with biological experiments and suggest how recent progress in computational modeling has advanced our understanding of airway branching morphogenesis.}
}
@article{WANG2003457,
title = {Thinking as saying: shuo (‘say’) in Taiwan Mandarin conversation and BBS talk},
journal = {Language Sciences},
volume = {25},
number = {5},
pages = {457-488},
year = {2003},
issn = {0388-0001},
doi = {https://doi.org/10.1016/S0388-0001(03)00020-2},
url = {https://www.sciencedirect.com/science/article/pii/S0388000103000202},
author = {Yu-Fang Wang and Aya Katz and Chih-Hua Chen},
keywords = {Grammaticalization, Metaphor, Propositional, Textual, Expressive},
abstract = {The research reported here is an attempt to explore the functions of shuo ‘say’ in informal Chinese speech and writing. We further probe into the grammaticalization of shuo, discussing how the various lexical, grammatical and discourse functions have come into being, with reference to the general tendencies of semantic change proposed by Traugott [(1982). In: Lehmann and Malkiel (Eds.) Perspectives on Historical Linguistics. Benjamins, Amsterdam. pp. 245–272; (1989) Language 65(1), 31–55] and Traugott and König [In: Traugott and Heine (Eds.), Approaches to Grammaticalization, Vol. I. John Benjamins, Philadelphia. pp. 189–218], and the metaphor MIND-AS-BODY proposed by Sweetser [(1990). From Etymology to Pragmatics. Cambridge University Press, Cambridge]. The corpus used in this study contains two sets of data: non-face-to-face talk on BBS (the Electronic Bulletin Board System) and face-to-face daily conversation, mainly produced by young people in Taiwan. Our data indicate that shuo, in addition to acting as a complementizer as discussed by S. Huang [On the (almost perfect) identify of speech and thought: Evidence from Chinese dialects. (1982). Paper presented at Fourteenth International Conference on Sino-Tibetan Languages and Linguistics] and Cheng [(1997). In: Cheng (Ed.), Taiwanese and Mandarin Structures and Their Developmental Trends in Taiwan II: Contacts between Taiwanese and Mandarin and Restructuring of their Synonyms. Yuan-Liou Publishing Co. Taipei. pp. 105–131], can also occur in an utterance-initial position, functioning as a marker of hearsay, and in an utterance-final position, as a marker of counterexpectation or as an intensifier. On the whole, the data suggest that the initial and final shuo's are innovations serving an expressive function. In particular, the lexeme shuo is moving from the propositional level to the expressive level; i.e., it is evolving from a verb meaning ‘say’ that prefaces an utterance conveying information into a discourse marker that encodes the attitude of the speaker toward the proposition.}
}
@article{LEE2023101274,
title = {Storytelling as a learning tool in creative education: A case study in an architecture design studio},
journal = {Thinking Skills and Creativity},
volume = {48},
pages = {101274},
year = {2023},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2023.101274},
url = {https://www.sciencedirect.com/science/article/pii/S1871187123000445},
author = {Keunhye Lee and Eunki Kang and Eun Joo Park},
keywords = {Storytelling, Creative thinking, Architecture design studio, Creative education, Communicative representation},
abstract = {This paper investigates the significant aspects of storytelling, when used as a pedagogical method to enhance students critical and creative thinking and communicative technique, by applying it to first-year students in the architecture design studio. Creativity is a substantial part of architectural education as it improves students’ design processes in innovative ways. This paper considers how the architecture design studio can form a creative design solution that can be learned and developed by learner-centred activity; it concentrates on aspects of storytelling, which many scholars have begun to discuss its significance in creative education. Thus, this paper aims to develop a creative learning strategy for use in the architecture design studio and suggest a new learning method by engaging storytelling in the design process. This paper starts with discussions about storytelling and its usages in the architecture design studio, referring to several theorists and educators, particularly focusing on McDrury and Alterio (2003); it helps to create a framework and develop a curriculum for the architecture design studio. The overall results suggest that using storytelling as a learning method in an architecture design studio is important in contextualising and articulating design work, from ideas to analysis, visualisation and expression, in a coherent context. It helps students gain better design skills and a greater understanding of the design process across the disciplines of the design studio, improving students creative thinking during the unique design process.}
}
@article{SU2022100049,
title = {Artificial intelligence in early childhood education: A scoping review},
journal = {Computers and Education: Artificial Intelligence},
volume = {3},
pages = {100049},
year = {2022},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2022.100049},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X22000042},
author = {Jiahong Su and Weipeng Yang},
keywords = {Artificial intelligence, Early childhood education, Teaching and learning, Machine learning, Computer science},
abstract = {Artificial intelligence (AI) tools are increasingly being used in the field of early childhood education (ECE) to enhance learning and development among young children. Previous proof-of-concept studies have demonstrated that AI can effectively improve teaching and learning in ECE; however, there is a scarcity of knowledge about how these studies are conducted and how AI is used across these studies. We conducted this scoping review to evaluate, synthesize and display the latest literature on AI in ECE. This review analyzed 17 eligible studies conducted in different countries from 1995 to 2021. Although few studies on this critical issue have been found, the existing references provide up-to-date insights into different aspects (knowledge, tools, activities, and impacts) of AI for children. Most studies have shown that AI has significantly improved children's concepts regarding AI, machine learning, computer science, and robotics and other skills such as creativity, emotion control, collaborative inquiry, literacy skills, and computational thinking. Future directions are also discussed for researching AI in ECE.}
}
@article{LISSACK2024389,
title = {Responsible Use of Large Language Models: An Analogy with the Oxford Tutorial System},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {10},
number = {4},
pages = {389-413},
year = {2024},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2024.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S2405872624000959},
author = {Michael Lissack and Brenden Meagher},
keywords = {responsible AI, Oxford Tutorial, large language models (LLMs), human-AI collaboration, critical thinking},
abstract = {In the rapidly evolving landscape of artificial intelligence, large language models (LLMs) have emerged as powerful tools with the potential to revolutionize how we process information, generate content, and solve complex problems. However, integrating these sophisticated AI systems into academic and professional practices raises critical questions about responsible use, ethical considerations, and the preservation of human expertise. This article introduces a novel framework for understanding and implementing responsible AI use by drawing an analogy between the optimal use of LLMs and the role of the second student in an Oxford Tutorial. Through an in-depth exploration of the Oxford Tutorial system and its parallels with LLM interaction, we propose a nuanced approach to leveraging AI language models while maintaining human agency, fostering critical thinking, and upholding ethical standards. The article examines the implications of this analogy, discusses potential risks of misuse, and provides detailed practical scenarios across various fields. By grounding the use of cutting-edge AI technology in a well-established and respected educational model, this research contributes to the ongoing discourse on AI ethics. It offers valuable insights for academics, professionals, and policymakers grappling with the challenges and opportunities presented by LLMs.}
}
@article{BILORIA2012259,
title = {Interactive morphologies: An investigation into integrated nodal networks and embedded computation processes for developing real-time responsive spatial systems},
journal = {Frontiers of Architectural Research},
volume = {1},
number = {3},
pages = {259-271},
year = {2012},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2012.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S2095263512000465},
author = {Nimish Biloria},
keywords = {Real-time interaction, Sensing and actuation, Performance, Adaptation, Emergence},
abstract = {The design-research illustrated in this research article focus on the emerging field of interactive architecture focusing on developing real-time information exchanging architectural bodies. These interactive bodies demonstrate a fusion between the material, the electronic and the digital domains. This fusion is explicitly attained through a synergistic merger between the fields of ambient sensing, control systems, ubiquitous computing, architectural design, pneumatic systems and computation. The resultant spatial bodies are thus visualised as complex adaptive systems, continually engaged in activities of data-exchange resulting in physical and ambient adaptations of their constituting components in response to contextual variations. Interdependent nodal networks, where every node/junction of a spatial prototype becomes a potential information hub by means of its ability to collect, process and communicate contextual data apart from working as an actuated detail owing to its ability to kinetically re-position itself in three-dimensional space is thus a critical outcome of this inter-disciplinary way of working. A strategy apt for binding material logistics with the digital to materialize dynamic spatial behaviours owing to real time data exchange between the prototypes and their context is thus embarked upon via three research and design projects, namely: Electronic Media Augmented Spatial Skins, The InteractiveWall and the Muscle Re-configured.}
}
@article{DALLACHIARA201669,
title = {A first-order epistemic quantum computational semantics with relativistic-like epistemic effects},
journal = {Fuzzy Sets and Systems},
volume = {298},
pages = {69-90},
year = {2016},
note = {Special Issue on Graded Logical Approaches and Their Applications},
issn = {0165-0114},
doi = {https://doi.org/10.1016/j.fss.2015.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S0165011415004145},
author = {Maria Luisa {Dalla Chiara} and Roberto Giuntini and Roberto Leporini and Giuseppe Sergioli},
keywords = {Quantum computation, Quantum computational logics, Epistemic operators},
abstract = {Quantum computation has suggested new forms of quantum logic, called quantum computational logics. In these logics well-formed formulas are supposed to denote pieces of quantum information: possible pure states of quantum systems that can store the information in question. At the same time, the logical connectives are interpreted as quantum logical gates: unitary operators that process quantum information in a reversible way, giving rise to quantum circuits. Quantum computational logics have been mainly studied as sentential logics (whose alphabet consists of atomic sentences and of logical connectives). In this article we propose a semantic characterization for a first-order epistemic quantum computational logic, whose language can express sentences like “Alice knows that everybody knows that she is pretty”. One can prove that (unlike the case of logical connectives) both quantifiers and epistemic operators cannot be generally represented as (reversible) quantum logical gates. The “act of knowing” and the use of universal (or existential) assertions seem to involve some irreversible “theoretic jumps”, which are similar to quantum measurements. Since all epistemic agents are characterized by specific epistemic domains (which contain all pieces of information accessible to them), the unrealistic phenomenon of logical omniscience is here avoided: knowing a given sentence does not imply knowing all its logical consequences.}
}
@article{LI2025126039,
title = {Correct like humans: Progressive learning framework for Chinese text error correction},
journal = {Expert Systems with Applications},
volume = {265},
pages = {126039},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.126039},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424029063},
author = {Yinghui Li and Shirong Ma and Shaoshen Chen and Haojing Huang and Shulin Huang and Yangning Li and Hai-Tao Zheng and Ying Shen},
keywords = {Chinese text error correction, Progressive learning, Natural language processing, Computational linguistics},
abstract = {Chinese Text Error Correction (CTEC) aims to detect and correct errors in the input text, which benefits human daily life and various downstream tasks. With the extensive research on Pre-trained Language Models (PLMs), Chinese Spelling Correction (CSC) and Chinese Grammatical Error Correction (CGEC), two subtasks of CTEC, have achieved good results. However, researchers usually study these two tasks separately. In addition, we argue that previous studies still overlook the importance of human thinking patterns. To enhance the development of PLMs for CTEC, inspired by humans’ daily error-correcting behavior, we propose a novel model-agnostic progressive learning framework, named ProTEC, which guides PLMs-based CTEC models to learn to correct like humans and can be applied to various existing CTEC models in both CSC and CGEC. During the training process, ProTEC guides the model to learn text error correction by incorporating these sub-tasks into a progressive paradigm. During the inference process, the model completes these sub-tasks in turn to generate the correction results. Extensive experiments and detailed analyses demonstrate the effectiveness and efficiency of our proposed model-agnostic ProTEC framework.}
}
@article{HEINZLE201621,
title = {Computational models of eye movements and their application to schizophrenia},
journal = {Current Opinion in Behavioral Sciences},
volume = {11},
pages = {21-29},
year = {2016},
note = {Computational modeling},
issn = {2352-1546},
doi = {https://doi.org/10.1016/j.cobeha.2016.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S2352154616300754},
author = {Jakob Heinzle and Eduardo A Aponte and Klaas Enno Stephan},
abstract = {Patients with neuropsychiatric disorders, in particular schizophrenia, show a variety of eye movement abnormalities that putatively reflect alterations of perceptual inference, learning and cognitive control. While these abnormalities are consistently found at the group level, a particularly difficult and important challenge is to translate these findings into clinically useful tests for single patients. In this paper, we argue that generative models of eye movement data, which allow for inferring individual computational and physiological mechanisms, could contribute to filling this gap. We present a selective overview of eye movement paradigms with clinical relevance for schizophrenia and review existing computational approaches that rest on (or could be turned into) generative models. We conclude by outlining desirable clinical applications at the individual subject level and discuss the necessary validation studies.}
}
@article{MURANO2020577,
title = {Model-checking graded computation-tree logic with finite path semantics},
journal = {Theoretical Computer Science},
volume = {806},
pages = {577-586},
year = {2020},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2019.09.021},
url = {https://www.sciencedirect.com/science/article/pii/S0304397519305651},
author = {Aniello Murano and Mimmo Parente and Sasha Rubin and Loredana Sorrentino},
keywords = {Computation tree logic, Model checking, Finite paths},
abstract = {This paper introduces Graded Computation Tree Logic with finite path semantics (GCTLf⁎, for short), a variant of Computation Tree Logic CTL⁎, in which path quantifiers are interpreted over finite paths and can count the number of such paths. State formulas of GCTLf⁎ are interpreted over Kripke structures. The syntax of GCTLf⁎ has path quantifiers of the form E≥gψ which express that there are at least g many distinct finite paths that satisfy ψ. After defining and justifying the logic GCTLf⁎, we solve its model checking problem and establish that its computational complexity is PSPACE-complete. Moreover, we investigate GCTLf⁎ under the imperfect information setting. Precisely, we introduce GCTLKf⁎, an epistemic extension of GCTLf⁎ and prove that the model checking problem also in this case is PSPACE-complete.}
}
@article{BOTANA2016115,
title = {Some issues on the automatic computation of plane envelopes in interactive environments},
journal = {Mathematics and Computers in Simulation},
volume = {125},
pages = {115-125},
year = {2016},
note = {8th Workshop STRUCTURAL DYNAMICAL SYSTEMS: Computational Aspects; Edited by Nicoletta Del Buono, Roberto Garrappa and Giulia Spaletta and Nonstandard Applications of Computer Algebra (ACA’2013); Edited by Francisco Botana, Antonio Hernando, Eugenio Roanes-Lozano and Michael J. Wester},
issn = {0378-4754},
doi = {https://doi.org/10.1016/j.matcom.2014.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S0378475414001529},
author = {Francisco Botana and Tomas Recio},
keywords = {Envelope, Dynamic Geometry, Automatic computation, GröbnerCover algorithm},
abstract = {This paper addresses some concerns, and describes some proposals, on the ellusive concept of envelope of an algebraic family of varieties, and on its automatic computation. We describe how to use the recently developed Gröbner Cover algorithm to study envelopes of families of algebraic curves, and we give a protocol towards its implementation in dynamic geometry environments. The proposal is illustrated through some examples. A beta version of GeoGebra is used to highlight new envelope abilities in interactive environments, and limitations of our approach are discussed, since the computations are performed in an algebraically closed field.}
}
@article{WANG2024,
title = {News Coverage of the COVID-19 Pandemic on Social Media and the Public’s Negative Emotions: Computational Study},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/48491},
url = {https://www.sciencedirect.com/science/article/pii/S143888712400308X},
author = {Hanjing Wang and Yupeng Li and Xuan Ning},
keywords = {web news coverage, emotions, social media, Facebook, COVID-19},
abstract = {Background
Social media has become an increasingly popular and critical tool for users to digest diverse information and express their perceptions and attitudes. While most studies endeavor to delineate the emotional responses of social media users, there is limited research exploring the factors associated with the emergence of emotions, particularly negative ones, during news consumption.
Objective
We aim to first depict the web coverage by news organizations on social media and then explore the crucial elements of news coverage that trigger the public’s negative emotions. Our findings can act as a reference for responsible parties and news organizations in times of crisis.
Methods
We collected 23,705 Facebook posts with 1,019,317 comments from the public pages of representative news organizations in Hong Kong. We used text mining techniques, such as topic models and Bidirectional Encoder Representations from Transformers, to analyze news components and public reactions. Beyond descriptive analysis, we used regression models to shed light on how news coverage on social media is associated with the public’s negative emotional responses.
Results
Our results suggest that occurrences of issues regarding pandemic situations, antipandemic measures, and supportive actions are likely to reduce the public’s negative emotions, while comments on the posts mentioning the central government and the Government of Hong Kong reveal more negativeness. Negative and neutral media tones can alleviate the rage and interact with the subjects and issues in the news to affect users’ negative emotions. Post length is found to have a curvilinear relationship with users’ negative emotions.
Conclusions
This study sheds light on the impacts of various components of news coverage (issues, subjects, media tone, and length) on social media on the public’s negative emotions (anger, fear, and sadness). Our comprehensive analysis provides a reference framework for efficient crisis communication for similar pandemics at present or in the future. This research, although first extending the analysis between the components of news coverage and negative user emotions to the scenario of social media, echoes previous studies drawn from traditional media and its derivatives, such as web newspapers. Although the era of COVID-19 pandemic gradually brings down the curtain, the commonality of this research and previous studies also contributes to establishing a clearer territory in the field of health crises.}
}
@article{SLOOT2010131,
title = {The cross-disciplinary road to true computational science},
journal = {Journal of Computational Science},
volume = {1},
number = {3},
pages = {131},
year = {2010},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2010.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S1877750310000451},
author = {Peter M.A. Sloot}
}
@article{IGNATOWSKI2014264,
title = {Wishful thinking or effective threat? Tightening bank resolution regimes and bank risk-taking},
journal = {Journal of Financial Stability},
volume = {15},
pages = {264-281},
year = {2014},
issn = {1572-3089},
doi = {https://doi.org/10.1016/j.jfs.2014.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S1572308914000485},
author = {Magdalena Ignatowski and Josef Korte},
keywords = {Bank resolution, Orderly Liquidation Authority, FDIC, Bank behavior, Risk-taking},
abstract = {We propose a framework for testing the effects of changes in bank resolution regimes on bank behavior. By exploiting the differential relevance of recent changes in U.S. bank resolution (i.e., the introduction of the Orderly Liquidation Authority, OLA) for different types of banks, we are able to simulate a quasi-natural experiment using a difference-in-difference framework. We find that banks that are more affected by the introduction of the OLA (1) significantly decrease their overall risk-taking and (2) shift their loan origination toward lower risk, indicating the general effectiveness of the regime change. This effect, however, does (3) not hold for the largest and most systemically important banks. Hence, the introduction of the OLA in the U.S. alone does not appear to have solved the too-big-to-fail problem and might need to be complemented with other measures to limit financial institutions’ risk-taking.}
}
@article{LONG201960,
title = {The mammalian kinetochore–microtubule interface: robust mechanics and computation with many microtubules},
journal = {Current Opinion in Cell Biology},
volume = {60},
pages = {60-67},
year = {2019},
note = {Cell Dynamics},
issn = {0955-0674},
doi = {https://doi.org/10.1016/j.ceb.2019.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S0955067419300250},
author = {Alexandra F Long and Jonathan Kuhn and Sophie Dumont},
abstract = {The kinetochore drives chromosome segregation at cell division. It acts as a physical link between chromosomes and dynamic microtubules, and as a signaling hub detecting and processing microtubule attachments to control anaphase onset. The mammalian kinetochore is a large macromolecular machine that forms a dynamic interface with the many microtubules that it binds. While we know most of the kinetochore’s component parts, how they work together to give rise to its robust functions remains poorly understood. Here we highlight recent findings that shed light on this question, driven by an expanding physical and molecular toolkit. We present emerging principles that underlie the kinetochore’s robust microtubule grip, such as redundancy, specialization, and dynamicity, and present signal processing principles that connect this microtubule grip to robust computation. Throughout, we identify open questions, and define simple engineering concepts that provide insight into kinetochore function.}
}
@article{ARSLAN2024340,
title = {Computational analysis of linguistic features in speech samples of first-episode bipolar disorder and psychosis},
journal = {Journal of Affective Disorders},
volume = {363},
pages = {340-347},
year = {2024},
issn = {0165-0327},
doi = {https://doi.org/10.1016/j.jad.2024.07.102},
url = {https://www.sciencedirect.com/science/article/pii/S0165032724011595},
author = {Berat Arslan and Elif Kizilay and Burcu Verim and Cemal Demirlek and Muhammed Demir and Ezgi Cesim and Merve S. Eyuboglu and Simge Uzman Ozbek and Ekin Sut and Berna Yalincetin and Emre Bora},
keywords = {Psychosis, Bipolar, First-episode, Natural language processing, Semantic similarity},
abstract = {Background
In recent years, automated analyses using novel NLP methods have been used to investigate language abnormalities in schizophrenia. In contrast, only a few studies used automated language analyses in bipolar disorder. To our knowledge, no previous research compared automated language characteristics of first-episode psychosis (FEP) and bipolar disorder (FEBD) using NLP methods.
Methods
Our study included 53 FEP, 40 FEBD and 50 healthy control participants who are native Turkish speakers. Speech samples of the participants in the Thematic Apperception Test (TAT) underwent automated generic and part-of-speech analyses, as well as sentence-level semantic similarity analysis based on SBERT.
Results
Both FEBD and FEP were associated with the use of shorter sentences and increased sentence-level semantic similarity but less semantic alignment with the TAT pictures. FEP also demonstrated reduced verbosity and syntactic complexity. FEP differed from FEBD in reduced verbosity, decreased first-person singular pronouns, fewer conjunctions, increased semantic similarity as well as shorter sentence and word length. The mean classification accuracy was 82.45 % in FEP vs HC, 71.1 % in FEBD vs HC, and 73 % in FEP vs FEBD. After Bonferroni correction, the severity of negative symptoms in FEP was associated with reduced verbal output and increased 5th percentile of semantic similarity.
Limitations
The main limitation of this study was the cross-sectional nature.
Conclusion
Our findings demonstrate that both patient groups showed language abnormalities, which were more severe and widespread in FEP compared to FEBD. Our results suggest that NLP methods reveal transdiagnostic linguistic abnormalities in FEP and FEBD.}
}
@article{COX2005104,
title = {Metacognition in computation: A selected research review},
journal = {Artificial Intelligence},
volume = {169},
number = {2},
pages = {104-141},
year = {2005},
note = {Special Review Issue},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2005.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S0004370205001530},
author = {Michael T. Cox},
keywords = {Cognitive monitoring, Computational introspection, Limited rationality, Metacognition, Meta-explanation, Metaknowledge, Meta-level architecture, Metareasoning, Self-reference, Reflection},
abstract = {Various disciplines have examined the many phenomena of metacognition and have produced numerous results, both positive and negative. I discuss some of these aspects of cognition about cognition and the results concerning them from the point of view of the psychologist and the computer scientist, and I attempt to place them in the context of computational theories. I examine metacognition with respect to both problem solving (e.g., planning) and to comprehension (e.g., story understanding) processes of cognition.}
}
@incollection{JIAO202081,
title = {Chapter 3 - Theoretical basis of natural computation},
editor = {Licheng Jiao and Ronghua Shang and Fang Liu and Weitong Zhang},
booktitle = {Brain and Nature-Inspired Learning Computation and Recognition},
publisher = {Elsevier},
pages = {81-95},
year = {2020},
isbn = {978-0-12-819795-0},
doi = {https://doi.org/10.1016/B978-0-12-819795-0.00003-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128197950000037},
author = {Licheng Jiao and Ronghua Shang and Fang Liu and Weitong Zhang},
keywords = {Artificial immune system, Evolutionary algorithms, Multiobjective optimization, Theoretical basis},
abstract = {Enlightened by nature, the natural computing method has the ability of self-adaptation, self-organization, and self-learning, and can solve complex problems which are difficult to be solved by traditional computing methods. Natural computing is not only a new hotspot in artificial intelligence research, but also a new thinking in the development of artificial intelligence. It is also a new achievement in the transformation of methodology. Its research results include evolutionary algorithms, artificial immune system, multiobjective optimization, and so on. Natural computing can solve many complex problems which are difficult to be solved by traditional computing methods. It has good application prospects in solving large-scale complex optimization problems, intelligent control, computer network security, and other fields.}
}
@article{WHITE1985287,
title = {Thinking about learning about thinking: An interview with Seymour Papert},
journal = {New Ideas in Psychology},
volume = {3},
number = {3},
pages = {287-292},
year = {1985},
issn = {0732-118X},
doi = {https://doi.org/10.1016/0732-118X(85)90025-X},
url = {https://www.sciencedirect.com/science/article/pii/0732118X8590025X},
author = {Barbara Y. White}
}
@article{PAPAVLASOPOULOU201850,
title = {How do you feel about learning to code? Investigating the effect of children’s attitudes towards coding using eye-tracking},
journal = {International Journal of Child-Computer Interaction},
volume = {17},
pages = {50-60},
year = {2018},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2018.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S2212868917300259},
author = {Sofia Papavlasopoulou and Kshitij Sharma and Michail N. Giannakos},
keywords = {Children’s attitudes, Eye-tracking, Coding, Computational thinking, Constructionism},
abstract = {Computational thinking and coding for children are attracting increasing attention. There are several efforts around the globe to implement coding frameworks for children, and there is a need to develop an empirical knowledge base of methods and tools. One major problem for integrating study results into a common body of knowledge is the relatively limited measurements applied, and the relation of the widely used self-reporting methods with more objective measurements, such as biophysical ones. In this study, eye-tracking activity was used to measure children’s learning and activity indicators. The goal of the study is to utilize eye-tracking to understand children’s activity while they learn how to code and to investigate any potential association between children’s attitudes and their gaze. In this contribution, we designed an experiment with 44 children (between 8 and 17 years old) who participated in a full-day construction-based coding activity. We recorded their gaze while they were working and captured their attitudes in relation to their learning, excitement and intention. The results showed a significant relation between children’s attitudes (what they think about coding) and their gaze patterns (how they behaved during coding). Eye-tracking data provide initial insights into the behaviour of children, for example if children have difficulty in extracting information or fail to accomplish an expected task. Therefore, further studies need to be conducted to shed additional light on children’s experience and learning duringcoding.}
}
@incollection{SEJNOWSKI200919,
title = {Computational Methods},
editor = {Larry R. Squire},
booktitle = {Encyclopedia of Neuroscience},
publisher = {Academic Press},
address = {Oxford},
pages = {19-22},
year = {2009},
isbn = {978-0-08-045046-9},
doi = {https://doi.org/10.1016/B978-008045046-9.01396-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780080450469013966},
author = {T.J. Sejnowski},
keywords = {Brain theory, Computational models, Mathematical analysis},
abstract = {Computational neuroscience is a relatively recent approach to understanding how nervous systems develop and interact with a changing and uncertain world. Computational models can be used to interpret experimental data in new ways, to confirm and extend existing hypotheses, and to generate new hypotheses for the function of neural systems. These hypotheses provide links between levels of description, from the molecular level to the systems level. Hypotheses that are tested and validated provide a conceptual framework that can lead to more abstract theories. The ultimate aim of theoretical and computational neuroscience is to provide linking principles from neural mechanisms to behavior.}
}
@article{YANG20111230,
title = {Computational optimization, modelling and simulation: Recent advances and overview},
journal = {Procedia Computer Science},
volume = {4},
pages = {1230-1233},
year = {2011},
note = {Proceedings of the International Conference on Computational Science, ICCS 2011},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2011.04.132},
url = {https://www.sciencedirect.com/science/article/pii/S1877050911001906},
author = {Xin-She Yang and Slawomir Koziel and Leifur Leifsson},
keywords = {algorithm, black-box modelling, computational optimization, derivative-free method, optimization algorithm, modelling, nonlinear optimization, surragate-based optimization, simulation},
abstract = {Computational optimization is becoming increasingly important in engineering design and industrial applications. Products and services are often concerned with the maximization of profits and reduction of cost, but also aim at being more energy-efficient, environment-friendly and safety-ensured; at the same time they are limited by resources, time and money. This second workshop on Computational Optimization, Modelling and Simulation (COMS 2011) at ICCS 2011 will further summarize the latest developments of optimization and modelling and their applications in science, engineering and industry.}
}
@article{RUSCH2020107488,
title = {Theory of mind and decision science: Towards a typology of tasks and computational models},
journal = {Neuropsychologia},
volume = {146},
pages = {107488},
year = {2020},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2020.107488},
url = {https://www.sciencedirect.com/science/article/pii/S0028393220301597},
author = {Tessa Rusch and Saurabh Steixner-Kumar and Prashant Doshi and Michael Spezio and Jan Gläscher},
keywords = {Theory of mind, Computational modeling, Decision making, Interactivity, Uncertainty},
abstract = {The ability to form a Theory of Mind (ToM), i.e., to theorize about others’ mental states to explain and predict behavior in relation to attributed intentional states, constitutes a hallmark of human cognition. These abilities are multi-faceted and include a variety of different cognitive sub-functions. Here, we focus on decision processes in social contexts and review a number of experimental and computational modeling approaches in this field. We provide an overview of experimental accounts and formal computational models with respect to two dimensions: interactivity and uncertainty. Thereby, we aim at capturing the nuances of ToM functions in the context of social decision processes. We suggest there to be an increase in ToM engagement and multiplexing as social cognitive decision-making tasks become more interactive and uncertain. We propose that representing others as intentional and goal directed agents who perform consequential actions is elicited only at the edges of these two dimensions. Further, we argue that computational models of valuation and beliefs follow these dimensions to best allow researchers to effectively model sophisticated ToM-processes. Finally, we relate this typology to neuroimaging findings in neurotypical (NT) humans, studies of persons with autism spectrum (AS), and studies of nonhuman primates.}
}
@article{GARCIANUNES2020102607,
title = {A computational tool for weak signals classification – Detecting threats and opportunities on politics in the cases of the United States and Brazilian presidential elections},
journal = {Futures},
volume = {123},
pages = {102607},
year = {2020},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2020.102607},
url = {https://www.sciencedirect.com/science/article/pii/S0016328720300999},
author = {Pedro Ivo Garcia-Nunes and Pedro Artico Rodrigues and Kaulitz Guimarães Oliveira and Ana Estela Antunes {da Silva}},
keywords = {Conceptual systems, Opportunities, Threats, Weak signals},
abstract = {The literature on weak signals (WS) has been fruitful in recent years and this specific type of information has attracted the attention of several disciplines, notably the futures studies. However, most of these studies still focus on conceptual discussions, terminology, or the proposal for frameworks that do not take advantage of the evolution of information and communication technologies. In this paper, authors discussed the lack of tools to computationally support WS handling. In response to this lack, a computational tool was developed considering a previously published method for WS classification based on conceptual systems. This tool was applied and evaluated in experimental cases about surprising events that occurred in politics in recent years, considering traditional metrics of information retrieval. Experiments illustrate that organizations can create several conceptual systems to represent different scenarios and types of knowledge; after all, results showed that the tool can operate according to different artifacts of knowledge representation. This capacity is useful to mitigate the effects of the surveillance filter though the evidence does not directly confirm its usefulness for the monitoring activities. Furthermore, the tool provides a list of threats, opportunities and unlabeled WS that can trigger other steps of sensemaking about these signals.}
}
@article{FILOMENA201914,
title = {A computational approach to ‘The Image of the City’},
journal = {Cities},
volume = {89},
pages = {14-25},
year = {2019},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2019.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0264275118309776},
author = {Gabriele Filomena and Judith A. Verstegen and Ed Manley},
keywords = {Image of the City, Cognitive maps, Kevin Lynch, Street network, GIScience},
abstract = {In The Image of the City Lynch describes how individuals perceive and recall features in urban spaces. The most distinctive elements in the urban landscape - categorised in paths, nodes, edges, districts and landmarks - give shape to individuals' mental representation of the city. Lynch’s approach has stimulated research into spatial cognition, urban design and artificial intelligence, and it still represents an essential pillar in the analysis of urban dynamics. Nevertheless, an explicit link between The Image of the City and GIScience has not been completely explored yet. In this paper, a computational approach to The Image of the City is proposed. Different perspectives in spatial cognition and GIS research are integrated to obtain a complete Image of the City, in which the most salient elements are shared by a large part of citizens. Nodes, paths and districts were identified through network science techniques. Methods drawn from the information approach to The Image of the City are used to detect landmarks, integrating the complexity of points of reference in their visual, structural and semantic components, as conceptualised by Lynch and successive research. The methods were applied to the central area of Boston and built using freely available spatial datasets. Results were compared to Lynch’s maps to evaluate the methodology: besides a considerable discrepancy with regard to landmarks, a good correspondence for paths, nodes, edges and districts was found.}
}
@incollection{BLACK2021105,
title = {10 - Mutual benefit from library collaboration with computational biologists: the cropPAL project at the University of Western Australia},
editor = {Jeremy Atkinson},
booktitle = {Technology, Change and the Academic Library},
publisher = {Chandos Publishing},
pages = {105-114},
year = {2021},
series = {Chandos Information Professional Series},
isbn = {978-0-12-822807-4},
doi = {https://doi.org/10.1016/B978-0-12-822807-4.00010-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128228074000105},
author = {Kylie Black},
keywords = {cropPAL, partnerships, collaboration, commercialisation, market research, DeweyFish, ON Prime},
abstract = {In 2016–17, the University of Western Australia (UWA) Library partnered with researchers in the Australian Research Council’s Centre of Excellence in Plant Energy Biology to produce cropPAL2, a database providing the subcellular locations for proteins in crops significant for food production. The project team consisted of computational biologists, software engineers and a librarian, in which the Library contributed expertise in developing search strategies, research data management and enhancing discoverability of cropPAL2 and its dataset. The Library continues to be a key player in this collaboration, a first for UWA, both in the innovative process and as a key driver in directing the development of commercial software for the wider benefit of researchers at UWA and beyond.}
}
@article{MOLINSRUANO2018428,
title = {Phogo: A low cost, free and “maker” revisit to Logo},
journal = {Computers in Human Behavior},
volume = {80},
pages = {428-440},
year = {2018},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2017.09.029},
url = {https://www.sciencedirect.com/science/article/pii/S0747563217305551},
author = {Pablo Molins-Ruano and Carlos Gonzalez-Sacristan and Carlos Garcia-Saura},
keywords = {Computational thinking, Technology education, Educational robots, LOGO, Pre-university education},
abstract = {Today it is almost impossible to spend a single day without depending on an information system, a computer or any other form of computation. Though the starting barrier is low, fundamental concepts are still required in order to manage the technicalities of the engineering environment and everyday computational systems. In 1967, Logo proposed to teach abstract programming concepts by providing a set of functions that had intuitive, visible effects over a robotic Turtle. LOGO was a success, but the robots quickly migrated into computer simulations. From LOGO, many followed. Scratch and Lego Mindstorm are some of the most notorious examples. Both introduced graphical block-based programming interfaces. We propose to bring back the powerful ideas behind LOGO by updating it with state of the art technologies. Phogo combines Python, Arduino and 3D printing into a low cost robot that is easy to build and control. The robot has a pen to draw shapes and can be commanded from a computer via a wireless link that is transparent to the students. The use of a physical robot can make programming more accessible for students with disabilities. The open and maker philosophies behind Phogo makes it more interesting as students will be able to access and study the electronic components. The textual programing language can be a long life companion for the students. In this work we discuss LOGO and other projects inspired by it, and we also share the methodology and design decisions behind Phogo, the results of its application in a workshop and the improvements we are currently developing.}
}
@article{CHEN2016222,
title = {Constraint local principal curve: Concept, algorithms and applications},
journal = {Journal of Computational and Applied Mathematics},
volume = {298},
pages = {222-235},
year = {2016},
issn = {0377-0427},
doi = {https://doi.org/10.1016/j.cam.2015.11.041},
url = {https://www.sciencedirect.com/science/article/pii/S0377042715005956},
author = {Dewang Chen and Jiateng Yin and Shiying Yang and Lingxi Li and Peter Pudney},
keywords = {Constraint local principal curve (CLPC), GPS, Local optimization, Adaptive radius, Principal of nearest neighbor},
abstract = {Existing principal curve algorithms have some drawbacks such as time consuming and narrow application scope in practice, since these algorithms are mainly based on global optimization. In this paper, we present the concept of Constraint Local Principal Curve (CLPC), which uses local optimization methods and restricts the principal curve with two fixed endpoints to reduce the computational complexity. In addition, we propose three CLPC algorithms by Local Optimization and Adaptive Radius to expand the range of applications and increase the solution quality. The first algorithm, i.e., CLPCg is based on greedy thinking. The second algorithm, i.e., CLPCs uses one dimensional search and the last algorithm CLPCc combines the greedy thinking and one dimensional search. Then, we define six performance indices to evaluate the performance of the CLPC algorithms. Finally, we present some numerical experiments with three simulation data sets and two GPS measured data sets in both highway and railway. The results indicate that all of the three CLPC algorithms can obtain high-accuracy data from multiple low-accuracy data efficiently. The CLPC algorithms can improve the accuracy and computational speed compared with the existing K-segment principal curve (KPC) algorithm. In addition, CLPCc outperforms CLPCg and CLPCs according to the comprehensive experiments while CLPCg runs much faster than other ones.}
}
@article{BUKOWSKI202116,
title = {Computational medicine, present and the future: obstetrics and gynecology perspective},
journal = {American Journal of Obstetrics and Gynecology},
volume = {224},
number = {1},
pages = {16-34},
year = {2021},
issn = {0002-9378},
doi = {https://doi.org/10.1016/j.ajog.2020.08.057},
url = {https://www.sciencedirect.com/science/article/pii/S0002937820308851},
author = {Radek Bukowski and Karl Schulz and Kelly Gaither and Keri K. Stephens and Dave Semeraro and Justin Drake and Gordon Smith and Craig Cordola and Thaleia Zariphopoulou and Thomas J.R. Hughes and Christopher Zarins and Dimitri Kusnezov and Donna Howard and Tinsley Oden},
keywords = {computation, data, data-driven models, machine learning, modeling, physics-based models, theory-based models, uncertainty},
abstract = {Medicine is, in its essence, decision making under uncertainty; the decisions are made about tests to be performed and treatments to be administered. Traditionally, the uncertainty in decision making was handled using expertise collected by individual providers and, more recently, systematic appraisal of research in the form of evidence-based medicine. The traditional approach has been used successfully in medicine for a very long time. However, it has substantial limitations because of the complexity of the system of the human body and healthcare. The complex systems are a network of highly coupled components intensely interacting with each other. These interactions give those systems redundancy and thus robustness to failure and, at the same time, equifinality, that is, many different causative pathways leading to the same outcome. The equifinality of the complex systems of the human body and healthcare system demand the individualization of medical care, medicine, and medical decision making. Computational models excel in modeling complex systems and, consequently, enabling individualization of medical decision making and medicine. Computational models are theory- or knowledge-based models, data-driven models, or models that combine both approaches. Data are essential, although to a different degree, for computational models to successfully represent complex systems. The individualized decision making, made possible by the computational modeling of complex systems, has the potential to revolutionize the entire spectrum of medicine from individual patient care to policymaking. This approach allows applying tests and treatments to individuals who receive a net benefit from them, for whom benefits outweigh the risk, rather than treating all individuals in a population because, on average, the population benefits. Thus, the computational modeling–enabled individualization of medical decision making has the potential to both improve health outcomes and decrease the costs of healthcare.}
}
@article{KARA2015526,
title = {A Critical Look at the Digital Technologies in Architectural Education: When, where, and how?},
journal = {Procedia - Social and Behavioral Sciences},
volume = {176},
pages = {526-530},
year = {2015},
note = {International Educational Technology Conference, IETC 2014, 3-5 September 2014, Chicago, IL, USA},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2015.01.506},
url = {https://www.sciencedirect.com/science/article/pii/S1877042815005431},
author = {Levent Kara},
keywords = {architectural pedagogy, architectural design, digital architecture, CAD, CAM, computational design, architectural design studio, architectural drawing, architectural modeling, architectural thinking, architectural geometry},
abstract = {In the past decade, architectural education has seen an increasing amount of digital technologies being involved in the design studio curricula. Following the trends in the profession, these various technologies of computer aided drafting, enumerating, modeling, and analysis became not only key pedagogical nodes in the design studio, but also started to shape the overall curricular structure of architectural education as they also needed to be implemented as support courses in order to compensate the learning curves and the number of software available to architects. These digital technologies range from one end of simple drafting, conventional three dimensional modeling, and more sophisticated animation of buildings with a computer, to the other end of inventing new tectonic and spatial geometries using parametric computations. In this context, it will be unrealistic to argue against teaching and using digital technologies in architectural education. When one thinks how the profession has evolved in the past decade, it is necessary to embrace these tools in the architectural curriculum. However, a discussion that has not been clearly resolved is when, where, and how these digital tools are thought and used in the architectural education. My paper argues that the conventional tools of hand drawing, physical modeling, and hand making should be embraced in the foundational levels, and the digital tools should be introduced after developing a certain set of skills of one-to-one physical making where a sense of tectonic resolution, scale, and spatial experience is cultivated as a basis of architectural thinking with digital tools. In what follows, I will discuss this viewpoint through examples from architectural design studio education in the United States and in Turkey.}
}
@article{CADDY1996219,
title = {Regime shifts and paradigm changes: is there still a place for equilibrium thinking?},
journal = {Fisheries Research},
volume = {25},
number = {3},
pages = {219-230},
year = {1996},
issn = {0165-7836},
doi = {https://doi.org/10.1016/0165-7836(95)00443-2},
url = {https://www.sciencedirect.com/science/article/pii/0165783695004432},
author = {J.F. Caddy}
}
@article{STOLPE2024100159,
title = {Artificial intelligence literacy for technology education},
journal = {Computers and Education Open},
volume = {6},
pages = {100159},
year = {2024},
issn = {2666-5573},
doi = {https://doi.org/10.1016/j.caeo.2024.100159},
url = {https://www.sciencedirect.com/science/article/pii/S2666557324000016},
author = {Karin Stolpe and Jonas Hallström},
keywords = {AI literacy, Ethical issues, AI in education},
abstract = {The interest in artificial intelligence (AI) in education has erupted during the last few years, primarily due to technological advances in AI. It is therefore argued that students should learn about AI, although it is debated exactly how it should be applied in education. AI literacy has been suggested as a way of defining competencies for students to acquire to meet a future everyday- and working life with AI. This study argues that researchers and educators need a framework for integrating AI literacy into technological literacy, where the latter is viewed as a multiliteracy. This study thus aims to critically analyse and discuss different components of AI literacy found in the literature in relation to technological literacy. The data consists of five AI literacy frameworks related to three traditions of technological knowledge: technical skills, technological scientific knowledge, and socio-ethical technical understanding. The results show that AI literacy for technology education emphasises technological scientific knowledge (e.g., knowledge about what AI is, how to recognise AI, and systems thinking) and socio-ethical technical understanding (e.g., AI ethics and the role of humans in AI). Technical skills such as programming competencies also appear but are less emphasised. Implications for technology education are also discussed, and a framework for AI literacy for technology education is suggested.}
}
@article{JARMAN2022225,
title = {Critical measurement issues in the assessment of social media influence on body image},
journal = {Body Image},
volume = {40},
pages = {225-236},
year = {2022},
issn = {1740-1445},
doi = {https://doi.org/10.1016/j.bodyim.2021.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S1740144521001583},
author = {Hannah K. Jarman and Siân A. McLean and Scott Griffiths and Samantha J. Teague and Rachel F. Rodgers and Susan J. Paxton and Emma Austen and Emily Harris and Trevor Steward and Adrian Shatte and Long {Khanh-Dao Le} and Tarique Anwar and Cathrine Mihalopoulos and Alexandra G. Parker and Zali Yager and Matthew Fuller-Tyszkiewicz},
keywords = {Social media, Body image, Qualitative, Survey, Experimental, Momentary assessment, Web scraping, Computational modelling, Measurement, Assessment},
abstract = {Progress towards understanding how social media impacts body image hinges on the use of appropriate measurement tools and methodologies. This review provides an overview of common (qualitative, self-report survey, lab-based experiments) and emerging (momentary assessment, computational) methodological approaches to the exploration of the impact of social media on body image. The potential of these methodologies is detailed, with examples illustrating current use as well as opportunities for expansion. A key theme from our review is that each methodology has provided insights for the body image research field, yet is insufficient in isolation to fully capture the nuance and complexity of social media experiences. Thus, in consideration of gaps in methodology, we emphasise the need for big picture thinking that leverages and combines the strengths of each of these methodologies to yield a more comprehensive, nuanced, and robust picture of the positive and negative impacts of social media.}
}
@article{DENHAAN2011175,
title = {Computational suite of models with heterogeneous agents II: Multi-country real business cycle models},
journal = {Journal of Economic Dynamics and Control},
volume = {35},
number = {2},
pages = {175-177},
year = {2011},
note = {Computational Suite of Models with Heterogeneous Agents II: Multi-Country Real Business Cycle Models},
issn = {0165-1889},
doi = {https://doi.org/10.1016/j.jedc.2010.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S0165188910002149},
author = {Wouter J. {Den Haan} and Kenneth L. Judd and Michel Juillard},
keywords = {Numerical solutions, Simulations, Approximations},
abstract = {This paper describes the second model considered in the computational suite project that compares the performance of different numerical algorithms. It is a multi-country model in which countries face different productivity shocks. Solving such models is a challenging numerical problem unless the number of countries is small. The solutions are functions of a large set of arguments and the functional forms are unknown. Moreover, the solution procedures have to deal with high-dimensional integration problems.}
}
@article{SWANSON2020100961,
title = {The relationship between executive processing and computational growth among monolingual and english learners with and without math difficulties: Does it help to be bilingual?},
journal = {Cognitive Development},
volume = {56},
pages = {100961},
year = {2020},
issn = {0885-2014},
doi = {https://doi.org/10.1016/j.cogdev.2020.100961},
url = {https://www.sciencedirect.com/science/article/pii/S0885201420301155},
author = {H. Lee Swanson},
keywords = {Math difficulties, English learner, Bilingual, Working memory, Cognition, Math computation},
abstract = {Does the commonly reported math achievement gap among elementary school monolingual and English learners (ELs) with and without math difficulties reflect variations in executive processing? This cohort-sequential study (N = 841) explored the cognitive processes that underlie in elementary school children’s math computational growth who are monolingual (English-only) or English learners with Spanish as a first language. Three language subgroups (proficient ELs [relatively proficient in both English and Spanish vocabulary], less proficient ELs [more proficient in English when compared to Spanish vocabulary] and monolingual [English-only]) children with and without math difficulties (MD) were compared on measures of math computation and cognitive growth. As expected, children with MD identified at wave 1 underperformed children without MD in their rate of growth and their level of computational and working memory (WM) performance in the final testing wave. However, two additional findings occurred. First, executive processing measures (working memory and inhibition) were significantly related to computational growth even when measures of reading, fluid intelligence, STM, naming speed and SES were partialed in the analysis. Second, no statistical advantages in executive processing or computation emerged in favor of EL children relative to monolingual children. Taken together, the results support the notion that (a) growth in math computation is tied to growth in the executive system and (b) EL children relatively proficient in English and Spanish experience no growth advantages in WM or computation compared to monolingual children.}
}
@article{ALI20201425,
title = {Re-thinking adaptive immunity in the beetles: Evolutionary and functional trajectories of lncRNAs},
journal = {Genomics},
volume = {112},
number = {2},
pages = {1425-1436},
year = {2020},
issn = {0888-7543},
doi = {https://doi.org/10.1016/j.ygeno.2019.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S0888754319302034},
author = {Ali Ali and Hesham M. {Abd El Halim}},
keywords = {Immune memory, Priming, , Macrophage},
abstract = {Unlike vertebrate animals, invertebrates lack lymphocytes and therefore have historically been believed not to develop immune memory. A few studies have reported evidence of immune priming in insects; however, these studies lack the molecular mechanism and proposed it might be different among taxa. Since lncRNAs are known to regulate the immune response, we identified 10,120 lncRNAs in Tribolium castaneum genome-wide followed by transcriptome analysis of primed and unprimed larvae of different infectious status. A shift in lncRNA expression between Btt primed larvae and other treatment groups provides evidence of immune memory response. A few “priming” lncRNAs (n = 9) were uniquely regulated in Btt primed larvae. Evidence suggests these lncRNAs are likely controlling immune priming in Tribolium by regulating expression of genes involved in proteasomal machinery, Notch system, zinc metabolism, and methyltransferase activity, which are necessary to modulate phagocytosis. Our results support a conserved immune priming mechanism in a macrophage-dependent manner.}
}
@article{YANG20101297,
title = {Computational optimization, modelling and simulation–a paradigm shift},
journal = {Procedia Computer Science},
volume = {1},
number = {1},
pages = {1297-1300},
year = {2010},
note = {ICCS 2010},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2010.04.144},
url = {https://www.sciencedirect.com/science/article/pii/S1877050910001456},
author = {Xin-She Yang and Slawomir Koziel},
keywords = {Algorithm, Black-box modelling, Computational optimization, Derivative-free method, Optimization algorithm, Modelling, Nonlinear optimization, Surragate-based optimization, Simulation},
abstract = {Computational optimization forms an integrated part of modern computational science. Any good design should intend to achieve certain optimality, though optimal solutions are often difficult to find in practice since uncertainty and nonlinearity always present in almost all real-world problems. As resources, time and money are always limited, optimization becomes even more important in practice. This workshop on Computational Optimization, Modelling and Simulation (COMS 2010) at ICCS 2010 will summarize the latest developments of optimization and modelling and their applications in science, engineering and industry}
}
@article{GONDOCS2024102769,
title = {AI in medical diagnosis: AI prediction & human judgment},
journal = {Artificial Intelligence in Medicine},
volume = {149},
pages = {102769},
year = {2024},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2024.102769},
url = {https://www.sciencedirect.com/science/article/pii/S0933365724000113},
author = {Dóra Göndöcs and Viktor Dörfler},
keywords = {Medical diagnosis, Melanoma, Human-computer interaction, Augmented intelligence, Explainability, Responsible AI},
abstract = {AI has long been regarded as a panacea for decision-making and many other aspects of knowledge work; as something that will help humans get rid of their shortcomings. We believe that AI can be a useful asset to support decision-makers, but not that it should replace decision-makers. Decision-making uses algorithmic analysis, but it is not solely algorithmic analysis; it also involves other factors, many of which are very human, such as creativity, intuition, emotions, feelings, and value judgments. We have conducted semi-structured open-ended research interviews with 17 dermatologists to understand what they expect from an AI application to deliver to medical diagnosis. We have found four aggregate dimensions along which the thinking of dermatologists can be described: the ways in which our participants chose to interact with AI, responsibility, ‘explainability’, and the new way of thinking (mindset) needed for working with AI. We believe that our findings will help physicians who might consider using AI in their diagnosis to understand how to use AI beneficially. It will also be useful for AI vendors in improving their understanding of how medics want to use AI in diagnosis. Further research will be needed to examine if our findings have relevance in the wider medical field and beyond.}
}
@article{BYSTRITSKY2012428,
title = {Computational non-linear dynamical psychiatry: A new methodological paradigm for diagnosis and course of illness},
journal = {Journal of Psychiatric Research},
volume = {46},
number = {4},
pages = {428-435},
year = {2012},
issn = {0022-3956},
doi = {https://doi.org/10.1016/j.jpsychires.2011.10.013},
url = {https://www.sciencedirect.com/science/article/pii/S0022395611002615},
author = {A. Bystritsky and A.A. Nierenberg and J.D. Feusner and M. Rabinovich},
keywords = {Phenomenology, Mathematical models, Non-linear dynamics, Winner less competition, Psychopathology},
abstract = {The goal of this article is to highlight the significant potential benefits of applying computational mathematical models to the field of psychiatry, specifically in relation to diagnostic conceptualization. The purpose of these models is to augment the current diagnostic categories that utilize a “snapshot” approach to describing mental states. We hope to convey to researchers and clinicians that non-linear dynamics can provide an additional useful longitudinal framework to understand mental illness. Psychiatric phenomena are complex processes that evolve in time, similar to many other processes in nature that have been successfully described and understood within deterministic chaos and non-linear dynamic computational models. Dynamical models describe mental processes and phenomena that change over time, more like a movie than a photograph, with multiple variables interacting over time. The use of these models may help us understand why and how current diagnostic categories are insufficient. They may also provide a new, more descriptive and ultimately more predictive approach leading to better understanding of the interrelationship between psychological, neurobiological, and genetic underpinnings of mental illness.}
}
@article{AILON2020234,
title = {Paraunitary matrices, entropy, algebraic condition number and Fourier computation},
journal = {Theoretical Computer Science},
volume = {814},
pages = {234-248},
year = {2020},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2020.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S0304397520300797},
author = {Nir Ailon},
keywords = {Fourier transform, Lower bounds, Complexity, Linear algebraic computation},
abstract = {The Fourier Transform is one of the most important linear transformations used in science and engineering. Cooley and Tukey's Fast Fourier Transform (FFT) from 1964 is a method for computing this transformation in time O(nlog⁡n). From a lower bound perspective, relatively little is known. Ailon shows in 2013 an Ω(nlog⁡n) bound for computing the normalized Fourier Transform assuming only unitary operations on two coordinates are allowed at each step, and no extra memory is allowed. In 2014, Ailon then improved the result to show that, in a κ-well conditioned computation, Fourier computation can be sped up by no more than O(κ). The main conjecture is that Ailon's result can be exponentially improved, in the sense that κ-well condition cannot admit ω(log⁡κ) speedup. The main result here is that ‘algebraic’ κ-well condition cannot admit ω(κ) speedup. One equivalent definition of algebraic condition number is related to the degree of polynomials naturally arising as the computation evolves. Using the maximum modulus theorem from complex analysis, we show that algebraic condition number upper bounds standard condition number, and equals it in certain cases. Algebraic condition number is an interesting measure of numerical computation stability in its own right, and provides a novel computational lens. Moreover, based on evidence from other recent related work, we believe that the approach of algebraic condition number has a good chance of establishing an algebraic version of the main conjecture.}
}
@incollection{WARD2018,
title = {Analogy☆},
booktitle = {Reference Module in Neuroscience and Biobehavioral Psychology},
publisher = {Elsevier},
year = {2018},
isbn = {978-0-12-809324-5},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.21889-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245218890},
author = {Thomas B. Ward},
keywords = {ACME, Analogy, Case study, Computational modeling, Laboratory study, In vivo study, Mapping, Multiconstraint theory, One-to-one correspondence, Parallel connectivity, Retrieval, SME, Source domain, Structure-mapping theory, Systematicity, Target domain},
abstract = {Analogical thinking is a fundamental cognitive process underlying creativity. Analogies map structured knowledge from one domain to another and serve as information for understanding, explaining and creating. Analogy is studied through case study, laboratory, in vivo, neuroscience and computational modeling approaches. The use of analogy is often suggested to be a helpful technique in applied approaches to creativity.}
}
@article{TURKHEIMER2015211,
title = {The brain's code and its canonical computational motifs. From sensory cortex to the default mode network: A multi-scale model of brain function in health and disease},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {55},
pages = {211-222},
year = {2015},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2015.04.014},
url = {https://www.sciencedirect.com/science/article/pii/S0149763415001189},
author = {Federico E. Turkheimer and Robert Leech and Paul Expert and Louis-David Lord and Anthony C. Vernon},
keywords = {Brain networks, Functional connectivity, Interneurons, Gamma-oscillations, NMDA, GABA, Lateral inhibition, Feedback inhibition, Feed-forward inhibition, Canonical neural computation, Motifs, Default mode network, fMRI, Schizophrenia},
abstract = {A variety of anatomical and physiological evidence suggests that the brain performs computations using motifs that are repeated across species, brain areas, and modalities. The computational architecture of cortex, for example, is very similar from one area to another and the types, arrangements, and connections of cortical neurons are highly stereotyped. This supports the idea that each cortical area conducts calculations using similarly structured neuronal modules: what we term canonical computational motifs. In addition, the remarkable self-similarity of the brain observables at the micro-, meso- and macro-scale further suggests that these motifs are repeated at increasing spatial and temporal scales supporting brain activity from primary motor and sensory processing to higher-level behaviour and cognition. Here, we briefly review the biological bases of canonical brain circuits and the role of inhibitory interneurons in these computational elements. We then elucidate how canonical computational motifs can be repeated across spatial and temporal scales to build a multiplexing information system able to encode and transmit information of increasing complexity. We point to the similarities between the patterns of activation observed in primary sensory cortices by use of electrophysiology and those observed in large scale networks measured with fMRI. We then employ the canonical model of brain function to unify seemingly disparate evidence on the pathophysiology of schizophrenia in a single explanatory framework. We hypothesise that such a framework may also be extended to cover multiple brain disorders which are grounded in dysfunction of GABA interneurons and/or these computational motifs.}
}
@incollection{MAERTENS2025358,
title = {Regrettable Substitutions},
editor = {Béla Török},
booktitle = {Encyclopedia of Green Chemistry (First Edition)},
publisher = {Elsevier},
edition = {First Edition},
address = {Oxford},
pages = {358-364},
year = {2025},
isbn = {978-0-443-28923-1},
doi = {https://doi.org/10.1016/B978-0-443-15742-4.00099-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780443157424000995},
author = {Alexandra Maertens and Thomas Hartung},
keywords = {Alternative assessments, Chemical policy, Environmental justice, Exposure science, Green toxicology, Hazard, Life cycle analysis, Toxicity mechanisms},
abstract = {Regrettable substitutions refer to the unintended consequences that arise when replacing one substance with another, often resulting in new problems or uncertainties. Regrettable substitutions have been observed in various functional classes, such as flame retardants, where initial solutions aimed at enhancing fire safety but have raised concerns about persistent environmental pollution and potential health risks. Regrettable substitutions are often caused by a lack of data about hazard or exposure, life-cycle considerations or a failure to consider other functionality more broadly. Initial solutions aimed at enhancing fire safety, product performance or crop protection have ended up raising new concerns about persistent environmental pollution, ecosystem effects, occupational hazards and long-term health risks. To avoid future regrettable substitutions, a more holistic, data-driven approach to chemical alternatives assessment is needed. This should incorporate human-relevant mechanistic toxicity testing, quantitative exposure modeling, life cycle thinking, and consideration of safer chemistry solutions that maintain product functionality. Enhanced cross-sector collaboration, data sharing, and clear risk communication to consumers is also critical. Integrating these green toxicology principles into chemical design and evaluation can help achieve sustainable substitutions that maximize benefits and minimize risks.}
}
@article{VANDENAMEELE2014334,
title = {Thinking out of the dish: what to learn about cortical development using pluripotent stem cells},
journal = {Trends in Neurosciences},
volume = {37},
number = {6},
pages = {334-342},
year = {2014},
issn = {0166-2236},
doi = {https://doi.org/10.1016/j.tins.2014.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S0166223614000447},
author = {Jelle {van den Ameele} and Luca Tiberi and Pierre Vanderhaeghen and Ira Espuny-Camacho},
abstract = {The development of the cerebral cortex requires the tightly coordinated generation of dozens of neuronal subtypes that will populate specific layers and areas. Recent studies have revealed how pluripotent stem cells (PSC), whether of mouse or human origin, can differentiate into a wide range of cortical neurons in vitro, which can integrate appropriately into the brain following in vivo transplantation. These models are largely artificial but recapitulate a substantial fraction of the complex temporal and regional patterning events that occur during in vivo corticogenesis. Here, we review these findings with emphasis on the new perspectives that they have brought for understanding of cortical development, evolution, and diseases.}
}
@article{BRASCH2012299,
title = {Thinking outside the cell: how cadherins drive adhesion},
journal = {Trends in Cell Biology},
volume = {22},
number = {6},
pages = {299-310},
year = {2012},
issn = {0962-8924},
doi = {https://doi.org/10.1016/j.tcb.2012.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S0962892412000529},
author = {Julia Brasch and Oliver J. Harrison and Barry Honig and Lawrence Shapiro},
abstract = {Cadherins are a superfamily of cell surface glycoproteins whose ectodomains contain multiple repeats of β-sandwich extracellular cadherin (EC) domains that adopt a similar fold to immunoglobulin domains. The best characterized cadherins are the vertebrate ‘classical’ cadherins, which mediate adhesion via trans homodimerization between their membrane-distal EC1 domains that extend from apposed cells, and assemble intercellular adherens junctions through cis clustering. To form mature trans adhesive dimers, cadherin domains from apposed cells dimerize in a ‘strand-swapped’ conformation. This occurs in a two-step binding process involving a fast-binding intermediate called the ‘X-dimer’. Trans dimers are less flexible than cadherin monomers, a factor that drives junction assembly following cell–cell contact by reducing the entropic cost associated with the formation of lateral cis oligomers. Cadherins outside the classical subfamily appear to have evolved distinct adhesive mechanisms that are only now beginning to be understood.}
}
@incollection{HUDLICKA2017383,
title = {Chapter 16 - Computational Modeling of Cognition–Emotion Interactions: Theoretical and Practical Relevance for Behavioral Healthcare},
editor = {Myounghoon Jeon},
booktitle = {Emotions and Affect in Human Factors and Human-Computer Interaction},
publisher = {Academic Press},
address = {San Diego},
pages = {383-436},
year = {2017},
isbn = {978-0-12-801851-4},
doi = {https://doi.org/10.1016/B978-0-12-801851-4.00016-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128018514000161},
author = {Eva Hudlicka},
keywords = {emotion–cognition modeling, modeling mechanism of therapeutic action, computational models of affective disorders and psychopathology, therapeutic games, behavioral healthcare technology, transdiagnostic model},
abstract = {Recent years have witnessed an increasing interest in developing computational models of emotion and emotion–cognition interaction, within the emerging area of computational affective science. At the same time, emotion theorists and clinical psychologists have begun to recognize the importance of moving beyond descriptive characterizations of psychopathology, and identifying the underlying mechanisms that mediate both the etiology of affective disorders, and their treatment: the transdiagnostic approach to psychopathology. Computational models of cognition–emotion interactions have the potential to facilitate more accurate assessment and diagnosis of affective disorders, and to provide a basis for more efficient and targeted approaches to their treatment, through an improved understanding of the underlying mechanisms. This chapter discusses the state-of-the-art in modeling emotion–cognition interaction and the relevance of these models for understanding the mechanisms mediating psychopathology and therapeutic action. The discussion is limited to symbolic models and theories defined at the psychological, versus neural, level. The chapter also outlines how these models can support the development of serious therapeutic games, to enhance assessment and treatment methods in behavioral healthcare.}
}
@article{MITTAL1994253,
title = {Massively parallel finite element computation of incompressible flows involving fluid-body interactions},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {112},
number = {1},
pages = {253-282},
year = {1994},
issn = {0045-7825},
doi = {https://doi.org/10.1016/0045-7825(94)90029-9},
url = {https://www.sciencedirect.com/science/article/pii/0045782594900299},
author = {S. Mittal and T.E. Tezduyar},
abstract = {We describe our massively parallel finite element computations of unsteady incompressible flows involving fluid-body interactions. These computations are based on the Deforming-Spatial-Domain/Stabilized-Space-Time (DSD/SST) finite element formulation. Unsteady flows past a stationary NACA 0012 airfoil are computed for Reynolds numbers 1000, 5000 and 100 000. Significantly different flow patterns are observed for these three cases. The method is then applied to computation of the dynamics of an airfoil falling in a viscous fluid under the influence of gravity. It is observed that the location of the center of gravity of the airfoil plays an important role in determining its pitch stability. Computations are reported also for simulation of the dynamics of a two-dimensional ‘projectile’ that has a certain initial velocity. Specially designed mesh moving schemes are employed to eliminate the need for remeshing. All these computations were carried out on the Thinking Machines CM-200 and CM-5 supercomputers, with major speed-ups compared to traditional supercomputers. The implicit equation systems arising from the finite element discretizations of these large-scale problems are solved iteratively by using the GMRES update technique with diagonal preconditioners. The finite element formulations and their parallel implementations assume unstructured meshes.}
}
@article{HAO20231,
title = {A Commentary on Towards autonomous artificial agents with an active self: Modeling sense of control in situated action},
journal = {Cognitive Systems Research},
volume = {79},
pages = {1-3},
year = {2023},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2022.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S1389041722001085},
author = {Chenxu Hao and Nele Russwinkel and Daniel F.B. Haeufle and Philipp Beckerle},
keywords = {Human–robot interaction, Unified models of HRI, Anticipatory thinking},
abstract = {Kahl et al., (2022) present a computational model of an autonomous agent implemented with an active self. With ideas based on the Free Energy Principle (Friston and Kiebel, 2009), their model tackles the challenge to unify higher-level cognitive activities and lower-level sensorimotor control as the autonomous agent maintains situational awareness while interacting with the environment. While Kahl et al., (2022) focus on modeling a single agent, we argue that this challenge similarly appears in modeling human–robot interaction (HRI). In this commentary, we discuss how the conceptual framework from Kahl et al., (2022) could inspire unified models of physical and cognitive HRI and how the modeling approach from Kahl et al., (2022) can potentially be applied to anticipatory thinking in robotics to support the human in daily life.}
}
@article{DELGADO2019133,
title = {Computational methods for Gene Regulatory Networks reconstruction and analysis: A review},
journal = {Artificial Intelligence in Medicine},
volume = {95},
pages = {133-145},
year = {2019},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2018.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S0933365718303865},
author = {Fernando M. Delgado and Francisco Gómez-Vela},
keywords = {Gene Network, Systems biology, Networks validation, Gene Regulatory Network, Gene Network inference},
abstract = {In the recent years, the vast amount of genetic information generated by new-generation approaches, have led to the need of new data handling methods. The integrative analysis of diverse-nature gene information could provide a much-sought overview to study complex biological systems and processes. In this sense, Gene Regulatory Networks (GRN) arise as an increasingly-promising tool for the modelling and analysis of biological processes. This review is an attempt to summarize the state of the art in the field of GRNs. Essential points in the field are addressed, thereof: (a) the type of data used for network generation, (b) machine learning methods and tools used for network generation, (c) model optimization and (d) computational approaches used for network validation. This survey is intended to provide an overview of the subject for readers to improve their knowledge in the field of GRN for future research.}
}
@article{COHEN1981285,
title = {The power of parallel thinking},
journal = {Journal of Economic Behavior & Organization},
volume = {2},
number = {4},
pages = {285-306},
year = {1981},
issn = {0167-2681},
doi = {https://doi.org/10.1016/0167-2681(81)90011-1},
url = {https://www.sciencedirect.com/science/article/pii/0167268181900111},
author = {Michael D. Cohen},
abstract = {A small computer model demonstrates that an appropriate organization of boundedly rational individuals can find optimal policies in an environment that is overwhelmingly complex for unorganized decision makers. The model is also used to identify conditions under which optimal — or even good — policies are not found. The demonstrated adaptive power of the model is interpreted in light of recent developments in the theory of computational complexity that place new stress on powerful methods of search, and of new models from computer science which markedly advance search effectiveness by harnessing parallel structures of information processing.}
}
@article{SHARP2025118,
title = {Anxiety involves altered planning},
journal = {Trends in Cognitive Sciences},
volume = {29},
number = {2},
pages = {118-121},
year = {2025},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S1364661324002924},
author = {Paul B. Sharp},
keywords = {planning, anxiety, reinforcement learning},
abstract = {Clinicians have suggested but not shown how anxiety involves altered planning. Here, I synthesize and extend computational models of planning in a framework that can be used to explain planning biases in anxiety. To spur its development, I spotlight two of its promising areas: task construal and meta-control.}
}
@article{DUGGAN2024101426,
title = {ChatGPT performance on radiation technologist and therapist entry to practice exams},
journal = {Journal of Medical Imaging and Radiation Sciences},
volume = {55},
number = {4},
pages = {101426},
year = {2024},
issn = {1939-8654},
doi = {https://doi.org/10.1016/j.jmir.2024.04.019},
url = {https://www.sciencedirect.com/science/article/pii/S193986542400122X},
author = {Ryan Duggan and Kaitlyn M. Tsuruda},
keywords = {Radiography, Radiotherapy, Nuclear Medicine, Magnetic Resonance Imaging, AI (Artificial Intelligence), Natural Language Processing, Teaching, Educational Measurement},
abstract = {Background
The aim of this study was to describe the proficiency of ChatGPT (GPT-4) on certification style exams from the Canadian Association of Medical Radiation Technologists (CAMRT), and describe its performance across multiple exam attempts.
Methods
ChatGPT was prompted with questions from CAMRT practice exams in the disciplines of radiological technology, magnetic resonance (MRI), nuclear medicine and radiation therapy (87-98 questions each). ChatGPT attempted each exam five times. Exam performance was evaluated using descriptive statistics, stratified by discipline and question type (knowledge, application, critical thinking). Light's Kappa was used to assess agreement in answers across attempts.
Results
Using a passing grade of 65 %, ChatGPT passed the radiological technology exam only once (20 %), MRI all five times (100 %), nuclear medicine three times (60 %), and radiation therapy all five times (100 %). ChatGPT's performance was best on knowledge questions across all disciplines except radiation therapy. It performed worst on critical thinking questions. Agreement in ChatGPT's responses across attempts was substantial within the disciplines of radiological technology, MRI, and nuclear medicine, and almost perfect for radiation therapy.
Conclusion
ChatGPT (GPT-4) was able to pass certification style exams for radiation technologists and therapists, but its performance varied between disciplines. The algorithm demonstrated substantial to almost perfect agreement in the responses it provided across multiple exam attempts. Future research evaluating ChatGPT's performance on standardized tests should consider using repeated measures.
RÉSUMÉ
Contexte
L'objectif de cette étude était de décrire la compétence du ChatGPT (GPT-4) dans les examens d'agrément de l'Association canadienne des technologues en radiation médicale (ACTRM), et de décrire sa performance à travers plusieurs tentatives d'examen.
Méthodes
ChatGPT a été invité à répondre à des questions provenant des examens pratiques de l'ACTRM dans les disciplines de la technologie de radiologie, de la résonance magnétique (IRM), de la médecine nucléaire et de la radiothérapie (87-98 questions pour chaque discipline). ChatGPT a tenté chaque examen cinq fois. La performance à l'examen a été évaluée à l'aide de statistiques descriptives, stratifiées par discipline et par type de question (connaissances, application, réflexion critique). Le Kappa de Light a été utilisé pour évaluer la concordance des réponses entre les tentatives.
Résultats
En utilisant une note de passage de 65 %, ChatGPT a réussi l'examen de technologie de radiologie une seule fois (20 %), l'IRM les cinq fois (100 %), la médecine nucléaire trois fois (60 %), et la radiothérapie les cinq fois (100 %). Les performances de ChatGPT ont été les meilleures pour les questions de connaissances dans toutes les disciplines, à l'exception de la radiothérapie. Il a été le moins performant pour les questions de réflexion critique. La concordance des réponses du ChatGPT entre les tentatives était substantielle dans les disciplines de la technologie de radiologie, de l'IRM et de la médecine nucléaire, et presque parfaite pour la radiothérapie.
Conclusion
ChatGPT (GPT-4) a été capable de réussir les examens d'agrément pour les technologues en radiation médicale et les radiothérapeutes, mais ses performances ont varié selon les disciplines. L'algorithme a démontré une concordance substantielle à presque parfaite dans les réponses qu'il a fournies à travers de multiples tentatives d'examen. Les futures recherches évaluant les performances de ChatGPT sur des tests standardisés devraient envisager l'utilisation de mesures répétées.}
}
@article{COWARD2014164,
title = {Brain Computational Primitives},
journal = {Procedia Computer Science},
volume = {41},
pages = {164-175},
year = {2014},
note = {5th Annual International Conference on Biologically Inspired Cognitive Architectures, 2014 BICA},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.11.100},
url = {https://www.sciencedirect.com/science/article/pii/S1877050914015452},
author = {L. Andrew Coward},
abstract = {The brain uses computational primitives that are analogous with but qualitatively different from the computational primitives used in electronic computer systems. The primary computational primitives of the brain are described, and their implementation in anatomy and physiology discussed. Combinations and sequences of these primitives implement cognitive tasks. Many of the primitives have also been implemented electronically. The brain is a very effective general learning system, and although an artificial general intelligence system will be required to learn a different range of behaviours from the brain, the computational primitives used by the brain are the best available guide to appropriate primitives for such an AGI system.}
}
@article{BEYTIA2022101732,
title = {Towards a Digital Reflexive Sociology: Using Wikipedia's Biographical Repository as a Reflexive Tool},
journal = {Poetics},
volume = {95},
pages = {101732},
year = {2022},
issn = {0304-422X},
doi = {https://doi.org/10.1016/j.poetic.2022.101732},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X22001140},
author = {Pablo Beytía and Hans-Peter Müller},
keywords = {Reflexive sociology, digital sociology, sociology of knowledge, computational social science, digital methods},
abstract = {We propose the development of 'digital reflexive sociology', understood as the use of digital methods and Big Data to reflect on the social and historical circumstances of sociologists and sociological thinking. To show this approach's potential, we employ Wikipedia as a ‘reflexive tool’, i.e., an external artefact of self-observation that can help sociologists to notice conventions, biases, and blind spots within their discipline. We analyse the collective patterns of the 500 most notable sociologists on Wikipedia, performing structural, network, and text analyses of their biographies. Our exploration reveals patterns in their historical frequency, gender composition, geographical concentration, birth-death mobility, centrality degree, biographical clustering, and proximity between countries, also stressing institutions, events, places, and relevant dates from a biographical point of view. Linking these patterns in a diachronic way, we distinguish five generations of sociologists recorded on Wikipedia and emphasise the high historical concentration of the discipline in geographical areas, gender, and schools of thought. Drawing on these results, we discuss the potential of using digital repositories and methods to enhance reflexivity within sociology.}
}
@article{MURRAY2018777,
title = {Biophysical Modeling of Large-Scale Brain Dynamics and Applications for Computational Psychiatry},
journal = {Biological Psychiatry: Cognitive Neuroscience and Neuroimaging},
volume = {3},
number = {9},
pages = {777-787},
year = {2018},
note = {Computational Methods and Modeling in Psychiatry},
issn = {2451-9022},
doi = {https://doi.org/10.1016/j.bpsc.2018.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S2451902218301782},
author = {John D. Murray and Murat Demirtaş and Alan Anticevic},
keywords = {Computational model, Functional connectivity, Neuroimaging, Resting-state, Schizophrenia, Transcriptomics},
abstract = {Noninvasive neuroimaging has revolutionized the study of the organization of the human brain and how its structure and function are altered in psychiatric disorders. A critical explanatory gap lies in our mechanistic understanding of how systems-level neuroimaging biomarkers emerge from underlying synaptic-level perturbations associated with a disease state. We describe an emerging computational psychiatry approach leveraging biophysically based computational models of large-scale brain dynamics and their potential integration with clinical and pharmacological neuroimaging. In particular, we focus on neural circuit models, which describe how patterns of functional connectivity observed in resting-state functional magnetic resonance imaging emerge from neural dynamics shaped by inter-areal interactions through underlying structural connectivity defining long-range projections. We highlight the importance of local circuit physiological dynamics, in combination with structural connectivity, in shaping the emergent functional connectivity. Furthermore, heterogeneity of local circuit properties across brain areas, which impacts large-scale dynamics, may be critical for modeling whole-brain phenomena and alterations in psychiatric disorders and pharmacological manipulation. Finally, we discuss important directions for future model development and biophysical extensions, which will expand their utility to link clinical neuroimaging to neurobiological mechanisms.}
}
@article{LIU2017168,
title = {A landmark-based data-driven approach on 2.5D facial attractiveness computation},
journal = {Neurocomputing},
volume = {238},
pages = {168-178},
year = {2017},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2017.01.050},
url = {https://www.sciencedirect.com/science/article/pii/S0925231217301248},
author = {Shu Liu and Yang-Yu Fan and Zhe Guo and Ashok Samal and Afan Ali},
keywords = {Facial attractiveness computation, 2.5 D, Geometric features, Data-driven, BJUT-3D},
abstract = {Investigating the nature and components of face attractiveness from a computational view has become an emerging topic in facial analysis research. In this paper, a multi-view (frontal and profile view, 2.5D) facial attractiveness computational model is developed to explore how face geometry affects its attractiveness. A landmark-based, data-driven method is introduced to construct a huge dimension of three kinds of geometric facial measurements, including ratios, angles, and inclinations. An incremental feature selection algorithm is proposed to systematically select the most discriminative subset of geometric features, which are finally mapped to an attractiveness score through the application of support vector regression (SVR). On a dataset of 360 facial images pre-processed from BJUT-3D Face Database and an attractiveness score dataset collected from human raters, we show that the computational model performs well with low statistic error (MSE=0.4969) and good predictability (R2=0.5756).}
}
@incollection{YERPUDE2022335,
title = {CHAPTER FOURTEEN - Computational analysis of nanofluids-based drug delivery system: Preparation, current development and applications of nanofluids},
editor = {Shriram S. Sonawane and Hussein A. Mohammed and Arvind Kumar Mungray and Shirish H. Sonawane},
booktitle = {Applications of Nanofluids in Chemical and Bio-medical Process Industry},
publisher = {Elsevier},
pages = {335-364},
year = {2022},
isbn = {978-0-323-90564-0},
doi = {https://doi.org/10.1016/B978-0-323-90564-0.00014-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780323905640000143},
author = {S.T. Yerpude and A.K. Potbhare and P.R. Bhilkar and Parag Thakur and Pratiksha Khiratkar and Martin F. Desimone and P.R. Dhongle and Shriram S. Sonawane and Clara Goncalves and R.G. Chaudhary},
keywords = {CFD, Computational analysis, Drug delivery, Mathematical modeling, Nanofluids, Nano-drugs},
abstract = {Nanoparticles have been widely employed as a drug delivery carrier and a direct targeting agent. Off course, nanoparticles have been precisely and accurately designed to improve their therapeutical efficacy. Nowadays, computational modeling is frequently used to design novel and smart nanoparticles. In this chapter, we provide an overview and general idea about nanofluids in association with computational applications aimed at the improvement of nano-drug delivery coordination. Nanotechnology and nanobiotechnology-based conceptual innovations in combination with computational modeling are extensively employed in various areas of basic and applied sciences. On the same line, these technologies have a greater impact in the field of medicine and biology. We intended to look upon different aspects regarding nano-drugs and nanofluids comprising their preparation and stabilization methods and also focusing on mathematical modeling, stability mechanism, and biomedical applications of nanofluids. Similarly, imperative and special concern was given to the topic of computational fluid dynamics (CFD).}
}
@incollection{GOMEZPEROSANZ2019906,
title = {Computational Immunogenetics},
editor = {Shoba Ranganathan and Michael Gribskov and Kenta Nakai and Christian Schönbach},
booktitle = {Encyclopedia of Bioinformatics and Computational Biology},
publisher = {Academic Press},
address = {Oxford},
pages = {906-930},
year = {2019},
isbn = {978-0-12-811432-2},
doi = {https://doi.org/10.1016/B978-0-12-809633-8.20452-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780128096338204524},
author = {Marta {Gómez Perosanz} and Giulia Russo and Jose Luis {Sanchez-Trincado Lopez} and Marzio Pennisi and Pedro A. Reche and Adrian Shepherd and Francesco Pappalardo},
keywords = {Agent based modelling, Antibody modelling, Bioinformatics for immune system modelling, Crystallography, Epitopes prediction, Immune system modelling, Immune system pathways, Immunotherapies, In silico trials, Molecular and cellular modelling, Multi-scale modelling, ODE modelling, Petri nets, T and B cells, Vaccines},
abstract = {Computational immunogenetics encompasses the use and application of bioinformatics methods, mathematical models and statistical techniques for the study of immune system function. The considerable heterogeneity of the immune system requires systems approaches to be used to model such a complexity and to respond to questions posed by biomedical audience to help them solve biomedical questions. Computational approaches are increasingly vital to understand the implications of the wealth of gene expression and epigenomics data being gathered from immune cells, and dozens of immune databases play a vital role in organizing the vast quantities of experimental data generated by modern high-throughput technologies. Multi-scale methodologies are increasingly being used to characterise the interplay between the molecular, cellular and organism levels of the immune system. Finally, computational immunology is making an important contribution to an emerging field of computational biomedicine: in silico clinical trials.}
}
@article{BELLO2025100031,
title = {Cloud computing for chatbot in the construction industry: An implementation framework for conversational-BIM voice assistant},
journal = {Digital Engineering},
volume = {5},
pages = {100031},
year = {2025},
issn = {2950-550X},
doi = {https://doi.org/10.1016/j.dte.2024.100031},
url = {https://www.sciencedirect.com/science/article/pii/S2950550X24000311},
author = {Sururah A. Bello and Lukumon O. Oyedele and Lukman A. Akanbi and Abdul-Lateef Bello},
keywords = {Software project management, Amazon web services, Cloud computing, Building information modelling (BIM), Conversational AI, Construction industry, Framework implementation, Chatbot, construction workers, Design thinking methodology, Focus group, Stakeholders management},
abstract = {This study presents a structural framework for selecting cloud services for the Conversational AI system implementation in the construction industry using Design Thinking Methodology. A focus group discussion approach was used to obtain user requirements from construction workers to implement the Conversational AI for BIM. This resulted in five factors: finance, speed of operation, privacy, estimation, and interface. The user specifications were mapped into technical modules, which were used to select cloud services employed to implement the virtual assistant for the construction industry. The study thus presented the comprehensive requirements for the different categories of construction workers to implement the Conversational-BIM Chatbot (Conversational-BIM) system. Furthermore, the study presented the architecture of Conversational-BIM using Amazon Web Services. The study is useful to researchers and IT developers in implementing chatbots for the construction industry as it presents the relevant considerations for conversational AI applications in the industry.}
}
@article{GEORGAKARAKOS2017291.e15,
title = {Custom-Made Conical Endograft in the Treatment of Saccular Abdominal Aortic Aneurysms with Tight and Calcified Distal Neck: Thinking Out of the Box},
journal = {Annals of Vascular Surgery},
volume = {39},
pages = {291.e15-291.e19},
year = {2017},
issn = {0890-5096},
doi = {https://doi.org/10.1016/j.avsg.2016.08.018},
url = {https://www.sciencedirect.com/science/article/pii/S0890509616312419},
author = {Efstratios Georgakarakos and Christos Argyriou and Nikolaos Schoretsanitis and George S. Georgiadis},
abstract = {Background
To describe the use of the combination of a conical custom-made TREO® (TREO CM) stent graft in the treatment of a saccular abdominal aortic endograft (AAA) with long but tight and calcified distal neck.
Materials and Methods
A 65-year-female patient was treated for a saccular 5.2 cm AAA with a 3-cm long but calcified and tight (16 mm) distal neck, precluding the safe use of a bifurcated endograft. Because the patient refused an open surgery, a conical TREO CM endograft was manufactured with 20% proximal oversizing, whereas the 3-cm caudal sealing segment demonstrated a conical configuration comprising a 2-cm and 1-cm nitinol-supported zones of 20% and 10% oversizing, respectively, to avoid excessive strain and incomplete expand at the most distal calcified area, leading ultimately to an insidious infolding and consequent type Ib endoleak. A 24 × 40 mm Treovance aortic cuff was centrally deployed resulting in a 30 mm overlap with the main endograft.
Results
After 6 months, there was complete sealing, and the AAA sac has been shrunk to 45 mm.
Conclusions
The use of a conical TREO CM endograft with a proximal cuff provides a firm fixation centrally and a sufficient distal sealing design in AAAs with calcified and tight distal aorta, constituting a reliable alternative to bifurcated endografts or aortouniliac configurations followed by crossover adjuncts.}
}
@article{MASELLI20235395,
title = {Computational analysis of five neurodegenerative diseases reveals shared and specific genetic loci},
journal = {Computational and Structural Biotechnology Journal},
volume = {21},
pages = {5395-5407},
year = {2023},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2023.10.031},
url = {https://www.sciencedirect.com/science/article/pii/S2001037023003835},
author = {Francesca Maselli and Salvatore D’Antona and Mattia Utichi and Matteo Arnaudi and Isabella Castiglioni and Danilo Porro and Elena Papaleo and Paolo Gandellini and Claudia Cava},
keywords = {Neurodegenerative diseases, Bioinformatics, GWAS, SNPs},
abstract = {Neurodegenerative diseases (ND) are heterogeneous disorders of the central nervous system that share a chronic and selective process of neuronal cell death. A computational approach to investigate shared genetic and specific loci was applied to 5 different ND: Amyotrophic lateral sclerosis (ALS), Alzheimer's disease (AD), Parkinson's disease (PD), Multiple sclerosis (MS), and Lewy body dementia (LBD). The datasets were analyzed separately, and then we compared the obtained results. For this purpose, we applied a genetic correlation analysis to genome-wide association datasets and revealed different genetic correlations with several human traits and diseases. In addition, a clumping analysis was carried out to identify SNPs genetically associated with each disease. We found 27 SNPs in AD, 6 SNPs in ALS, 10 SNPs in PD, 17 SNPs in MS, and 3 SNPs in LBD. Most of them are located in non-coding regions, with the exception of 5 SNPs on which a protein structure and stability prediction was performed to verify their impact on disease. Furthermore, an analysis of the differentially expressed miRNAs of the 5 examined pathologies was performed to reveal regulatory mechanisms that could involve genes associated with selected SNPs. In conclusion, the results obtained constitute an important step toward the discovery of diagnostic biomarkers and a better understanding of the diseases.}
}
@article{MANCHES2020105859,
title = {Identifying embodied metaphors for computing education},
journal = {Computers in Human Behavior},
volume = {105},
pages = {105859},
year = {2020},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2018.12.037},
url = {https://www.sciencedirect.com/science/article/pii/S074756321830623X},
author = {Andrew Manches and Peter E. McKenna and Gnanathusharan Rajendran and Judy Robertson},
keywords = {Embodied cognition, Gesture, Metaphor, Computing education, Computational thinking, Representation},
abstract = {Computing education is increasing in global importance, with calls for greater understanding of conceptual development that can inform pedagogy. Here, we report a study investigating elementary computing concepts through the lens of Embodied Cognition. Sixteen students (9 female) studying university-level computing were asked to explain their understanding of computing concepts (without materials) in individually video-recorded sessions. We analysed the gestures generated for three elementary concepts: algorithms, loops, and conditional statements. In total, 368 representational gestures were identified across 48 (16 × 3) explanations, thereby providing evidence that offline thinking in this domain is embodied. Our analysis of representational gestures showed that participants drew upon two overarching embodied metaphors in their explanations: 1) Computing Constructs as Physical Objects, in which participants simulated manipulating physical objects (e.g., pinching) when referring to range of computing constructs, and 2) Computing Processes as Motion along a Path, whereby participants moved their hands along one of three body-based axes when referring to temporal sequences. We contrast our findings to similar research in mathematics and discuss implications for computing pedagogy – namely the role of gesture in the classroom and technologies that can exploit embodied metaphors.}
}
@article{LEVIN2019125,
title = {Planarian regeneration as a model of anatomical homeostasis: Recent progress in biophysical and computational approaches},
journal = {Seminars in Cell & Developmental Biology},
volume = {87},
pages = {125-144},
year = {2019},
note = {Planarian regeneration},
issn = {1084-9521},
doi = {https://doi.org/10.1016/j.semcdb.2018.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S1084952117301970},
author = {Michael Levin and Alexis M. Pietak and Johanna Bischof},
keywords = {Planaria, Dugesia japonica, Regeneration, Patterning, Morphostasis},
abstract = {Planarian behavior, physiology, and pattern control offer profound lessons for regenerative medicine, evolutionary biology, morphogenetic engineering, robotics, and unconventional computation. Despite recent advances in the molecular genetics of stem cell differentiation, this model organism’s remarkable anatomical homeostasis provokes us with truly fundamental puzzles about the origin of large-scale shape and its relationship to the genome. In this review article, we first highlight several deep mysteries about planarian regeneration in the context of the current paradigm in this field. We then review recent progress in understanding of the physiological control of an endogenous, bioelectric pattern memory that guides regeneration, and how modulating this memory can permanently alter the flatworm’s target morphology. Finally, we focus on computational approaches that complement reductive pathway analysis with synthetic, systems-level understanding of morphological decision-making. We analyze existing models of planarian pattern control and highlight recent successes and remaining knowledge gaps in this interdisciplinary frontier field.}
}
@article{VANDENBOS201842,
title = {Computational neuroscience across the lifespan: Promises and pitfalls},
journal = {Developmental Cognitive Neuroscience},
volume = {33},
pages = {42-53},
year = {2018},
note = {Methodological Challenges in Developmental Neuroimaging: Contemporary Approaches and Solutions},
issn = {1878-9293},
doi = {https://doi.org/10.1016/j.dcn.2017.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S1878929317301068},
author = {Wouter {van den Bos} and Rasmus Bruckner and Matthew R. Nassar and Rui Mata and Ben Eppinger},
keywords = {Computational neuroscience, Reinforcement learning, Risk-taking, Decision-making, Brain development, Identification, Strategies},
abstract = {In recent years, the application of computational modeling in studies on age-related changes in decision making and learning has gained in popularity. One advantage of computational models is that they provide access to latent variables that cannot be directly observed from behavior. In combination with experimental manipulations, these latent variables can help to test hypotheses about age-related changes in behavioral and neurobiological measures at a level of specificity that is not achievable with descriptive analysis approaches alone. This level of specificity can in turn be beneficial to establish the identity of the corresponding behavioral and neurobiological mechanisms. In this paper, we will illustrate applications of computational methods using examples of lifespan research on risk taking, strategy selection and reinforcement learning. We will elaborate on problems that can occur when computational neuroscience methods are applied to data of different age groups. Finally, we will discuss potential targets for future applications and outline general shortcomings of computational neuroscience methods for research on human lifespan development.}
}
@incollection{PHIPPEN20253,
title = {Artificial Intelligence},
editor = {David Baker and Lucy Ellis},
booktitle = {Encyclopedia of Libraries, Librarianship, and Information Science (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {3-11},
year = {2025},
isbn = {978-0-323-95690-1},
doi = {https://doi.org/10.1016/B978-0-323-95689-5.00098-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780323956895000985},
author = {Andy Phippen},
keywords = {Artificial intelligence, Computer science, Deep learning, Digital literacy, Ethics, Information science, Large language models, Machine learning, Natural language processing},
abstract = {Artificial Intelligence (AI) is attracting considerable, and justified, attention about its potential and impact on information systems. However, it is important to look at this evolution against its history. AI’s historical evolution has been beset with underperformance and ethical concerns in data training and responsible deployment. Information science has undergone significant changes with AI׳s integration, impacting information retrieval, classification, and library automation. More specifically Machine Learning plays a crucial role in understanding human requirements for information and processing large data set, but challenges like bias persist. Large Language Models (LLMs) like ChatGPT represent the vanguard of public adoption of AI driven information systems and have exhibited remarkable performance in natural language processing. While they enhance information searching and content creation, users must understand limitations, biases, and practice critical thinking for responsible utilisation in a digital age.}
}
@article{DROSATOS2014170,
title = {Privacy-preserving computation of participatory noise maps in the cloud},
journal = {Journal of Systems and Software},
volume = {92},
pages = {170-183},
year = {2014},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2014.01.035},
url = {https://www.sciencedirect.com/science/article/pii/S0164121214000430},
author = {George Drosatos and Pavlos S. Efraimidis and Ioannis N. Athanasiadis and Matthias Stevens and Ellie D’Hondt},
keywords = {Privacy-preserving computation, Cloud computing, Participatory sensing},
abstract = {This paper presents a privacy-preserving system for participatory sensing, which relies on cryptographic techniques and distributed computations in the cloud. Each individual user is represented by a personal software agent, deployed in the cloud, where it collaborates on distributed computations without loss of privacy, including with respect to the cloud service providers. We present a generic system architecture involving a cryptographic protocol based on a homomorphic encryption scheme for aggregating sensing data into maps, and demonstrate security in the Honest-But-Curious model both for the users and the cloud service providers. We validate our system in the context of NoiseTube, a participatory sensing framework for noise pollution, presenting experiments with real and artificially generated data sets, and a demo on a heterogeneous set of commercial cloud providers. To the best of our knowledge our system is the first operational privacy-preserving system for participatory sensing. While our validation pertains to the noise domain, the approach used is applicable in any crowd-sourcing application relying on location-based contributions of citizens where maps are produced by aggregating data – also beyond the domain of environmental monitoring.}
}
@article{SLOOT2012439,
title = {Young Russian researchers take up challenges in the computational sciences},
journal = {Journal of Computational Science},
volume = {3},
number = {6},
pages = {439-440},
year = {2012},
note = {Next Generation Computational Scientists: Russian Federation},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2012.08.009},
url = {https://www.sciencedirect.com/science/article/pii/S1877750312000981},
author = {Peter M.A. Sloot and Alexander V. Boukhanovsky}
}
@article{NEWHALL2025105044,
title = {An introductory-level undergraduate CS course that introduces parallel computing},
journal = {Journal of Parallel and Distributed Computing},
volume = {199},
pages = {105044},
year = {2025},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2025.105044},
url = {https://www.sciencedirect.com/science/article/pii/S0743731525000115},
author = {Tia Newhall and Kevin C. Webb and Vasanta Chaganti and Andrew Danner},
keywords = {CS curriculum, Parallel computing, Introductory CS},
abstract = {We present the curricular design, pedagogy, and goals of an introductory-level course on computer systems that introduces parallel and distributed computing (PDC) to students who have only a CS1 background. With the ubiquity of multicore processors, cloud computing, and hardware accelerators, PDC topics have become fundamental knowledge areas in the undergraduate CS curriculum. As a result, it is increasingly important for students to learn a common core of introductory parallel and distributed computing topics and to develop parallel thinking skills early in their CS studies. Our introductory-level course focuses on three main curricular goals: 1) understanding how a computer runs a program, 2) evaluating system costs associated with running a program, and 3) taking advantage of the power of parallel computing. We elaborate on the goals and details of our course's key modules, and we discuss our pedagogical approach that includes active-learning techniques. We also include an evaluation of our course and a discussion of our experiences teaching it since Fall 2012. We find that the PDC foundation gained through early exposure in our course helps students gain confidence in their ability to expand and apply their understanding of PDC concepts throughout their CS education.}
}
@article{SCHORLEMMER2021118,
title = {A uniform model of computational conceptual blending},
journal = {Cognitive Systems Research},
volume = {65},
pages = {118-137},
year = {2021},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2020.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S1389041720300759},
author = {Marco Schorlemmer and Enric Plaza},
keywords = {Conceptual blending, Computational creativity, Amalgams, Category theory, Case-based reasoning},
abstract = {We present a mathematical model for the cognitive operation of conceptual blending that aims at being uniform across different representation formalisms, while capturing the relevant structure of this operation. The model takes its inspiration from amalgams as applied in case-based reasoning, but lifts them into category theory so as to follow Joseph Goguen’s intuition for a mathematically precise characterisation of conceptual blending at a representation-independent level of abstraction. We prove that our amalgam-based category-theoretical model of conceptual blending is essentially equivalent to the pushout model in the ordered category of partial maps as put forward by Goguen. But unlike Goguen’s approach, our model is more suitable to capture computational realisations of conceptual blending, and we exemplify this by concretising our model to computational conceptual blends for various representation formalisms and application domains.}
}
@incollection{OREILLY2019317,
title = {Chapter 17 - Computational models of motivated frontal function},
editor = {Mark D'Esposito and Jordan H. Grafman},
series = {Handbook of Clinical Neurology},
publisher = {Elsevier},
volume = {163},
pages = {317-332},
year = {2019},
booktitle = {The Frontal Lobes},
issn = {0072-9752},
doi = {https://doi.org/10.1016/B978-0-12-804281-6.00017-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128042816000173},
author = {Randall C. O’Reilly and Jacob Russin and Seth A. Herd},
keywords = {Computational models, Frontal cortex, Basal ganglia, Goal-directed, Motivation, Working memory, Reinforcement learning},
abstract = {Computational models of frontal function have made important contributions to understanding how the frontal lobes support a wide range of important functions, in their interactions with other brain areas including, critically, the basal ganglia (BG). We focus here on the specific case of how different frontal areas support goal-directed, motivated decision-making, by representing three essential types of information: possible plans of action (in more dorsal and lateral frontal areas), affectively significant outcomes of those action plans (in ventral, medial frontal areas including the orbital frontal cortex), and the overall utility of a given plan compared to other possible courses of action (in anterior cingulate cortex). Computational models of goal-directed action selection at multiple different levels of analysis provide insight into the nature of learning and processing in these areas and the relative contributions of the frontal cortex versus the BG. The most common neurologic disorders implicate these areas, and understanding their precise function and modes of dysfunction can contribute to the new field of computational psychiatry, within the broader field of computational neuroscience.}
}
@article{ALEXANDROV20151685,
title = {Computational Science Research Methods for Science Education at PG Level},
journal = {Procedia Computer Science},
volume = {51},
pages = {1685-1693},
year = {2015},
note = {International Conference On Computational Science, ICCS 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.05.305},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915011138},
author = {Nia Alexandrov and Vassil Alexandrov},
keywords = {Computational Science Research Methods, Postgraduate Education, Science Subjects},
abstract = {The role of Computational Science research methods teaching to science students at PG level is to enhance their research profile developing their abilities to investigate complex problems, analyze the resulting data and use adequately HPC environments and tools for computation and visualization. The paper analyses the current state and proposes a program that encompasses mathematical modelling, data science, advanced algorithms development, parallel programming and visualization tools. It also gives examples of specific scientific domains with explicitly taught and embedded Computational Science subjects.}
}
@article{GARDNER201582,
title = {A new Canadian interdisciplinary Ph.D. in computational sciences},
journal = {Journal of Computational Science},
volume = {9},
pages = {82-87},
year = {2015},
note = {Computational Science at the Gates of Nature},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2015.04.028},
url = {https://www.sciencedirect.com/science/article/pii/S1877750315000666},
author = {William B. Gardner and Gary Grewal and Deborah Stacey and David A. Calvert and Stefan C. Kremer and Fangju Wang},
keywords = {Interdisciplinary, Computational science, Computer science, Postgraduate studies},
abstract = {In response to growing demands of society for experts trained in computational skills applied to various domains, the School of Computer Science at the University of Guelph is creating a new approach to doctoral studies called an interdisciplinary Ph.D. in computational sciences. The program is designed to appeal to candidates with strong backgrounds in either computer science or an application discipline who are not necessarily seeking a traditional academic career. Thesis based, it features minimal course requirements and short duration, with the student’s research directed by co-advisors from computer science and the application discipline. The degree program’s rationale and special characteristics are described. Related programs in Ontario and reception of this innovative proposal at the institutional level are discussed.}
}
@article{WANG20152603,
title = {Bayesian Computational Sensor Networks: Small-scale Structural Health Monitoring},
journal = {Procedia Computer Science},
volume = {51},
pages = {2603-2612},
year = {2015},
note = {International Conference On Computational Science, ICCS 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.05.368},
url = {https://www.sciencedirect.com/science/article/pii/S187705091501176X},
author = {Wenyi Wang and Anshul Joshi and Nishith Tirpankar and Philip Erickson and Michael Cline and Palani Thangaraj and Thomas C. Henderson},
keywords = {Bayesian Computational Sensor Networks, Uncertainty, Structural Health Monitoring, Cloud Computing},
abstract = {The Bayesian Computational Sensor Network methodology is applied to small-scale structural health monitoring. A mobile robot, equipped with vision and ultrasound sensors, maps small-scale structures for damage (e.g., holes, cracks) by localizing itself and the damage in the map. The combination of vision and ultrasound reduces the uncertainty in damage localization. The data storage and analysis takes place exploiting cloud computing mechanisms, and there is also an off-line computational model calibration component which returns information to the robot concerning updated on-board models as well as proposed sampling points. The approach is validated in a set of physical experiments.}
}
@incollection{WEIKUM200220,
title = {Chapter 4 - Self-tuning Database Technology and Information Services: From Wishful Thinking to Viable Engineering},
editor = {Philip A. Bernstein and Yannis E. Ioannidis and Raghu Ramakrishnan and Dimitris Papadias},
booktitle = {VLDB '02: Proceedings of the 28th International Conference on Very Large Databases},
publisher = {Morgan Kaufmann},
address = {San Francisco},
pages = {20-31},
year = {2002},
isbn = {978-1-55860-869-6},
doi = {https://doi.org/10.1016/B978-155860869-6/50011-1},
url = {https://www.sciencedirect.com/science/article/pii/B9781558608696500111},
author = {Gerhard Weikum and Axel Moenkeberg and Christof Hasse and Peter Zabback},
abstract = {Publisher Summary
The COMFORT project was started in 1990, and it was then expected that automatic tuning could be achieved with a few simple principles. While the feedback control loop framework provides useful guidance, the difficult problems are in the details of the various tuning issues. For robust solutions, workload statistics and mathematical models are key assets, and for viable engineering, these must be carefully designed to ensure acceptable overhead. The field, in general, has made significant progress towards self-tuning database technology, but there is no breakthrough. The biggest challenges that the research community should address as high-priority problems are the interactions of different system components and their tuning knobs, and the interference between different workload classes. For tackling this complexity, it is believed that a drastic simplification of today's overly complex system architectures is overdue. If one is able to build individually self-tuning components, the composition of these building blocks into higher-level e-services with service-quality guarantees seems feasible only with sufficiently simple component interfaces and radical minimization of cross talk.}
}

@article{EKINS2014115,
title = {Progress in computational toxicology},
journal = {Journal of Pharmacological and Toxicological Methods},
volume = {69},
number = {2},
pages = {115-140},
year = {2014},
issn = {1056-8719},
doi = {https://doi.org/10.1016/j.vascn.2013.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S1056871913003250},
author = {Sean Ekins},
keywords = {Bayesian, Computational toxicology, Machine learning, Support Vector Machine},
abstract = {Introduction: Computational methods have been widely applied to toxicology across pharmaceutical, consumer product and environmental fields over the past decade. Progress in computational toxicology is now reviewed. Methods: A literature review was performed on computational models for hepatotoxicity (e.g. for drug-induced liver injury (DILI)), cardiotoxicity, renal toxicity and genotoxicity. In addition various publications have been highlighted that use machine learning methods. Several computational toxicology model datasets from past publications were used to compare Bayesian and Support Vector Machine (SVM) learning methods. Results: The increasing amounts of data for defined toxicology endpoints have enabled machine learning models that have been increasingly used for predictions. It is shown that across many different models Bayesian and SVM perform similarly based on cross validation data. Discussion: Considerable progress has been made in computational toxicology in a decade in both model development and availability of larger scale or ‘big data’ models. The future efforts in toxicology data generation will likely provide us with hundreds of thousands of compounds that are readily accessible for machine learning models. These models will cover relevant chemistry space for pharmaceutical, consumer product and environmental applications.}
}
@incollection{JUDD2006881,
title = {Chapter 17 Computationally Intensive Analyses in Economics},
editor = {L. Tesfatsion and K.L. Judd},
series = {Handbook of Computational Economics},
publisher = {Elsevier},
volume = {2},
pages = {881-893},
year = {2006},
issn = {1574-0021},
doi = {https://doi.org/10.1016/S1574-0021(05)02017-4},
url = {https://www.sciencedirect.com/science/article/pii/S1574002105020174},
author = {Kenneth L. Judd},
keywords = {computational economics, economic methodology},
abstract = {Computer technology presents economists with new tools, but also raises novel methodological issues. This essay discusses the challenges faced by computational researchers, and proposes some solutions.}
}
@article{SAHA2021113452,
title = {Hierarchical Deep Learning Neural Network (HiDeNN): An artificial intelligence (AI) framework for computational science and engineering},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {373},
pages = {113452},
year = {2021},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2020.113452},
url = {https://www.sciencedirect.com/science/article/pii/S004578252030637X},
author = {Sourav Saha and Zhengtao Gan and Lin Cheng and Jiaying Gao and Orion L. Kafka and Xiaoyu Xie and Hengyang Li and Mahsa Tajdari and H. Alicia Kim and Wing Kam Liu},
keywords = {Deep learning, Machine learning, Reduced order model, Data-driven discovery, Multiscale simulation, Artificial intelligence},
abstract = {In this work, a unified AI-framework named Hierarchical Deep Learning Neural Network (HiDeNN) is proposed to solve challenging computational science and engineering problems with little or no available physics as well as with extreme computational demand. The detailed construction and mathematical elements of HiDeNN are introduced and discussed to show the flexibility of the framework for diverse problems from disparate fields. Three example problems are solved to demonstrate the accuracy, efficiency, and versatility of the framework. The first example is designed to show that HiDeNN is capable of achieving better accuracy than conventional finite element method by learning the optimal nodal positions and capturing the stress concentration with a coarse mesh. The second example applies HiDeNN for multiscale analysis with sub-neural networks at each material point of macroscale. The final example demonstrates how HiDeNN can discover governing dimensionless parameters from experimental data so that a reduced set of input can be used to increase the learning efficiency. We further present a discussion and demonstration of the solution for advanced engineering problems that require state-of-the-art AI approaches and how a general and flexible system, such as HiDeNN-AI framework, can be applied to solve these problems.}
}
@article{MCCLELLAND20221047,
title = {Capturing advanced human cognitive abilities with deep neural networks},
journal = {Trends in Cognitive Sciences},
volume = {26},
number = {12},
pages = {1047-1050},
year = {2022},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2022.09.018},
url = {https://www.sciencedirect.com/science/article/pii/S136466132200239X},
author = {James L. McClelland},
keywords = {scientific reasoning, mathematical cognition, neural networks, goal-directed thinking, artificial intelligence},
abstract = {How can artificial neural networks capture the advanced cognitive abilities of pioneering scientists? I suggest they must learn to exploit human-invented tools of thought and human-like ways of using them, and must engage in explicit goal-directed problem solving as exemplified in the activities of scientists and mathematicians and taught in advanced educational settings.}
}
@article{DEMARTINO20131222,
title = {In the Mind of the Market: Theory of Mind Biases Value Computation during Financial Bubbles},
journal = {Neuron},
volume = {79},
number = {6},
pages = {1222-1231},
year = {2013},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2013.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S0896627313005680},
author = {Benedetto De Martino and John P. O’Doherty and Debajyoti Ray and Peter Bossaerts and Colin Camerer},
abstract = {Summary
The ability to infer intentions of other agents, called theory of mind (ToM), confers strong advantages for individuals in social situations. Here, we show that ToM can also be maladaptive when people interact with complex modern institutions like financial markets. We tested participants who were investing in an experimental bubble market, a situation in which the price of an asset is much higher than its underlying fundamental value. We describe a mechanism by which social signals computed in the dorsomedial prefrontal cortex affect value computations in ventromedial prefrontal cortex, thereby increasing an individual’s propensity to ‘ride’ financial bubbles and lose money. These regions compute a financial metric that signals variations in order flow intensity, prompting inference about other traders’ intentions. Our results suggest that incorporating inferences about the intentions of others when making value judgments in a complex financial market could lead to the formation of market bubbles.}
}
@article{HENDRIARTO20241225,
title = {The development of mobile application for the deaf to learn better},
journal = {Procedia Computer Science},
volume = {245},
pages = {1225-1237},
year = {2024},
note = {9th International Conference on Computer Science and Computational Intelligence 2024 (ICCSCI 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.352},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924031600},
author = {Helena Angelie Margaretha Hendriarto and Yudhistya Ayu Kusumawati and Rudi Yulio Arindiono},
keywords = {Deaf, Education, Learning features, Mobile application},
abstract = {Education is very important for all individuals, including people with disabilities such as the deaf, to advance the nation and survive. In this case, effective communication of educational material is important to create a conducive learning environment. Most people also believe that deaf people can make a big contribution to society if they receive the right education, and this becomes a challenge for deaf teachers and students. Therefore, this paper aims to find a solution that can become a means of independent education for deaf people. This paper is using design thinking method to achieve the goal. The result of this research is the development of an educational mobile application specifically for the deaf, namely 'V-Voice'. This application provides various learning features, such as; animated videos, education games and texts that are attractively designed. Through 'V-Voice', it is hoped that deaf people can study harder independently and be helped to manage information and develop their soft skills and hard skills.}
}
@article{THIRUNAVUKARASU2022106020,
title = {Towards computational solutions for precision medicine based big data healthcare system using deep learning models: A review},
journal = {Computers in Biology and Medicine},
volume = {149},
pages = {106020},
year = {2022},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2022.106020},
url = {https://www.sciencedirect.com/science/article/pii/S0010482522007429},
author = {Ramkumar Thirunavukarasu and George Priya Doss C and Gnanasambandan R and Mohanraj Gopikrishnan and Venketesh Palanisamy},
keywords = {Personalized medicine, Precision medicine, Artificial intelligence, Deep learning, Healthcare big data},
abstract = {The emergence of large-scale human genome projects, advances in DNA sequencing technologies, and the massive volume of electronic medical records [EMR] shift the transformation of healthcare research into the next paradigm, namely ‘Precision Medicine.’ This new clinical system model uses patients' genomic profiles and disparate healthcare data sources to a greater extent and provides personalized deliverables. As an advanced analytical technique, deep learning models significantly impact precision medicine because they can process voluminous amounts of diversified data with improved accuracy. Two salient features of deep learning models, namely processing a massive volume of multi-model data at multiple levels of abstraction and the ability to identify inherent features from the input data on their own, attract the implication of deep learning techniques in precision medicine research. The proposed review highlights the importance of deep learning-based analytical models in handling diversified and disparate big data sources of precision medicine. To augment further, state-of-the-art precision medicine research based on the taxonomy of deep learning models has been reviewed along with their research outcomes. The diversified data inputs used in research attempts, their applications, benchmarking data repositories, and usage of various evaluation measures for accuracy estimations are highlighted in this review. This review also brings out some promising analytical avenues of precision medicine research that give directions for future exploration.}
}
@article{LAWNICZAK20102227,
title = {Computational intelligence based architecture for cognitive agents},
journal = {Procedia Computer Science},
volume = {1},
number = {1},
pages = {2227-2235},
year = {2010},
note = {ICCS 2010},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2010.04.249},
url = {https://www.sciencedirect.com/science/article/pii/S1877050910002504},
author = {Anna T. Lawniczak and Bruno N. {Di Stefano}},
keywords = {Agent, Agent modeling, Cognitive agent, Computational intelligence},
abstract = {We discuss some limitations of reflexive agents to motivate the need to develop cognitive agents and propose a hierarchical, layered, architecture for cognitive agents. Our examples often involve the discussion of cognitive agents in highway traffic models. A cognitive agent is an agent capable of performing cognitive acts, i.e. a sequence of the following activities: “Perceiving” information in the environment and provided by other agents, “Reasoning” about this information using existing knowledge, “Judging” the obtained information using existing knowledge, “Responding” to other cognitive agents or to the external environment, as it may be required, and “Learning”, i.e. changing (and, hopefully augmenting) the existing knowledge if the newly acquired information allows it. We describe how computational intelligence techniques (e.g., fuzzy logic, neural networks, genetic algorithms, etc) allow mimicking to a certain extent the cognitive acts performed by human beings. The order with which the cognitive actions take place is important and so is the order with which the various computational intelligence techniques are applied. We believe that a hierarchical layered model should be defined for the generic cognitive agents in a style akin to the hierarchical OSI 7 layer model used in data communication. We outline in broad sense such a reference model.}
}
@article{REN201310351,
title = {Challenges in the assignment of relative and absolute configurations of complex molecules: computation can resolve conflicts between theory and experiment},
journal = {Tetrahedron},
volume = {69},
number = {48},
pages = {10351-10356},
year = {2013},
issn = {0040-4020},
doi = {https://doi.org/10.1016/j.tet.2013.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S004040201301538X},
author = {Jie Ren and Guo-You Li and Lan Shen and Guo-Lin Zhang and Laurance A. Nafie and Hua-Jie Zhu},
keywords = {Absolute configuration reassignment, DFT, Chiroptical spectroscopy, Transition state, X-ray},
abstract = {The configuration of (−)-brevianamides was assigned as (2S,13S) based on X-ray structure analysis and hydrolysis experiments. However, our theoretical investigation of its chiroptical properties strongly implied that the correct configuration should be (2R,13R). The reasons for the incorrect earlier assignment are analyzed by calculations of conversion energy barriers among different intermediates, starting materials and final products. This study demonstrates that conflicting theoretical and, experimental results suggest that it is premature to assign the configuration of a natural product.}
}
@incollection{WARD201140,
title = {Analogies},
editor = {Mark A. Runco and Steven R. Pritzker},
booktitle = {Encyclopedia of Creativity (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {San Diego},
pages = {40-45},
year = {2011},
isbn = {978-0-12-375038-9},
doi = {https://doi.org/10.1016/B978-0-12-375038-9.00009-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780123750389000091},
author = {T.B. Ward},
keywords = {ACME, Analogy, Case study, Computational modeling,  study, Laboratory study, Mapping, Multiconstraint theory, One-to-one correspondence, Parallel connectivity, Retrieval, SME, Source domain, Structure-mapping theory, Systematicity, Target domain},
abstract = {Analogical thinking is a fundamental cognitive process underlying creativity. Analogies map structured knowledge from one domain to another and serve as information for understanding, explaining and creating. Analogy is studied through case study, laboratory, in vivo and computational modeling approaches. The use of analogy is often suggested to be a helpful technique in applied approaches to creativity.}
}
@article{PSYCHARIS2011547,
title = {The computational experiment and its effects on approach to learning and beliefs on physics},
journal = {Computers & Education},
volume = {56},
number = {3},
pages = {547-555},
year = {2011},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2010.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S0360131510002642},
author = {Sarantos Psycharis},
keywords = {ICT, Programming, Interactive learning environments, Physics learning, Computational experiment},
abstract = {Contemporary instructional approaches expect students to be active producers of knowledge. This leads to the need for creation of instructional tools and tasks that can offer students opportunities for active learning. This study examines the effect of a computational experiment as an instructional tool-for Grade 12 students, using a computer simulation environment created in Java for the domain of “linear oscillations without damping”. In this study we use the computational experiment as an integration of the computational science with the discovery learning method. The computational experiment supports both types of research, the exploratory as well as the inventive research, helping the learners to develop not only exploratory but also expressive models. The aim of the paper is threefold. At first we want to examine the influence of the computational experiment on students’ learning performance. The other two aims are related to the investigation of the experiment’s influence on students’ approach to learning and their beliefs on physics. Our results indicate that there is a strong shift on students’ conceptual understanding and to the consideration of the coherence of physics, as well as to the realization that physics is strongly connected to mathematics. Finally students realized that mathematics, physics and information theory are strongly connected cognitive disciplines.}
}
@incollection{MOORE2013200,
title = {Gene Interaction},
editor = {Stanley Maloy and Kelly Hughes},
booktitle = {Brenner's Encyclopedia of Genetics (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {San Diego},
pages = {200-201},
year = {2013},
isbn = {978-0-08-096156-9},
doi = {https://doi.org/10.1016/B978-0-12-374984-0.00592-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780123749840005921},
author = {J.H. Moore},
keywords = {Epistasis, Synergy, Systems genetics},
abstract = {Gene interaction is a broad term used to describe the joint role of multiple genes in determining phenotypic variability. It is often studied from the molecular point of view as biomolecular interactions or from a more genetic point of view as phenotypic effects due to the role of DNA sequence variations and their influence on biological processes. We are now moving from an era of thinking about interactions among several genes to interacting networks or systems of many genes in a genome-wide scale. The study of gene interactions using systems genetics approaches is being made possible by advances in DNA sequencing technology and more powerful experimental, statistical, and computational methods.}
}
@article{XU2011331,
title = {New Recursive Construction of Magic Squares Using Kronecker Compositional Operations and Its Application in Engineering Computation},
journal = {Systems Engineering Procedia},
volume = {2},
pages = {331-337},
year = {2011},
note = {Complexity System and Engineering Management},
issn = {2211-3819},
doi = {https://doi.org/10.1016/j.sepro.2011.10.046},
url = {https://www.sciencedirect.com/science/article/pii/S2211381911001354},
author = {Dandan Xu and Zisen Mao and Bei Chen and Ping Huang},
keywords = {Magic squares, symmetrical, pandiagonal, construction, engineering computation},
abstract = {Owing to the depth research on the remarkable properties of magic squares, a new recursive method for constructing high order magic squares will be firstly presented, based on the matrix operations, we refer to as the Kronecker compositional operations. Furthermore, popularizing this method,, we successfully demonstrate that large size magic squares of odd order with symmetrical and pandiagonal features can be generated by lower order initiators,which leads to the impressive application in engineering computation. Finally, we enumerate two small symmetrical and pandiagonal magic squares.}
}
@article{MOHAMMADIZIABARI2018376,
title = {Computational Analysis of Gender Differences in Coping with Extreme Stressful Emotions},
journal = {Procedia Computer Science},
volume = {145},
pages = {376-385},
year = {2018},
note = {Postproceedings of the 9th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2018 (Ninth Annual Meeting of the BICA Society), held August 22-24, 2018 in Prague, Czech Republic},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.11.088},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918323767},
author = {S. Sahand {Mohammadi Ziabari} and Jan Treur},
keywords = {Adaptive Network, Rumination, Extreme Emotion, Gender},
abstract = {In this paper a computational analysis is presented of differences between men and women in coping with extreme emotions. This analysis is based on an adaptive temporal-causal network model. It takes into account the suppression of connections between preparation states and sensory representations of action effects due to an extreme stressful emotion. It is shown how this model can be used to represent the difference between males and females facing an extreme emotion, thereby performing their own methods in coping with the extreme emotion, for males fight or flight and for females tend-and-befriend.}
}
@article{DAYAN2011661,
title = {Networks, circuits and computation},
journal = {Current Opinion in Neurobiology},
volume = {21},
number = {5},
pages = {661-663},
year = {2011},
note = {Networks, circuits and computation},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2011.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S0959438811001267},
author = {Peter Dayan and Marla Feller and Dan Feldman}
}
@article{WESTERA201732,
title = {How people learn while playing serious games: A computational modelling approach},
journal = {Journal of Computational Science},
volume = {18},
pages = {32-45},
year = {2017},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2016.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S1877750316304483},
author = {Wim Westera},
keywords = {Serious gaming, Learning, Simulation, Modelling, Flow theory, Methodology},
abstract = {This paper proposes a computational modelling approach for investigating the interplay of learning and playing in serious games. A formal model is introduced that allows for studying the details of playing a serious game under diverse conditions. The dynamics of player action and motivation is based on cognitive flow theory, which is expressed in quantitative terms for this purpose. Seven extensive simulation studies involving over 100,000 iterations have demonstrated the stability of the model and its potential as a research instrument for serious gaming. The model allows researchers to deeply investigate quantitative dependences between relevant game variables, gain deeper understanding of how people learn from games, and develop approaches to improving serious game design.}
}
@article{TANG2024103266,
title = {A causal counterfactual graph neural network for arising-from-chair abnormality detection in parkinsonians},
journal = {Medical Image Analysis},
volume = {97},
pages = {103266},
year = {2024},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2024.103266},
url = {https://www.sciencedirect.com/science/article/pii/S1361841524001919},
author = {Xinlu Tang and Rui Guo and Chencheng Zhang and Xiaohua Qian},
keywords = {Parkinson's disease, Arising-from-chair, Graph neural network, Causal inference, Counterfactual thinking},
abstract = {The arising-from-chair task assessment is a key aspect of the evaluation of movement disorders in Parkinson's disease (PD). However, common scale-based clinical assessment methods are highly subjective and dependent on the neurologist's expertise. Alternate automated methods for arising-from-chair assessment can be established based on quantitative susceptibility mapping (QSM) images with multiple-instance learning. However, performance stability for such methods can be typically undermined by the presence of irrelevant or spuriously-relevant features that mask the intrinsic causal features. Therefore, we propose a QSM-based arising-from-chair assessment method using a causal graph-neural-network framework, where counterfactual and debiasing strategies are developed and integrated into this framework for capturing causal features. Specifically, the counterfactual strategy is proposed to suppress irrelevant features caused by background noise, by producing incorrect predictions when dropping causal parts. The debiasing strategy is proposed to suppress spuriously relevant features caused by the sampling bias and it comprises a resampling guidance scheme for selecting stable instances and a causal invariance constraint for improving stability under various interferences. The results of extensive experiments demonstrated the superiority of the proposed method in detecting arising-from-chair abnormalities. Its clinical feasibility was further confirmed by the coincidence between the selected causal features and those reported in earlier medical studies. Additionally, the proposed method was extensible for another motion task of leg agility. Overall, this study provides a potential tool for automated arising-from-chair assessment in PD patients, and also introduces causal counterfactual thinking in medical image analysis. Our source code is publicly available at https://github.com/SJTUBME-QianLab/CFGNN-PDarising.}
}
@incollection{CARETTE202215,
title = {Chapter Two - Embracing the laws of physics: Three reversible models of computation},
editor = {Ali R. Hurson},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {126},
pages = {15-63},
year = {2022},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2021.11.009},
url = {https://www.sciencedirect.com/science/article/pii/S0065245821000838},
author = {Jacques Carette and Roshan P. James and Amr Sabry},
keywords = {Reversible programming, Reversible Boolean circuits, Monoidal categories, Type isomorphisms, Commutative semirings, Homotopy-type theory, Quantum circuits, Permutations},
abstract = {Our main models of computation (the Turing Machine and the RAM) and most modern computer architectures make fundamental assumptions about which primitive operations are realizable on a physical computing device. The consensus is that these primitive operations include logical operations like conjunction, disjunction and negation, as well as reading and writing to a large collection of memory locations. This perspective conforms to a macro-level view of physics and indeed these operations are realizable using macro-level devices involving thousands of electrons. This point of view is however incompatible with computation realized using quantum devices or analyzed using elementary thermodynamics as both these fundamental physical theories imply that information is a conserved quantity of physical processes and hence of primitive computational operations. Our aim is to redevelop foundational computational models in a way that embraces the principle of conservation of information. We first define what information is and what its conservation means in a computational setting. We emphasize the idea that computations must be reversible transformations on data. One can think of data as modeled using topological spaces and programs as modeled by reversible deformations of these spaces. We then illustrate this idea using three notions of data and their associated reversible computational models. The first instance only assumes unstructured finite data, i.e., discrete topological spaces. The corresponding notion of reversible computation is that of permutations. We show how this simple model subsumes conventional computations on finite sets. We then consider a modern structured notion of data based on the Curry–Howard correspondence between logic and type theory. We develop the corresponding notion of reversible deformations using a sound and complete programming language for witnessing type isomorphisms and proof terms for commutative semirings. We then “move up a level” to examine spaces that treat programs as data, which is a crucial notion for any universal model of computation. To derive the corresponding notion of reversible programs between programs, i.e., reversible program equivalences, we look at the “higher dimensional” analog to commutative semirings: symmetric rig groupoids. The coherence laws for these groupoids turn out to be exactly the sound and complete reversible program equivalences we seek. We conclude with some possible generalizations inspired by homotopy type theory and survey several open directions for further research.}
}
@article{CARUSI20171,
title = {Validation and models in computational biomedical sciences: Philosophy, science, engineering},
journal = {Progress in Biophysics and Molecular Biology},
volume = {129},
pages = {1-2},
year = {2017},
note = {Validation of Computer Modelling},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2017.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S007961071730192X},
author = {Annamaria Carusi and Blanca Rodriguez and Kevin Burrage}
}
@article{OZKAYA2006381,
title = {Requirement-driven design: assistance for information traceability in design computing},
journal = {Design Studies},
volume = {27},
number = {3},
pages = {381-398},
year = {2006},
note = {Digital Design},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2005.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X0500089X},
author = {Ipek Ozkaya and Ömer Akin},
keywords = {requirement-driven design, information processing, design knowledge, design process, design methods},
abstract = {We describe requirement-driven computational design thinking as an approach to leverage the distinctive characteristics of the digital design process. We primarily focus on information continuity and traceability in the digital medium. Requirement-driven design is an information-based approach facilitating consistent design rationale tracking and evaluation, verification, and validation of design. We present the characteristics of requirement-driven design, which leverage the pervasive nature of digital design thinking. We demonstrate a requirement–design coupling approach, modeling a continuous and interactive design process for integrating problem formulation and form exploration.}
}
@article{ZHU2006287,
title = {Children can solve Bayesian problems: the role of representation in mental computation},
journal = {Cognition},
volume = {98},
number = {3},
pages = {287-308},
year = {2006},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2004.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S0010027705000132},
author = {Liqi Zhu and Gerd Gigerenzer},
keywords = {Bayesian problems, Computation, Binary hypothesis},
abstract = {Can children reason the Bayesian way? We argue that the answer to this question depends on how numbers are represented, because a representation can do part of the computation. We test, for the first time, whether Bayesian reasoning can be elicited in children by means of natural frequencies. We show that when information was presented to fourth, fifth, and sixth graders in terms of probabilities, their ability to estimate the Bayesian posterior probability was zero. Yet when the same information was presented in natural frequencies, Bayesian reasoning showed a steady increase from fourth to sixth grade, reaching an average level of 19, 39, and 53%, respectively, in two studies. Sixth graders' performance with natural frequencies matched the performance of adults with probabilities. But this general increase was accompanied by striking individual differences. More than half of the sixth graders solved most or all problems, whereas one third could not solve a single one. An analysis of the children's responses provides evidence for the use of three non-Bayesian strategies. These follow an overlapping wave model of development and continue to be observed in the minds of adults. More so than adults' probabilistic reasoning, children's reasoning depends on a proper representation of information.}
}
@incollection{DAVIS2017xv,
title = {Survival of the Fittest Computational Chemists, Computers, and Reference Works (Over a 30-Year Period)},
editor = {Samuel Chackalamannil and David Rotella and Simon E. Ward},
booktitle = {Comprehensive Medicinal Chemistry III},
publisher = {Elsevier},
address = {Oxford},
pages = {xv-xxii},
year = {2017},
isbn = {978-0-12-803201-5},
doi = {https://doi.org/10.1016/B978-0-12-409547-2.12337-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780124095472123376},
author = {A.M. Davis and C.M. Edge}
}
@article{GAAR202167,
title = {Towards a computational proof of Vizing's conjecture using semidefinite programming and sums-of-squares},
journal = {Journal of Symbolic Computation},
volume = {107},
pages = {67-105},
year = {2021},
issn = {0747-7171},
doi = {https://doi.org/10.1016/j.jsc.2021.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S0747717121000092},
author = {Elisabeth Gaar and Daniel Krenn and Susan Margulies and Angelika Wiegele},
keywords = {Vizing's conjecture, Algebraic model, Gröbner basis, Sum-of-squares problems, Semidefinite programming},
abstract = {Vizing's conjecture (open since 1968) relates the product of the domination numbers of two graphs to the domination number of their Cartesian product graph. In this paper, we formulate Vizing's conjecture as a Positivstellensatz existence question. In particular, we select classes of graphs according to their number of vertices and their domination number and encode the conjecture as an ideal/polynomial pair such that the polynomial is non-negative on the variety associated with the ideal if and only if the conjecture is true for this graph class. Using semidefinite programming we obtain numeric sum-of-squares certificates, which we then manage to transform into symbolic certificates confirming non-negativity of our polynomials. Specifically, we obtain exact low-degree sparse sum-of-squares certificates for particular classes of graphs. The obtained certificates allow generalizations for larger graph classes. Besides computational verification of these more general certificates, we also present theoretical proofs as well as conjectures and questions for further investigations.}
}
@article{COOPER201442,
title = {Implementations are not specifications: Specification, replication and experimentation in computational cognitive modeling},
journal = {Cognitive Systems Research},
volume = {27},
pages = {42-49},
year = {2014},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2013.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S1389041713000314},
author = {Richard P. Cooper and Olivia Guest},
keywords = {Theory specification, Implementation detail, Replication, Sensitivity analysis, Computational experimentation},
abstract = {Contemporary methods of computational cognitive modeling have recently been criticized by Addyman and French (2012) on the grounds that they have not kept up with developments in computer technology and human–computer interaction. They present a manifesto for change according to which, it is argued, modelers should devote more effort to making their models accessible, both to non-modelers (with an appropriate easy-to-use user interface) and modelers alike. We agree that models, like data, should be freely available according to the normal standards of science, but caution against confusing implementations with specifications. Models may embody theories, but they generally also include implementation assumptions. Cognitive modeling methodology needs to be sensitive to this. We argue that specification, replication and experimentation are methodological approaches that can address this issue.}
}
@article{DHAYAKA20241238,
title = {BeKarsa: A strategic approach to alleviate unemployment challenges in Malang City},
journal = {Procedia Computer Science},
volume = {245},
pages = {1238-1248},
year = {2024},
note = {9th International Conference on Computer Science and Computational Intelligence 2024 (ICCSCI 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.353},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924031612},
author = {Pricillia Yohana Dhayaka and Yudhistya Ayu Kusumawati and Rudi Yulio Arindiono},
keywords = {Unemployment, Malang city, Work},
abstract = {Creating decent work and economic growth is not an easy thing. Decent work and economic growth aim to create a decent work environment and financial stability. Malang City, known as the City of Education, has a relatively high unemployment rate, although it has decreased since it spiked during the COVID-19 pandemic. This figure is also still higher than the unemployment rate in East Java. One of the problems contributing to this unemployment rate is the ineffective dissemination of skills training and job vacancies, so this needs to be improved. To overcome this problem and find the most effective solution to reduce the unemployment rate in Malang City, this research is being conducted. The purpose of this research is to determine the most effective solution to the problem using the design thinking method to help decrease the high unemployment rates. To assist the audience in obtaining information related to certified training and job vacancies, the researcher aims to design a platform in the form of a website so that the audience can access information effectively. The semantical differential method is also used in this research to assess the audience's impression of the solution and determine whether the solution is acceptable to the target audience and can help with the problem of information dissemination. This solution is expected to help people obtain information related to certified training and job openings. In addition, this research will improve certified training information services in Malang City to be more effective and easily accessible to the public.}
}
@incollection{SEDERBERG2010145,
title = {Learning and Memory: Computational Models},
editor = {George F. Koob and Michel Le Moal and Richard F. Thompson},
booktitle = {Encyclopedia of Behavioral Neuroscience},
publisher = {Academic Press},
address = {Oxford},
pages = {145-153},
year = {2010},
isbn = {978-0-08-045396-5},
doi = {https://doi.org/10.1016/B978-0-08-045396-5.00140-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780080453965001408},
author = {P.B. Sederberg and K.A. Norman},
keywords = {Computational models, Context, Cortex, Episodic memory, Hippocampus, Learning, Memory, Neural networks, Recognition, Recall, Semantic memory, Synaptic plasticity},
abstract = {The goal of learning and memory research is to understand how we store and retrieve information based on our experiences. Computational models provide formal implementations of memory theories that attempt to predict both behavior and neural data. This article describes computational models of declarative memory, including episodic memory (memory for specific events) and semantic memory (memory for meanings), with a particular focus on the role of context in supporting both types of memory.}
}
@article{JUNG201787,
title = {Computational Collective Intelligence with Big Data: Challenges and Opportunities},
journal = {Future Generation Computer Systems},
volume = {66},
pages = {87-88},
year = {2017},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2016.08.021},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X16302837},
author = {Jason J. Jung},
keywords = {Computational collective intelligence, Computer-supported collaboration, Big data},
abstract = {Collective intelligence has been an important research topic in many AI communities. With The big data phenomenon, we have been facing on many research problems on how to integrate the big data with collective intelligence. This special issue has selected 9 high quality papers covering various research issues.}
}
@article{VALENTINOV2015491,
title = {Nonprofit organizations, institutional economics, and systems thinking},
journal = {Economic Systems},
volume = {39},
number = {3},
pages = {491-501},
year = {2015},
note = {Symposium: Financial System and Development in China},
issn = {0939-3625},
doi = {https://doi.org/10.1016/j.ecosys.2014.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0939362515000278},
author = {Vladislav Valentinov and Stefan Hielscher and Ingo Pies},
keywords = {Nonprofit organizations, John Kenneth Galbraith, Countervailing power, Niklas Luhmann},
abstract = {The present paper applies the logic of John Kenneth Gailbraith's institutional economics analysis of corporate power to inquiring into the societal role of the nonprofit sector. Building on Galbraith's insight that corporations cause subtle but pervasive societal imbalances, the paper locates the role of nonprofit organizations in compensating for these imbalances, thus showing corporations and nonprofit organizations to be mutually complementary rather than antagonistic actors. This argument is supported by Niklas Luhmann's vision of the precarious relationship between the complexity and sustainability of social systems as well as by Kenneth Boulding's analysis of the farmer and labor movement. Luhmann's and Boulding's perspectives show profit-seeking corporations to be social systems developing high technological complexity at the cost of sacrificing their societal sustainability, while the improvement of the latter constitutes the rationale of many nonprofit organizations. The same systems-theoretic logic suggests, however, that nonprofit organizations may tend to underestimate the technological complexity of implementing their mission-related activities, thereby undermining their own effectiveness.}
}
@article{DESTEXHE2011717,
title = {Intracellular and computational evidence for a dominant role of internal network activity in cortical computations},
journal = {Current Opinion in Neurobiology},
volume = {21},
number = {5},
pages = {717-725},
year = {2011},
note = {Networks, circuits and computation},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2011.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0959438811001012},
author = {Alain Destexhe},
abstract = {The mammalian cerebral cortex is characterized by intense spontaneous activity, depending on brain region, age, and behavioral state. Classically, the cortex is considered as being driven by the senses, a paradigm which corresponds well to experiments in quiescent or deeply anesthetized states. In awake animals, however, the spontaneous activity cannot be considered as ‘background noise’, but is of comparable—or even higher—amplitude than evoked sensory responses. Recent evidence suggests that this internal activity is not only dominant, but also it shares many properties with the responses to natural sensory inputs, suggesting that the spontaneous activity is not independent of the sensory input. Such evidence is reviewed here, with an emphasis on intracellular and computational aspects. Statistical measures, such as the spike-triggered average of synaptic conductances, show that the impact of internal network state on spiking activity is major in awake animals. Thus, cortical activity cannot be considered as being driven by the senses, but sensory inputs rather seem to modulate and modify the internal dynamics of cerebral cortex. This view offers an attractive interpretation not only of dreaming activity (absence of sensory input), but also of several mental disorders.}
}
@incollection{ALEKSANDER200777,
title = {Computational studies of consciousness},
editor = {Rahul Banerjee and Bikas K. Chakrabarti},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {168},
pages = {77-93},
year = {2007},
booktitle = {Models of Brain and Mind},
issn = {0079-6123},
doi = {https://doi.org/10.1016/S0079-6123(07)68007-8},
url = {https://www.sciencedirect.com/science/article/pii/S0079612307680078},
author = {Igor Aleksander and Helen Morton},
keywords = {brain modelling, consciousness, neural architectures},
abstract = {In this chapter we present a computational architecture intended to add clarity to the concept of consciousness. We briefly review some of the motivations of work done in this area in various institutes around the world and looks closely at our own work which specifically includes phenomenology, the sense of a self in a perceptual world. This breaks consciousness into five axioms: presence, imagination, attention, volition and emotions. It develops plausible mechanisms of each and how they interact to give a single sensation. An abstract architecture, the kernel architecture, is introduced as a starting point for building computational models. It is shown that through this architecture it is possible to discuss puzzling aspects of consciousness, for example are animals conscious? What happens when we dream? What goes on when we experience an illusion? This paper is intended to elucidate and update some concepts introduced in Aleksander (2005).}
}
@article{MARSIK2021108,
title = {Introducing ⦇ λ ⦈, a λ-calculus for effectful computation},
journal = {Theoretical Computer Science},
volume = {869},
pages = {108-155},
year = {2021},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2021.02.038},
url = {https://www.sciencedirect.com/science/article/pii/S0304397521001225},
author = {Jirka Maršík and Maxime Amblard and Philippe {de Groote}},
keywords = {Side effects, Monads, -calculus, Handlers, CRS, IDTS},
abstract = {We present ⦇λ⦈, a calculus with special constructions for dealing with effects and handlers. This is an extension of the simply-typed λ-calculus (STLC). We enrich STLC with a type for representing effectful computations alongside with operations to create and process values of this type. The calculus is motivated by natural language modelling, and especially semantic representation. Traditionally, the meaning of a sentence is calculated using λ-terms, but some semantic phenomena need more flexibility. In this article we introduce the calculus and show that the calculus respects the laws of algebraic structures and it enjoys strong normalisation. To do so, confluence is proven using the Combinatory Reduction Systems (CRSs) of Klop and termination using the Inductive Data Type Systems (IDTSs) of Blanqui.}
}
@article{WHALLEY2001743,
title = {Reliability and uncertainty in flow measurement techniques - some current thinking},
journal = {Physics and Chemistry of the Earth, Part C: Solar, Terrestrial & Planetary Science},
volume = {26},
number = {10},
pages = {743-749},
year = {2001},
issn = {1464-1917},
doi = {https://doi.org/10.1016/S1464-1917(01)95019-6},
url = {https://www.sciencedirect.com/science/article/pii/S1464191701950196},
author = {N. Whalley and R.S. Iredale and A.F. Clare},
keywords = {flow measurement, current meter gauging, flow measurement structures, calibration, stage-discharge relationship},
abstract = {Improvements in the quality and availability of flow measurement equipment are undoubtedly capable of enhancing the reliability and accuracy of the hydrometric data that we require. However much of the UK's hydrometric data is acquired by the tried and trusted methods that have remained the mainstay of flow monitoring for many years. Should the results provided by these established techniques always be so readily accepted given the range of assumptions on which they are based? Current meter gauging is the principle technique used for the establishment of stage discharge relationships in the UK. Either directly for the establishment of stage-discharge relationships in open channels, indirectly for calibration of flow measurement equipment (e.g. ultrasonic Doppler velocity meters) or as a means of verification of existing flow measurement structures. Recent projects involving current meter gauging techniques have provoked much thought as to the validity of established techniques and in particular the assumptions on which they are based. The chosen case studies highlight a number of projects where there have been questions regarding the reliability and uncertainty of the flow measurement techniques employed. The alternative approaches required to deal with such problems are also discussed.}
}
@article{ALISHA20241202,
title = {Interactive role-playing game for elementary students to introducing Javan Langur},
journal = {Procedia Computer Science},
volume = {245},
pages = {1202-1212},
year = {2024},
note = {9th International Conference on Computer Science and Computational Intelligence 2024 (ICCSCI 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.350},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924031582},
author = {Nurulizza Eshal Alisha and Yudhistya Ayu Kusumawati},
keywords = {Endangered animals, Interactive Game, Javan Langur, Learning Media},
abstract = {Indonesia is a country with a lot of biodiversity, both in the form of animals and plants, unfortunately, some of the biodiversity is classified as almost extinct, or even extinct, and the Javan Langur is included in the group of endangered animals because of its declining population, recorded at the Javan Langur Center there are only a few of Javan Langurs that have been successfully repatriated. Javan Langurs are also not widely known to people about their existence and extinction conditions, so there must be media to provide information to the wider community, especially to elementary students to form knowledge and prevention. With the rapid development of technology in the current era, there are various learning media that can be used, one of which is interactive games. This work aims to help students recognize endangered animals, including the Javan Langur, and help teaching institutions provide effective learning media for students. This research use design thinking as the research method. Questionnaires and interviews with resource persons who are elementary school students in grades 5 and 6, teachers, and parents. The result of this research is an interactive learning media in the form of a game with storytelling feature. This storytelling feature also include lesson contents and some challenge games with a character that will guide the storyline, much like a role-playing game or RPG.}
}
@article{KLIEMANN20181,
title = {The social neuroscience of mentalizing: challenges and recommendations},
journal = {Current Opinion in Psychology},
volume = {24},
pages = {1-6},
year = {2018},
note = {Social Neuroscience},
issn = {2352-250X},
doi = {https://doi.org/10.1016/j.copsyc.2018.02.015},
url = {https://www.sciencedirect.com/science/article/pii/S2352250X17302786},
author = {Dorit Kliemann and Ralph Adolphs},
abstract = {Our ability to understand and think about the mental states of other people is referred to as ‘mentalizing’ or ‘theory of mind’. It features prominently in all social behavior, is essential for maintaining relationships, and shows pronounced individual differences. Here we review new approaches to study the underlying psychological mechanisms and discuss how they could best be investigated using modern tools from social neuroscience. We list key desiderata for the field, such as validity, specificity, and reproducibility, and link them to specific recommendations for the future. We also discuss new computational modeling approaches, and the application to psychopathology.}
}
@article{MAITY2016152,
title = {A Computational Model to Predict Aesthetic Quality of Text Elements of GUI},
journal = {Procedia Computer Science},
volume = {84},
pages = {152-159},
year = {2016},
note = {Proceeding of the Seventh International Conference on Intelligent Human Computer Interaction (IHCI 2015)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.04.081},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916300965},
author = {Ranjan Maity and Akshay Madrosiya and Samit Bhattacharya},
keywords = {Aesthetics, web page, text elements, aesthetic score, categorization},
abstract = {The role of aesthetics in determining usability of interactive systems has come under focus in recent time. The issue is relevant for Graphical User Interfaces (GUI) containing elements of widely varying nature. It is important to evaluate GUI aesthetically to determine their acceptability to the users. Computational models have been reported in the literature to perform objective assessment of interface aesthetics. However, the existing models only consider geometric features at the highest level, without considering the content inside the geometry. To address this issue, we propose a computational model to evaluate aesthetics of textual contents present on a GUI. The proposed model is based on empirical data collected from user studies. The model is a weighted sum of six features characterizing text: chromatic contrast, luminance contrast, font size, letter spacing, line height and word spacing. A separate validation study demonstrates the feasibility and potential of the model (showing 87% accuracy in model prediction), which is expected to be useful in predicting usability of a web page in a more refined way. Such modeling has its obvious implications in the context of engineering interactive systems. The proposed model along with the user studies are presented in this paper.}
}
@article{LADLEY20152412,
title = {The impact of individual versus group rewards on work group performance and cooperation: A computational social science approach},
journal = {Journal of Business Research},
volume = {68},
number = {11},
pages = {2412-2425},
year = {2015},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2015.02.020},
url = {https://www.sciencedirect.com/science/article/pii/S0148296315001022},
author = {Daniel Ladley and Ian Wilkinson and Louise Young},
keywords = {Cooperation, Work groups, Incentive, Iterated, Group versus individual reward systems, Complex systems, Agent based models, Computational social science},
abstract = {Purpose
To examine the effect of individual versus group evaluation and reward systems on work group behavior and performance under different task conditions.
Methodology
Uses computational social methods using Agent Based Models to simulate work group interactions as different forms of iterated games.
Findings
Group based systems outperform individual based and mixed systems, producing more cooperative behavior, the best performing groups and individuals in most types of interaction games. A new role emerges, the self-sacrificer, who plays a critical role in enabling other group members and the group, to perform better at their own expense.
Research Implications
Suggest opportunities for model development and guidelines for designing real world experiments.
Practical Implications
Helps firms engineer better performing work groups as well as the design of other business systems.
Social Implications
Identifies mechanisms by which cooperation can be developed in social systems.
Originality/Value
Demonstrates the role and value of computational social science methods and agent based models to business research.}
}
@article{YANG2018242,
title = {Multi-disciplinary and multi-objective optimization problem re-formulation in computational design exploration: A case of conceptual sports building design},
journal = {Automation in Construction},
volume = {92},
pages = {242-269},
year = {2018},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2018.03.023},
url = {https://www.sciencedirect.com/science/article/pii/S0926580517309317},
author = {Ding Yang and Shibo Ren and Michela Turrin and Sevil Sariyildiz and Yimin Sun},
keywords = {Multi-disciplinary optimization, Multi-objective optimization, Computational design exploration, Knowledge extraction, Statistical analysis techniques, Optimization problem re-formulation, Sports buildings, Architectural performance, Climate performance, Structural performance},
abstract = {The benefits of applying multi-objective optimization (MOO) in building design have been increasingly recognized in recent decades. The existing or traditional computational design optimization (CDO) approaches mostly focus on optimization problem solving (OPS), as they often conduct optimizations directly by assuming the optimization problems in question are good enough. In contrast, the computational design exploration (CDE) approaches defined in this research mainly focus on optimization problem formulation (OPF), which are considered more essential and aim to achieve or ensure appropriate optimization problems before conducting optimizations. However, the application of the CDE is very limited especially in conceptual architectural design. The necessity of re-formulating original optimization problems and its potential impacts on optimization results are often overlooked or not emphasized enough. This paper proposes a new CDE approach that highlights the knowledge-supported re-formulation of a changeable initial optimization problem. It improves upon the traditional CDO approach by introducing a changeable initial OPF and inserting a CDE module. The changeable initial OPF allows expanding the dimensionality of an objective space and design space being investigated, and the CDE module can re-formulate the changeable optimization problem using the information and knowledge extracted from statistical analyses. To facilitate designers in achieving the proposed approach, an improved computational platform is used which combines parametric modeling software (including simulation plug-ins) and design optimization software. Assisted by the platform, the proposed approach is applied to the conceptual design of an indoor sports building that considers multi-disciplinary performance criteria (including architecture-, climate- and structure-related criteria) and a wide range of geometric variations. Through the case study, this paper demonstrates the use of the proposed approach, verifies its benefits over the traditional method, and unveils the factors that may affect the behaviour of the proposed approach. Besides, it also shows the suitability of the computational platform used.}
}
@article{CONSTABLE201760,
title = {The practice of chemistry still needs to change},
journal = {Current Opinion in Green and Sustainable Chemistry},
volume = {7},
pages = {60-62},
year = {2017},
note = {New Synthetic Methods 2017},
issn = {2452-2236},
doi = {https://doi.org/10.1016/j.cogsc.2017.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S2452223617300755},
author = {David J.C. Constable},
abstract = {There is now over a 20-year history of green and sustainable chemistry efforts in the US, but for a majority of chemicals that have been synthesized, chemists and chemical engineers lack key information about what it takes to commercialize them, their toxicity to humans or the environment, their degradability (biological or otherwise), their ability to be recycled or reused, or their ability to be source renewably. While the depth, breadth, and variety of innovations in chemistry gives one hope that chemists and chemical engineers will make many significant advances in the next 20 years, there is still a need to incorporate systems and life cycle thinking into chemistry. This is especially true as one considers limitations in the supply of key elements chemists rely on very heavily. Recent advances in computational chemistry and machine learning show great promise for moving chemistry toward a more sustainable practice of chemistry.}
}
@article{KOTAGODAHETTI2024118926,
title = {Life cycle-based multi-objective model for optimal gaseous fuel generation and portfolio allocation in gas grids: A strategic decarbonization},
journal = {Energy Conversion and Management},
volume = {319},
pages = {118926},
year = {2024},
issn = {0196-8904},
doi = {https://doi.org/10.1016/j.enconman.2024.118926},
url = {https://www.sciencedirect.com/science/article/pii/S0196890424008677},
author = {Ravihari Kotagodahetti and Kasun Hewage and Ezzeddin Bakhtavar and Rehan Sadiq},
keywords = {Biomethane, Hydrogen, Environmental impacts, Economic impacts, Life cycle thinking, Multi-objective optimization},
abstract = {Biomethane and hydrogen are acknowledged as transformative opportunities for decarbonizing the conventional gas grid. Essential to this transformation is the modeling of the gaseous fuel supply chain, particularly with hydrogen and biomethane, offering crucial insights for decision-makers. This study introduces a life cycle thinking-based multi-objective optimization model for the integrated design of biomethane and hydrogen gaseous fuel supply chain networks. The model determines optimal resource allocation for the production of the two fuels, integrating them into the conventional gas network. Moreover, it allocates conventional natural gas, biomethane, and hydrogen optimally across building, industry, and transport sectors, considering the life cycle environmental and economic performance of fuel integration paths. Objective functions include minimization of life cycle emissions and levelized cost of energy while maximizing revenue from fuel sales. Integrating life cycle assessment and cost analysis tools, the optimization model quantifies emissions and life cycle costs for biomethane and hydrogen paths. Results identify Pareto-optimal fuel production paths and portfolios, revealing that integrating the alternative fuels into the current gas grid can significantly reduce emissions (up to 250 tonCO2eq/year) and generate substantial carbon tax savings (up to $16,250/year). This model is useful for gaseous fuel industry stakeholders, offering a comprehensive view of supply chain costs and detailed insights into emission benefits when integrating alternative fuels into existing gas networks.}
}
@article{CROLLEN2019549,
title = {Recruitment of the occipital cortex by arithmetic processing follows computational bias in the congenitally blind},
journal = {NeuroImage},
volume = {186},
pages = {549-556},
year = {2019},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2018.11.034},
url = {https://www.sciencedirect.com/science/article/pii/S1053811918321153},
author = {Virginie Crollen and Latifa Lazzouni and Mohamed Rezk and Antoine Bellemare and Franco Lepore and Marie-Pascale Noël and Xavier Seron and Olivier Collignon},
keywords = {Blindness, Mental arithmetic, Multiplication, Neural correlates, Subtraction},
abstract = {Arithmetic reasoning activates the occipital cortex of congenitally blind people (CB). This activation of visual areas may highlight the functional flexibility of occipital regions deprived of their dominant inputs or relate to the intrinsic computational role of specific occipital regions. We contrasted these competing hypotheses by characterizing the brain activity of CB and sighted participants while performing subtraction, multiplication and a control letter task. In both groups, subtraction selectively activated a bilateral dorsal network commonly activated during spatial processing. Multiplication triggered activity in temporal regions thought to participate in memory retrieval. No between-group difference was observed for the multiplication task whereas subtraction induced enhanced activity in the right dorsal occipital cortex of the blind individuals only. As this area overlaps with regions showing selective tuning to auditory spatial processing and exhibits increased functional connectivity with a dorsal “spatial” network, our results suggest that the recruitment of occipital regions during high-level cognition in the blind actually relates to the intrinsic computational role of the activated regions.}
}
@article{MOGHADDAM2020112879,
title = {A neuro-inspired computational model for adaptive fault diagnosis},
journal = {Expert Systems with Applications},
volume = {140},
pages = {112879},
year = {2020},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2019.112879},
url = {https://www.sciencedirect.com/science/article/pii/S0957417419305895},
author = {Mohsen Moghaddam and Qiliang Chen and Abhijit V. Deshmukh},
keywords = {Machine consciousness, Deep learning, Convolutional neural networks, Transfer learning},
abstract = {Fault diagnosis is a key process to ensure reliable and cost-effective performance of time-critical engineered systems. This article develops a data-driven computational model for adaptive fault diagnosis by drawing an analogy with the neurobiological process of conscious attention—a dynamic process that brings only the most novel 0.01% of the signals we receive with our five senses to our conscious experience. A model of conscious attention based on the theory of dynamic core hypothesis is first outlined, followed by a computational model that mimics key stages of the conscious attention process. Convolutional neural networks serve as a basis for modeling perceptual categorization and concept formation through automatic feature extraction, due to their analogy with the processes of neural group selection and reentry in the brain. Further, the process of incremental learning and its impact on signal novelty are modeled via transfer learning. The model is tested on the NASA C-MAPSS turbofan engine model, which indicated 95–99% fault diagnosis accuracy. This study aims at familiarizing the engineering community with the neurobiological process of conscious attention and its applications for adaptive process monitoring and improvement in engineered systems.}
}
@article{VARTIAINEN2020100182,
title = {Learning machine learning with very young children: Who is teaching whom?},
journal = {International Journal of Child-Computer Interaction},
volume = {25},
pages = {100182},
year = {2020},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2020.100182},
url = {https://www.sciencedirect.com/science/article/pii/S2212868920300155},
author = {Henriikka Vartiainen and Matti Tedre and Teemu Valtonen},
keywords = {Machine learning, Computational thinking, K-12, Participatory learning, Early childhood, Participatory research, Artificial intelligence},
abstract = {While artificial intelligence and machine learning is becoming a commonplace feature of people’s everyday lives, so far few theoretical or empirical studies have focused on investigating it in K-12​ education. Drawing on the sociocultural theory of learning and participation, this case study explored how six very young children taught and explored Google’s Teachable Machine in nonschool settings. Through fine-grained analysis of video recordings and interviews with the children, the article illustrates the content and the process of teaching where 3–9 year old children were producing machine learning data sets and models as well as observing, exploring, and explaining their own interaction with machine learning systems. The results illustrate the quick-paced and embodied nature of the child-computer interaction that also supported children to reason about the relationship between their own bodily expressions and the output of an interactive ML-based tool. The article concludes with discussions on the emergent process of teaching and learning as well as on ways of promoting children’s participation and sense of agency in the age of machine learning.}
}
@article{NIGHTINGALE2016558,
title = {Impact responses of the cervical spine: A computational study of the effects of muscle activity, torso constraint, and pre-flexion},
journal = {Journal of Biomechanics},
volume = {49},
number = {4},
pages = {558-564},
year = {2016},
issn = {0021-9290},
doi = {https://doi.org/10.1016/j.jbiomech.2016.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0021929016000154},
author = {Roger W. Nightingale and Jake Sganga and Hattie Cutcliffe and Cameron R. ‘Dale’ Bass},
keywords = {Biomechanics, Cervical spine, Bilateral facet Dislocation, Buckling, Muscle, Initial conditions, Compression, Pre-flexion, Preflexion, Alignment},
abstract = {Cervical spine injuries continue to be a costly societal problem. Future advancements in injury prevention depend on improved physical and computational models, which are predicated on a better understanding of the neck response during dynamic loading. Previous studies have shown that the tolerance of the neck is dependent on its initial position and its buckling behavior. This study uses a computational model to examine three important factors hypothesized to influence the loads experienced by vertebrae in the neck under compressive impact: muscle activation, torso constraints, and pre-flexion angle of the cervical spine. Since cadaver testing is not practical for large scale parametric analyses, these factors were studied using a previously validated computational model. On average, simulations with active muscles had 32% larger compressive forces and 25% larger shear forces—well in excess of what was expected from the muscle forces alone. In the short period of time required for neck injury, constraints on torso motion increased the average neck compression by less than 250N. The pre-flexion hypothesis was tested by examining pre-flexion angles from neutral (0°) to 64°. Increases in pre-flexion resulted in the largest increases in peak loads and the expression of higher-order buckling modes. Peak force and buckling modality were both very sensitive to pre-flexion angle. These results validate the relevance of prior cadaver models for neck injury and help explain the wide variety of cervical spine fractures that can result from ostensibly similar compressive loadings. They also give insight into the mechanistic differences between burst fractures and lower cervical spine dislocations.}
}
@article{HERAS2011685,
title = {fKenzo: A user interface for computations in Algebraic Topology},
journal = {Journal of Symbolic Computation},
volume = {46},
number = {6},
pages = {685-698},
year = {2011},
issn = {0747-7171},
doi = {https://doi.org/10.1016/j.jsc.2011.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S0747717111000174},
author = {J. Heras and V. Pascual and J. Rubio and F. Sergeraert},
keywords = {Symbolic computation systems, User interface, Constructive Algebraic Topology},
abstract = {fKenzo (= friendly Kenzo) is a graphical user interface providing a user-friendly front-end for the Kenzo system, a Common Lisp program devoted to Algebraic Topology. The fKenzo system provides the user interface itself, an XML intermediary generator-translator and, finally the Kenzo kernel. We describe in this paper the main points of fKenzo, and we explain also the advantages and limitations of fKenzo with respect to Kenzo itself. The text is separated into two parts, trying to cover both the user and the developer perspectives.}
}
@article{PRADIPA20241213,
title = {Malang Voyage: A sustainable digital landscape in Malang City},
journal = {Procedia Computer Science},
volume = {245},
pages = {1213-1224},
year = {2024},
note = {9th International Conference on Computer Science and Computational Intelligence 2024 (ICCSCI 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.351},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924031594},
author = {I Gede Cahya Pradipa and Yudhistya Ayu Kusumawati and Yongkie Angkawijaya},
keywords = {Sustainable tourism, Tourism development, Digital infrastructure, Malang City},
abstract = {In the scope of global tourism, Malang stands as a potential yet underutilized tourism city. Known as the "Paris of East Java," its captivating landscapes and pleasant climate offer a unique experience. Despite this, the city's tourism sector remains underdeveloped, evident from the low number of visitors compared to what it has to offer. Existing studies reveal the city's yet undiscovered potential, especially in city tourism, cultural experiences, and culinary. However, limited information and digital infrastructure pose significant challenges. This research addresses these gaps, proposing the development of a robust digital platform in the form of a dedicated social media travel hub for Malang's sustainable tourism. By utilizing design thinking methodology, the study aims to revolutionize how tourists access information and interact with local attractions. It hypothesizes that a well-designed digital infrastructure will enhance the city's tourism quality, attracting more visitors. Additionally, adopting sustainable tourism principles will further boost Malang's tourism industry. This research is not just a digital upgrade, it's a transformative journey, paving the way for Malang to emerge as a sustainable tourism hub. Through innovative design and a user-focused approach, this study is set to unlock Malang's full tourism potential of balanced growth with environmental and cultural preservation.}
}
@article{ROLLS2007962,
title = {A computational neuroscience approach to consciousness},
journal = {Neural Networks},
volume = {20},
number = {9},
pages = {962-982},
year = {2007},
note = {Brain and Consciousness},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2007.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S089360800700189X},
author = {Edmund T. Rolls},
keywords = {Consciousness, Higher order thought, Synchrony, Oscillations, Backward masking, Binding},
abstract = {Simultaneous recordings from populations of neurons in the inferior temporal visual cortex show that most of the information about which stimulus was shown is available in the number of spikes (or firing rate) of each neuron, and not from stimulus-dependent synchrony, so that it is unlikely that stimulus-dependent synchrony (or indeed oscillations) is an essential aspect of visual object perception. Neurophysiological investigations of backward masking show that the threshold for conscious visual perception may be set to be higher than the level at which small but significant information is present in neuronal firing and which allows humans to guess which stimulus was shown without conscious awareness. The adaptive value of this may be that the systems in the brain that implement the type of information processing involved in conscious thoughts are not interrupted by small signals that could be noise in sensory pathways. I then consider what computational processes are closely related to conscious processing, and describe a higher order syntactic thought (HOST) computational theory of consciousness. It is argued that the adaptive value of higher order thoughts is to solve the credit assignment problem that arises if a multistep syntactic plan needs to be corrected. It is then suggested that it feels like something to be an organism that can think about its own linguistic, and semantically-based thoughts. It is suggested that qualia, raw sensory and emotional feels, arise secondarily to having evolved such a higher order thought system, and that sensory and emotional processing feels like something because it would be unparsimonious for it to enter the planning, higher order thought, system and not feel like something.}
}
@incollection{CHOE2005187,
title = {Thinking about Visual Behavior; Learning about Photoreceptor Function},
series = {Current Topics in Developmental Biology},
publisher = {Academic Press},
volume = {69},
pages = {187-213},
year = {2005},
booktitle = {Neural Development},
issn = {0070-2153},
doi = {https://doi.org/10.1016/S0070-2153(05)69007-2},
url = {https://www.sciencedirect.com/science/article/pii/S0070215305690072},
author = {Kwang‐Min Choe and Thomas R. Clandinin},
abstract = {Visual behavioral assays in Drosophila melanogaster were initially developed to explore the genetic control of behavior, but have a rich history of providing conceptual openings into diverse questions in cell and developmental biology. Here, we briefly summarize the early efforts to employ three of these behaviors: phototaxis, the UV‐visible light choice, and the optomotor response. We then discuss how each of these assays has expanded our understanding of neuronal connection specificity and synaptic function. All of these studies have contributed to the development of sophisticated tools for manipulating gene expression, assessing cell fate specification, and visualizing neuronal development. With these tools in hand, the field is now poised to return to the original goal of understanding visual behavior using genetic approaches.}
}
@article{TROGER201953,
title = {Exploitation vs. exploration—computational temporal and semantic analysis explains semantic verbal fluency impairment in Alzheimer's disease},
journal = {Neuropsychologia},
volume = {131},
pages = {53-61},
year = {2019},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2019.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S0028393218305116},
author = {Johannes Tröger and Nicklas Linz and Alexandra König and Philippe Robert and Jan Alexandersson and Jessica Peter and Jutta Kray},
keywords = {Alzheimer's disease, MCI (mild cognitive impairment), Semantic speech analysis, Temporal analysis},
abstract = {Impaired Semantic Verbal Fluency (SVF) in dementia due to Alzheimer's Disease (AD) and its precursor Mild Cognitive Impairment (MCI) is well known. Yet, it remains open whether this impairment mirrors the breakdown of semantic memory retrieval processes or executive control processes. Therefore, qualitative analysis of the SVF has been proposed but is limited in terms of methodology and feasibility in clinical practice. Consequently, research draws no conclusive picture which of these afore-mentioned processes drives the SVF impairment in AD and MCI. This study uses a qualitative computational approach—combining temporal and semantic information—to investigate exploitation and exploration patterns as indicators for semantic memory retrieval and executive control processes. Audio SVF recordings of 20 controls (C, 66–81 years), 55 MCI (57–94 years) and 20 AD subjects (66–82 years) were assessed while groups were matched according to age and education. All groups produced, on average, the same amount of semantically related items in rapid succession within word clusters. Conversely, towards AD, there was a clear decline in semantic as well as temporal exploration patterns between clusters. Results strongly point towards preserved exploitation—semantic memory retrieval processes—and hampered exploration—executive control processes—in AD and potentially in MCI.}
}
@article{LISOWSKI2014634,
title = {Computational Intelligence Methods of a Safe Ship Control},
journal = {Procedia Computer Science},
volume = {35},
pages = {634-643},
year = {2014},
note = {Knowledge-Based and Intelligent Information & Engineering Systems 18th Annual Conference, KES-2014 Gdynia, Poland, September 2014 Proceedings},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.08.145},
url = {https://www.sciencedirect.com/science/article/pii/S1877050914011107},
author = {Józef Lisowski},
keywords = {Game Control, Optimal Control, Neural Networks, Safety of Navigation, Computer-Aided Decision, Computer Simulation},
abstract = {The paper describes the application of selected methods of optimal control theory, game theory and artificial neural networks with the aim of computer support for a safe ship control in collision situations. It shows the structure of the control system and defines the task of safe control. Also presented are methodologies and models for collision avoidance strategies. Using Matlab software, positional game, risk game and dynamic optimal trajectory algorithms have been developed to provide computer support of navigator for collision avoidance at sea. A computer simulations showing safe trajectory through eighteen met ships at sea illustrates this.}
}
@incollection{READMONTAGUE2018273,
title = {Chapter 11 - Computational Phenotypes Revealed by Interactive Economic Games},
editor = {Alan Anticevic and John D. Murray},
booktitle = {Computational Psychiatry},
publisher = {Academic Press},
pages = {273-292},
year = {2018},
isbn = {978-0-12-809825-7},
doi = {https://doi.org/10.1016/B978-0-12-809825-7.00011-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128098257000110},
author = {P. {Read Montague}},
keywords = {Approach and avoidance, Computational phenotyping, Computational psychiatry, Decision-making models, Economic games, Psychopathology, Reinforcement learning, Trust game},
abstract = {Reinforcement learning models provide an excellent example of how a computational process approach can help organize ideas and understanding of underlying neurobiology. In a strong sense, this is the assumption behind computational neuroscience. Computational psychiatry, as a translational arm of computational neuroscience, can also profit from the computational process approach but applied at many levels ranging from low-level neurobiology through characterization of mental states and even up to the level of multiple interacting humans. Here, we review some of the early evidence for why reinforcement learning in its modern versions moves well beyond behaviorist accounts and provides an excellent “computational paradigm” for framing value-dependent decision-making; something that goes awry in a number of psychiatry conditions. We focus in particular on how social exchange between humans can engage reward systems and can be used as a computational device good for parsing subjects into categories that relate in interesting ways to traditional depictions of psychopathology.}
}
@article{TOZZI2018133,
title = {Syntax meets semantics during brain logical computations},
journal = {Progress in Biophysics and Molecular Biology},
volume = {140},
pages = {133-141},
year = {2018},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2018.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S0079610717303140},
author = {Arturo Tozzi and James F. Peters and Andrew A. Fingelkurts and Alexander A. Fingelkurts and Leonid Perlovsky},
keywords = {Borsuk-ulam, Brouwer, Computation, Meaning, Truth, Syntactic},
abstract = {The discrepancy between syntax and semantics is a painstaking issue that hinders a better comprehension of the underlying neuronal processes in the human brain. In order to tackle the issue, we at first describe a striking correlation between Wittgenstein's Tractatus, that assesses the syntactic relationships between language and world, and Perlovsky's joint language-cognitive computational model, that assesses the semantic relationships between emotions and “knowledge instinct”. Once established a correlation between a purely logical approach to the language and computable psychological activities, we aim to find the neural correlates of syntax and semantics in the human brain. Starting from topological arguments, we suggest that the semantic properties of a proposition are processed in higher brain's functional dimensions than the syntactic ones. In a fully reversible process, the syntactic elements embedded in Broca's area project into multiple scattered semantic cortical zones. The presence of higher functional dimensions gives rise to the increase in informational content that takes place in semantic expressions. Therefore, diverse features of human language and cognitive world can be assessed in terms of both the logic armor described by the Tractatus, and the neurocomputational techniques at hand. One of our motivations is to build a neuro-computational framework able to provide a feasible explanation for brain's semantic processing, in preparation for novel computers with nodes built into higher dimensions.}
}
@article{KUGEL1986137,
title = {Thinking may be more than computing},
journal = {Cognition},
volume = {22},
number = {2},
pages = {137-198},
year = {1986},
issn = {0010-0277},
doi = {https://doi.org/10.1016/0010-0277(86)90057-0},
url = {https://www.sciencedirect.com/science/article/pii/0010027786900570},
author = {Peter Kugel},
abstract = {The uncomputable parts of thinking (if there are any) can be studied in much the same spirit that Turing (1950) suggested for the study of its computable parts. We can develop precise accounts of cognitive processes that, although they involve more than computing, can still be modelled on the machines we call ‘computers’. In this paper, I want to suggest some ways that this might be done, using ideas from the mathematical theory of uncomputability (or Recursion Theory). And I want to suggest some uses to which the resulting models might be put. (The reader more interested in the models and their uses than the mathematics and its theorems, might want to skim or skip the mathematical parts.)
Résumé
Les éléments du raisonnement ne relevant pas du calculable (uncomputable), (s'il en existe), peuvent s'etudier dans I'optique suggérée par Turing (1950) pour l'étude des éléments calculables (computable). On peut rendre compte avec précision des processus cognitifs qui, bien qu'impliquant plus que des calculs, peuvent cependant être modélisés sur ordinateurs. Dans cet article l'auteur propose des modalités pour arriver à ces résultats en utilisant les idées de la théorie mathdmatique de la Récursion (uncomputability). L'auteur suggère aussi des utilisations pour les modéles que en découlent (Il est possible au lecteur plus intéressé par les modèles et leurs utilisations que par les mathématiques et les théorèmes de passer rapidement sur la partie mathématique ou d'omettre de la lire.)}
}
@article{WANG2020106763,
title = {Fuzzy Linear regression based on approximate Bayesian computation},
journal = {Applied Soft Computing},
volume = {97},
pages = {106763},
year = {2020},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.106763},
url = {https://www.sciencedirect.com/science/article/pii/S1568494620307018},
author = {Ning Wang and Marek Reformat and Wen Yao and Yong Zhao and Xiaoqian Chen},
keywords = {Fuzzy linear regression, Bayes statistics, Approximate Bayesian computation},
abstract = {Fuzzy linear regression with crisp inputs and fuzzy output data constitutes an important modeling problem. Basic strategies used to solve this problem, i.e., the possibilistic method and the least squares method, together with their extensions, have some drawbacks. The possibilistic methods put emphasis on an inclusion property while the least squares methods focus on a central tendency property. Therefore, many researchers work on combining these two methods to obtain a better performance. In this paper, in contrast to most existing techniques which treat fuzzy linear regression as an optimization problem, we set the problem of constructing a fuzzy linear regression model in Bayesian statistics and propose a new fuzzy linear regression method based on approximate Bayesian computation (ABC). The method applies the likelihood-free inference algorithm ABC to generate independent samples of unknown model coefficients from Bayesian posterior distribution. This overcomes difficulty of defining likelihood function in fuzzy environment. By adjusting a prior distribution and a threshold of the ABC algorithm, the proposed approach can flexibly balance the inclusion property of the possibilistic methods and the central tendency property of the least squares methods. The convergence property of the proposed ABC algorithm is verified by a numerical example. Two measuring criteria, i.e., a distance metric and a degree of fitting index, which indicate the central tendency property and the inclusion property, respectively, are introduced to evaluate the quality of regression results. Three numerical examples are applied to show the performances of the proposed method. The numerical results are also compared with those obtained by some classical and recently proposed approaches. Additionally, a practical engineering application example is used to illustrate effectiveness of the proposed method.}
}
@article{MAIA2017382,
title = {Theory-Based Computational Psychiatry},
journal = {Biological Psychiatry},
volume = {82},
number = {6},
pages = {382-384},
year = {2017},
note = {Computational Psychiatry},
issn = {0006-3223},
doi = {https://doi.org/10.1016/j.biopsych.2017.07.016},
url = {https://www.sciencedirect.com/science/article/pii/S0006322317318164},
author = {Tiago V. Maia and Quentin J.M. Huys and Michael J. Frank}
}
@article{LI2017183,
title = {SeeMore: A kinetic parallel computer sculpture for educating broad audiences on parallel computation},
journal = {Journal of Parallel and Distributed Computing},
volume = {105},
pages = {183-199},
year = {2017},
note = {Keeping up with Technology: Teaching Parallel, Distributed and High-Performance Computing},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2017.01.017},
url = {https://www.sciencedirect.com/science/article/pii/S0743731517300230},
author = {Bo Li and John Mooring and Sam Blanchard and Aditya Johri and Melinda Leko and Kirk W. Cameron},
keywords = {Parallel and distributed computing, Kinetic art, Computer science education},
abstract = {We discuss the design, implementation, and evaluation of a 256-node Raspberry-Pi cluster with kinetic properties. Each compute node is attached to a servo mechanism such that movement results from local computation. The result is SeeMore, a kinetic parallel computer sculpture designed to enable visualization of parallel algorithms in an effort to educate broad audiences as to the beauty, complexity, and importance of parallel computation. The algorithms and interfaces were implemented by students from various related courses at VA Tech. We describe these designs in sufficient detail to enable others to build their own kinetic computing sculptures to augment their experiential learning programs. Our evaluations at exhibitions indicate 63% and 84% of visitors enjoyed interacting with SeeMore while 69% and 87% believed SeeMore has educational value.}
}
@article{TRYK2023101372,
title = {The electrochemistry of platinum-group and noble metals as it relates to fuel cells and water electrolysis: Vibrational spectroscopic and computational insights},
journal = {Current Opinion in Electrochemistry},
volume = {41},
pages = {101372},
year = {2023},
issn = {2451-9103},
doi = {https://doi.org/10.1016/j.coelec.2023.101372},
url = {https://www.sciencedirect.com/science/article/pii/S2451910323001655},
author = {Donald A. Tryk and Akiyoshi Kuzume},
abstract = {The intrinsic electrochemistry of platinum and other platinum-group metals and noble metals has been under intense investigation for over forty years but is still not fully understood. Various in situ spectroscopic techniques, particularly vibrational spectroscopies, have provided and continue to provide many insights, but challenges remain. The intrinsic electrochemistry is capable of being elucidated through the combination of electrochemistry, vibrational spectroscopy and theory and is then further able to clarify the catalytic reactions involved in H2–O2 fuel cells and water electrolysis.}
}
@article{FIGUEIRASAMPAIO2009484,
title = {A constructivist computational tool to assist in learning primary school mathematical equations},
journal = {Computers & Education},
volume = {53},
number = {2},
pages = {484-492},
year = {2009},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2009.03.012},
url = {https://www.sciencedirect.com/science/article/pii/S036013150900075X},
author = {Aleandra da Silva Figueira-Sampaio and Eliane Elias Ferreira {dos Santos} and Gilberto Arantes Carrijo},
keywords = {Elementary education, Improving classroom teaching, Interactive learning environments, Virtual reality},
abstract = {In constructivist principles, learning is a process in which individuals construct knowledge. Research in Mathematics Education looks for ways to make mathematics education less dry and more attractive. When solving polynomial equations of the first degree, it is very common for teachers to work with the mistaken idea of “changing the sign” when “moving” the member. To minimize this problem, a balance can be used to illustrate the idea of equilibrium and also properties of equality. The objectives of this study were (1) develop a computational tool to replace a conventional balance in practical mathematics exercises thereby solving two material challenges for Brazilian teachers: verifying the accuracy of balances and the lack of student physical and social activity through direct participation; (2) determine how substituting the conventional balance with a computational tool for the solution of first degree polynomial equations affected the aspects inherent in the learning process like motivation, cooperation, dialogue, discussion, reflection, reciprocity, negotiation and responsibility. The results indicate that the cognitive computational tool met the challenges of Brazilian teachers. First, because it lacks mechanisms that need to be verified for accuracy in order to demonstrate equilibrium. Second, because it allows the direct participation of students (physical experience) and the use of the tool in small groups (social experience). The hands on completion of the activity, realistic appearance, the interaction with the tool, visual feedback on the panel, and two students using the same tool awakened motivation, responsibility for completing the activity, dialogue, cooperation, discussion and reflection. Doing the experiment with others aroused concern about the learning of others and reciprocity of knowledge for the improvement of the procedure to be constructed for solving 1st degree equations.}
}
@article{BRODLAND201562,
title = {How computational models can help unlock biological systems},
journal = {Seminars in Cell & Developmental Biology},
volume = {47-48},
pages = {62-73},
year = {2015},
note = {Coding and non-coding RNAs & Mammalian development},
issn = {1084-9521},
doi = {https://doi.org/10.1016/j.semcdb.2015.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S1084952115001287},
author = {G. Wayne Brodland},
keywords = {Review, Models, Computational modelling, Cell mechanics, Tissue mechanics, Embryo mechanics, Embryogenesis, Morphogenetic movements, Developmental mechanisms, Biological systems},
abstract = {With computation models playing an ever increasing role in the advancement of science, it is important that researchers understand what it means to model something; recognize the implications of the conceptual, mathematical and algorithmic steps of model construction; and comprehend what models can and cannot do. Here, we use examples to show that models can serve a wide variety of roles, including hypothesis testing, generating new insights, deepening understanding, suggesting and interpreting experiments, tracing chains of causation, doing sensitivity analyses, integrating knowledge, and inspiring new approaches. We show that models can bring together information of different kinds and do so across a range of length scales, as they do in multi-scale, multi-faceted embryogenesis models, some of which connect gene expression, the cytoskeleton, cell properties, tissue mechanics, morphogenetic movements and phenotypes. Models cannot replace experiments nor can they prove that particular mechanisms are at work in a given situation. But they can demonstrate whether or not a proposed mechanism is sufficient to produce an observed phenomenon. Although the examples in this article are taken primarily from the field of embryo mechanics, most of the arguments and discussion are applicable to any form of computational modelling.}
}
@article{LEE2012579,
title = {Developing an efficient computational method that estimates the ability of students in a Web-based learning environment},
journal = {Computers & Education},
volume = {58},
number = {1},
pages = {579-589},
year = {2012},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2011.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S0360131511002259},
author = {Young-Jin Lee},
keywords = {Ability estimation, Educational data mining, Item response theory, Log file analysis, Web-based learning environment},
abstract = {This paper presents a computational method that can efficiently estimate the ability of students from the log files of a Web-based learning environment capturing their problem solving processes. The computational method developed in this study approximates the posterior distribution of the student’s ability obtained from the conventional Bayes Modal Estimation (BME) approach to a simple Gaussian function in order to reduce the amount of computations required in the subsequent ability update processes. To verify the correctness and usefulness of this method, the abilities of 407 college students who solved 61 physics problems in a Web-based learning environment were estimated from the log files of the learning environment. The reduced chi-squared statistic and Pearson’s chi-square test for the goodness of fit indicate that the estimated abilities were able to successfully explain the observed problem solving performance of students within error. The educational implications of estimating the ability of students in Web-based learning environments were also discussed.}
}
@article{KLIMOVA20171,
title = {Where Youth strives in Computational Science: retrospective Analysis of Young Scientist Conference in HPC and Simulation},
journal = {Procedia Computer Science},
volume = {119},
pages = {1-7},
year = {2017},
note = {6th International Young Scientist Conference on Computational Science, YSC 2017, 01-03 November 2017, Kotka, Finland},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.11.153},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917323633},
author = {Alexandra Klimova and Anna Bilyatdinova and Jari Kortelainen and Peter M.A. Sloot and Alexander Boukhanovsky},
keywords = {computational science, high-performance computing, leading scientists program, international conference},
abstract = {This volume presents the selected papers of young computational scientists – participants of YSC-2017. Annual Young Scientist Conferences (YSC) in high performance computing, modeling and simulation are traditionally held since 2012 by the University of Amsterdam (the Netherlands) and ITMO University (St. Petersburg, Russia) as the open international events which aim to develop a dialogue about the present and future of computational science with a focus on applications of modeling and simulation solving a wide range of problems of science, industry, and business. The conference has already been organized for six times, which gives us an opportunity for retrospective analysis of conference’ results and trends in high performance computing (HPC). The results are presented in this editorial.}
}
@article{GIROTTO1991111,
title = {Event controllability in counterfactual thinking},
journal = {Acta Psychologica},
volume = {78},
number = {1},
pages = {111-133},
year = {1991},
issn = {0001-6918},
doi = {https://doi.org/10.1016/0001-6918(91)90007-M},
url = {https://www.sciencedirect.com/science/article/pii/000169189190007M},
author = {Vittorio Girotto and Paolo Legrenzi and Antonio Rizzo},
abstract = {The counterfactual assessment of events, i.e. is the mental construction of alternatives to factual events, is a pervasive mental process that is quite natural for people. For example, people easily make counterfactual statements when reflecting on dramatic events (‘If only I hadn't drunk alcohol the night of the car accident…’). The way in which people select the events to mutate when requested to undo a scenario outcome seems to be governed by general rules. One is that subjects tend to select exceptional (i.e. unusual or surprising) rather than normal events (Kahneman and Tversky 1982a,b; Kahneman and Miller 1986). Another is that subjects prefer to select the first rather than the subsequent events in a causal chain (Wells, Taylor and Turtle 1987). We hypothesized that events corresponding to controllable actions (i.e. voluntary decisions) by the protagonist of a scenario are more mentally mutable than events which occur in the surrounding background. In experiment 1, we manipulated the order and the controllability of four events in a scenario. Contrary to the causal order effect hypothesis, subjects preferred to change the event corresponding to a coluntary decision of the scenario actor, regardless of its relative position in the scenario. Experiment 2 showed that subjects made this choice regardless of the normal vs. exceptional status of the voluntary action event. Experiment 3 gave evidence that an unconstrained action performed by the focal actor of a story is more mutable than a constrained action performed by the same actor. The implications of these findings for the analysis of accidents involving human errors are discussed.}
}
@article{TRASMUNDI2024101615,
title = {Dialogical cognition},
journal = {Language Sciences},
volume = {103},
pages = {101615},
year = {2024},
issn = {0388-0001},
doi = {https://doi.org/10.1016/j.langsci.2024.101615},
url = {https://www.sciencedirect.com/science/article/pii/S0388000124000044},
author = {Sarah Bro Trasmundi and Sune Vork Steffensen},
keywords = {Per Linell, Dialogical cognition, Distributed cognition, Cognitive ethnography, Distributed language},
abstract = {In this article we review Per Linell's work within the last five decades that led to his dialogism framework, which he defines as a general epistemology of language, cognition and communication. We critically discuss how his contribution on the one hand, altered and qualified existent models within language, communication and cognitive science, because dialogism removed language and cognition from their abstract and mental seat in the brain, and embedded them instead in situational contexts and embodied interaction. In that sense, his dialogism successfully replaced monological assumptions about the mind, action and thinking with more contextual and temporally distributed ones. On the other hand, we also question why Linell has not pursued a more rigorous empirical program for studying human cognition, when he did establish a theoretical apparatus for approaching cognition from a dialogical starting point. In going through Linell's arguments over the past five decades we suggest that this absence of an empirical program is due to his humanistic roots which both have sensitised him to appreciating the contingencies and dynamics of human sense making and cognition, and have impeded him from buying into a necessary condition for pursuing a cognitive analysis, even if he conceptually and methodologically accepts a distributed view on cognition. The outcome of this discussion leads to an empirical-based cognitive analysis of a medical interaction. Altogether, the purpose of this article is to show how Linell's conceptual framework can be put to use in ways that make a dialogical cognitive science achievable.}
}
@article{TEZDUYAR20061872,
title = {Parallel finite element computations in fluid mechanics},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {195},
number = {13},
pages = {1872-1884},
year = {2006},
note = {A Tribute to Thomas J.R. Hughes on the Occasion of his 60th Birthday},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2005.05.038},
url = {https://www.sciencedirect.com/science/article/pii/S0045782505003105},
author = {Tayfun E. Tezduyar and Ahmed Sameh},
keywords = {Parallel computing, Fluid mechanics, Moving boundaries and interfaces, Mesh update, Preconditioned iterative algorithms},
abstract = {We provide an overview of the role of parallel finite element computations in fluid mechanics. We emphasize the class of flow problems involving moving boundaries and interfaces. Some of the computationally most challenging flow problems, such as fluid–object and fluid–structure interactions as well as free-surface and two-fluid flows, belong to this class. In the development of the methods targeting this class of problems, the computational challenges involved need to be addressed in such a way that 3D computation of complex applications can be carried out efficiently on parallel computers. This requirement has to be one of the key factors in designing various components of the overall solution approach, such as solution techniques for the discretized equations and mesh update methods for handling the changes in the spatial domain occupied by the fluid. This overview includes a description of how the computational challenges are addressed and how the computational schemes can be enhanced with special preconditioning techniques.}
}
@article{DIFRANCO2019386,
title = {Information-gain computation in the Fifth system},
journal = {International Journal of Approximate Reasoning},
volume = {105},
pages = {386-395},
year = {2019},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2018.11.013},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X18301610},
author = {Anthony {Di Franco}},
keywords = {Declarative programming, Probabilistic logic programming, , Adaptive evaluation strategy, Multi-armed bandits},
abstract = {Despite large incentives, correctness in software remains an elusive goal. Declarative programming techniques, where algorithms are derived from a specification of the desired behavior, offer hope to address this problem, since there is a combinatorial reduction in complexity in programming in terms of specifications instead of algorithms, and arbitrary desired properties can be expressed and enforced in specifications directly. However, limitations on performance have prevented programming with declarative specifications from becoming a mainstream technique for general-purpose programming, because a strategy which is both efficient and fully general to derive algorithms from specifications does not yet exist. To address this bottleneck, I propose information-gain computation, a framework where an adaptive evaluation strategy is used to efficiently perform a search which derives algorithms that provide information about a query via the most efficient routes. Within this framework, opportunities to compress the search space present themselves, which suggest that information-theoretic bounds on the performance of such a system might be articulated and a system might be designed to achieve them. The computation of the information measures that are the basis of this strategy crucially depends on a probabilistic semantics for the relations represented by predicates, which may either already be present in a probabilistic logic language, or may be superimposed on a pure logic language. I describe a prototype implementation of Fifth, a system that implements these techniques, and a preliminary empirical study of adaptive evaluation for a simple test program. In the test, the evaluation strategy adapts successfully to efficiently evaluate a query with pathological features that would prevent its evaluation by standard general-purpose strategies.}
}
@article{LEE2023121253,
title = {Artificial intelligence enabled energy-efficient heating, ventilation and air conditioning system: Design, analysis and necessary hardware upgrades},
journal = {Applied Thermal Engineering},
volume = {235},
pages = {121253},
year = {2023},
issn = {1359-4311},
doi = {https://doi.org/10.1016/j.applthermaleng.2023.121253},
url = {https://www.sciencedirect.com/science/article/pii/S1359431123012826},
author = {Dasheng Lee and Shang-Tse Lee},
keywords = {Artificial intelligence (AI), Heating, ventilation and air conditioning (HVAC), Energy saving, Design thinking, Hardware upgrade},
abstract = {Literature search across different databases showed that the application of artificial intelligence (AI) in heating, ventilation and air conditioning (HVAC) equipment has been extensively studied. On the commercial front, Internet search suggested that numerous AI-equipped HVAC products have been launched. These products apply AI in very different ways, and their energy-saving effects are also different. Such divergence and uncertain energy-saving effects may hinder AI application. To overcome this difference and accelerate the development of AI applications, the present study proposed a double diamond preferred reporting items for systematic reviews and meta-analysis (PRISMA) method—an analysis method that combined literature review with design thinking. Through a process of divergence-convergence-re-divergence, this study described how to design AI functions for energy-efficient HVAC systems, taking into account more than 1,700 research papers it had reviewed. However, there was a limitation on the part re-divergence. Because the vast majority of research papers only published results of successful AI applications, no cases of failed applications were available for review, making it impossible to re-think profoundly. Instead, this study collected raw data from 88 research papers and used these data to analyze the effectiveness and ineffectiveness of AI in depth. It was concluded that AI application must be accompanied by necessary hardware improvements to achieve effective energy savings. AI-enabled energy-saving effects for chillers, air-handing units, heating systems, and air conditioners, as well as corresponding hardware upgrades, were discussed.}
}
@article{SIETTOS20061632,
title = {A systems-based approach to multiscale computation: Equation-free detection of coarse-grained bifurcations},
journal = {Computers & Chemical Engineering},
volume = {30},
number = {10},
pages = {1632-1642},
year = {2006},
note = {Papers form Chemical Process Control VII},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2006.05.019},
url = {https://www.sciencedirect.com/science/article/pii/S0098135406001360},
author = {C.I. Siettos and R. Rico-Martinez and I.G. Kevrekidis},
keywords = {Multiscale, Equation-free, Bifurcation},
abstract = {We discuss certain basic features of the equation-free (EF) approach to modeling and computation for complex/multiscale systems. We focus on links between the equation-free approach and tools from systems and control theory (design of experiments, data analysis, estimation, identification and feedback). As our illustrative example, we choose a specific numerical task (the detection of stability boundaries in parameter space) for stochastic models of two simplified heterogeneous catalytic reaction mechanisms. In the equation-free framework the stochastic simulator is treated as an experiment (albeit a computational one). Short bursts of fine scale simulation (short computational experiments) are designed, executed, and their outputs processed and fed back to the process, in integrated protocols aimed at performing the particular coarse-grained task (the detection of a macroscopic instability). Two distinct approaches are presented; one is a direct translation of our previous protocol for adaptive detection of instabilities in laboratory experiments [Rico-Martinez, R., Krisher, K., Flatgen, G., Anderson, J. S., & Kevrekidis, I. G. (2003). Adaptive detection of instabilities: An experimental feasibility study. Physica D, 176, 1–18]; the second approach is motivated from numerical bifurcation algorithms for critical point detection. A comparison of the two approaches brings forth a key feature of equation-free computation: computational experiments can be easily initialized at will, in contrast to laboratory ones.}
}
@article{TOIVONEN202052,
title = {Computational creativity beyond machine learning},
journal = {Physics of Life Reviews},
volume = {34-35},
pages = {52-53},
year = {2020},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2020.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S1571064520300373},
author = {Hannu Toivonen}
}
@article{ISMAILOVA2018183,
title = {Basic Constructions of the Computational Model of Support for Access Operations to the Semantic Network},
journal = {Procedia Computer Science},
volume = {123},
pages = {183-188},
year = {2018},
note = {8th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2017 (Eighth Annual Meeting of the BICA Society), held August 1-6, 2017 in Moscow, Russia},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.01.030},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918300310},
author = {Larisa Yu. Ismailova and Viacheslav E. Wolfengagen and Sergey V. Kosikov},
keywords = {informational objects, semantics, computational model, semantic network, intensional logic, access operation},
abstract = {The paper considers the approach to solving the task of storing data in the Web environment using semantic networks (SN). The control over the access to SN is identified as a critical task. An approach to the solution based on the use of the controlling SN is proposed. The rationale for the approach involves developing a computational model for supporting the access operations. The construction of a model based on intensional logic is proposed. The basic logical constructions, necessary for building a model, are considered. The testing of the model’s constructions was performed when building the tools of semantic support for the implementation of the best available technologies (BAT).}
}
@article{CUI2022104203,
title = {Pore-network modeling of flow in shale nanopores: Network structure, flow principles, and computational algorithms},
journal = {Earth-Science Reviews},
volume = {234},
pages = {104203},
year = {2022},
issn = {0012-8252},
doi = {https://doi.org/10.1016/j.earscirev.2022.104203},
url = {https://www.sciencedirect.com/science/article/pii/S0012825222002872},
author = {Ronghao Cui and S. Majid Hassanizadeh and Shuyu Sun},
keywords = {Pore-network modeling, Shale rock, Nanoporous media, Flow theory, Thermodynamics},
abstract = {Hydrocarbons in subsurface nanoporous media, such as shale, are promising energy resources to compensate for the shortage of conventional reservoirs. Pore-network modeling serves as a valuable tool for simulating microscale fluid transport and elucidating flow physics in porous media. However, traditional pore-network models have failed to capture features of spatial structure and fluid flow in unconventional shale rock. This work presents a critical review of pore-network modeling of single-phase and two-phase flow in shale rock. Pore-network modeling advances of shale are reviewed based on three major parts: network morphology and geometries, flow principles in nanocapillaries, and pore-network computational algorithms. First, based on key geological features of shale rock, we analyze network topology, multiscale network, pore geometries, and network representativeness of shale pore-network models. Then, we discuss four important aspects that may influence flow principles of fluids in nanocapillaries: gas and liquid slippage, sorption and diffusion behavior, hydrocarbon thermodynamics, and the presence of water. Finally, we present pore-network modeling methods used for flow simulations in shale rock, including quasi-static and dynamic algorithms. We hope that this review could shed light on fundamentals of pore-network modeling of shale rock.}
}
@article{ATANCE2010297,
title = {Thinking about false belief: It’s not just what children say, but how long it takes them to say it},
journal = {Cognition},
volume = {116},
number = {2},
pages = {297-301},
year = {2010},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2010.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S0010027710001101},
author = {Cristina M. Atance and Daniel M. Bernstein and Andrew N. Meltzoff},
keywords = {Theory of mind, False-belief reasoning, Conceptual development, Response latencies},
abstract = {We examined 240 children’s (3.5-, 4.5-, and 5.5-year-olds) latency to respond to questions on a battery of false-belief tasks. Response latencies exhibited a significant cross-over interaction as a function of age and response type (correct vs. incorrect). 3.5-year-olds’ incorrect latencies were faster than their correct latencies, whereas the opposite pattern emerged for 4.5- and 5.5-year-olds. Although these results are most consistent with conceptual change theories of false-belief reasoning, no extant theory fully accounts for our data pattern. We argue that response latency data provide new information about underlying cognitive processes in theory of mind reasoning, and can shed light on concept acquisition more broadly.}
}
@article{ZHAO2015194,
title = {Bring CS2013 Recommendations into c Programming Course},
journal = {Procedia - Social and Behavioral Sciences},
volume = {176},
pages = {194-199},
year = {2015},
note = {International Educational Technology Conference, IETC 2014, 3-5 September 2014, Chicago, IL, USA},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2015.01.461},
url = {https://www.sciencedirect.com/science/article/pii/S187704281500498X},
author = {Lingling Zhao and Xiaohong Su and Tiantian Wang},
keywords = {CS2013, C programming course, CS curriculum planning, CS major ;},
abstract = {Computer Science Curriculum 2013 has become the guidance of computing education since it was released in 2013by the ACM/IEEE-Computer Society. This paper analyzes the CS curriculum development trend, trying to dig the programming-related core from CS2013 with respect to the knowledge areas, topics, organization of teaching, and the building of students’ capability. Considering the characteristic of our local institution and undergraduates, we present an updated teaching curriculum and lab curriculum for C Programming Language course in relation to CS2013 recommendations, which highlight the development of the students’ abilities on programming, problem-solving, self-regulated learning, and computational thinking. Finally, we present and assess the implementation of the resulting curriculum.}
}
@article{ROSSITER202473,
title = {A MATLAB virtual laboratory to support learning of auto-tuning PID approaches},
journal = {IFAC-PapersOnLine},
volume = {58},
number = {7},
pages = {73-78},
year = {2024},
note = {4th IFAC Conference on Advances in Proportional-Integral-Derivate Control PID 2024},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2024.08.013},
url = {https://www.sciencedirect.com/science/article/pii/S2405896324007250},
author = {J.A. Rossiter and A. Visioli and S. Dormido and R. Bars},
keywords = {Control101 toolbox, PID compensation, virtual laboratories, independent learning},
abstract = {This paper presents a small number of MATLAB APPs and livescript files designed to help students both understand and implement PID tuning. The paper presents the thinking behind the use of MATLAB and the topic itself before then describing the proposed resources in detail. The resources split into files with detailed mathematical and coding background students can use for self-study and assignments, and a virtual laboratory which is more intuitive and interactive and useful for familiarisation with core concepts. The files were recently added to the control101 toolbox (Rossiter, 2023).}
}
@article{JONES2020100801,
title = {Scalar and vector line integrals: A conceptual analysis and an initial investigation of student understanding},
journal = {The Journal of Mathematical Behavior},
volume = {59},
pages = {100801},
year = {2020},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2020.100801},
url = {https://www.sciencedirect.com/science/article/pii/S0732312320300651},
author = {Steven R. Jones},
keywords = {Multivariable calculus, Definite integrals, Line integrals, Conceptual analysis, Student understanding},
abstract = {This paper adds to the growing body of research happening in multivariable calculus by examining scalar and vector line integrals. This paper contributes in two ways. First, this paper provides a conceptual analysis for both types of line integrals in terms of how theoretical ways of thinking about definite integrals summarized from the research literature might be applied to understanding line integrals specifically. Second, this paper provides an initial investigation of students’ understandings of line integral expressions, and connects these understanding to the theoretical ways of thinking drawn from the literature. One key finding from the empirical part is that several students appeared to understand individual pieces of the integral expression based on one way of thinking, such as adding up pieces or anti-derivatives, while trying to understand the overall integral expression through a different way of thinking, such as area under a curve.}
}
@article{DOIRON2019iii,
title = {Editorial overview: Computational neuroscience},
journal = {Current Opinion in Neurobiology},
volume = {58},
pages = {iii-vii},
year = {2019},
note = {Computational Neuroscience},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2019.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S0959438819300728},
author = {Brent Doiron and Máté Lengyel}
}
@article{DOUKAS2013227,
title = {Modelling of linguistic variables in multicriteria energy policy support},
journal = {European Journal of Operational Research},
volume = {227},
number = {2},
pages = {227-238},
year = {2013},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2012.11.026},
url = {https://www.sciencedirect.com/science/article/pii/S0377221712008740},
author = {Haris Doukas},
keywords = {Decision support, Multicriteria analysis, Linguistic variables, Energy policy, Sustainable development},
abstract = {The climate change and the increasing complexity of the energy sector along with the prerequisite for sustainability have broadened the energy policy shaping field by bringing out new challenges. Decision support tools and methods, such as Multicriteria Decision Aid (MCDA), are necessary for energy policy, in the pursuit of appropriate approaches necessary to support the restructuring of the energy sector, concerning patterns of energy extraction, generation, transformation and use, from unsustainable to sustainable forms of development. Papers devoted to the investigation of MCDA models using linguistic variables for energy policy support seem to be not available in the international literature. The scope of this paper is to explore different linguistic representation and computational models in MCDA that are or can be applied to energy policy support and to establish a clear linkage between them. This paper argues that MCDA methodologies with direct computation on linguistic variables can support energy policy frameworks, bridging the gap between energy policy makers thinking, reasoning, representation and computing. Finally, current trends, open questions and prospects in this topic are pointed out.}
}
@article{CATENACCIVOLPI20141,
title = {How active perception and attractor dynamics shape perceptual categorization: A computational model},
journal = {Neural Networks},
volume = {60},
pages = {1-16},
year = {2014},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2014.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608014001440},
author = {Nicola {Catenacci Volpi} and Jean Charles Quinton and Giovanni Pezzulo},
keywords = {Hopfield networks, Perceptual categorization, Prediction, Active vision, Dynamic choice},
abstract = {We propose a computational model of perceptual categorization that fuses elements of grounded and sensorimotor theories of cognition with dynamic models of decision-making. We assume that category information consists in anticipated patterns of agent–environment interactions that can be elicited through overt or covert (simulated) eye movements, object manipulation, etc. This information is firstly encoded when category information is acquired, and then re-enacted during perceptual categorization. The perceptual categorization consists in a dynamic competition between attractors that encode the sensorimotor patterns typical of each category; action prediction success counts as “evidence” for a given category and contributes to falling into the corresponding attractor. The evidence accumulation process is guided by an active perception loop, and the active exploration of objects (e.g., visual exploration) aims at eliciting expected sensorimotor patterns that count as evidence for the object category. We present a computational model incorporating these elements and describing action prediction, active perception, and attractor dynamics as key elements of perceptual categorizations. We test the model in three simulated perceptual categorization tasks, and we discuss its relevance for grounded and sensorimotor theories of cognition.}
}
@article{OCAMPO2024111111,
title = {An integrated three-way decision methodology for sustainability of wastewater circularity in thermal power plants},
journal = {Applied Soft Computing},
volume = {151},
pages = {111111},
year = {2024},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2023.111111},
url = {https://www.sciencedirect.com/science/article/pii/S1568494623011298},
author = {Lanndon Ocampo and Jenebyb Cabigas and Dylan Jones and Ashraf Labib},
keywords = {Water circularity, Wastewater, Water reuse, MARCOS, Three-way decision},
abstract = {The presence of multiple criteria for evaluating wastewater reuse applications indicates the potential usage of Multi-Criteria Decision-Making (MCDM) methods for this purpose. However, there is currently a scarcity of studies in the domain literature that utilize MCDM approaches in this application topic. This paper therefore advances the domain literature in two distinctive ways. Firstly, it analyzes and advances the reuse agenda of wastewater from thermal power plants, recognized as large-scale users of water, thus promoting greater water circularity. Secondly, it provides a methodological advance by integrating the notion of Three-Way Decision (3WD) into the computational structure of MCDM methods by introducing a middle reference point. Such an initiative results in a novel 3WD extension of the Measurement of Alternatives and Ranking according to COmpromise Solution (MARCOS) method. Additionally, this work provides a proof that the MARCOS method utilizes a compromise solution in identifying priority alternatives, along with the integration of a Weighted Aggregated Sum Product ASsessment (WASPAS) metric. An initial hypothetical example illustrates how the proposed approach augments the canonical MARCOS method, particularly in promoting the “thinking in threes” as a more natural information processing approach and the high degree of distinguishability of priorities between decision alternatives. An actual case study in a thermal power plant then demonstrates the contributions of this work. With the best-worst method used to determine the priorities of the decision attributes, the findings reveal that wastewater reuse applications achieving reduced costs for needed infrastructures, operational simplicity, technological compatibility, consumer safety and household savings are preferred by stakeholders. The 3WD-MARCOS approach identifies industrial and commercial use, municipal use, environmental restoration, and household use as the high-priority alternatives, with cooking and drinking as least preferred. These insights guide stakeholders in their design of initiatives that allocate resources for greater wastewater reuse. A comparative analysis yields high consistency of these findings with similar MCDM methods. In addition, the efficacy of the novel 3WD-MARCOS method highlights its potential in handling MCDM problems, including those promoting water circularity.}
}
@article{JEYASUBRAMANIAN2021120243,
title = {A complete review on biochar: Production, property, multifaceted applications, interaction mechanism and computational approach},
journal = {Fuel},
volume = {292},
pages = {120243},
year = {2021},
issn = {0016-2361},
doi = {https://doi.org/10.1016/j.fuel.2021.120243},
url = {https://www.sciencedirect.com/science/article/pii/S0016236121001198},
author = {K. Jeyasubramanian and B. Thangagiri and A. Sakthivel and J. {Dhaveethu Raja} and S. Seenivasan and P. Vallinayagam and D. Madhavan and S. {Malathi Devi} and B. Rathika},
keywords = {Biochar, Engineered Biochar, Biomass, Applications, Production methods, Mechanism},
abstract = {Burning crop residues release large amounts of greenhouse gases, particulate matter, carbon monoxide, etc. which influence a lot of environmental issues that are hazardous to all living beings including humans. One of the useful methods of using crop residues is in the form of biochar obtained after employing thermo-chemical routes. Apart from the crop residues, the carbon rich contents obtained from forest, animal compost, waste plastics, etc., can be heated in oxygen starved atmosphere, that left char having enriched carbon and trace amount of minerals finds extensive applications in agriculture, especially to make soil more fertile, as a carbon sequestration agent, increases crops yields, etc. This review focuses on the synthetic strategies adopted to obtain biochar, and the numerous applications in various fields. Further, the interactions involved in between the host–guest molecules are explained using computational studies like Density Functional Theory, Artificial Neural Network analysis, Machine Learning methods, and Visual MINTEQ program.}
}
@article{CHANG20161,
title = {COMPUTATIONAL DESIGN in the past, present and future of digital architecture},
journal = {Automation in Construction},
volume = {72},
pages = {1-2},
year = {2016},
note = {Computational and generative design for digital fabrication: Computer-Aided Architectural Design Research in Asia (CAADRIA)},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2016.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S092658051630303X},
author = {Teng-Wen Chang and Tane J. Moleta and Daekwon Park}
}
@article{TREMOLIERE2012379,
title = {Mortality salience and morality: Thinking about death makes people less utilitarian},
journal = {Cognition},
volume = {124},
number = {3},
pages = {379-384},
year = {2012},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2012.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S0010027712001035},
author = {Bastien Trémolière and Wim De Neys and Jean-François Bonnefon},
keywords = {Mortality salience, Moral judgment, Utilitarian responses, Cognitive resources},
abstract = {According to the dual-process model of moral judgment, utilitarian responses to moral conflict draw on limited cognitive resources. Terror Management Theory, in parallel, postulates that mortality salience mobilizes these resources to suppress thoughts of death out of focal attention. Consequently, we predicted that individuals under mortality salience would be less likely to give utilitarian responses to moral conflicts. Two experiments corroborated this hypothesis. Experiment 1 showed that utilitarian responses to non-lethal harm conflicts were less frequent when participants were reminded of their mortality. Experiment 2 showed that the detrimental effect of mortality salience on utilitarian conflict judgments was comparable to that of an extreme concurrent cognitive load. These findings raise the question of whether private judgment and public debate about controversial moral issues might be shaped by mortality salience effects, since these issues (e.g., assisted suicide) often involve matters of life and death.}
}
@article{BENTLEY20131240,
title = {Predicting the future: Towards symbiotic computational and experimental angiogenesis research},
journal = {Experimental Cell Research},
volume = {319},
number = {9},
pages = {1240-1246},
year = {2013},
note = {Special Issue: Endothelial Biology},
issn = {0014-4827},
doi = {https://doi.org/10.1016/j.yexcr.2013.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S0014482713000426},
author = {Katie Bentley and Martin Jones and Bert Cruys},
keywords = {Computational modelling, Interdisciplinary, Angiogenesis, Prediction, Simulation},
abstract = {Understanding the fundamental organisational principles underlying the complex and multilayered process of angiogenesis is the mutual aim of both the experimental and theoretical angiogenesis communities. Surprisingly, these two fields have in the past developed in near total segregation, with neither fully benefiting from the other. However, times are changing and here we report on the new direction that angiogenesis research is taking, where from well-integrated collaborations spring new surprises, experimental predictions and research avenues. We show that several successful ongoing collaborations exist in the angiogenesis field and analyse what aspects of their approaches led them to achieve novel and impactful biological insight. We conclude that there are common elements we can learn from for the future, and provide a list of guidelines to building a successful collaborative venture. Specifically, we find that a near symbiosis of computation with experimentation reaps the most impactful results by close cyclical feedback and communication between the two disciplines resulting in continual refinement of models, experimental directions and our understanding. We discuss high impact examples of predictive modelling from the wider, more established integrated scientific domains and conclude that the angiogenesis community can do nothing but benefit from joining this brave new, integrated world.}
}
@article{WANG2014638,
title = {Computational Psychiatry},
journal = {Neuron},
volume = {84},
number = {3},
pages = {638-654},
year = {2014},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2014.10.018},
url = {https://www.sciencedirect.com/science/article/pii/S0896627314009167},
author = {Xiao-Jing Wang and John H. Krystal},
abstract = {Psychiatric disorders such as autism and schizophrenia, arise from abnormalities in brain systems that underlie cognitive, emotional, and social functions. The brain is enormously complex and its abundant feedback loops on multiple scales preclude intuitive explication of circuit functions. In close interplay with experiments, theory and computational modeling are essential for understanding how, precisely, neural circuits generate flexible behaviors and their impairments give rise to psychiatric symptoms. This Perspective highlights recent progress in applying computational neuroscience to the study of mental disorders. We outline basic approaches, including identification of core deficits that cut across disease categories, biologically realistic modeling bridging cellular and synaptic mechanisms with behavior, and model-aided diagnosis. The need for new research strategies in psychiatry is urgent. Computational psychiatry potentially provides powerful tools for elucidating pathophysiology that may inform both diagnosis and treatment. To achieve this promise will require investment in cross-disciplinary training and research in this nascent field.}
}
@article{BAKER2023238,
title = {13Ccarbene nuclear magnetic resonance chemical shift analysis confirms CeIVC double bonding in cerium(iv)–diphosphonioalkylidene complexes††Electronic supplementary information (ESI) available: Computational details. See DOI: https://doi.org/10.1039/d3sc04449a},
journal = {Chemical Science},
volume = {15},
number = {1},
pages = {238-249},
year = {2023},
issn = {2041-6520},
doi = {https://doi.org/10.1039/d3sc04449a},
url = {https://www.sciencedirect.com/science/article/pii/S2041652023058364},
author = {Cameron F. Baker and John A. Seed and Ralph W. Adams and Daniel Lee and Stephen T. Liddle},
abstract = {Diphosphonioalkylidene dianions have emerged as highly effective ligands for lanthanide and actinide ions, and the resulting formal metal–carbon double bonds have challenged and developed conventional thinking about f-element bond multiplicity and covalency. However, f-element–diphosphonioalkylidene complexes can be represented by several resonance forms that render their metal–carbon double bond status unclear. Here, we report an experimentally-validated 13C Nuclear Magnetic Resonance computational assessment of two cerium(iv)–diphosphonioalkylidene complexes, [Ce(BIPMTMS)(ODipp)2] (, BIPMTMS = {C(PPh2NSiMe3)2}2−; Dipp = 2,6-diisopropylphenyl) and [Ce(BIPMTMS)2] (). Decomposing the experimental alkylidene chemical shifts into their corresponding calculated shielding (σ) tensor components verifies that these complexes exhibit CeC double bonds. Strong magnetic coupling of CeC σ/π* and π/σ* orbitals produces strongly deshielded σ11 values, a characteristic hallmark of alkylidenes, and the largest 13C chemical shift tensor spans of any alkylidene complex to date (, 801 ppm; , 810 ppm). In contrast, the phosphonium-substituent shielding contributions are much smaller than the CeC σ- and π-bond components. This study confirms significant Ce 4f-orbital contributions to the CeC bonding, provides further support for a previously proposed inverse-trans-influence in , and reveals variance in the 4f spin–orbit contributions that relate to the alkylidene hybridisation. This work thus confirms the metal–carbon double bond credentials of f-element–diphosphonioalkylidenes, providing quantified benchmarks for understanding diphosphonioalkylidene bonding generally.}
}
@article{KANIZSA198523,
title = {Seeing and thinking},
journal = {Acta Psychologica},
volume = {59},
number = {1},
pages = {23-33},
year = {1985},
issn = {0001-6918},
doi = {https://doi.org/10.1016/0001-6918(85)90040-X},
url = {https://www.sciencedirect.com/science/article/pii/000169188590040X},
author = {G. Kanizsa},
abstract = {According to ratiomorphic theories of perception every visual phenomenon would be the result of unconscious inferences through which the visual system, starting from a set of axioms and premises, reaches certain conclusions (which constitute actually the visual phenomena) by a process analogous to a reasoning process. The author presents some examples from the area of amodal completion which, according to him, hardly support a ratiomorphic theory. Instead they constitute counterexamples that rather support the hypothesis that seeing and thinking function according to different rules.}
}
@article{LEONARDI2018824,
title = {A Method for the computation of entropy in the Recurrence Quantification Analysis of categorical time series},
journal = {Physica A: Statistical Mechanics and its Applications},
volume = {512},
pages = {824-836},
year = {2018},
issn = {0378-4371},
doi = {https://doi.org/10.1016/j.physa.2018.08.058},
url = {https://www.sciencedirect.com/science/article/pii/S0378437118309981},
author = {Giuseppe Leonardi},
keywords = {Recurrence Quantification Analysis, Entropy, Categorical time series, Dynamical measures, Recurrence Plot},
abstract = {In this work, I propose a new method for the computation of informational entropy from Recurrence Plots when the analyzed time series are categorical in nature. In such cases, there is typically a simplification in choosing the parameters of the analysis, in the sense that no embedding in multidimensional space is usually assumed and that recurrence is restricted to exact matching (equivalence) of the numerically coded categories. However, such a simplified parameterization brings about some notable changes in the appearance of the obtained Recurrence Plots, which has consequences for the extraction of the standard dynamical measures. Specifically, a categorical Recurrence Plot is often composed of rectangular structures rather than line structures (diagonal and horizontal/vertical), over which the recurrence quantification measures were originally proposed. Starting from this observation, I consider alternative computational procedures to extract a non-biased measure of entropy for the categorical case, showing the viability of such a choice with simulated data}
}
@article{FARAZI2024103661,
title = {Planning electric vertical takeoff and landing aircraft (eVTOL)-based package delivery with community noise impact considerations},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {189},
pages = {103661},
year = {2024},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2024.103661},
url = {https://www.sciencedirect.com/science/article/pii/S1366554524002527},
author = {Nahid Parvez Farazi and Bo Zou},
keywords = {Advanced air mobility (AAM), eVTOL, Package delivery, Community noise impact, Bi-objective integer programming model, Tailored solution algorithm},
abstract = {The rapid development of Advanced Air Mobility (AAM) in recent years suggests a promise to use electric vertical takeoff and landing aircraft (eVTOLs) for package delivery in metro areas. While eVTOL manufacturers and logistics service providers are actively developing prototype eVTOLs and exploring their potentials for moving freight, a system thinking about the suitability and ways to operate an eVTOL-based package delivery system remains scarce. A key aspect of the system thinking is the noise impact of eVTOL operations on surrounding communities. In this study, we provide an operation planning framework that aims to prepare AAM to be both economically efficient and community friendly for package delivery. We first develop a method to quantify the community noise impact of an eVTOL operation, using a “population exposure” measure which is based on the level of sound generated and accounts for both the number of people impacted and duration of the impact. Then, a bi-objective integer programming model is formulated which simultaneously optimizes total shipping cost and community noise impact of eVTOL operations. The optimization takes into consideration operational constraints including maximum distance for local delivery, latest package departure time from the warehouse, and eVTOL fleet size and carrying capacity. A tailored solution algorithm which augments non-dominated sorting genetic algorithm 2 (NSGA2) with compact solution representation, guided generation of initial population of solutions, and customized local search heuristics is devised. The model and the algorithm are implemented in a case study in the Chicago metro area. Numerical results reveal the trade-off between the minimization of shipping cost and community noise impact. Several operational insights about eVTOL-based package delivery are obtained. The computational efficiency and effectiveness of the proposed solution algorithm are also demonstrated in comparison with alternative solution methods.}
}
@article{MARRA2025102557,
title = {Bridging the gaps in sustainability assessment: A systematic literature review, 2014–2023},
journal = {Evaluation and Program Planning},
volume = {110},
pages = {102557},
year = {2025},
issn = {0149-7189},
doi = {https://doi.org/10.1016/j.evalprogplan.2025.102557},
url = {https://www.sciencedirect.com/science/article/pii/S0149718925000242},
author = {Mita Marra},
keywords = {Sustainability Assessment (SA), Sustainability, Bibliometric analysis, Evaluation Journals},
abstract = {This article highlights recurrent themes and research communities in Sustainability Assessment (SA), a rapidly growing trans-disciplinary area particularly relevant to the global evaluation community. This bibliometric analysis signals the emergence of a substantial research community based in Asia and the Middle East, whose production is distinct from North American and European-centric evaluation studies. While the latter primarily address methodological challenges related to sustainability issues in social policy, organizational capacity building, and public health, the broader SA literature centers on life-cycle assessments to integrate the analysis of environmental and socioeconomic effects in such domains as biodiversity, energy efficiency, urban planning, alternative agriculture, and supply chain management. This mapping exercise highlights the global distribution of research output and identifies existing gaps and potential future cross-fertilization. The transdisciplinary SA literature can draw from theory-based designs attuned to complexity and systems thinking. Policy analysts and evaluators can gain insights from diverse SA perspectives and policy approaches to tackle sustainability challenges more systematically.}
}
@article{YANG2013855,
title = {Computational Optimization, Modelling and Simulation: Recent Trends and Challenges},
journal = {Procedia Computer Science},
volume = {18},
pages = {855-860},
year = {2013},
note = {2013 International Conference on Computational Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2013.05.250},
url = {https://www.sciencedirect.com/science/article/pii/S1877050913003931},
author = {Xin-She Yang and Slawomir Koziel and Leifur Leifsson},
keywords = {algorithm, black-box modelling, computational optimization, optimization algorithm, modelling, metaheursitics, nonlinear optimization, stochastic optimization, surragate-based optimization, simulation ;},
abstract = {Modelling, simulation and optimization form an integrated part of modern design practice in engineering and industry. Tremendous progress has been observed for all three components over the last few decades. However, many challenging issues remain unresolved, and the current trends tend to use nature-inspired algorithms and surrogate-based techniques for modelling and optimization. This 4th workshop on Computational Optimization, Modelling and Simulation (COMS 2013) at ICCS 2013 will further summarize the latest developments of optimization and modelling and their applications in science, engineering and industry. In this review paper, we will analyse the recent trends in modelling and optimization, and their associated challenges. We will discuss important topics for further research, including parameter-tuning, large-scale problems, and the gaps between theory and applications.}
}
@article{YONG2024322,
title = {Students’ perception of non-placement work-integrated learning in chemical engineering: Work-related skills towards the post-pandemic future},
journal = {South African Journal of Chemical Engineering},
volume = {47},
pages = {322-332},
year = {2024},
issn = {1026-9185},
doi = {https://doi.org/10.1016/j.sajce.2023.12.008},
url = {https://www.sciencedirect.com/science/article/pii/S1026918523001270},
author = {Su Ting Yong and Nishanth G. Chemmangattuvalappil and Dominic C.Y. Foo},
keywords = {Non-placement, Work-integrated learning, Virtual communication, Technology usage, Critical thinking, Problem solving},
abstract = {Work-integrated learning (WIL) is a pedagogical activity designed to enhance the integration of theoretical knowledge and practical skills in an authentic context. WIL is typically accomplished through work placement, but a non-placement WIL is potentially promising. In this study, a non-placement WIL programme was incorporated into chemical engineering final year projects. The students worked on industrial problems without a work placement. The purpose of the study was to investigate work-related skills learned in a non-placement WIL programme. A qualitative dominant mixed-methods research approach was adopted. Data was collected using a quantitative questionnaire (n = 69) and a qualitative interview (n = 15). Quantitative findings revealed no significant difference between students working on non-placement WIL and academic projects. However, qualitative findings revealed seven insightful work-related skills in the non-placement WIL: (1) professional relationship with industrial experts and academic supervisors, (2) virtual communication and collaboration, (3) technology skills in the latest industrial software and tools, (4) motivation to undertake novel and challenging industrial problems, (5) creative and innovative strategies, (6) application of higher order thinking skills to model authentic problems, (7) inductive and deductive reasoning. The COVID-19 pandemic has changed how engineers work. Today, it is a necessity to embrace creative problem-solving skills and adopt various types of modern technologies to work effectively and remotely.}
}
@article{MISZTAL2017731,
title = {Invited review: efficient computation strategies in genomic selection},
journal = {Animal},
volume = {11},
number = {5},
pages = {731-736},
year = {2017},
issn = {1751-7311},
doi = {https://doi.org/10.1017/S1751731116002366},
url = {https://www.sciencedirect.com/science/article/pii/S1751731116002366},
author = {I. Misztal and A. Legarra},
keywords = {genomic selection, single-step, genomic relationship matrix, inverse, REML},
abstract = {The purpose of this study is review and evaluation of computing methods used in genomic selection for animal breeding. Commonly used models include SNP BLUP with extensions (BayesA, etc), genomic BLUP (GBLUP) and single-step GBLUP (ssGBLUP). These models are applied for genomewide association studies (GWAS), genomic prediction and parameter estimation. Solving methods include finite Cholesky decomposition possibly with a sparse implementation, and iterative Gauss–Seidel (GS) or preconditioned conjugate gradient (PCG), the last two methods possibly with iteration on data. Details are provided that can drastically decrease some computations. For SNP BLUP especially with sampling and large number of SNP, the only choice is GS with iteration on data and adjustment of residuals. If only solutions are required, PCG by iteration on data is a clear choice. A genomic relationship matrix (GRM) has limited dimensionality due to small effective population size, resulting in infinite number of generalized inverses of GRM for large genotyped populations. A specific inverse called APY requires only a small fraction of GRM, is sparse and can be computed and stored at a low cost for millions of animals. With APY inverse and PCG iteration, GBLUP and ssGBLUP can be applied to any population. Both tools can be applied to GWAS. When the system of equations is sparse but contains dense blocks, a recently developed package for sparse Cholesky decomposition and sparse inversion called YAMS has greatly improved performance over packages where such blocks were treated as sparse. With YAMS, GREML and possibly single-step GREML can be applied to populations with >50 000 genotyped animals. From a computational perspective, genomic selection is becoming a mature methodology.}
}
@article{BAUTISTA2023109,
title = {Acceptance and commitment therapy in parents of children with cancer at psychosocial risk: A randomized multiple baseline evaluation},
journal = {Journal of Contextual Behavioral Science},
volume = {29},
pages = {109-121},
year = {2023},
issn = {2212-1447},
doi = {https://doi.org/10.1016/j.jcbs.2023.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S2212144723000789},
author = {Ana B. Bautista and Francisco J. Ruiz and Juan C. Suárez-Falcón},
keywords = {Acceptance and commitment therapy, Repetitive negative thinking, Childhood cancer, Parents, Single-case experimental design, Psychosocial risk},
abstract = {Developing and testing psychological interventions for primary caregivers of children with cancer at significant psychosocial risk is still needed. One psychological factor contributing to their emotional distress is repetitive negative thinking (RNT). This study conducted a randomized, multiple-baseline evaluation of the effect of an individual, online, 2-session, RNT-focused ACT intervention in 12 parents. Participants responded to daily measures of emotional symptoms, RNT, and progress in values during baseline, intervention, and the 2-month follow-up. These measures have shown adequate psychometric properties at the individual level in this study. All 12 participants completed the intervention. A Bayesian hierarchical model indicated that most participants showed reductions in emotional symptoms and RNT (10 of 11), and 8 of 12 participants showed increases in valued living. The design-comparable standardized mean difference was computed to estimate the intervention effect overall. The effect sizes were large for all variables (PHQ-4: d = 0.83, 95% CI [0.27, 1.40]; RNTQ-3: d = 0.81, 95% CI [0.34, 1.28]; VQ-3: d = 1.07, 95% CI [0.22, 1.91]). Participants evaluated the intervention as useful at the 2-month follow-up. In conclusion, a brief and online RNT-focused intervention showed promising results in parents of children with cancer at significant psychosocial risk.}
}
@article{PATAC2025101301,
title = {Using ChatGPT for academic support: Managing cognitive load and enhancing learning efficiency – A phenomenological approach},
journal = {Social Sciences & Humanities Open},
volume = {11},
pages = {101301},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101301},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125000282},
author = {Louida P. Patac and Adriano V. Patac},
keywords = {Cognitive load theory, ChatGPT, AI in education, Academic support, Mathematics education, Phenomenology},
abstract = {This study aims to discuss the effects of ChatGPT on the management of students' cognitive load and learning outcomes. Participants used ChatGPT for answering particular questions, checking information, and solving complex problems involving equations. Results show that ChatGPT lowers intrinsic and extrinsic cognitive load with very detailed responses and efficient search for information, even though it has difficulties in entering mathematical notation. Students consider that ChatGPT is a tool able to enhance understanding, engage, and promote critical thinking. These findings underline that the level of AI assistance must be balanced against independent learning and critical evaluation.}
}
@article{MATSUMURA2023100689,
title = {Tasks and feedback: An exploration of students’ opportunity to develop adaptive expertise for analytic text-based writing},
journal = {Assessing Writing},
volume = {55},
pages = {100689},
year = {2023},
issn = {1075-2935},
doi = {https://doi.org/10.1016/j.asw.2022.100689},
url = {https://www.sciencedirect.com/science/article/pii/S107529352200085X},
author = {Lindsay Clare Matsumura and Elaine Lin Wang and Richard Correnti and Diane Litman},
keywords = {Feedback, Instruction, Tasks, Text-based writing},
abstract = {In this study, we apply a cognitive theoretical lens to investigate students’ opportunity to develop their analytic text-based writing skills (N = 35 fifth and sixth grade classrooms). Specifically, we examine the thinking demands of classroom text-based writing tasks and teachers’ written feedback on associated student work. Four text-based writing tasks with drafts of associated student work were collected from teachers across a school year. Results of qualitative analyses showed that about half of the classroom text-based writing tasks considered by teachers to be challenging guided students to express analytic thinking about what they read (n = 73). A minority of student work received written feedback focused on students’ use of evidence, expression of thinking, and text comprehension; or received feedback that provided guidance for strategies students could take to meet genre goals. Most teachers provided content-related, instructive, and/or localized feedback on at least one piece of student work. Only a small number of teachers, however, consistently provided content-related, instructive or localized feedback on their students’ essays. Overall, results suggest that students have few opportunities to practice analytic text-based writing and receive feedback that would be expected to advance their conceptual understanding and adaptive expertise for writing in this genre.}
}
@incollection{HARDIN2025519,
title = {Disinformation, Misinformation, and Fake News: The Latest Trends and Issues in Research},
editor = {David Baker and Lucy Ellis},
booktitle = {Encyclopedia of Libraries, Librarianship, and Information Science (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {519-530},
year = {2025},
isbn = {978-0-323-95690-1},
doi = {https://doi.org/10.1016/B978-0-323-95689-5.00171-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780323956895001711},
author = {Greg Hardin},
keywords = {Disinformation, Evaluating sources, Fake news, Information literacy, Malinformation, Misinformation},
abstract = {Information comes in many forms and there are various ways in which false or fabricated information travels throughout the information ecosystem. Fake news, disinformation, misinformation, and malinformation have similarities and differences, but all have in common that they cause harm. Understanding misinformation in all its various forms is key to minimizing the negative effects on individuals and society. While it may be impossible to eradicate misinformation in all its various forms, librarians have a history of and are poised to promote information literacy and critical thinking skills.}
}
@article{LIU2021110585,
title = {Computational insights into electronic characteristics of 2D PtSe2 nanomaterials: Effects of vacancy defects and strain engineering},
journal = {Vacuum},
volume = {194},
pages = {110585},
year = {2021},
issn = {0042-207X},
doi = {https://doi.org/10.1016/j.vacuum.2021.110585},
url = {https://www.sciencedirect.com/science/article/pii/S0042207X21005340},
author = {Guogang Liu and Tong Chen and Zhonghui Xu and Guanghui Zhou and Xianbo Xiao},
keywords = {PtSe, Electronic structure, Defects, Strain engineering},
abstract = {The epitaxial growth of PtSe2 monolayer has brings new opportunities for the application and development of materials science. Using first-principles calculations, the effect of vacancy defects, and strain engineering on the electronic properties of PtSe2 monolayer are systematically investigated. The results show that the Pt single vacancy induces a large magnetic moment of 4.0 μB on PtSe2 monolayer and transforms it from semiconductor to metal. However, the Se single vacancy systems are nonmagnetic and realize the PtSe2 from an indirect semiconductor to a direct one. Moreover, the band gap of PtSe2 monolayer can be prominently modulated within a appreciable uniaxial strain range, and the band gap are monotonically increase/decrease as decrease/increase the magnitude of the compressive/tensile strain. In particular, when a specific strain applied, a wide and high absorption peak across near-infrared, visible light and ultraviolet region. These findings not only enrich the fundamental understanding of PtSe2 monolayer but also provide useful guidance to design PtSe2-based spintronic, optoelectronic and gas sensing applications.}
}
@incollection{BARTHEYE2020385,
title = {Chapter 19 - Human-machine sense making in context-based computational decision},
editor = {William F. Lawless and Ranjeev Mittu and Donald A. Sofge},
booktitle = {Human-Machine Shared Contexts},
publisher = {Academic Press},
pages = {385-398},
year = {2020},
isbn = {978-0-12-820543-3},
doi = {https://doi.org/10.1016/B978-0-12-820543-3.00019-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128205433000195},
author = {Olivier Bartheye and Laurent Chaudron},
keywords = {Human/machine sense making, Knowledge processing, Decision mechanism, Causal break, Hopf algebras, Computational contexts, Continuous inference},
abstract = {In this chapter, we present what should be the inner structure of a decision algebra whose motivation is to fill a causal break induced by context invalidity to ultimately permit human-machine interactions. It turns out that such a decision structure can be qualified using the context change arrow as a disruptive process or as a phase transition according to the geometrical representation of computational contexts as double S-curves. In particular a computational context is always characterized by a shift between sense making and temporal causality. That is, once a causal break occurs, it has to be filled locally by a decision. A causal break is always continuous and never discrete; in effect, in the discrete case, combinatoric analysis causes unwanted complexity due to a lack of knowledge, whereas we need full knowledge thanks to a very precise semantic of a causal break. Intuitively, rather than separating brutally models and counter-models as a proof can do by setting a strong negation operator, we prefer to use the continuous inference as an implementation of sense making. Sense is that way taken as the rationality of the transition. Full knowledge requires a special structure, a Hopf algebra in which the continuous property we cannot implement is replaced by the computable co-continuous property in the co-algebraic component of the decision Hopf algebra. We hope that thanks to co-continuous structures and to co-dimensional exterior algebras, we’ll be able to find out a representation of the continuous inference able to compute a decision rather than admitting definitely and desperately that “such a mechanism is totally out of bounds” and will never ever concern a machine.}
}
@incollection{PENN2006338,
title = {Symbolic Computational Linguistics: Overview},
editor = {Keith Brown},
booktitle = {Encyclopedia of Language & Linguistics (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {338-352},
year = {2006},
isbn = {978-0-08-044854-1},
doi = {https://doi.org/10.1016/B0-08-044854-2/00875-0},
url = {https://www.sciencedirect.com/science/article/pii/B0080448542008750},
author = {G. Penn},
keywords = {computational linguistics, concept ontologies, lambda calculus, logic, phrase structure trees, typed feature structures},
abstract = {Symbolic computational linguistics is a diverse body of research that uses logical, graphical and other discrete mathematical representations to model structure and meaning at the various levels of linguistic investigation. This article provides an informal introduction to these representations, along with a discussion of their applications.}
}
@article{CAMACHOLIE202435,
title = {Development of basic thermodynamics workshops integrating a cubic equations of state simulator and MATLAB Grader courses},
journal = {Education for Chemical Engineers},
volume = {49},
pages = {35-54},
year = {2024},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2024.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S1749772824000228},
author = {Mariola Camacho-Lie and Rodrigo Alberto Hernández-Ochoa and Adriana Palacios},
keywords = {Teaching of thermodynamics, Digital tools in education, Deep learning, Constructive Alignment, Preparation for Future Learning, Productive Failure},
abstract = {This paper describes the development of EoS Simulator, a cubic equations of state simulator created in the MATLAB R2022b App Designer platform, which aims to be a practical digital tool for chemical engineering students that facilitates the solution, analysis, and critical thinking about thermodynamic problems. In the simulator, numerical algorithms were implemented based on a theoretical framework, such as fugacity test, bracketing methods, and the calculation of residual properties. EoS Simulator can estimate two-phase envelopes, isobars, isotherms, and surfaces related to PTVHS properties. MATLAB Grader courses were proposed to test student learning using the software in two different workshops. The evaluation was based on the achievement of tasks related to intended learning outcomes. Survey responses about the simulator and learning environment were collected, concluding that most students improved their skills in understanding thermodynamics phenomena, but some improvements are necessary for future versions of the software and online courses.}
}
@article{LEONELLI201229,
title = {Re-thinking organisms: The impact of databases on model organism biology},
journal = {Studies in History and Philosophy of Science Part C: Studies in History and Philosophy of Biological and Biomedical Sciences},
volume = {43},
number = {1},
pages = {29-36},
year = {2012},
note = {Data-Driven Research in the Biological and Biomedical Sciences On Nature and Normativity: Normativity, Teleology, and Mechanism in Biological Explanation},
issn = {1369-8486},
doi = {https://doi.org/10.1016/j.shpsc.2011.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S1369848611000793},
author = {Sabina Leonelli and Rachel A. Ankeny},
keywords = {Database, Data, Model organism, Data-intensive science, Curator},
abstract = {Community databases have become crucial to the collection, ordering and retrieval of data gathered on model organisms, as well as to the ways in which these data are interpreted and used across a range of research contexts. This paper analyses the impact of community databases on research practices in model organism biology by focusing on the history and current use of four community databases: FlyBase, Mouse Genome Informatics, WormBase and The Arabidopsis Information Resource. We discuss the standards used by the curators of these databases for what counts as reliable evidence, acceptable terminology, appropriate experimental set-ups and adequate materials (e.g., specimens). On the one hand, these choices are informed by the collaborative research ethos characterising most model organism communities. On the other hand, the deployment of these standards in databases reinforces this ethos and gives it concrete and precise instantiations by shaping the skills, practices, values and background knowledge required of the database users. We conclude that the increasing reliance on community databases as vehicles to circulate data is having a major impact on how researchers conduct and communicate their research, which affects how they understand the biology of model organisms and its relation to the biology of other species.}
}
@article{SNIDER2021108795,
title = {Reinforcer pathology in cocaine use disorder: Temporal window determines cocaine valuation},
journal = {Drug and Alcohol Dependence},
volume = {225},
pages = {108795},
year = {2021},
issn = {0376-8716},
doi = {https://doi.org/10.1016/j.drugalcdep.2021.108795},
url = {https://www.sciencedirect.com/science/article/pii/S0376871621002908},
author = {Sarah E. Snider and Jamie K. Turner and Samuel M. McClure and Warren K. Bickel},
keywords = {Reinforcer pathology, Experimental medicine approach, Episodic future thinking, Delay discounting, Behavioral economic demand, Cocaine use disorder},
abstract = {Aims
The Experimental Medicine Approach offers a unique perspective to determine clinical behavior change by engaging a target underlying the cause of a disorder. The present work engaged a novel target of addiction, Reinforcer Pathology, in two studies to test changes in behavior among individuals with cocaine use disorder.
Methods
In Study 1, n = 44 participants engaged the temporal window with episodic future thinking (EFT), a positive prospection exercise. Changes in temporal view and cocaine valuation were tested using delay discounting and behavioral economic demand, respectively. Additionally, a computational model assessed the relative reliance on the near- and far-sighted systems during EFT. In Study 2, n = 71 engaged the temporal window with a negatively-valenced hurricane scenario to test the opposite effects on window length and cocaine valuation.
Results
Results demonstrated systematic and symmetrical engagement of the behavioral target. Study 1 robustly replicated previous work, wherein EFT lengthened the temporal window and decreased cocaine valuation. Moreover, EFT increased the weighting of the modeled far-sighted system, increasing the relative impact of long-term discounting decisions. Study 2 produced opposite outcomes, shortened temporal window and increased cocaine valuation.
Conclusions
This approximately equal and opposite reaction to the manipulations supports reinforcer pathology theory and implicates the temporal window over which rewards are valued as a target to be pushed and pulled to produce clinically meaningful behavior change. Using the Experimental Medicine Approach as a guide, future work should identify new potential interventions to engage reinforcer pathology and use the clinically relevant outcomes as a litmus test for mechanism.}
}

@article{MA201542,
title = {Towards computational models of animal cognition, an introduction for computer scientists},
journal = {Cognitive Systems Research},
volume = {33},
pages = {42-69},
year = {2015},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2014.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S1389041714000357},
author = {Zhanshan (Sam) Ma},
keywords = {Animal cognition, Cognitive ecology, Social learning, Bioinspired computing and communication, Behavioral informatics, Computational behavior biology},
abstract = {The last few years of the twentieth century witnessed the emerging convergence of biology and computer science and this trend has been accelerating since then. The study of animal behavior or behavior biology has been one of the major contributors for this convergence. Behavior is fascinating because it is the response of an organism to internal and external signals and it is controlled by complex interactions among nerves, the sensory and the motor systems. To some extent, behavior is similar to the output (or response) of a computer system or a network node if we consider an animal brain as a computer node. This paper is the first in a two-part series in which I review the state-of-the-art research in behavior biology inspired computing and communication, with the first part focusing on animal cognition and the second part on animal communication (Ma, 2014). The present article also assumes the task of presenting a general introduction on behavior biology literature, which sets a foundation for synthesizing both parts of the series but the synthesis will be performed in the second part of the series. I sets three objectives in this ‘cognition’ part: (i) to present a brief overview on the literature of behavior biology for computer scientists; (ii) to summarize the state-of-the-art studies in several cognitive aspects of animal behavior: focusing on emerging research in cognitive ecology, social learning and innovation, as well as animal logics; (iii) to review some important existing studies inspired by animal behavior and further present a perspective on the future research. These cognition-related topics offer insights for research fields such as machine learning, human computer interactions (HCI), brain computer interfaces (BCIs), evolutionary computing, pervasive computing, etc. In perspective, I suggest that the interaction between behavioral biology and computer science should be bidirectional, and a new subject, behavioral informatics, or more general computational behavior biology, should be developed by the cooperative efforts between biologists and computer scientists.}
}
@incollection{GALLEGATI20173,
title = {Chapter 1 - An Introduction to Agent-Based Computational Macroeconomics},
editor = {Mauro Gallegati and Antonio Palestrini and Alberto Russo},
booktitle = {Introduction to Agent-Based Economics},
publisher = {Academic Press},
pages = {3-11},
year = {2017},
isbn = {978-0-12-803834-5},
doi = {https://doi.org/10.1016/B978-0-12-803834-5.00002-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128038345000023},
author = {Mauro Gallegati and Antonio Palestrini and Alberto Russo}
}
@article{LOONG2014237,
title = {Tourism and Simulacrum: The Computational Economy of Algorithmic Destinations},
journal = {Procedia - Social and Behavioral Sciences},
volume = {144},
pages = {237-246},
year = {2014},
note = {5th Asia-Euro Conference 2014 in Tourism, Hospitality & Gastronomy},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2014.07.292},
url = {https://www.sciencedirect.com/science/article/pii/S1877042814042207},
author = {Bernard Lew Shian Loong},
keywords = {gamified tourism, algorithmic destinations, simulacrum, computational economics, tourism computability, reflexivity},
abstract = {The paper establishes a conceptual and methodological link between destinations and simulacrum through gamified tourism. As a paradigm, gamified tourism provides a rationale and a setting within which to apply computational economics to tourism, an approach amounting to tourism computability. Algorithmic destinations serve as “petri dishes” for real destinations. Utilizing rule sets that embody destination growth dynamics and visitor behavioural norms, seeding points in a cellular automata model (CA) were grown into algorithmic destinations. This is followed by a morphological transformation of geo-tagged satellite images into spatial points. The overlap of this additive and subtractive approach is at the core of tourism computability. Finally, the spatio-temporal dynamics of economic resilience was traced out through a visual phenomenology of algorithmic destinations. The gamification of tourism should be embraced as it holds up a flicker of hope for mature destinations, amidst the onset of museumification and increased commoditization of heritage sites. Gamification is treated as part of the reflexive cycle for destination authenticity; a notion that that Cohen (1988) alluded to in his discussion of emergent authenticity in destination image formation. Seen in this light, the museumification of Venice and the proliferation of its simulacrum, such as the Venetian Hotel in Macao and Venice-themed hotels across the globe, are prefigures and archetypes of a glorious age of gamified tourism.}
}
@article{NAKHLEH2013719,
title = {Computational approaches to species phylogeny inference and gene tree reconciliation},
journal = {Trends in Ecology & Evolution},
volume = {28},
number = {12},
pages = {719-728},
year = {2013},
issn = {0169-5347},
doi = {https://doi.org/10.1016/j.tree.2013.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S0169534713002139},
author = {Luay Nakhleh},
abstract = {An intricate relation exists between gene trees and species phylogenies, due to evolutionary processes that act on the genes within and across the branches of the species phylogeny. From an analytical perspective, gene trees serve as character states for inferring accurate species phylogenies, and species phylogenies serve as a backdrop against which gene trees are contrasted for elucidating evolutionary processes and parameters. In a 1997 paper, Maddison discussed this relation, reviewed the signatures left by three major evolutionary processes on the gene trees, and surveyed parsimony and likelihood criteria for utilizing these signatures to elucidate computationally this relation. Here, I review progress that has been made in developing computational methods for analyses under these two criteria, and survey remaining challenges.}
}
@article{OISHI2017327,
title = {Computational mechanics enhanced by deep learning},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {327},
pages = {327-351},
year = {2017},
note = {Advances in Computational Mechanics and Scientific Computation—the Cutting Edge},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2017.08.040},
url = {https://www.sciencedirect.com/science/article/pii/S0045782517306199},
author = {Atsuya Oishi and Genki Yagawa},
keywords = {Deep learning, Artificial neural network, Numerical quadrature, Element stiffness matrix},
abstract = {The present paper describes a method to enhance the capability of, or to broaden the scope of computational mechanics by using deep learning, which is one of the machine learning methods and is based on the artificial neural network. The method utilizes deep learning to extract rules inherent in a computational mechanics application, which usually are implicit and sometimes too complicated to grasp from the large amount of available data A new method of numerical quadrature for the FEM stiffness matrices is developed by using the proposed method, where a kind of optimized quadrature rule superior in accuracy to the standard Gauss–Legendre quadrature is obtained on the element-by-element basis. The detailed formulation of the proposed method is given with the sample application above, and an acceleration technique for the proposed method is discussed}
}
@article{GU2024825,
title = {Enhancing campus OS community engagement through the miniOS pilot class: A nine-year journey},
journal = {Future Generation Computer Systems},
volume = {160},
pages = {825-834},
year = {2024},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2024.06.011},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X24003042},
author = {Jianhua Gu and Mingxuan Liu and Tianhai Zhao},
keywords = {Community engagement, Software engineering education, Operating system, Software engineering management},
abstract = {Recognized as the crown jewel of system software, Operating System (OS) is notoriously challenging to teach and learn, given its abstract concepts, broad scope, and the imperative for hands-on experience. How to cater to the keen interest in OS among students across all universities while providing a rich system software engineering experience? Engaging the OS community on campus plays a pivotal role in enhancing undergraduate education. Our institution has implemented a novel approach over the past nine years through the miniOS pilot class initiative. This program allows students enrolled in the OS course to opt into an additional, practical component where they engage in developing the OS kernel using miniOS, our teaching platform. Participants dedicate their spare time to a series of labs aimed at incrementally introducing them to miniOS, collaborate on a project to add a new functional module to miniOS, and ultimately present their work in a formal defense. This hands-on experience supplements the theoretical coursework, with the notable advantage that pilot class participants are exempt from the traditional final exam. Instead, their grade is determined by their contributions to the pilot class, with distinguished projects being integrated into the evolving miniOS kernel—a witness to the collective effort of each class. Since its inception in 2015, the miniOS pilot class has nurtured 182 undergraduates and 22 graduate students, contributing significantly to the OS community engagement on campus. Through this initiative, we have gleaned six key insights and six lessons, which we are eager to share with the broader educational community.}
}
@article{ARDALAN2018170,
title = {Neurofinance versus the efficient markets hypothesis},
journal = {Global Finance Journal},
volume = {35},
pages = {170-176},
year = {2018},
issn = {1044-0283},
doi = {https://doi.org/10.1016/j.gfj.2017.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S1044028317302715},
author = {Kavous Ardalan},
keywords = {Neurofinance, Behavioral finance, Costly thinking, Efficient markets hypothesis},
abstract = {This paper develops the implication of neurofinance with respect to the efficient markets hypothesis. Neurofinance informs us that thinking imposes strain on the mind, in the sense that thinking is a comparatively laborious, biologically costly, and neurologically expensive cognitive process. The paper shows that people balance the costs and benefits of thinking and demonstrates mathematically that such balancing makes financial markets inefficient.}
}
@article{WANG20241359,
title = {On Metaphor Translation into English Based on Artificial Intelligence},
journal = {Procedia Computer Science},
volume = {247},
pages = {1359-1365},
year = {2024},
note = {The 11th International Conference on Applications and Techniques in Cyber Intelligence},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.162},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924029636},
author = {Zikang Wang and Jinlian Chai},
keywords = {Artificial intelligence, English translation of metaphor, Machine translation},
abstract = {As a rhetorical device, metaphor plays an instrumental role in facilitating human thinking, cognition and communication. The translation of metaphors into English represents a significant challenge, involving cross-cultural, cross-linguistic and cross-domain considerations. In recent years, the rapid development of artificial intelligence has provided a new method and approach for English metaphor translation. This article mainly discusses the basic concept of artificial intelligence, puts forward the key technologies of metaphor translation in artificial intelligence, and then analyzes the difficulties and methods of metaphor translation with the purpose of providing a reference point and helpful insights.}
}
@incollection{PERRI202255,
title = {Chapter 4 - High-performance computing and computational intelligence applications with a multi-chaos perspective},
editor = {Yeliz Karaca and Dumitru Baleanu and Yu-Dong Zhang and Osvaldo Gervasi and Majaz Moonis},
booktitle = {Multi-Chaos, Fractal and Multi-Fractional Artificial Intelligence of Different Complex Systems},
publisher = {Academic Press},
pages = {55-76},
year = {2022},
isbn = {978-0-323-90032-4},
doi = {https://doi.org/10.1016/B978-0-323-90032-4.00010-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780323900324000109},
author = {Damiano Perri and Marco Simonetti and Osvaldo Gervasi and Sergio Tasso},
keywords = {Cloud computing, Computational intelligence, Container, High performance computing, Machine learning, Multi-chaos, Neural networks, Privacy, Quantum computing},
abstract = {The experience of the COVID-19 pandemic, which has accelerated many chaotic processes in modern society, has highlighted in a very serious and urgent way the need to understand complex processes in order to achieve the common well-being. Modern high performance computing technologies, quantum computing, computational intelligence are shown to be extremely efficient and useful in safeguarding the fate of mankind. These technologies are the state-of-the-art of IT evolution and are fundamental to be competitive and efficient today. If a company is familiar with these techniques and technologies, it will be able to deal with any unexpected and complicated scenarios more efficiently and effectively. The main contribution of our work is a set of best practices and case studies that can help the researcher address computationally complex problems. We offer a range of software technologies, from high performance computing to machine learning and quantum computing, which represent today the state-of-the-art to deal with extremely complex computational issues, driven by chaotic events and not easily predictable. In this chapter we analyze the different technologies and applications that will lead mankind to overcome this difficult moment as well as to understand more and more deeply the profound aspects of very complex phenomena. In this environment of rising complexity, in terms of technology, algorithms, and changing lifestyles, it is critical to emphasize the importance of achieving maximum efficiency and outcomes while protecting the integrity of everyone's personal data and respecting the human being as a whole.}
}
@article{MATENCIO2021129639,
title = {A physicochemical, thermodynamical, structural and computational evaluation of kynurenic acid/cyclodextrin complexes},
journal = {Food Chemistry},
volume = {356},
pages = {129639},
year = {2021},
issn = {0308-8146},
doi = {https://doi.org/10.1016/j.foodchem.2021.129639},
url = {https://www.sciencedirect.com/science/article/pii/S0308814621006452},
author = {Adrián Matencio and Fabrizio Caldera and Alberto {Rubin Pedrazzo} and Yousef {Khazaei Monfared} and Nilesh {K. Dhakar} and Francesco Trotta},
keywords = {Kynurenic acid, Cyclodextrin, Inclusion complex, Physicochemical, Stability},
abstract = {In this work, the interaction between Kynurenic acid (KYNA) and several natural and modified cyclodextrins (CDs) is carried out. Among all the CD tested, HPβ-CD showed the strongest complexation constant (KF), with a value of 270.94 ± 29.80 M−1. Between natural (α- and β-) CDs, the complex of KYNA with β-CD was the most efficient. The inclusion complex of KYNA with CDs showed a strong influence of pH and temperature. The KF value decreased at high pH values, when the pKa was passed. Moreover, an increase of the temperature caused a decrease in the KF values. The thermodynamic parameters of the complexation (ΔH°, ΔS° and ΔG°) were studied with negative entropy, enthalpy and spontaneity of the process at 25 °C. Moreover, the inclusion complex was also characterized using FTIR and TGA. Finally, molecular docking calculations provided different interactions and their influence in the complexation constant.}
}
@article{ZHAN2022100096,
title = {The effectiveness of gamification in programming education: Evidence from a meta-analysis},
journal = {Computers and Education: Artificial Intelligence},
volume = {3},
pages = {100096},
year = {2022},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2022.100096},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X22000510},
author = {Zehui Zhan and Luyao He and Yao Tong and Xinya Liang and Shihao Guo and Xixin Lan},
keywords = {Programming education, Gamification, Meta-analysis, Game-based learning},
abstract = {This paper aimed at constructing a systematic framework and examining the effect of gamification in programming education through a meta-analysis conducted on 21 empirical studies published in the last decade. We examined the effects of game types, gamification applications, pedagogical agents, programming types, and schooling levels on students' academic achievement, cognitive load, motivation, and thinking skills in programming education by cross-tabulation analysis. Results verified the positive impact of gamification in programming education. Gamification has the largest effect on students' motivation, followed by academic achievement, whereas it has the least effect on students' cognitive load. As for game types, the reasoning strategy game is most effective on academic achievement, while the puzzle game is most effective on motivation. As for gamification application, the games as a competitive mechanism has the greatest impact on students’ thinking skills and motivation. However, when games were adopted as teaching tools or student works, the effects are mainly represented in academic achievement. Pedagogical agents have a limited effect on programming education. With regard to programming types, the effect of gamification is more pronounced in text-based programming rather than graphical programming. This study provided an analytic framework and shed light on potential directions for further studies in the field.}
}
@article{WANG2007126,
title = {Nature-inspired Computation — Effective Realization of Artificial Intelligence},
journal = {Systems Engineering - Theory & Practice},
volume = {27},
number = {5},
pages = {126-134},
year = {2007},
issn = {1874-8651},
doi = {https://doi.org/10.1016/S1874-8651(08)60034-4},
url = {https://www.sciencedirect.com/science/article/pii/S1874865108600344},
author = {Lei WANG and Qi KANG and Qi-di WU},
keywords = {nature-inspired computation, general mode, uniform framework mode, neural networks, swarm intelligence},
abstract = {In nature-inspired computation, different intelligent computation modes of agents usually have different extrinsic forms; but can they take on some relative uniform characteristics? To validate this idea, further systematic study on nature-inspired computation from a more macroscopical angle is made in this article and the uniform framework mode of nature-inspired computation is consequently summarized and presented, as well as described with feedback neural network and swarm intelligence algorithms. On the basis of the defined general mode framework, agents of the algorithms in a nature-inspired computation field can show a type of uniform intelligent computation mode.}
}
@article{SU2021100862,
title = {Is the Text-Based Cognitive Tool More Effective Than the Concept Map on Improving the Pre-Service Teachers’ Argumentation Skills?},
journal = {Thinking Skills and Creativity},
volume = {41},
pages = {100862},
year = {2021},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2021.100862},
url = {https://www.sciencedirect.com/science/article/pii/S1871187121000778},
author = {Guo Su and Taotao Long},
keywords = {Argumentation skills, cognitive tools, pre-service teachers},
abstract = {How to improve pre-service teachers’ argumentation skills has been receiving more and more attention from teacher educators. Visual cognitive tool refers to tools which users can learn with and creatively use to construct knowledge online. Current research revealed that it could help to improve learners’ higher-order thinking skills. This experimental study aimed to investigate the effect of two kinds of cognitive tools, the text-based online visual cognitive tool and the visual concept map, on improving the pre-service teachers’ skills on constructing and evaluating arguments. Post-test argumentation measurement scores and attitude questionnaire showed that the text-based cognitive tool was more effective than the concept map on improving pre-service teachers’ argumentation skills. However, the concept map was useful for externalizing the pre-service teachers’ thinking process as well as collaborative learning. This study also found that the pre-service teachers with teaching experience were inferior to the ones without any teaching experience in the ability on constructing arguments.}
}
@article{IBARRATORRES2024413,
title = {Use of basic programming tools to foster programming logic in university students with school preparation other than computer science},
journal = {Procedia Computer Science},
volume = {237},
pages = {413-419},
year = {2024},
note = {International Conference on Industry Sciences and Computer Science Innovation},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.05.122},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924011384},
author = {Fernando Ibarra-Torres and Gustavo Caiza and Marcelo V. García and Valeria Barona-Pico},
keywords = {Programming logic, programming tools, software development, undergraduate student},
abstract = {Teaching programming logic to students who do not have a background in computer science is challenging, as the instructor has to awaken problem-solving, critical thinking, and logical reasoning skills Several programming tools have been created to teach coding concepts to computer science students of different ages. However, these tools are not well designed to meet the challenge of teaching programming to new developers who come with school training in other areas such as accounting, management, etc. Therefore, this research focused on analyzing the importance of the application of online programming tools to students starting college who come with a school background in an area other than technology. A pre/post experimental design was carried out with 82 first-level students of the Technical University of Ambato in the careers of Systems and Electronics. The results revealed that 45% of the students increased their levels of application and analysis in programming processes. In addition, the research revealed that students who come from a background other than computer science agree with the integration of online programming tools from the first level of university entrance since this method helps to improve their learning capacity.}
}
@article{KORIYAMA2021458,
title = {Inclusive cognitive hierarchy},
journal = {Journal of Economic Behavior & Organization},
volume = {186},
pages = {458-480},
year = {2021},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2021.04.016},
url = {https://www.sciencedirect.com/science/article/pii/S0167268121001578},
author = {Yukio Koriyama and Ali I. Ozkes},
keywords = {Cognitive hierarchy, Collective decision-making, Level- model, Strategic thinking},
abstract = {Cognitive hierarchy theory, a collection of structural models of non-equilibrium thinking, in which players’ best responses rely on heterogeneous beliefs on others’ strategies including naïve behavior, proved powerful in explaining observations from a wide range of games. We propose an inclusive cognitive hierarchy model, in which players do not rule out the possibility of facing opponents at their own thinking level. Our theoretical results show that inclusiveness is crucial for asymptotic properties of deviations from equilibrium behavior in expansive games. We show that the limiting behaviors are categorized in three distinct types: naïve, Savage rational with inconsistent beliefs, and sophisticated. We test the model in a laboratory experiment of collective decision-making. The data suggests that inclusiveness is indispensable with regard to explanatory power of the models of hierarchical thinking.}
}
@article{DALLACHIARA201894,
title = {A many-valued approach to quantum computational logics},
journal = {Fuzzy Sets and Systems},
volume = {335},
pages = {94-111},
year = {2018},
note = {Special Issue: Selected Papers from the 36th Linz Seminar on Fuzzy Set Theory},
issn = {0165-0114},
doi = {https://doi.org/10.1016/j.fss.2016.12.015},
url = {https://www.sciencedirect.com/science/article/pii/S0165011416304560},
author = {M.L. {Dalla Chiara} and R. Giuntini and G. Sergioli and R. Leporini},
keywords = {Quantum logics, Quantum tomography, Logical gates},
abstract = {Quantum computational logics are special examples of quantum logic where formulas are supposed to denote pieces of quantum information (qubit-systems or mixtures of qubit-systems), while logical connectives are interpreted as reversible quantum logical gates. Hence, any formula of the quantum computational language represents a synthetic logical description of a quantum circuit. We investigate a many-valued approach to quantum information, where the basic notion of qubit has been replaced by the more general notion of qudit. The qudit-semantics allows us to represent as reversible gates some basic logical operations of Łukasiewicz many-valued logics. In the final part of the article we discuss some problems that concern possible implementations of gates by means of optical devices.}
}
@incollection{LAWSON1990108,
title = {9 - Creative thinking},
editor = {Bryan Lawson},
booktitle = {How Designers Think (Second Edition)},
publisher = {Butterworth-Heinemann},
edition = {Second Edition},
pages = {108-120},
year = {1990},
isbn = {978-0-7506-0268-6},
doi = {https://doi.org/10.1016/B978-0-7506-0268-6.50013-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780750602686500139},
author = {Bryan Lawson},
abstract = {Publisher Summary
This chapter discusses creative thinking in design. Design is a creative occupation, and good designers are creative people. One of the most vexing and perennial questions in design education concerns the balance between the free, open-ended, and expressive work demanded of the student and attention to the acquisition of knowledge, discipline, and experience. The effects of experience on problem solving are not always beneficial. In industry, the need to improve already successful products provides the ultimate test of creative thinking. When using personal analogy, the problem solver identifies personally with some part of the problem or solution, thus acting out the situation. Fantasy analogy allows the designer to suspend the sense of credulity and to explore the seemingly fantastic or impossible. Creativity is not only skill or talent but is also related to context—the situation within which the person perceives the problem and performs the process.}
}
@article{MYERSCOUGH2014e143,
title = {Tracking the development of atherosclerosis in silico: a computational model for early inflammatory events},
journal = {Atherosclerosis},
volume = {235},
number = {2},
pages = {e143},
year = {2014},
issn = {0021-9150},
doi = {https://doi.org/10.1016/j.atherosclerosis.2014.05.404},
url = {https://www.sciencedirect.com/science/article/pii/S0021915014006406},
author = {M. Myerscough and A. Chalmers}
}
@article{PERFORS2012486,
title = {When do memory limitations lead to regularization? An experimental and computational investigation},
journal = {Journal of Memory and Language},
volume = {67},
number = {4},
pages = {486-506},
year = {2012},
issn = {0749-596X},
doi = {https://doi.org/10.1016/j.jml.2012.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S0749596X12000800},
author = {Amy Perfors},
keywords = {Regularization, Less is More, Computational modeling, Language acquisition},
abstract = {The Less is More hypothesis suggests that one reason adults and children differ in their ability to learn language is that they also differ in other cognitive capacities. According to one version of this hypothesis, children’s relatively poor memory may make them more likely to regularize inconsistent input (Hudson Kam and Newport, 2005, Hudson Kam and Newport, 2009). This paper reports the result of an experimental and computational investigation of one aspect of this version of the hypothesis. A series of seven experiments in which adults were placed under a high cognitive load during a language-learning task reveal that in adults, increased load during learning (as opposed to retrieval) does not result in increased regularization. A computational model offers a possible explanation for these results. It demonstrates that, unless memory limitations distort the data in a particular way, regularization should occur only in the presence of both memory limitations and a prior bias for regularization. Taken together, these findings suggest that the difference in regularization between adults and children may not be solely attributable to differences in memory limitations during learning.}
}
@article{KARPOVA2016v,
title = {Editorial overview: Neurobiology of cognitive behavior: Complexity of neural computation and cognition},
journal = {Current Opinion in Neurobiology},
volume = {37},
pages = {v-viii},
year = {2016},
note = {Neurobiology of cognitive behavior},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2016.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S0959438816300125},
author = {Alla Karpova and Roozbeh Kiani}
}
@article{SUN200912529,
title = {A computational model of an intuitive reasoner for ecosystem control},
journal = {Expert Systems with Applications},
volume = {36},
number = {10},
pages = {12529-12536},
year = {2009},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2009.04.037},
url = {https://www.sciencedirect.com/science/article/pii/S0957417409003686},
author = {Yung-Chien Sun and Grant Clark},
keywords = {Artificial Intelligence, Intuition, Knowledge acquisition, Limited certainty},
abstract = {Intuition is the human capacity to make decisions under novel, complex situations where knowledge is incomplete and of variable levels of certainty. We take the view that intuition can be modeled as a rational and deductive mode of information processing which is suited to novel, complex situations. In this research, a computational algorithm, or “intuitive reasoner”, is proposed which mimics some aspects of human intuition by combining established mathematical tools, such as fuzzy set theory, and some novel innovations. A rule-based scheme is followed and a rule-learning module that allows rules to be learned from incomplete datasets is developed. The input and the rules drawn by the reasoner are allowed to be fuzzy, multi-valued, and low in certainty. A measure of the certainty level, Strength of Belief, is attached to each input as well as each rule. Solutions are formulated through iterations of consolidating intermediate reasoning results, during which the Strength of Belief of corroborating intermediate results is combined. An experimental implementation of the proposed intuitive reasoner is reported, in which the reasoner was used to solve a classification problem. The results showed that, when given increasingly sparse input data, the rule-learning module generated more rules of lower associated certainty than when presented with more complete data. The intuitive reasoner was able to make use of these low-certainty rules to solve the classification problems with an accuracy that compared favorably to that of traditional methods based on complete datasets.}
}
@article{DEHOLLANDER2016101,
title = {Different Ways of Linking Behavioral and Neural Data via Computational Cognitive Models},
journal = {Biological Psychiatry: Cognitive Neuroscience and Neuroimaging},
volume = {1},
number = {2},
pages = {101-109},
year = {2016},
issn = {2451-9022},
doi = {https://doi.org/10.1016/j.bpsc.2015.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S2451902215000166},
author = {Gilles {de Hollander} and Birte U. Forstmann and Scott D. Brown},
keywords = {Cognition, Computational models, Functional neuroimaging, Joint modeling, Linking, Mathematical models},
abstract = {Cognitive neuroscientists sometimes apply formal models to investigate how the brain implements cognitive processes. These models describe behavioral data in terms of underlying, latent variables linked to hypothesized cognitive processes. A goal of model-based cognitive neuroscience is to link these variables to brain measurements, which can advance progress in both cognitive and neuroscientific research. However, the details and the philosophical approach for this linking problem can vary greatly. We propose a continuum of approaches that differ in the degree of tight, quantitative, and explicit hypothesizing. We describe this continuum using four points along it, which we dub qualitative structural, qualitative predictive, quantitative predictive, and single model linking approaches. We further illustrate by providing examples from three research fields (decision making, reinforcement learning, and symbolic reasoning) for the different linking approaches.}
}
@article{TRNKOVA2019106900,
title = {Rigorous computations with an approximate Dirichlet domain},
journal = {Topology and its Applications},
volume = {268},
pages = {106900},
year = {2019},
issn = {0166-8641},
doi = {https://doi.org/10.1016/j.topol.2019.106900},
url = {https://www.sciencedirect.com/science/article/pii/S0166864119303116},
author = {Maria Trnková},
keywords = {Length spectrum, Dirichlet domain, Hyperbolic 3-manifold},
abstract = {In this paper we address some problems concerning an approximate Dirichlet domain. We show that under some assumptions an approximate Dirichlet domain can work equally well as an exact Dirichlet domain. In particular, we consider a problem of tiling a hyperbolic ball with copies of the Dirichlet domain. This problem arises in the construction of the length spectrum algorithm which is implemented by the computer program SnapPea. Our result explains the empirical fact that the program works surprisingly well despite it does not use exact data. Also we demonstrate a rigorous verification whether two words of the fundamental group of a hyperbolic 3-manifold are the same or not.}
}
@article{MARUYAMA1987437,
title = {New economic thinking: Morphogenetic causal loops and product adaptation strategy},
journal = {Futures},
volume = {19},
number = {4},
pages = {437-441},
year = {1987},
issn = {0016-3287},
doi = {https://doi.org/10.1016/0016-3287(87)90005-X},
url = {https://www.sciencedirect.com/science/article/pii/001632878790005X},
author = {Magoroh Maruyama},
abstract = {This article sets out to dispel two widespread economic superstitions—the belief in an inherent equilibrium of the economic system, and the perception of international trade as a zero-sum game. The author argues that morphogenetic causal loops disprove the first assumption, and should be used to aid policy making; and that positive-sum results could be obtained by lifting import restrictions and adapting products for foreign markets.}
}
@article{LEE2024107,
title = {Project-Based Learning Course Design for Multi-Agent Autonomy Using Quadrotors⁎⁎This group design project of academic year 2023/24 has been sponsored by Leonardo S.p.A.},
journal = {IFAC-PapersOnLine},
volume = {58},
number = {16},
pages = {107-112},
year = {2024},
note = {2nd IFAC Workshop on Aerospace Control Education - WACE 2024},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2024.08.470},
url = {https://www.sciencedirect.com/science/article/pii/S2405896324012394},
author = {Hae-In Lee and Dmitry Ignatyev and Hyo-Sang Shin and Antonios Tsourdos},
keywords = {Project-Based Learning, Autonomous Multi-Agent System, Unmanned Aerial Vehicles, Quadrotor, Surveillance},
abstract = {This paper proposes a project-based learning course utilising multiple quadrotors, aiming to solidify and amplify technical knowledge and develop critical thinking capabilities. An engineering problem is provided as a surveillance mission with multiple quadrotors autonomously searching, detecting, and tracking ground vehicles. The course covers all stages of multi-agent autonomy development, from identiflying system requirements, designing software and hardware, to conducting demonstrations in a drone flying arena. During the course, students improve their ability to critically formulate, solve and evaluate engineering problems as well as gain and apply technical knowledge in all aspects of autonomy such as fight dynamics, control, navigation, guidance, task allocation, situational awareness and communication. The paper details the problem design, course timeline, outcomes, and key lessons learnt from the course.}
}
@article{SALAJ2024298,
title = {Competencies for Smart City Challenges},
journal = {IFAC-PapersOnLine},
volume = {58},
number = {3},
pages = {298-303},
year = {2024},
note = {22nd IFAC Conference on Technology, Culture and International Stability TECIS 2024},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2024.07.167},
url = {https://www.sciencedirect.com/science/article/pii/S2405896324002507},
author = {Alenka Temeljotov Salaj and Olav Torp and Elham Andalib},
keywords = {smart solutions, competencies, AI, education},
abstract = {It is acknowledged that technological innovation is needed in all sectors to cope with new demands. From social innovations, it introduces novel ideas, whether products, services, or models, to fulfil societal needs and foster new partnerships or collaborations. The aim is to enhance social interactions and elevate human well-being. Development of cutting-edge digital technologies is reality. The challenge is on human resource side, how quickly we can prepare employees to adapt to the requirements of Industry 4.0 and Society 5.0. In the paper, the new competencies were identified with the business stakeholders by conducting a survey among industry partners to recognize the requirements for the future labor market. The stakeholders in the construction field act as target groups for monitoring and development of the competencies. The focus of the result part is on the competencies companies mostly miss from their employees from digital perspectives, e.g. reason to hire highly educated people, training possibilities for digitally upskilling employees, lacking appropriate competencies (critical thinking, systems and analytical thinking, information management, advanced computer/IT skills (AI), ensuring security). Digital skills Advanced data/IT skills were the competencies in that companies defined as key competencies expected to be developed in 21st-century higher education employees. It is highly important to consider the job market needs for development and to adopt the engineering education system to be responsive to the needs of labor market.}
}
@incollection{MAERTENS2025352,
title = {Chapter 00098 - Green Toxicology},
editor = {Béla Török},
booktitle = {Encyclopedia of Green Chemistry (First Edition)},
publisher = {Elsevier},
edition = {First Edition},
address = {Oxford},
pages = {352-357},
year = {2025},
isbn = {978-0-443-28923-1},
doi = {https://doi.org/10.1016/B978-0-443-15742-4.00098-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443157424000983},
author = {Alexandra Maertens and Thomas Hartung},
keywords = {Exposomics, In Silico, In Vitro, QSAR, SAR},
abstract = {Green toxicology is an emerging discipline that seeks to make toxicology a partner in the field of green chemistry, by providing chemists and toxicologists the tools necessary to identify potential hazards based on chemical structure alone, test efficiently for bioactivity, and better predict the human health impacts of chemicals. It seeks to make toxicology a data-driven, 21st century science by incorporating advanced techniques such as computational modeling, high-throughput screening, and alternative testing methods to assess chemical safety.}
}
@article{CONTI2021272,
title = {Harnessing Visual Imagery and Oculomotor Behaviour to Understand Prospection},
journal = {Trends in Cognitive Sciences},
volume = {25},
number = {4},
pages = {272-283},
year = {2021},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2021.01.009},
url = {https://www.sciencedirect.com/science/article/pii/S1364661321000115},
author = {Federica Conti and Muireann Irish},
keywords = {future thinking, visual mental imagery, episodic memory, imagination, hippocampus, default mode network},
abstract = {Much of the rich internal world constructed by humans is derived from, and experienced through, visual mental imagery. Despite growing appreciation of visual exploration in guiding episodic memory processes, extant theories of prospection have yet to accommodate the precise role of visual mental imagery in the service of future-oriented thinking. We propose that the construction of future events relies on the assimilation of perceptual details originally experienced, and subsequently reinstantiated, predominantly in the visual domain. Individual differences in the capacity to summon discrete aspects of visual imagery can therefore account for the diversity of content generated by humans during future simulation. Our integrative framework provides a novel testbed to query alterations in future thinking in health and disease.}
}
@article{DIAZ2021247,
title = {Evaluating Aspects of Usability in Video Game-Based Programming Learning Platforms},
journal = {Procedia Computer Science},
volume = {181},
pages = {247-254},
year = {2021},
note = {CENTERIS 2020 - International Conference on ENTERprise Information Systems / ProjMAN 2020 - International Conference on Project MANagement / HCist 2020 - International Conference on Health and Social Care Information Systems and Technologies 2020, CENTERIS/ProjMAN/HCist 2020},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.01.141},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921001812},
author = {Jaime Díaz and Jeferson Arango López and Samuel Sepúlveda and Gabriel Mauricio {Ramírez Villegas} and Danay Ahumada and Fernando Moreira},
keywords = {Human-Computer Interaction, Usability, Video-games, Training, Computer Programming},
abstract = {Teaching computer programming is an important topic. Due to Science and Technology initiatives, these topics are considered in different training cycles. For higher education, students must cultivate fundamental concepts for the development of software applications, which not only contribute to the knowledge of programming languages but also to opening guidelines for computational thinking. However, selecting a proper tool can be complex. Especially for the diversity of alternatives on the web. Further, not all of them meet basic usability requirements. In this study, we present a set of platforms that seek to develop programming skills based on video games. The search consisted of 4 stages: (i) definition of the research questions, (ii) scope review, (iii) execution of search and (iv) platform selection. Finally, we employ a usability heuristic evaluation for a novice programming system to determine best practices.}
}
@article{SHARMA2022132755,
title = {Conformational stability, quantum computational, spectroscopic, molecular docking and molecular dynamic simulation study of 2-hydroxy-1-naphthaldehyde},
journal = {Journal of Molecular Structure},
volume = {1259},
pages = {132755},
year = {2022},
issn = {0022-2860},
doi = {https://doi.org/10.1016/j.molstruc.2022.132755},
url = {https://www.sciencedirect.com/science/article/pii/S0022286022004288},
author = {Arun Sharma and Ghazala Khanum and Anuj Kumar and Aysha Fatima and Meenakshi Singh and Khamael M. Abualnaja and Khaled Althubeiti and S. Muthu and Nazia Siddiqui and Saleem Javed},
keywords = {DFT studies, Fukui Function, MEP, ELF, Hirshfeld, Molecular docking},
abstract = {Experimental FTIR, NMR and UV-visible spectrum analyses were used to describe the title compound 2-Hydroxy-1-Naphthaldehyde. The optimized molecular geometry and vibrational wave numbers were determined by using the DFT approach and B3LYP/6-311++G(d, p) basis set. VEDA was used to determine the vibrational assignments. The GIAO technique was used to compute carbon and proton NMR chemical shifts in CDCl3. The most reactive location of the 2H1NA molecule, according to MEP map analysis, is the site containing the oxygen atom. TD-DFT approach was used to produce the theoretical UV-visible spectrum in MeOH and gas phase. HOMO-LUMO and Donor-Acceptor (NBO) interactions were investigated for the title compound. In addition, nonlinear optical characteristics, ELF and Fukui activity were investigated. Temperature-dependent thermodynamic characteristics were also computed. The 3D intermolecular interactions of the crystal surface were characterised using Hirshfeld surface analysis, whereas the 2D interactions were explained using fingerprint plots. 2H1NA was stabilized by the development of H—H/H—C/H—O contacts. The bioactive probability of the title molecule was theoretically demonstrated by computing the electrophilicity index. In a biological study six different receptors, molecular docking was performed to evaluate the best ligand-protein interactions and likeness to the active substance. Biomolecular stability was investigated using a molecular dynamics simulation.}
}
@article{READ2017237,
title = {Virtual personalities: Using computational modeling to understand within-person variability},
journal = {Journal of Research in Personality},
volume = {69},
pages = {237-249},
year = {2017},
note = {Within-Person Variability in Personality},
issn = {0092-6566},
doi = {https://doi.org/10.1016/j.jrp.2016.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0092656616301738},
author = {Stephen J. Read and Benjamin J. Smith and Vitaliya Droutman and Lynn C. Miller},
keywords = {Virtual personalities, Within-person variability, Between-person variability, Social computational modeling},
abstract = {How can the same underlying psychological/neurobiological system result in both stable between-individual differences and high levels of within-individual variability in personality states over time and situations? We argue that both types of variability result from a psychological system based on structured, chronic motivations, where behavior at a specific point in time is a joint function of the current availability of motive affordances in the situation, current motivationally relevant bodily or interoceptive states, and the result of the competition among alternative active motives. Here we present a biologically-based theoretical framework, embodied in two different computational models, that shows how individuals with stable personality characteristics, can nevertheless exhibit considerable within-person variability in personality states across time and situations.}
}
@article{CAPUTO2023113309,
title = {Building T-shaped professionals for mastering digital transformation},
journal = {Journal of Business Research},
volume = {154},
pages = {113309},
year = {2023},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2022.113309},
url = {https://www.sciencedirect.com/science/article/pii/S0148296322007640},
author = {Francesco Caputo and Valentina Cillo and Fabio Fiano and Marco Pironti and Marco Romano},
keywords = {Digital transformation, T-shaped professionals, Systems thinking, Soft skills, Cognitive domain},
abstract = {Digital transformation is a multidimensional challenge that is requiring to change consolidated approaches and managerial models. New organized entities are emerging because of this ongoing transformation and new competences are required for managing and living them. Thanks to the interpretative contribution provided by the systems thinking, the paper focuses the attention on the paradigm shift required for defining t-shaped professionals able to master digital transformation in emerging dynamics. A conceptual model is proposed and discussed building upon the T-shaped model with the aim to enrich current theoretical and managerial debates about strategies for supporting both individuals and organizations in facing the challenges imposed by the digital transformation.}
}
@article{NOWICKI2012324,
title = {Improving the computational efficiency of metric-based spares algorithms},
journal = {European Journal of Operational Research},
volume = {219},
number = {2},
pages = {324-334},
year = {2012},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2011.12.033},
url = {https://www.sciencedirect.com/science/article/pii/S0377221711011271},
author = {David R. Nowicki and Wesley S. Randall and Jose Emmanuel Ramirez-Marquez},
keywords = {Inventory, Performance based logistics, Logistics, Supply chain, Optimization, Outcome based contracting},
abstract = {We propose a new heuristic algorithm to improve the computational efficiency of the general class of Multi-Echelon Technique for Recoverable Item Control (METRIC) problems. The objective of a METRIC-based decision problem is to systematically determine the location and quantity of spares that either maximizes the operational availability of a system subject to a budget constraint or minimizes its cost subject to an operational availability target. This type of sparing analysis has proven essential when analyzing the sustainment policies of large-scale, complex repairable systems such as those prevalent in the defense and aerospace industries. Additionally, the frequency of these sparing studies has recently increased as the adoption of performance-based logistics (PBL) has increased. PBL represents a class of business strategies that converts the recurring cost associated with maintenance, repair, and overhaul (MRO) into cost avoidance streams. Central to a PBL contract is a requirement to perform a business case analysis (BCA) and central to a BCA is the frequent need to use METRIC-based approaches to evaluate how a supplier and customer will engage in a performance based logistics arrangement where spares decisions are critical. Due to the size and frequency of the problem there exists a need to improve the efficiency of the computationally intensive METRIC-based solutions. We develop and validate a practical algorithm for improving the computational efficiency of a METRIC-based approach. The accuracy and effectiveness of the proposed algorithm are analyzed through a numerical study. The algorithm shows a 94% improvement in computational efficiency while maintaining 99.9% accuracy.}
}
@article{MOUTOUSSIS20212025,
title = {Decision-making ability, psychopathology, and brain connectivity},
journal = {Neuron},
volume = {109},
number = {12},
pages = {2025-2040.e7},
year = {2021},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2021.04.019},
url = {https://www.sciencedirect.com/science/article/pii/S0896627321002853},
author = {Michael Moutoussis and Benjamín Garzón and Sharon Neufeld and Dominik R. Bach and Francesco Rigoli and Ian Goodyer and Edward Bullmore and Peter Fonagy and Peter Jones and Tobias Hauser and Rafael Romero-Garcia and Michelle {St Clair} and Petra Vértes and Kirstie Whitaker and Becky Inkster and Gita Prabhu and Cinly Ooi and Umar Toseeb and Barry Widmer and Junaid Bhatti and Laura Villis and Ayesha Alrumaithi and Sarah Birt and Aislinn Bowler and Kalia Cleridou and Hina Dadabhoy and Emma Davies and Ashlyn Firkins and Sian Granville and Elizabeth Harding and Alexandra Hopkins and Daniel Isaacs and Janchai King and Danae Kokorikou and Christina Maurice and Cleo McIntosh and Jessica Memarzia and Harriet Mills and Ciara O’Donnell and Sara Pantaleone and Jenny Scott and Pasco Fearon and John Suckling and Anne-Laura {van Harmelen} and Rogier Kievit and Marc Guitart-Masip and Raymond J. Dolan},
keywords = {decision acuity, computational psychiatry, functional connectivity, adolescence, development},
abstract = {Summary
Decision-making is a cognitive process of central importance for the quality of our lives. Here, we ask whether a common factor underpins our diverse decision-making abilities. We obtained 32 decision-making measures from 830 young people and identified a common factor that we call “decision acuity,” which was distinct from IQ and reflected a generic decision-making ability. Decision acuity was decreased in those with aberrant thinking and low general social functioning. Crucially, decision acuity and IQ had dissociable brain signatures, in terms of their associated neural networks of resting-state functional connectivity. Decision acuity was reliably measured, and its relationship with functional connectivity was also stable when measured in the same individuals 18 months later. Thus, our behavioral and brain data identify a new cognitive construct that underpins decision-making ability across multiple domains. This construct may be important for understanding mental health, particularly regarding poor social function and aberrant thought patterns.}
}
@incollection{KANELLOPOULOS2024111,
title = {Chapter Five - Adversarial modeling},
editor = {Aris Kanellopoulos and Lijing Zhai and Filippos Fotiadis and Kyriakos G. Vamvoudakis},
booktitle = {Control and Game Theoretic Methods for Cyber-Physical Security},
publisher = {Academic Press},
pages = {111-170},
year = {2024},
series = {Emerging Methodologies and Applications in Modelling, Identification and Control},
isbn = {978-0-443-15408-9},
doi = {https://doi.org/10.1016/B978-0-44-315408-9.00011-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780443154089000117},
author = {Aris Kanellopoulos and Lijing Zhai and Filippos Fotiadis and Kyriakos G. Vamvoudakis},
keywords = {Bounded rationality, Differential games, Attack prediction},
abstract = {In this chapter we utilize results from game theory to model the interactions of the CPS operator with different types of adversarial agents. To approach accurate prediction of realistic attacks, we present and exploit results from behavioral game theory, namely level-k thinking and cognitive hierarchy. Finally, we propose a method of predicting future adversarial behavior of adapting, learning opponents.}
}
@article{CHEN2021101001,
title = {Instructed concept appropriation for developing knowledge of second language academic discourse context},
journal = {Journal of English for Academic Purposes},
volume = {52},
pages = {101001},
year = {2021},
issn = {1475-1585},
doi = {https://doi.org/10.1016/j.jeap.2021.101001},
url = {https://www.sciencedirect.com/science/article/pii/S147515852100045X},
author = {Jing Chen and Danli Li},
keywords = {Concept-based language instruction, , Mediation, Concept appropriation, Writing activity, Academic literacy},
abstract = {Recent studies from sociocultural perspectives have explored the effects of Concept-based Language Instruction (C-BLI) on L2 development through the explicit teaching of scientific concepts. However, there has been little research into the effects of C-BLI on the development of L2 academic literacy. This article reports on a case study of how C-BLI mediated a Chinese doctoral student's development of conceptual knowledge of context and subsequent context-specific performance in academic writing. Drawing on data from writing tutorials and interviews, the learner's drafts and invited comments, and think-aloud protocols, the study revealed that the C-BLI interventions that integrated symbolic and dialogic mediation helped the learner attain and enhance awareness of contextual components. The learner appropriated the concept as a tool for thinking in judging appropriateness of rules of thumb and choices of exclusive discourse features in specific contexts of use, which consequently mediated his planning for writing and resulted in the development of performance. The study demonstrates the potential of C-BLI as a driving force for the development of conceptual knowledge and context-specific performance in the academic literacy of L2 learners. It has pedagogical implications for curriculum design, C-BLI-informed literacy and concept-based materials, and teacher development to stimulate teacher awareness in C-BLI.}
}
@article{WU2024101625,
title = {The moderating effects of brain network connectivity on the relationship between individual and interactive creativity},
journal = {Thinking Skills and Creativity},
volume = {54},
pages = {101625},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101625},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124001639},
author = {Ching-Lin Wu},
keywords = {Connectome, Diffusion tensor imaging, Divergent thinking, Online creativity task, Remote associates test},
abstract = {The correlation between individuals’ creativity performances in a one-to-one interactive situation was preliminarily explored. Neuroimaging has provided many insights into the neural connectome that underlies creativity; however, the role of brain structure in individuals’ creativity performance when collaborating with others remains largely unexplored. Therefore, this study collected data from 74 single- and paired-player participants using an interactive creativity task platform, including the alternative use task (AUT) and the Chinese Radical Remote Associates Test (CRRAT). Participants’ AUT and CRRAT scores in the above two modes were collected to analyze the moderating effects of connective efficiency (CE). The results showed that the relationship between originality performance in the single- and paired-player modes was moderated by four theoretical graph measures. Specifically, in the case of a high clustering coefficient, local efficiency, global efficiency, or low characteristic path length, individual originality performance was more predictive of interactive originality. Additionally, the relationship between fluency performance in the above two modes was not moderated by CE, flexibility, or CRRAT performance. This study identified the effects of neural transmission efficiency on the relationship between creativity in the two modes. This study investigated neurocognitive factors influencing creativity performance in interactive situations.}
}
@article{SLOOT2010189,
title = {Computational science: A kaleidoscopic view into science},
journal = {Journal of Computational Science},
volume = {1},
number = {4},
pages = {189},
year = {2010},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2010.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S1877750310000694},
author = {Peter M.A. Sloot}
}
@article{MANTELERO2014643,
title = {The future of consumer data protection in the E.U. Re-thinking the “notice and consent” paradigm in the new era of predictive analytics},
journal = {Computer Law & Security Review},
volume = {30},
number = {6},
pages = {643-660},
year = {2014},
issn = {0267-3649},
doi = {https://doi.org/10.1016/j.clsr.2014.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S026736491400154X},
author = {Alessandro Mantelero},
keywords = {Data protection, Consent, Data protection impact assessment, Big Data, Data protection authorities},
abstract = {The new E.U. proposal for a general data protection regulation has been introduced to give an answer to the challenges of the evolving digital environment. In some cases, these expectations could be disappointed, since the proposal is still based on the traditional main pillars of the last generation of data protection laws. In the field of consumer data protection, these pillars are the purpose specification principle, the use limitation principle and the “notice and consent” model. Nevertheless, the complexity of data processing, the power of modern analytics and the “transformative” use of personal information drastically limit the awareness of consumers, their capability to evaluate the various consequences of their choices and to give a free and informed consent. To respond to the above, it is necessary to clarify the rationale of the “notice and consent” paradigm, looking back to its origins and assessing its effectiveness in a world of predictive analytics. From this perspective, the paper considers the historical evolution of data protection and how the fundamental issues coming from the technological and socio-economic contexts have been addressed by regulations. On the basis of this analysis, the author suggests a revision of the “notice and consent” model focused on the opt-in and proposes the adoption of a different approach when, such as in Big Data collection, the data subject cannot be totally aware of the tools of analysis and their potential output. For this reason, the author sustains the provision of a subset of rules for Big Data analytics, which is based on a multiple impact assessment of data processing, on a deeper level of control by data protection authorities, and on the different opt-out model.}
}
@article{CHIASTRA20162102,
title = {Computational replication of the patient-specific stenting procedure for coronary artery bifurcations: From OCT and CT imaging to structural and hemodynamics analyses},
journal = {Journal of Biomechanics},
volume = {49},
number = {11},
pages = {2102-2111},
year = {2016},
note = {Selected Articles from the International Conference on CFD in Medicine and Biology (Albufeira, Portugal – August 30th - September 4th, 2015)},
issn = {0021-9290},
doi = {https://doi.org/10.1016/j.jbiomech.2015.11.024},
url = {https://www.sciencedirect.com/science/article/pii/S0021929015006661},
author = {Claudio Chiastra and Wei Wu and Benjamin Dickerhoff and Ali Aleiou and Gabriele Dubini and Hiromasa Otake and Francesco Migliavacca and John F. LaDisa},
keywords = {Mathematical model, Finite element analysis, Computational fluid dynamics, Coronary bifurcation, Stent},
abstract = {The optimal stenting technique for coronary artery bifurcations is still debated. With additional advances computational simulations can soon be used to compare stent designs or strategies based on verified structural and hemodynamics results in order to identify the optimal solution for each individual’s anatomy. In this study, patient-specific simulations of stent deployment were performed for 2 cases to replicate the complete procedure conducted by interventional cardiologists. Subsequent computational fluid dynamics (CFD) analyses were conducted to quantify hemodynamic quantities linked to restenosis. Patient-specific pre-operative models of coronary bifurcations were reconstructed from CT angiography and optical coherence tomography (OCT). Plaque location and composition were estimated from OCT and assigned to models, and structural simulations were performed in Abaqus. Artery geometries after virtual stent expansion of Xience Prime or Nobori stents created in SolidWorks were compared to post-operative geometry from OCT and CT before being extracted and used for CFD simulations in SimVascular. Inflow boundary conditions based on body surface area, and downstream vascular resistances and capacitances were applied at branches to mimic physiology. Artery geometries obtained after virtual expansion were in good agreement with those reconstructed from patient images. Quantitative comparison of the distance between reconstructed and post-stent geometries revealed a maximum difference in area of 20.4%. Adverse indices of wall shear stress were more pronounced for thicker Nobori stents in both patients. These findings verify structural analyses of stent expansion, introduce a workflow to combine software packages for solid and fluid mechanics analysis, and underscore important stent design features from prior idealized studies. The proposed approach may ultimately be useful in determining an optimal choice of stent and position for each patient.}
}
@article{SIMMONS2022103318,
title = {Freedom from what? Separating lay concepts of freedom},
journal = {Consciousness and Cognition},
volume = {101},
pages = {103318},
year = {2022},
issn = {1053-8100},
doi = {https://doi.org/10.1016/j.concog.2022.103318},
url = {https://www.sciencedirect.com/science/article/pii/S1053810022000502},
author = {Claire Simmons and Paul Rehren and John-Dylan Haynes and Walter Sinnott-Armstrong},
abstract = {Debates about freedom of will and action and their connections with moral responsibility have raged for centuries, but the opposing sides might disagree because they use different concepts of freedom. Based on previous work, we hypothesized that people who assert freedom in a determined (D) or counterfactual-intervener (CI) scenario assert this because they are thinking about freedom from constraint and not about freedom from determination (in D) or from inevitability (in CI). We also hypothesized that people who deny that freedom in D or in CI deny this because they are thinking about freedom from determination or from inevitability, respectively, and not about freedom from constraint. To test our hypotheses, we conducted two main online studies. Study I supported our hypotheses that people who deny freedom in D and CI are thinking about freedom from determinism and from inevitability, respectively, but these participants seemed to think about freedom from constraint when they were later considering modified scenarios where acts were not determined or inevitable. Study II investigated a contrary bypassing hypothesis that those who deny freedom in D denied this because they took determinism to exclude mental causation and hence to exclude freedom from constraint. We found that participants who took determinism to exclude freedom generally did not deny causation by mental states, here represented by desires and decisions. Their responses regarding causation by desires and decisions at most weakly mediated the relation between determinism and freedom or responsibility among this subgroup of our participants. These results speak against the bypassing hypothesis and in favor of our hypothesis that these participants were not thinking about freedom from constraint.}
}
@article{HUANGHUANG2023315,
title = {Teacher educator learning to implement equitable mathematics teaching using technology through lesson study},
journal = {International Journal for Lesson and Learning Studies},
volume = {12},
number = {4},
pages = {315-329},
year = {2023},
issn = {2046-8253},
doi = {https://doi.org/10.1108/IJLLS-05-2023-0049},
url = {https://www.sciencedirect.com/science/article/pii/S2046825323000537},
author = {RongjinRongjin HuangHuang and Christopher T.Christopher T. BonnesenBonnesen and Amanda LakeAmanda Lake HeathHeath and Jennifer M.Jennifer M. SuhSuh},
keywords = {Equitable instruction, Technology, Teacher educator learning, Lesson study},
abstract = {Purpose
This paper examines how mathematics teacher educators (MTEs) learn to enact equitable mathematics instruction using technology through lesson study (LS).
Design/methodology/approach
A LS team with three MTEs conducted three iterations of LS on teaching the Pythagorean Theorem in an in-person, technology-mediated environment. Many forms of data were collected: Desmos activities, videos of research lessons (RLs), videos of MTE RL debriefings, artifacts of student learning in the Desmos Dashboard, and MTEs' written self-reflection. The authors investigate the teacher educators' learning through LS by analyzing the MTE debriefings of the RLs using Bannister’s (2015) framework for teacher learning in communities of practice.
Findings
The MTEs learned to enact equitable mathematics instruction using technology through addressing emerging issues related to intellectual authority and use of student thinking. Throughout the LS, the MTEs sought ways of promoting students' mathematical authority and using student thinking through features of the Desmos platform.
Research limitations/implications
This study focuses on MTEs' learning without examining participating preservice teachers' learning. It demonstrates the benefits of LS for MTEs' professional learning.
Practical implications
This study showcases how a research-based Desmos activity is used and refined to promote MTE learning how to implement equitable mathematics instruction.
Originality/value
The study contributes to better understanding of how LS could be used to develop MTEs' professional learning. Moreover, the dual process of participation and reification was concretized through diagnostic and prognostic frames in the LS context, which enriches the concept of community of practice.}
}
@article{BATINI2025101896,
title = {Shared reading aloud fosters intelligence: Three cluster-randomized control trials in elementary and middle school},
journal = {Intelligence},
volume = {108},
pages = {101896},
year = {2025},
issn = {0160-2896},
doi = {https://doi.org/10.1016/j.intell.2024.101896},
url = {https://www.sciencedirect.com/science/article/pii/S0160289624000904},
author = {Federico Batini and Marco Bartolucci and Giulia Toti and Emanuele Castano},
keywords = {Intelligence, Cognitive development, Narrative fiction, Storytelling, Reading},
abstract = {Storytelling played a crucial role in human evolution. To this day, through stories humans gain declarative and procedural knowledge, and learn the skills that support learning itself. Research shows that reading stories to children enhances their reading and language skills. Does it also enhance their intelligence? To answer this question, we conducted three (N = 626, 254, 195) longitudinal, cluster-randomized control trials in Italian elementary and middle schools. Over a 4-month period, for half of the participants 1 h/day of standard, active language instructional activities were substituted with reading-aloud of stories by a teacher. Compared to those who kept doing language instructional activities, read-aloud condition children showed a stronger increase on two measures of intelligence focusing on knowing things and thinking skills. This result, which emerged in three independent trials conducted in different regions of Italy, suggests avenues for easily scalable interventions to improve children's intelligence.}
}
@article{MARTINEZLEDESMA20203567,
title = {Computational methods for detecting cancer hotspots},
journal = {Computational and Structural Biotechnology Journal},
volume = {18},
pages = {3567-3576},
year = {2020},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2020.11.020},
url = {https://www.sciencedirect.com/science/article/pii/S2001037020304876},
author = {Emmanuel Martinez-Ledesma and David Flores and Victor Trevino},
keywords = {Mutations, Cancer, Hotspots, Recurrent mutations, Algorithms, Genomics, Sequencing, Exome, Whole genome sequencing},
abstract = {Cancer mutations that are recurrently observed among patients are known as hotspots. Hotspots are highly relevant because they are, presumably, likely functional. Known hotspots in BRAF, PIK3CA, TP53, KRAS, IDH1 support this idea. However, hundreds of hotspots have never been validated experimentally. The detection of hotspots nevertheless is challenging because background mutations obscure their statistical and computational identification. Although several algorithms have been applied to identify hotspots, they have not been reviewed before. Thus, in this mini-review, we summarize more than 40 computational methods applied to detect cancer hotspots in coding and non-coding DNA. We first organize the methods in cluster-based, 3D, position-specific, and miscellaneous to provide a general overview. Then, we describe their embed procedures, implementations, variations, and differences. Finally, we discuss some advantages, provide some ideas for future developments, and mention opportunities such as application to viral integrations, translocations, and epigenetics.}
}
@incollection{GEYER2020125,
title = {Chapter 6 - Physical meets digital: Blending reality and computational power with digital sticky notes},
editor = {Bo T. Christensen and Kim Halskov and Clemens N. Klokmose},
booktitle = {Sticky Creativity},
publisher = {Academic Press},
pages = {125-151},
year = {2020},
series = {Explorations in Creativity Research},
isbn = {978-0-12-816566-9},
doi = {https://doi.org/10.1016/B978-0-12-816566-9.00006-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128165669000069},
author = {Florian Geyer and Johannes Zagermann and Harald Reiterer},
keywords = {Affinity diagramming, Blended interaction, Post-WIMP user interface, Interaction design, Tangible user interface, User interface design framework, Creativity tool},
abstract = {The high utility and usability of paper sticky notes support workflows and social dynamics of collaborative design activities and methods like affinity diagramming. In this chapter, we show how these natural collaboration activities can be blended with computational power by applying our framework Blended Interaction for a case study on affinity diagramming. Based on four domains of design, we embed our design solutions in a specific physical environment, preserve workflows, and emphasize individual and social interaction. Our proposed design solution to augment sticky notes with digital power blends the benefits of physical materials with the digital power of interactive surfaces, tangibles, and digital pens in an outstanding way. We hope that our design solutions inspire other researchers and practitioners to find innovative solutions that carefully blend real-world practices with the power of digital computing.}
}
@article{BULLOCK2009757,
title = {Computational perspectives on forebrain microcircuits implicated in reinforcement learning, action selection, and cognitive control},
journal = {Neural Networks},
volume = {22},
number = {5},
pages = {757-765},
year = {2009},
note = {Advances in Neural Networks Research: IJCNN2009},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2009.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608009001117},
author = {Daniel Bullock and Can Ozan Tan and Yohan J. John},
keywords = {Basal ganglia, Acetylcholine, Dopamine, Striatum, Decision making},
abstract = {Abundant new information about signaling pathways in forebrain microcircuits presents many challenges, and opportunities for discovery, to computational neuroscientists who strive to bridge from microcircuits to flexible cognition and action. Accurate treatment of microcircuit pathways is especially critical for creating models that correctly predict the outcomes of candidate neurological therapies. Recent models are trying to specify how cortical circuits that enable planning and voluntary actions interact with adaptive subcortical microcircuits in the basal ganglia. The basal ganglia are strongly implicated in reinforcement learning, and in all behavior and cognition over which the frontal lobes exert flexible control. The persisting role of the basal ganglia shows that ancient vertebrate designs for motivated action selection proved adaptable enough to support many “modern” behavioral innovations, including fluent generation of language and speech. This paper summarizes how recent models have incorporated realistic representations of microcircuit features, and have begun to trace their computational implications. Also summarized are recent empirical discoveries that provide guidance regarding how to formulate the rules for synaptic modification that govern learning in cortico-striatal pathways. Such efforts are contributing to an emerging synthesis based on an interlocking set of computational hypotheses regarding cortical interactions with basal ganglia and thalamic nuclei. These hypotheses specify how specialized microcircuits solve learning and control problems inherent to the brain’s parallel design.}
}
@article{BROM20121,
title = {A computational model of the allocentric and egocentric spatial memory by means of virtual agents, or how simple virtual agents can help to build complex computational models},
journal = {Cognitive Systems Research},
volume = {17-18},
pages = {1-24},
year = {2012},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2011.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S1389041711000404},
author = {Cyril Brom and Jan Vyhnánek and Jiří Lukavský and David Waller and Rudolf Kadlec},
keywords = {Spatial cognition, Paradigm of pointing, Disorientation effect, Intelligent virtual agent},
abstract = {The ability to acquire, remember and use information about locations of objects in one’s proximal surrounding is a fundamental aspect of human spatial cognition. In this paper, we present a computational model of this ability. The model provides a possible explanation of contradictory results from experimental psychology related to this ability, namely explanation of why some experiments have reproduced the so-called “disorientation effect” while others have failed to do so. Additionally, in contrast to other computational models of various aspects of spatial cognition, our model is integrated within an intelligent virtual agent. Thus, on a more general level, this paper also demonstrates that it is possible to use intelligent virtual agents as a powerful research tool in computational cognitive sciences.}
}
@article{LIGOMENIDES200910,
title = {The reality of Mathematics},
journal = {Journal of Computational and Applied Mathematics},
volume = {227},
number = {1},
pages = {10-16},
year = {2009},
note = {Special Issue of Proceedings of NUMAN 2007 Conference: Recent Approaches to Numerical Analysis: Theory, Methods and Applications},
issn = {0377-0427},
doi = {https://doi.org/10.1016/j.cam.2008.07.029},
url = {https://www.sciencedirect.com/science/article/pii/S0377042708003257},
author = {Panos A. Ligomenides},
keywords = {Languages of mathematics, Mathematical reality, Information science, Cyber-world},
abstract = {The power of mathematics is discussed as a way of expressing reasoning, aesthetics and insight in symbolic non-verbal communication. The human culture of discovering mathematical ways of thinking in the enterprise of exploring the understanding of the nature and the evolution of our world through hypotheses, theories and experimental affirmation of the scientific notion of algorithmic and non-algorithmic ‘computation’, is examined and commended upon.}
}
@article{MAVRIDIS202311223,
title = {Attack Identification for Cyber-Physical Security in Dynamic Games under Cognitive Hierarchy},
journal = {IFAC-PapersOnLine},
volume = {56},
number = {2},
pages = {11223-11228},
year = {2023},
note = {22nd IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2023.10.851},
url = {https://www.sciencedirect.com/science/article/pii/S2405896323012314},
author = {Christos N. Mavridis and Aris Kanellopoulos and Kyriakos G. Vamvoudakis and John S. Baras and Karl Henrik Johansson},
abstract = {This paper considers the problem of identifying the profiles and capabilities of attackers injecting adversarial inputs to a cyber-physical system. The system in question interacts with attackers of different levels of intelligence, each employing different feedback controllers against the system. Principles of behavioral game theory – specifically the concept of level-k thinking – is employed to construct a database of potential attack vectors. By observing the state trajectories under sequential interactions with different adversaries, the defender adaptively estimates both the number and profiles of the different attack signals using an online deterministic annealing approach. This information is used to dynamically estimate the level of intelligence of the attackers. Simulation results showcase the efficacy of the proposed method.}
}
@article{RAZ2024101598,
title = {Open and closed-ended problem solving in humans and AI: The influence of question asking complexity},
journal = {Thinking Skills and Creativity},
volume = {53},
pages = {101598},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101598},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124001366},
author = {Tuval Raz and Roni Reiter-Palmon and Yoed N. Kenett},
keywords = {Question asking, Problem-solving, AI, Creativity},
abstract = {Question-asking, an underexplored aspect of creativity, is integral to creative problem-solving and information-seeking. Previous research reveals that lower creativity correlates with asking simpler, closed questions, while higher creativity correlates with complex, open-ended inquiries. The present study explores the relation between question asking complexity and problem-solving tasks involving open- and close-ended thinking and how these abilities generalize and compare to AI. In Study 1, participants (N = 89) completed the alternative questions task (AQT), a close-ended riddles task (Stumpers), and the alternate uses task (AUT), a creativity measure. Our results show AQT question complexity wasn't correlated with stumpers performance, although it correlated with AUT originality (r = .3). In Study 2, participants (N = 100) completed the AQT, AUT, and open-ended creative problem-solving (CPS) task. CPS responses were evaluated for originality and quality. A positive correlation was observed between CPS quality and AQT complexity (r = .29) and originality (r = .34). In study 3, AI agents (N = 100) completed the AQT, AUT, stumpers, and CPS tasks. Like humans, AI's AQT originality and complexity were related with open, but not closed problem-solving. AI questions were also significantly more creative and complex, it solved more stumpers and gave higher quality CPS solutions. Surprisingly, human and AI CPS originality didn't differ. We find significant links between question complexity and open—but not closed-ended—problem-solving in humans, which generalize to AI. Our results highlight the significance of complex and creative question-asking in everyday life and as an integral part of our problem-solving toolkit.}
}
@article{LIN2021103944,
title = {Lessons learned from critical accidental fires in tunnels},
journal = {Tunnelling and Underground Space Technology},
volume = {113},
pages = {103944},
year = {2021},
issn = {0886-7798},
doi = {https://doi.org/10.1016/j.tust.2021.103944},
url = {https://www.sciencedirect.com/science/article/pii/S0886779821001358},
author = {Chien Liang Lin and Chao Fu Chien},
keywords = {Systems thinking, Lessons learned, Accidental tunnel fires, Causal loop diagram},
abstract = {Historical data indicate that tunnel fires often cause casualties and damage to both vehicles and tunnels. These severe consequences suggest that (1) humans seldom effectively learn from history, and (2) people lack optimal safety response strategies for tunnel fires. To investigate the root causes of accidental tunnel fires and learn from them, we first surveyed the literature on historical tunnel accidents and described the common timeline of accidental tunnel fires. We employed systems thinking, based on the past research, to depict a causal loop diagram of common accidental tunnel fires. We arrived at the following three findings: (1) the literature review proved that the causes of tunnel fires are far more complex than other types of fires, and the damage they generate is greater; (2) in the context of systems thinking, accidental tunnel fires involve many causal relationships which are both continuous and dynamic, including at least three systems, namely vehicles, tunnel control, and safety response; (3) the mental models “the experience of the operators at the tunnel operation control center is just as vital as the safety response” and “safety is more critical than the traffic volume in the tunnel”, can strengthen safety response systems and ensure safe driving in tunnels. Although the structure of each tunnel and the characteristics of each fire differ and present different causal relationships, this study elucidated lessons from accidental tunnel fires and provided required messages for establishing effective safety measures. The results of this study can be used to establish systems thinking models of tunnel fires and can serve as a reference for policy planning and establishing standard operating procedures for safety responses.}
}
@article{LEROYER20112070,
title = {Numerical strategies to speed up CFD computations with free surface—Application to the dynamic equilibrium of hulls},
journal = {Ocean Engineering},
volume = {38},
number = {17},
pages = {2070-2076},
year = {2011},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2011.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S0029801811002009},
author = {Alban Leroyer and Jeroen Wackers and Patrick Queutey and Emmanuel Guilmineau},
keywords = {Marine hydrodynamics, Free surface capturing, Dynamic equilibrium, RANS simulation},
abstract = {This article presents two numerical procedures to speed up computations when dealing with a Reynolds Averaged Navier Stokes (RANS) solver based on the Volume of Fluid (VoF) or multifluid method to treat the free surface. The first one is a time-splitting procedure for the volume fraction equation, enabling the use of larger time steps for the resolution of the flow, without penalizing accuracy. However, these large time steps destabilize the coupling with the ship motion simulation when computing a dynamic equilibrium position in marine applications. The second procedure is therefore a quasi-static approach to solve the coupled problem of dynamic equilibrium. A comparison of these procedures with classical simulations shows that numerical solutions of realistic problems can be obtained up to four times faster.}
}
@article{BAN2020102789,
title = {3D Computational Sketch Synthesis Framework: Assisting Design Exploration Through Generating Variations of User Input Sketch and Interactive 3D Model Reconstruction},
journal = {Computer-Aided Design},
volume = {120},
pages = {102789},
year = {2020},
issn = {0010-4485},
doi = {https://doi.org/10.1016/j.cad.2019.102789},
url = {https://www.sciencedirect.com/science/article/pii/S0010448518301726},
author = {Seonghoon Ban and Kyung Hoon Hyun},
keywords = {Intelligent design system, Assisted creativity, Sketch-based modeling, Computational design, Virtual reality},
abstract = {A framework is proposed for facilitating the exploration process during the early design phase through computational sketch synthesis and interactive 3D reconstruction. In that phase, designers concentrate on developing concepts through numerous alternatives. Therefore, they constantly sketch so that they can rapidly visualize their ideas. Recently, the design industry has attempted to streamline the design process by implementing 3D model generation in the early design phase so that ideas may be more thoroughly explored, thus improving concept and final design conformance; however, efficiency issues have arisen. In this study, a 3D computational sketch synthesis framework was developed comprising two major components. First, a robust method was proposed to synthesize design alternatives by interpolating an input sketch with sketches in a database so that unvisited combinations may be explored. Secondly, a novel interactive 3D model reconstruction method was developed to facilitate the shape transition of design elements so that designers can quickly evaluate the potential of a large number of design variations. Finally, an interface for design refinement was developed so that designs may be embodied by sketching over the 3D model. To test the proposed methodology, expert designers were recruited for a validation experiment with two conditions followed up by in-depth interviews. In the first condition, the participants were asked to sketch based on a design brief in their current working manner. In the second condition, they were asked to create designs using the proposed framework. It was tested whether there was a difference in the design outcomes. It was demonstrated that the proposed framework resulted in more satisfactory and higher-quality designs and generated design alternatives faster and in greater quantities. All participants agreed that the framework could be useful in the early design phase and responded that the proposed system provides more design inspiration than traditional design methods. Most importantly, it was demonstrated that the proposed framework could enhance the reevaluation potential of design concepts and assist in making better-informed design decisions.}
}
@article{STEPHENS2021100871,
title = {From “You have to have three numbers and a plus sign” to “It’s the exact same thing”: K–1 students learn to think relationally about equations},
journal = {The Journal of Mathematical Behavior},
volume = {62},
pages = {100871},
year = {2021},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2021.100871},
url = {https://www.sciencedirect.com/science/article/pii/S0732312321000328},
author = {Ana Stephens and Ranza {Veltri Torres} and Yewon Sung and Susanne Strachota and Angela {Murphy Gardiner} and Maria Blanton and Rena Stroud and Eric Knuth},
keywords = {Equal sign, Equations, Elementary grades, Early algebra, Algebraic thinking},
abstract = {This research shares progressions in thinking about equations and the equal sign observed in ten students who took part in an early algebra classroom intervention across Kindergarten and first grade. We report on data from task-based interviews conducted prior to the intervention and at the conclusion of each school year that elicited students’ interpretations of the equal sign and equations of various forms. We found at the beginning of the intervention that most students viewed the equal sign as an operational symbol and did not accept many equations forms as valid. By the end of first grade, almost all students described the symbol as indicating the equivalence of two amounts and were much more successful interpreting and working with equations in a variety of forms. The progressions we observed align with those of other researchers and provide evidence that very young students can learn to reason flexibly about equations.}
}
@article{LIU20183231,
title = {Nickel catalyzed regio- and stereoselective arylation and methylation of allenamides via coupling reactions. An experimental and computational study11Electronic supplementary information (ESI) available. CCDC 1548725 and 1817608. For ESI and crystallographic data in CIF or other electronic format see DOI: 10.1039/c8qo00729b},
journal = {Organic Chemistry Frontiers},
volume = {5},
number = {22},
pages = {3231-3239},
year = {2018},
issn = {2052-4129},
doi = {https://doi.org/10.1039/c8qo00729b},
url = {https://www.sciencedirect.com/science/article/pii/S2052411022005156},
author = {Yang Liu and Alessandro Cerveri and Assunta {De Nisi} and Magda Monari and Olalla {Nieto Faza} and Carlos Silva Lopez and Marco Bandini},
abstract = {The nickel catalyzed regio- and stereoselective condensation of boronic acids to allenamides is documented as a novel synthetic route to stereochemically defined tri-substituted enamides. The protocol has been implemented into a three-component variant intercepting the in situ formed allyl-Ni intermediate with a range of aldehydes. Additionally, evidence for the effective extension of this methodology to Me2Zn is documented. Full rationale on the mechanism as well as its stereochemical outcome is provided by a synergistic experimental/computational approach.}
}
@article{DEICHMANN2024105260,
title = {Contrasting philosophical and scientific views in the long history of studying the generation of form in development},
journal = {BioSystems},
volume = {242},
pages = {105260},
year = {2024},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2024.105260},
url = {https://www.sciencedirect.com/science/article/pii/S030326472400145X},
author = {Ute Deichmann},
keywords = {Genomic causality, Developmental gene regulatory networks, Physical-chemical selforganization in form generation, Preformation versus epigenesis, Morphogenesis, Stochastic fluctuations, Eric Davidson, Aristotle},
abstract = {Focusing on the opposing ways of thinking of philosophers and scientists to explain the generation of form in biological development, I show that today's controversies over explanations of early development bear fundamental similarities to the dichotomy of preformation theory versus epigenesis in Greek antiquity. They are related to the acceptance or rejection of the idea of a physical form of what today would be called information for the generating of the embryo as a necessary pre-requisite for specific development and heredity. As a recent example, I scrutinize the dichotomy of genomic causality versus self-organization in 20th and 21st century theories of the generation of form. On the one hand, the generation of patterns and form, as well as the constant outcome in development, are proposed to be causally related to something that is "preformed" in the germ cells, the nucleus of germ cells, or the genome. On the other hand, it is proposed that there is no pre-existing form or information, and development is seen as a process where genuinely new characters emerge from formless matter, either by immaterial "forces of life," or by physical-chemical processes of self-organization. I also argue that these different ways of thinking and the research practices associated with them are not equivalent, and maintain that it is impossible to explain the generation of form and constant outcome of development without the assumption of the transmission of pre-existing information in the form of DNA sequences in the genome. Only in this framework of "preformed" information can "epigenesis" in the form of physical and chemical processes of self-organization play an important role.}
}
@article{YEH2011794,
title = {Evaluation approach to stock trading system using evolutionary computation},
journal = {Expert Systems with Applications},
volume = {38},
number = {1},
pages = {794-803},
year = {2011},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2010.07.035},
url = {https://www.sciencedirect.com/science/article/pii/S0957417410006639},
author = {I-Cheng Yeh and Che-hui Lien and Yi-Chen Tsai},
keywords = {Genetic algorithms, Neural networks, Decision system, Stock market, Over-learning},
abstract = {The past researches emphasize merely the avoidance of over-learning at the system level and ignore the problem of over-learning at the model level, which lead to the poor performance of the evolutionary computation based stock trading decision-making system. This study presents a new evaluation approach to focus on evaluating the generalization capability at the model level. An empirical study was provided and the results reveal four important findings. First, the decision-making system generated at the model design stage outperforms the system generated at the model validation stage, which shows over-learning at the model level. Secondly, for the decision-making system generated either at the model design stage or at the model validation stage, the investment performance in the training period is much better than that in the testing period, exhibiting over-learning at the system level. Third, employing moving timeframe approach is unable to improve the investment performance at the model validation stage. Fourth, reducing the evolution generation and input variables are unable to avoid the over-learning at the model level. The major contribution of this study is to clarify the issue of over-learning at the model and the system level. For future research, this study developed a more reliable evaluation approach in examining the generalization capability of evolutionary computation based decision-making system.}
}
@incollection{WARE20221,
title = {Chapter 1 - Visual Queries},
editor = {Colin Ware},
booktitle = {Visual Thinking for Information Design (Second Edition)},
publisher = {Morgan Kaufmann},
edition = {Second Edition},
pages = {1-22},
year = {2022},
isbn = {978-0-12-823567-6},
doi = {https://doi.org/10.1016/B978-0-12-823567-6.00001-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012823567600001X},
author = {Colin Ware},
keywords = {Visual queries, visual search, distributed cognition, predictive cognition, visual system, visual thinking},
abstract = {The mechanisms and processes of visual thinking are introduced together with how this knowledge can help us make design decisions. We begin with a review of the evidence that we actually take in very little information with each glance and the implication that seeing is a process exquisitely tuned to our cognitive task of the moment. As a key part of this process, our brains execute visual queries using eye movements; visual features are detected in parallel to pick out just what is needed to resolve part of a cognitive problem and move on the next step. We begin to understand how seeing can be a distributed cognitive process executed partly in the brain and partly using a visualization as a tool. In particular, when the visualization is part of an interactive computer application, it provides the primary interface between cognitive operations in the human brain and computational operations. The theory of predictive cognition is introduced as a basis for how we should design presentations.}
}
@article{VARMA2024101673,
title = {Recruitment of magnitude representations to understand graded words},
journal = {Cognitive Psychology},
volume = {153},
pages = {101673},
year = {2024},
issn = {0010-0285},
doi = {https://doi.org/10.1016/j.cogpsych.2024.101673},
url = {https://www.sciencedirect.com/science/article/pii/S0010028524000446},
author = {Sashank Varma and Emily M. Sanford and Vijay Marupudi and Olivia Shaffer and R. {Brooke Lea}},
keywords = {Magnitude representations, Numerical cognition, Graded words, Distributional word semantics, Multi-dimensional scaling, Machine learning},
abstract = {Language understanding and mathematics understanding are two fundamental forms of human thinking. Prior research has largely focused on the question of how language shapes mathematical thinking. The current study considers the converse question. Specifically, it investigates whether the magnitude representations that are thought to anchor understanding of number are also recruited to understand the meanings of graded words. These are words that come in scales (e.g., Anger) whose members can be ordered by the degree to which they possess the defining property (e.g., calm, annoyed, angry, furious). Experiment 1 uses the comparison paradigm to find evidence that the distance, ratio, and boundary effects that are taken as evidence of the recruitment of magnitude representations extend from numbers to words. Experiment 2 uses a similarity rating paradigm and multi-dimensional scaling to find converging evidence for these effects in graded word understanding. Experiment 3 evaluates an alternative hypothesis – that these effects for graded words simply reflect the statistical structure of the linguistic environment – by using machine learning models of distributional word semantics: LSA, word2vec, GloVe, counterfitted word vectors, BERT, RoBERTa, and GPT-2. These models fail to show the full pattern of effects observed of humans in Experiment 2, suggesting that more is needed than mere statistics. This research paves the way for further investigations of the role of magnitude representations in sentence and text comprehension, and of the question of whether language understanding and number understanding draw on shared or independent magnitude representations. It also informs the role of machine learning models in cognitive psychology research.}
}
@article{DROZDZEWSKI2024100086,
title = {Developing QualNotes: A collaborative and cross-disciplinary ethnography},
journal = {Digital Geography and Society},
volume = {6},
pages = {100086},
year = {2024},
issn = {2666-3783},
doi = {https://doi.org/10.1016/j.diggeo.2024.100086},
url = {https://www.sciencedirect.com/science/article/pii/S2666378324000084},
author = {Danielle Drozdzewski and Jose Oriol Lopez Berengueres},
keywords = {QualNotes, Collaborative ethnography, Cross-disciplinary, Mobile application, Digital},
abstract = {Rarely do academics reveal the ‘backend’ of their research; the hours of labour invested into question generation, ethics compliance, transcription, translation, and data analysis, and in our case, coding. Further, when working collaboratively, the conversations that occur between collaborators seldom appear in final publications either. The development of the mobile application QualNotes, provided a productive digital space for collaboration across disciplines. In this paper, we use three vignettes to explicate the ‘backend’ of the development of that mobile application. We chart howour collaborative cross-disciplinary ethnography revealed the generative potential of thinking-with the digital and across disciplinary divides. This paper's contribution is in revealing ‘how’ we work using our disciplinary expertise, but at the same time at the edges of those disciplines too, where we contest, argue, adapt, understand, and, where we learn.}
}
@article{TRAYLOR2024110895,
title = {Model-based experiments as epistemic evidence in paleoecology},
journal = {Ecological Modelling},
volume = {498},
pages = {110895},
year = {2024},
issn = {0304-3800},
doi = {https://doi.org/10.1016/j.ecolmodel.2024.110895},
url = {https://www.sciencedirect.com/science/article/pii/S0304380024002837},
author = {Wolfgang Traylor},
keywords = {Epistemology, Bayesian, Preregistration, Blinding, Uncertainty analysis},
abstract = {Where ordinary experiments are impossible and observational data scarce and indirect—particularly in paleoecosystems—computational experiments are often our only means to learn about reality. There are good arguments to count such model-based predictions as evidence, testing hypotheses and updating our beliefs about the world. However, the epistemic weight of computational experiments depends on an adequate model representation of the target system, transparency about predictive uncertainty, and the avoidance of confirmation bias. I argue that mechanistic models are particularly suited for paleoecological predictions but that iterative uncertainty analyses should guide their development. Using a Bayesian framework I propose preregistration and blinded analysis as tools to strengthen the epistemic value of computational experiments. Here, a preregistration marks the boundary between exploratory model development, which establishes credence in the model, and predictive model application, which tests hypotheses. As good modeling practice I suggest clarifying epistemic goals at the outset of a project and accordingly choose methods to maximize the epistemic weight of the computational experiment.}
}
@article{EGBERT2021104173,
title = {“It's a chance to make mistakes”: Processes and outcomes of coding in 2nd grade classrooms},
journal = {Computers & Education},
volume = {168},
pages = {104173},
year = {2021},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2021.104173},
url = {https://www.sciencedirect.com/science/article/pii/S0360131521000506},
author = {Joy Egbert and Seyed Abdollah Shahrokni and Reima Abobaker and Nataliia Borysenko},
keywords = {Elementary education, Robotics, Coding, Teacher learning, Computational thinking},
abstract = {Several gaps exist in the literature on coding. First, little exploration has focused on early elementary school students. In addition, close description of the overall context of coding tasks at this level is rare. Further, there is a need for both teacher and student voices around coding experiences to be heard. Moreover, a task engagement framework has not been used to evaluate the process or outcomes of early elementary coding tasks. Therefore, an exploratory holistic case study design was used to investigate student and teacher processes and outcomes of coding lessons in order to fill gaps in the literature. In this study, forty-six 2nd grade students, two teachers, and four researchers completed two one-week units on basic coding. Multiple descriptive and numeric data sources were employed to describe the process and outcomes of learning coding. Conclusions include: (1) teachers should start learning about coding first with short awareness sessions and then move to their own classrooms with knowledge brokers and other forms of assistance; (2) a focus on content and process, including problem-solving, is effective for coding with young children; (3) there can be a high level of engagement for teachers and students with the use of robots and welldesigned, age-appropriate coding tasks, and; (4) multiple data sources and the inclusion of both teacher and student data are essential in exploring coding in classrooms.}
}
@article{GUHE2011249,
title = {A computational account of conceptual blending in basic mathematics},
journal = {Cognitive Systems Research},
volume = {12},
number = {3},
pages = {249-265},
year = {2011},
note = {Special Issue on Complex Cognition},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2011.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S1389041711000155},
author = {Markus Guhe and Alison Pease and Alan Smaill and Maricarmen Martinez and Martin Schmidt and Helmar Gust and Kai-Uwe Kühnberger and Ulf Krumnack},
keywords = {Mathematical cognition, Metaphor, Mathematical reasoning, Analogy, Anti-unification, Conceptual blending, HDTP},
abstract = {We present an account of a process by which different conceptualisations of number can be blended together to form new conceptualisations via recognition of common features, and judicious combination of their distinctive features. The accounts of number are based on Lakoff and Núñez’s cognitively-based grounding metaphors for arithmetic. The approach incorporates elements of analogical inference into a generalised framework of conceptual blending, using some ideas from the work of Goguen. The ideas are worked out using Heuristic-Driven Theory Projection (HDTP, a method based on higher-order anti-unification). HDTP provides generalisations between domains, giving a crucial step in the process of finding commonalities between theories. In addition to generalisations, HDTP can also transfer concepts from one domain to another, allowing the construction of new conceptual blends. Alongside the methods by which conceptual blends may be constructed, we provide heuristics to guide this process.}
}
@incollection{YONGSATIANCHOT2021651,
title = {Chapter 19 - Computational models of appraisal to understand the person-situation relation},
editor = {Dustin Wood and Stephen J. Read and P.D. Harms and Andrew Slaughter},
booktitle = {Measuring and Modeling Persons and Situations},
publisher = {Academic Press},
pages = {651-674},
year = {2021},
isbn = {978-0-12-819200-9},
doi = {https://doi.org/10.1016/B978-0-12-819200-9.00005-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128192009000053},
author = {Nutchanon Yongsatianchot and Stacy Marsella},
abstract = {Appraisal theories of emotion argue that emotions arise from a process of comparing individual needs and concerns to external demands. That is, emotions cannot be explained by solely focusing on the environment or by solely focusing on the individual. Rather, they reflect an individual’s subjective assessment of their relation to the environment. Appraisal theories further posit this relationship is characterized by the individual (appraised) in terms of a set of criteria, variously called appraisal variables, checks, or dimensions; for example, Is an event congruent with a person’s goals or concerns?; Who or what caused it?; Was it unexpected?; and What control does the person have over its unfolding? The results of these appraisal checks are in turn mapped to emotion. In this chapter, we do not explore appraisal as a theory of emotion elicitation. Rather, we suggest appraisal theories, specifically the criteria that appraisal theories posit, provide a useful framework for characterizing how situations are perceived by a person and influence their behavior. We go on to suggest that computational models of appraisal can provide a clear specification of how these criteria are assessed. Furthermore, such models can help us explore the dynamics of the person-environment relation, specifically how changes in the environment as well as changes in the person’s perceptions and behavior arise and induce those dynamics.}
}
@article{COTTAM2024105343,
title = {Intelligence: Natural, artificial, or what?},
journal = {BioSystems},
volume = {246},
pages = {105343},
year = {2024},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2024.105343},
url = {https://www.sciencedirect.com/science/article/pii/S0303264724002284},
author = {Ron Cottam and Roger Vounckx},
abstract = {We consider the competing attributes of natural intelligence (NI) and artificial intelligence (AI). Attention is paid to conceptual, theoretical, stylistic and structural aspects of both, and non-human intelligence. Intelligence is related to information processing and current views of physical structuring. Means of distinguishing between NI and AI are noted, and neural and digital structures are described. Pribram's bi-computational neural networks are introduced, and high-level Pribram computation is discussed. We describe the hierarchical Aquarium scheme, along with an AI implementation, and conclude with a proposition for future quantum-based artificial intelligence.}
}
@article{ISLAM2021104757,
title = {EEG Channel Correlation Based Model for Emotion Recognition},
journal = {Computers in Biology and Medicine},
volume = {136},
pages = {104757},
year = {2021},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2021.104757},
url = {https://www.sciencedirect.com/science/article/pii/S0010482521005515},
author = {Md. Rabiul Islam and Md. Milon Islam and Md. Mustafizur Rahman and Chayan Mondal and Suvojit Kumar Singha and Mohiuddin Ahmad and Abdul Awal and Md. Saiful Islam and Mohammad Ali Moni},
keywords = {Emotion, Convolutional neural network, Feature extraction, EEG, Pearson's correlation coefficient, Complexity},
abstract = {Emotion recognition using Artificial Intelligence (AI) is a fundamental prerequisite to improve Human-Computer Interaction (HCI). Recognizing emotion from Electroencephalogram (EEG) has been globally accepted in many applications such as intelligent thinking, decision-making, social communication, feeling detection, affective computing, etc. Nevertheless, due to having too low amplitude variation related to time on EEG signal, the proper recognition of emotion from this signal has become too challenging. Usually, considerable effort is required to identify the proper feature or feature set for an effective feature-based emotion recognition system. To extenuate the manual human effort of feature extraction, we proposed a deep machine-learning-based model with Convolutional Neural Network (CNN). At first, the one-dimensional EEG data were converted to Pearson's Correlation Coefficient (PCC) featured images of channel correlation of EEG sub-bands. Then the images were fed into the CNN model to recognize emotion. Two protocols were conducted, namely, protocol-1 to identify two levels and protocol-2 to recognize three levels of valence and arousal that demonstrate emotion. We investigated that only the upper triangular portion of the PCC featured images reduced the computational complexity and size of memory without hampering the model accuracy. The maximum accuracy of 78.22% on valence and 74.92% on arousal were obtained using the internationally authorized DEAP dataset.}
}
@article{ASHTIANI201618,
title = {A hesitant fuzzy model of computational trust considering hesitancy, vagueness and uncertainty},
journal = {Applied Soft Computing},
volume = {42},
pages = {18-37},
year = {2016},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2016.01.023},
url = {https://www.sciencedirect.com/science/article/pii/S1568494616300102},
author = {Mehrdad Ashtiani and Mohammad Abdollahi Azgomi},
keywords = {Trust modeling, Hesitant fuzzy sets (HFS), Comparative linguistic expressions, Vagueness, Uncertainty, Multi-criteria decision making (MCDM)},
abstract = {The aim of this work is to introduce a trust model, which is highly consistent with the social nature of trust in computational domains. To this end, we propose a hesitant fuzzy multi-criteria decision making based computational trust model capable of taking into account the fundamental building blocks corresponding to the concept of trust. The proposed model is capable of considering the contextuality property of trust and the subjective priorities of the trustor regarding the chosen goal. This is due to viewing trust not as a single label or an integrated concept, but as a collection of trustworthiness facets that may form the trust decision in various contexts and toward different goals. The main benefit of the proposed model is the consideration of the hesitancy of recommenders and the trustor in the process of trust decision making which can create a more flexible mapping between the social and computational requirements of trust. This type of formulation also allows for taking into account the vagueness of the provided opinions. In addition to the vagueness of the provided opinions, the model is capable of considering the certainty of recommendations and its effect on the aggregation process of gathered opinions. In the proposed model, the taste of the recommenders and the similarity of opinions are also considered. This will allow the model to assign more weight to recommendations that have a similar taste compared to the trustor. Finally, taking into consideration the attitudes of the trustors toward change of personality that may occur for various entities in the environment is another advantage of the proposed model. A step-by-step illustrative example and the results of several experimental evaluations, which demonstrate the benefits of the proposed model, are also presented in this paper.}
}
@article{KINLEY2022105843,
title = {Pathologies of precision: A Bayesian account of goals, habits, and episodic foresight in addiction},
journal = {Brain and Cognition},
volume = {158},
pages = {105843},
year = {2022},
issn = {0278-2626},
doi = {https://doi.org/10.1016/j.bandc.2022.105843},
url = {https://www.sciencedirect.com/science/article/pii/S027826262200001X},
author = {Isaac Kinley and Michael Amlung and Suzanna Becker},
keywords = {Addiction, Goals, Habits, Free energy, Bayesian statistics, Episodic future thinking},
abstract = {The brain is thought to implement two decision-making systems: a goal-directed system in which decisions are made through planning on the basis of action–outcome relationships, and a habitual system in which behaviour reflects stimulus–response associations. A prominent theory of addiction sees it as arising due to an extreme dominance of habit over goal-directed action. The balance between these systems is thought to be arbitrated by the relative precision of their separate predictions of reward. In this paper, we argue that various factors in addiction create hyper-precise reward predictions in the habitual system and hypo-precise reward predictions in the goal-directed system, shifting the balance of behavioural control in favour of habit. Based on this, we offer a theoretical account of the utility of episodic future thinking in addiction, interpreting it as increasing the precision of reward estimates in the goal-directed system, thereby enhancing the control of this system over behaviour.}
}
@article{KLEINSCHMIDT2004842,
title = {Thinking Big: Many Modules or Much Cortex?},
journal = {Neuron},
volume = {41},
number = {6},
pages = {842-844},
year = {2004},
issn = {0896-6273},
doi = {https://doi.org/10.1016/S0896-6273(04)00154-0},
url = {https://www.sciencedirect.com/science/article/pii/S0896627304001540},
author = {Andreas Kleinschmidt},
abstract = {Is there a neural system dedicated to generic magnitude judgments? In this issue of Neuron, Pinel et al. report qualitative spatial overlap of fMRI responses during judgments of luminance, size, and numerical magnitude but also quantitative response differences in intraparietal cortex that mirror behavioral interference between perceptual and symbolic magnitude.}
}
@article{CARLEY2002253,
title = {Computational organizational science and organizational engineering},
journal = {Simulation Modelling Practice and Theory},
volume = {10},
number = {5},
pages = {253-269},
year = {2002},
note = {Organisational Processes},
issn = {1569-190X},
doi = {https://doi.org/10.1016/S1569-190X(02)00119-3},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X02001193},
author = {Kathleen M Carley},
keywords = {Computational modeling, Simulation, Organization science, Organizational design, Organizational learning},
abstract = {The past decade has witnessed the emergence of a new scientific discipline––computational social and organizational science. Within organization science in particular, and social science more generally, scientists and practitioners are turning to computational analysis to address fundamental socio-technical problems that are so complex and dynamic that they cannot be fully addressed by traditional techniques. Consequently, there is an explosion of computational models, computationally generated findings, interest in doing simulation, and a dearth of support for this enterprise. This paper contains discussions of the underlying fundamental perspective, the relation of models to empirical data and characteristics of necessary infrastructure.}
}
@article{HUMPHREYS1991315,
title = {Vol. 3: Thinking: edited by Daniel N. Osherson and Edward E. Smith (x + 308 pages) ISBN 0 262 65035 5},
journal = {Trends in Neurosciences},
volume = {14},
number = {7},
pages = {315},
year = {1991},
issn = {0166-2236},
doi = {https://doi.org/10.1016/0166-2236(91)90148-N},
url = {https://www.sciencedirect.com/science/article/pii/016622369190148N},
author = {Glyn W. Humphreys}
}
@article{CROLLEN2020290,
title = {How visual is the « number sense »? Insights from the blind},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {118},
pages = {290-297},
year = {2020},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2020.07.022},
url = {https://www.sciencedirect.com/science/article/pii/S0149763420304851},
author = {Virginie Crollen and Olivier Collignon},
keywords = {Blindness, Mathematical cognition, Brain plasticity},
abstract = {Is vision a necessary building block for the foundations of mathematical cognition? A straightforward model to test the causal role visual experience plays in the development of numerical abilities is to study people born without sight. In this review we will demonstrate that congenitally blind people can develop numerical abilities that equal or even surpass those of sighted individuals, despite representing numbers using a qualitatively different representational format. We will also show that numerical thinking in blind people maps onto regions typically involved in visuo-spatial processing in the sighted, highlighting how intrinsic computational biases may constrain the reorganization of numerical networks in case of early visual deprivation. More generally, we will illustrate how the study of arithmetic abilities in congenitally blind people represents a compelling model to understand how sensory experience scaffolds the development of higher-level cognitive representations.}
}
@article{MILLER1990489,
title = {Towards a believable theory of planning: D. E. Wilkins. Practical Planning. San Mateo, CA: Morgan Kaufmann, 1988. Pp. xii + 205. $49.95. S. L. Friedman. E. K. Scholnick, and R. R. Cocking. Blueprints for Thinking, London/New York: Cambridge Univ. Press, 1987. Pp. xv + 559. $58.50 K. Hammond. Case-Based Planning. San Diego: Academic Press, 1989. Pp. xviii + 277. $34.95},
journal = {Journal of Mathematical Psychology},
volume = {34},
number = {4},
pages = {489-498},
year = {1990},
issn = {0022-2496},
doi = {https://doi.org/10.1016/0022-2496(90)90028-8},
url = {https://www.sciencedirect.com/science/article/pii/0022249690900288},
author = {David P. Miller}
}
@article{BATEMAN2021100502,
title = {What are digital media?},
journal = {Discourse, Context & Media},
volume = {41},
pages = {100502},
year = {2021},
issn = {2211-6958},
doi = {https://doi.org/10.1016/j.dcm.2021.100502},
url = {https://www.sciencedirect.com/science/article/pii/S2211695821000386},
author = {John A. Bateman},
keywords = {Digital media, Digital information, Literacy, Models of communication, Multimodality, Medium, Development of media, Computational media},
abstract = {This essay addresses the nature of so–called ‘digital media’ in a literacy context from the perspectives of semiotics, theories of the ‘medium’, and computation. It argues that most accounts that attempt to work with some notion of ‘digital media’ anchor themselves insufficiently in semiotics and computation and the essential combination of these that is necessary when discussing digital media as an object of study. This weakens approaches, particularly when the concern is to develop ways of teaching engagement with contemporary communication practices at any level, i.e., improving ‘digital literacies’ of various kinds. Achieving more robust foundations is important for interventions which are not only more effective but also sustainable, minimizing the danger of obsolescence with each new technological turn of the screw. Foundations are also essential for a more balanced perspective on learning situations that does not dichotomize allegedly ‘digital’ and ‘non–digital’ practices and skills. Many such boundaries are deeply misleading and so unnecessarily compartmentalize thinking and restrict the application of relevant research results and methods. The focus of this essay is therefore to consider how a closer examination of media and their development, combined with the contributions made by information technologies, may help articulate notions of digital media that are more supportive of productive engagements with research and issues of literacy.}
}
@article{ZHANG202524,
title = {Farmers’ decisions on crop residues utilization, greenhouse gases reduction and subsidy of crop residue-based bioenergy: An agent-based life cycle model},
journal = {Sustainable Production and Consumption},
volume = {55},
pages = {24-36},
year = {2025},
issn = {2352-5509},
doi = {https://doi.org/10.1016/j.spc.2025.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S2352550925000235},
author = {Jiaqi Zhang and Chengxiang Zhuge and Qitong Huang and Bin Wang and Yu'e Li and Peter Oosterveer},
keywords = {Agent-based model, Crop residue-based bioenergy, Life cycle thinking, Environmental and economic impacts, Farmer decision making},
abstract = {To further advance the crop residue-based bioenergy (CRB) industry for climate change mitigation, it is crucial to better understand the influence of stakeholders' behaviours on greenhouse gases (GHG) mitigation potentials. However, the heterogeneity and social dynamics of stakeholders, particularly farmers, have received less attention. This study develops an Agent-based Environmental and Economic assessment (AEE) model that integrates agent-based model and life cycle thinking methods to simulate the CRB system. The AEE model was applied in Heilongjiang Province of China, to investigate how stakeholder decisions affect CRB's GHG reduction potential and government subsidies. Scenario analyses explore the effects of grain markets, subsidies, and collection distance on environmental and economic outcomes. The findings indicate that more farmers are willing to adopt crop residues collection than those currently practicing it, primarily due to logistical constraints. Key factors influencing adoption include farming income, age, farm size and crop types. CRB contributed to 70.6 % of overall GHG reductions with only 41.6 % of the subsidy, demonstrating higher mitigation efficiency. In conclusion, the government must address the deficiency in crop residues logistics to promote CRB development. Additionally, agricultural policies play a crucial role in ensuring CRB feedstock availability by guiding crop types selection. The results suggest that AEE model is adequate in simulating both micro and macro dynamics in the context of CRB, highlighting the robustness of integrating agent-based model and life cycle thinking methods to study complex issues.}
}
@article{MARTI2025345,
title = {Fifty years of metaheuristics},
journal = {European Journal of Operational Research},
volume = {321},
number = {2},
pages = {345-362},
year = {2025},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2024.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S0377221724002637},
author = {Rafael Martí and Marc Sevaux and Kenneth Sörensen},
keywords = {Heuristics, Combinatorial optimization, Critical review, Metaheuristics},
abstract = {In this paper, we review the milestones in the development of heuristic methods for optimization over the last 50 years. We propose a critical analysis of the main findings and contributions, mainly from a European perspective. Starting with the roots of the area that can be traced back to the classical philosophers, we follow the historical path of heuristics and metaheuristics in the field of operations research and list the main milestones, up to the latest proposals to hybridize metaheuristics with machine learning. We pay special attention to the theories that changed our way of thinking about problem solving, and to the role played by the European Journal of Operational Research in the development of these theories. Our approach emphasizes methodologies and their connections with related areas, which permits to identify potential lines of future research.}
}
@article{EYSENCK19921359,
title = {Thinking clearly about psychology volume 2: Personality and psychopathology: William M. Grove and Dante Cicchetti: Minneapolis: University of Minnesota Press (1991). pp. v–vi, 3–467. Cloth, ISBN 0-8166-1892-5 v. 2.$45.00.},
journal = {Personality and Individual Differences},
volume = {13},
number = {12},
pages = {1359-1360},
year = {1992},
issn = {0191-8869},
doi = {https://doi.org/10.1016/0191-8869(92)90185-R},
url = {https://www.sciencedirect.com/science/article/pii/019188699290185R},
author = {H.J. Eysenck}
}
@article{JUHOLA2021106367,
title = {On computational classification of genetic cardiac diseases applying iPSC cardiomyocytes},
journal = {Computer Methods and Programs in Biomedicine},
volume = {210},
pages = {106367},
year = {2021},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2021.106367},
url = {https://www.sciencedirect.com/science/article/pii/S0169260721004417},
author = {Martti Juhola and Henry Joutsijoki and Kirsi Penttinen and Disheet Shah and Katriina Aalto-Setälä},
keywords = {Genetic cardiac diseases, Induced pluripotent stem cells, Cardiomyocytes, Transient profiles, Machine learning, Classification, Leave-one-out, -fold cross-validation},
abstract = {Background
Cardiomyocytes differentiated from human induced pluripotent stem cells (iPSC-CMs) can be used to study genetic cardiac diseases. In patients these diseases are manifested e.g. with impaired contractility and fatal cardiac arrhythmias, and both of these can be due to abnormal calcium transients in cardiomyocytes. Here we classify different genetic cardiac diseases using Ca2+ transient data and different machine learning algorithms.
Methods
By studying calcium cycling of disease-specific iPSC-CMs and by using calcium transients measured from these cells it is possible to classify diseases from each other and also from healthy controls by applying machine learning computation on the basis of peak attributes detected from calcium transient signals.
Results
In the current research we extend our previous study having Ca-transient data from four different genetic diseases by adding data from two additional diseases (dilated cardiomyopathy and long QT Syndrome 2). We also study, in the light of the current data, possible differences and relations when machine learning modelling and classification accuracies were computed by using either leave-one-out test or 10-fold cross-validation.
Conclusions
Despite more complex classification tasks compared to our earlier research and having more different genetic cardiac diseases in the analysis, it is still possible to attain good disease classification results. As excepted, leave-one-out test and 10-fold cross-validation achieved virtually equal results.}
}
@article{DESOUZA2024100042,
title = {The generative AI revolution, cognitive mediation networks theory and the emergence of a new mode of mental functioning: Introducing the Sophotechnic Mediation scale},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {2},
number = {1},
pages = {100042},
year = {2024},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2024.100042},
url = {https://www.sciencedirect.com/science/article/pii/S2949882124000021},
author = {Bruno Campello {de Souza} and Agostinho {Serrano de Andrade Neto} and Antonio Roazzi},
keywords = {ChatGPT, Chatbots, Artificial intelligence, Cognitive mediation networks theory, Hyperculture, Sophotechnic},
abstract = {This paper examines the recent emergence of AI-powered chatbots such as ChatGPT through the lens of the Cognitive Mediation Networks Theory (CMNT), deducing that the introduction of this radically new technology will likely create a new stage of collective cognitive functioning, called “Sophotechnic Mediation”, with characteristics that can be extrapolated from the way these new tools work and the dynamics of the sociocultural structures being created around them. From that description, the Sophotechnic Mediation Scale is proposed as a means to assess the extent of an individual's internalization of the new form of thinking. A preliminary empirical investigation with 132 higher education professors and students found the instrument to be statistically consistent, yielding a unidimensional and Gaussian score that behaves as a developmental trait emerging from the interaction with generative AIs, mediated by age and mastery of previous digital technologies and their cultural elements. It is concluded that the results are suggestive of the validity of the new scale and warrant further research.}
}
@article{BOHMANN2018185,
title = {Computational tools for topological coHochschild homology},
journal = {Topology and its Applications},
volume = {235},
pages = {185-213},
year = {2018},
issn = {0166-8641},
doi = {https://doi.org/10.1016/j.topol.2017.12.008},
url = {https://www.sciencedirect.com/science/article/pii/S0166864117306442},
author = {Anna Marie Bohmann and Teena Gerhardt and Amalie Høgenhaven and Brooke Shipley and Stephanie Ziegenhagen},
keywords = {Topological Hochschild homology, Coalgebra, Hochschild–Kostant–Rosenberg},
abstract = {In recent work, Hess and Shipley [18] defined a theory of topological coHochschild homology (coTHH) for coalgebras. In this paper we develop computational tools to study this new theory. In particular, we prove a Hochschild–Kostant–Rosenberg type theorem in the cofree case for differential graded coalgebras. We also develop a coBökstedt spectral sequence to compute the homology of coTHH for coalgebra spectra. We use a coalgebra structure on this spectral sequence to produce several computations.}
}
@article{DASH201640,
title = {An evolutionary hybrid Fuzzy Computationally Efficient EGARCH model for volatility prediction},
journal = {Applied Soft Computing},
volume = {45},
pages = {40-60},
year = {2016},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2016.04.014},
url = {https://www.sciencedirect.com/science/article/pii/S1568494616301624},
author = {Rajashree Dash and P.K. Dash},
keywords = {Volatility prediction, Stock markets, GARCH model variants, Fuzzy logic based hybrids, Fuzzy inference with nonlinear functions, Multistep prediction, Differential evolution, Super predictive ability test},
abstract = {Accurate modeling for forecasting of stock market volatility is a widely interesting research area both in academia as well as financial markets. This paper proposes an innovative Fuzzy Computationally Efficient EGARCH model to forecast the volatility of three stock market indexes. The proposed model represents a joint estimation of the membership function parameters of a TSK-type fuzzy inference system along with the leverage effect, asymmetric shock by leverage effect of EGARCH model in forecasting highly nonlinear and complicated financial time series model more accurately. Further unlike the conventional TSK type fuzzy neural network the proposed model uses a functional link neural network (FLANN) in the consequent part of the fuzzy rules to provide an improved mapping. Moreover, a differential evolution (DE) algorithm is suggested to solve the parameters estimation problem of Fuzzy Computationally Efficient EGARCH model. Being a parallel direct search algorithm, DE has the strength of finding global optimal solutions regardless of the initial values of its few control parameters. Furthermore, the DE based algorithm aims to achieve an optimal solution with a rapid convergence rate. The proposed model has been compared with some GARCH family models and hybrid fuzzy systems and GARCH models based on three performance metrics: MSFE, RMSFE, and MAFE. The results indicate that the proposed method offers significant improvements in volatility forecasting performance in comparison with all other specified models.}
}
@article{CABITZA201765,
title = {The semiotics of configurations for the immanent design of interactive computational systems},
journal = {Journal of Visual Languages & Computing},
volume = {40},
pages = {65-90},
year = {2017},
note = {Semiotics, Human-Computer Interaction and End-User Development},
issn = {1045-926X},
doi = {https://doi.org/10.1016/j.jvlc.2017.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S1045926X16300246},
author = {Federico Cabitza and Alvise Mattozzi},
keywords = {Semiotics of Configurations, Immanent design, End-User Development platforms, Document management systems, Electronic Health Record},
abstract = {In this paper the authors propose a novel semiotic approach to the design of interactive systems and computational systems, grounded in the most recent contributions within the debate around semiotic theory and analysis. This approach, that is here called Semiotics of Configurations (SoC), is proposed for its analytic power in describing material artifacts and settings with a purposely a-conceptualistic stance. The resulting analysis informs a kind of design that is aimed at reproducing and supporting the programs of action detected in the use of artifacts, as this use is “abducted” from the physical and material form of the artifacts themselves and from the observation of how content is transformed within and across them. This approach to design, called immanent design, has inspired a platform for the user-driven development and use of electronic documents and forms in cooperative and organizational domains. The framework is illustrated with a case drawn from a study performed in the domain of hospital work.}
}
@article{PRATT2023103217,
title = {Bringing advanced technology to strategic decision-making: The Decision Intelligence/Data Science (DI/DS) Integration framework},
journal = {Futures},
volume = {152},
pages = {103217},
year = {2023},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2023.103217},
url = {https://www.sciencedirect.com/science/article/pii/S0016328723001222},
author = {Lorien Pratt and Christophe Bisson and Thierry Warin},
keywords = {Strategic decision making, Decision intelligence, Corporate foresight, Artificial intelligence, Complexity, Kahneman’s systems thinking},
abstract = {There is a widespread stated desire amongst both public and private organizations worldwide to engage in more significant “evidence-based reasoning” and to be more “data-driven.” We argue that these two goals are proxies for the often-unstated goal of improving the exploration of possible futures as foresights that could lead to better strategic decisions and improved business outcomes. From this perspective, data and analytics hold great promise and are necessary—but not sufficient—for improving strategic decision-making. Something more is needed to realize this potential. We specify how to fill this gap using an integration framework between technology and decision-makers, which is especially appropriate in complex and/or volatile environments. Our solution—which comprises a methodology as well as a software architecture—therefore unifies not only human decision makers to technology but each other and also integrates several disciplines that have been hitherto unnecessarily separated. Thereby, it could help organizations to address increasing challenges better as well as improve the exploration of possible futures.}
}
@article{AALTO2019145,
title = {Modeling of biomass supply system by combining computational methods – A review article},
journal = {Applied Energy},
volume = {243},
pages = {145-154},
year = {2019},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2019.03.201},
url = {https://www.sciencedirect.com/science/article/pii/S0306261919306178},
author = {Mika Aalto and Raghu KC and Olli-Jussi Korpinen and Kalle Karttunen and Tapio Ranta},
keywords = {Biomass, Supply chain, Life cycle assessment, Geographical information system, Agent-based modeling and simulation, Discrete-event simulation},
abstract = {As computing power increases, more complex computational models are utilized for biomass supply system studies. The paper describes three commonly used modeling methods in this context, geographic information systems, life-cycle assessment, and discrete-time simulation and presents bibliometric analysis of work using these three study methods. Of the 498 publications identified in searches of the Scopus and Web of Science databases, 17 reported on combinations of methods: 10 on life-cycle assessment and geographic information systems, six on joint use of life-cycle assessment and discrete-time simulation, and one on use of geographic information systems jointly with discrete-time simulation. While no articles dealt directly with simultaneous use of all three methods, several acknowledged the potential of this. The authors discuss numerous challenges identified in the review that arise in combining methods, among them computational load, the increasing number of assumptions, guaranteeing coherence between the models used, and the large quantities of data required. Discussion of issues such as the complexity of reporting and the need for standard procedures and terms becomes more critical as repositories bring together research materials, including entire models, from various sources. Efforts to mitigate many of modeling’s challenges have involved phase-specific modeling and use of such methods as expressions or uncertainty analysis in place of a complex secondary model. The authors conclude that combining modeling methods offer considerable potential for taking more variables into account; improving the results; and benefiting researchers, decision–makers, and operation managers by producing more reliable information.}
}
@article{KRZHIZHANOVSKAYA2015288,
title = {Russian-Dutch double-degree Master’s programme in computational science in the age of global education},
journal = {Journal of Computational Science},
volume = {10},
pages = {288-298},
year = {2015},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2015.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S1877750315000812},
author = {Valeria V. Krzhizhanovskaya and Alexey V. Dukhanov and Anna Bilyatdinova and Alexander V. Boukhanovsky and Peter M.A. Sloot},
keywords = {Computational science, Master’s programme, Graduate program, Double degree, Curriculum, Enrollment, Student research, Funding opportunities},
abstract = {We present a new double-degree graduate (Master’s) programme developed together by the ITMO University, Russia and University of Amsterdam, The Netherlands. First, we look into the global aspects of integration of different educational systems and list some funding opportunities. Then, we describe our double-degree program curriculum, suggest the timeline of enrollment and studies, and give some examples of student research topics. Finally, we discuss the issues of joint programs with Russia and suggest possible solutions, analyze the results of the first three student intakes and reflect on the lessons learnt, and share our thoughts and experiences that could be of interest to the international community expanding the educational markets to the vast countries like Russia, China or India. The paper is written for education professionals and contains useful information for potential students. This is an extended version of a conference paper (http://dx.doi.org/10.1016/j.procs.2014.05.130) invited to this special issue of the Journal of Computational Science.}
}
@incollection{MILLER201455,
title = {Chapter 5 - Managing and Integrating Exposome Data: Maps, Models, Computation, and Systems Biology},
editor = {Gary W. Miller},
booktitle = {The Exposome},
publisher = {Academic Press},
address = {San Diego},
pages = {55-69},
year = {2014},
isbn = {978-0-12-417217-3},
doi = {https://doi.org/10.1016/B978-0-12-417217-3.00005-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780124172173000057},
author = {Gary W. Miller},
keywords = {Bioinformatics, systems biology, computational biology, machine learning, Bayesian methods},
abstract = {Exposome-related data will come from a myriad of sources. The huge amounts of data must be organized in some manner that allows appropriate interpretations and associations to be drawn. Models and maps are often used to provide organization to complex data sets. Maps are quite appropriate for exposome research as the location of the sources and exposures is a critical component, and spatial statistics could play a major role in exposome data organization. The complex types of data will undoubtedly require mathematical approaches, including bioinformatics, computational, and systems biology-based techniques. This chapter reviews some of the possible strategies that can be used to keep track of the diverse and massive data sets that will result from exposome research.}
}
@article{VALTON2017631,
title = {Comprehensive review: Computational modelling of schizophrenia},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {83},
pages = {631-646},
year = {2017},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2017.08.022},
url = {https://www.sciencedirect.com/science/article/pii/S0149763416307357},
author = {Vincent Valton and Liana Romaniuk and J. {Douglas Steele} and Stephen Lawrie and Peggy Seriès},
keywords = {Psychotic symptoms, Schizophrenia, Computational models, Computational psychiatry},
abstract = {Computational modelling has been used to address: (1) the variety of symptoms observed in schizophrenia using abstract models of behavior (e.g. Bayesian models – top-down descriptive models of psychopathology); (2) the causes of these symptoms using biologically realistic models involving abnormal neuromodulation and/or receptor imbalance (e.g. connectionist and neural networks – bottom-up realistic models of neural processes). These different levels of analysis have been used to answer different questions (i.e. understanding behavioral vs. neurobiological anomalies) about the nature of the disorder. As such, these computational studies have mostly supported diverging hypotheses of schizophrenia's pathophysiology, resulting in a literature that is not always expanding coherently. Some of these hypotheses are however ripe for revision using novel empirical evidence. Here we present a review that first synthesizes the literature of computational modelling for schizophrenia and psychotic symptoms into categories supporting the dopamine, glutamate, GABA, dysconnection and Bayesian inference hypotheses respectively. Secondly, we compare model predictions against the accumulated empirical evidence and finally we identify specific hypotheses that have been left relatively under-investigated.}
}
@article{POSTAN2018111,
title = {Dioids for Computational Effects},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {339},
pages = {111-134},
year = {2018},
note = {The XLII Latin American Computing Conference},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2018.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S1571066118300525},
author = {Ezequiel Postan and Exequiel Rivas and Mauro Jaskelioff},
keywords = {dioid, monad, Haskell, computational effect},
abstract = {There are different algebraic structures that one can use to model notions of computation. The most well- known are monads, but lately, applicative functors have been gaining popularity. These two structures can be understood as instances of the unifying notion of monoid in a monoidal category. When dealing with non-determinism, it is usual to extend monads and applicative functors with additional structure. However, depending on the desired non-determinism, there are different options of interaction between the existing and the additional structure. This article studies one of those options, which is captured algebraically by dioids. We generalise dioids to dioid categories and show how dioids in such a category model non- determinism in monads and applicative functors. Moreover, we study the construction of free dioids in a programming context.}
}
@article{MA2017144,
title = {A decomposition-based multi-objective optimization for simultaneous balance computation and transformation in signed networks},
journal = {Information Sciences},
volume = {378},
pages = {144-160},
year = {2017},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2016.10.035},
url = {https://www.sciencedirect.com/science/article/pii/S0020025516313883},
author = {Lijia Ma and Maoguo Gong and Jianan Yan and Fuyan Yuan and Haifeng Du},
keywords = {Structural balance computation, Balance transformation, Multi-objective optimization, Decomposition, Signed networks},
abstract = {Many social systems have a set of opposite interactions such as friend/enemy, cooperation/competition and support/opposition. In these signed systems, there exist functional imbalances from the system-level view because of the existence of unbalanced interactions. However, it is difficult to compute the unbalance degree and transform unbalanced factors to balanced ones in real signed systems. Earlier studies tackled these two issues separately and gave a unique solution, and thus cannot be well applied to real applications with constraints. In this paper, we devise a decomposition-based and network-specific multi-objective optimization algorithm to solve the balance computation and transformation of signed networks simultaneously. The devised algorithm aims at finding a set of optimal balance transformation solutions, and each of which is the trade-off between the twin objectives (i.e., the minimization of inter-cluster positive links and the minimization of intra-cluster negative links). Of these solutions, the one with the fewest unbalanced links corresponds to the solution to the balance computation. And each trade-off solution corresponds to an optimal balance transformation way under a certain transformation cost. Extensive experiments on four social networks demonstrate the effectiveness of the devised algorithm on both the computation and the transformation of structural balance. They also show that the devised algorithm can provide multiple optimal solutions at the same transformation cost.}
}
@article{KUO201232,
title = {Conceptual study of micro-tab device in airframe noise reduction: (II) 3D computation},
journal = {Aerospace Science and Technology},
volume = {17},
number = {1},
pages = {32-39},
year = {2012},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2011.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S127096381100040X},
author = {Brian C. Kuo and Nesrin Sarigul-Klijn},
keywords = {Computational aeroacoustics, High-lift devices, Micro-tab, Airframe noise},
abstract = {A three-dimensional numerical study is conducted to better understand noise reduction results seen in the previous two-dimensional investigation of the acoustic effects of micro-tab device on airframe noise reduction. Without sacrificing the aerodynamic performance, it is possible to achieve high-lift noise reduction with the application of the micro-tab device attached to the pressure side of the flap surface near its trailing-edge. This study was carried out by numerical hybrid method, which combines Computational Fluid Dynamics and acoustic analogy to predict the farfield noise spectrum. The near-full-scale computational results show that the micro-tab device with reduced deflection of the high-lift devices achieves noise reduction in mid-to-high frequency domain, in particular the range that human beings are most sensitive to. In addition, a parametric study in terms of geometric variation of the micro-tab was also investigated and reported. The three-dimensional results obtained thus far show reduction in noise levels with use of micro-tab.}
}
@article{RICHARD2019136,
title = {CastLab: an object-oriented finite element toolbox within the Matlab environment for educational and research purposes in computational solid mechanics},
journal = {Advances in Engineering Software},
volume = {128},
pages = {136-151},
year = {2019},
issn = {0965-9978},
doi = {https://doi.org/10.1016/j.advengsoft.2018.08.016},
url = {https://www.sciencedirect.com/science/article/pii/S0965997818301303},
author = {Benjamin Richard and Giuseppe Rastiello and Cédric Giry and Francesco Riccardi and Romili Paredes and Eliass Zafati and Santosh Kakarla and Chaymaa Lejouad},
keywords = {Matlab toolbox, Nonlinear solid mechanics, Computational mechanics, Educational tools, Finite elements},
abstract = {The Matlab environment has become widely used among the computational mechanics community, not only for research purposes but also to teach either undergraduate or graduate classes. This paper aims to present a new toolbox devoted to computational mechanics and in particular to solid mechanics. Both recent and well-established numerical formulations have been implemented in it. One of its strengths resides in the fact that it was developed within an object-oriented framework. This key feature makes the CastLab toolbox easy-to-use and with extensive capabilities for customized user developments. After a brief description of the theoretical background related to the problems that can be solved by means of the toolbox, several representative case-studies are presented. These examples have been selected to illustrate not only the numerical efficiency of the toolbox, which is of primary importance for research purposes, but also its strong educational and pedagogic potential.}
}
@article{KUMAR2006806,
title = {Applying computational modeling to drug discovery and development},
journal = {Drug Discovery Today},
volume = {11},
number = {17},
pages = {806-811},
year = {2006},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2006.07.010},
url = {https://www.sciencedirect.com/science/article/pii/S1359644606002868},
author = {Neil Kumar and Bart S. Hendriks and Kevin A. Janes and David {de Graaf} and Douglas A. Lauffenburger},
abstract = {Computational models of cells, tissues and organisms are necessary for increased understanding of biological systems. In particular, modeling approaches will be crucial for moving biology from a descriptive to a predictive science. Pharmaceutical companies identify molecular interventions that they predict will lead to therapies at the organism level, suggesting that computational biology can play a key role in the pharmaceutical industry. We discuss pharmaceutically-relevant computational modeling approaches currently used as predictive tools. Specific examples demonstrate how companies can employ these computational models to improve the efficiency of transforming targets into therapies.}
}
@incollection{VAMVOUDAKIS2024,
title = {Multi Agent Q-Learning With Adversaries in Nash Equilibrium and Non Equilibrium Settings},
booktitle = {Reference Module in Materials Science and Materials Engineering},
publisher = {Elsevier},
year = {2024},
isbn = {978-0-12-803581-8},
doi = {https://doi.org/10.1016/B978-0-443-14081-5.00082-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443140815000829},
author = {Kyriakos G. Vamvoudakis},
keywords = {Adaptive control, Adaptive learning, Bounded rationality, Cyber-physical systems, Game theory, Model-free, Multi-agent systems, Nash games, Networked systems, Optimal control, Q-learning, Reinforcement learning},
abstract = {The purpose of this chapter is to demonstrate how to solve optimal control problems, both for single-player games and multiplayer games with intermittent and continuous feedback in centralized and multi agent settings. We achieve this by using Q-learning, leveraging data measured along the trajectories. Importantly, our approaches do not require any prior knowledge of the system dynamics. This model-free and dynamic framework allows learning agents to adapt their objectives or optimality criteria on the fly. In addressing nonequilibrium results in shifting, dynamical environments, a control-oriented multi agent formulation of the interactions between different thinking agents is also shown.}
}
@article{ATSALAKIS2016107,
title = {Using computational intelligence to forecast carbon prices},
journal = {Applied Soft Computing},
volume = {43},
pages = {107-116},
year = {2016},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2016.02.029},
url = {https://www.sciencedirect.com/science/article/pii/S1568494616300801},
author = {George S. Atsalakis},
keywords = {ANFIS forecasting, Carbon allowance, Carbon price forecasting, Computational intelligent forecasting, Neuro-fuzzy forecasting, PATSOS forecasting},
abstract = {European Union has introduced the European Trading System (ETS) as a tool for developing and implementing international treaties related to climate changes and to identify the most cost-effective methods for reducing greenhouse gas emissions, in particular carbon dioxide (CO2), which is the most substantial. Companies producing carbon emissions must effectively manage associated costs by buying or selling carbon emission futures. Viewed from this perspective, this paper provides a model for managing the risk by buying and selling carbon emission futures by implementing techniques that leverage computational intelligence. Three computational intelligence techniques are proposed to provide accurate and timely forecasts for changes in the price of carbon: a novel hybrid neuro-fuzzy controller that forms a closed-loop feedback mechanism called PATSOS; an artificial neural network (ANN) based system; an adaptive neuro-fuzzy inference system (ANFIS). Results are based on 1074 daily carbon price observations collected to comprise a useful time-series dataset and for evaluation of the proposed techniques. The extra-sample performance of the proposed techniques is calculated. Analysis results are compared with those produced by other models. Comparison studies reveal that PATSOS is the most accurate and promising methodology for predicting the price of carbon. It is stated that this paper registers a first attempt to apply a hybrid neuro-fuzzy controller to forecasting carbon prices.}
}
@article{SHARMA20221,
title = {The design and evaluation of an AR-based serious game to teach programming},
journal = {Computers & Graphics},
volume = {103},
pages = {1-18},
year = {2022},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2022.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0097849322000024},
author = {Vandit Sharma and Kaushal Kumar Bhagat and Huai-Hsuan Huang and Nian-Shing Chen},
keywords = {Augmented Reality, Computational thinking, Learning Analytics, Gamification, Feedback design, System usability},
abstract = {The ubiquity of smartphone and tablet devices, combined with the increasing availability of serious games, has enabled students to learn various abstract concepts in an appealing and convenient manner. While several researchers have explored the use of Augmented Reality (AR) in serious games, many of these games have not been critically explained or evaluated. To that end, we employed game-based learning methodologies and Game Learning Analytics (GLA) to systematize the design and evaluation of an AR-based serious game to teach programming. We evaluated our game for usability and effectiveness by conducting a user study on twenty-seven undergraduate students. The evaluation primarily consisted of a learning test conducted twice – before and after playing the game – along with a usability questionnaire that players completed after playing the game. Our results showed that players made significant progress after playing the game. The game helped players improve their basic programming skills, especially for the group having lower prior programming skills. The results highlighted various ways in which GLA can be used to benefit different stakeholders in the game. Based on players’ qualitative responses, we also identified several areas of improvement, most prominently the trade-off between ease of use and game complexity. We provide suggestions and discuss implications for future work.}
}
@article{SINGH20212537,
title = {Resources and computational strategies to advance small molecule SARS-CoV-2 discovery: Lessons from the pandemic and preparing for future health crises},
journal = {Computational and Structural Biotechnology Journal},
volume = {19},
pages = {2537-2548},
year = {2021},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2021.04.059},
url = {https://www.sciencedirect.com/science/article/pii/S2001037021001719},
author = {Natesh Singh and Bruno O. Villoutreix},
abstract = {There is an urgent need to identify new therapies that prevent SARS-CoV-2 infection and improve the outcome of COVID-19 patients. This pandemic has thus spurred intensive research in most scientific areas and in a short period of time, several vaccines have been developed. But, while the race to find vaccines for COVID-19 has dominated the headlines, other types of therapeutic agents are being developed. In this mini-review, we report several databases and online tools that could assist the discovery of anti-SARS-CoV-2 small chemical compounds and peptides. We then give examples of studies that combined in silico and in vitro screening, either for drug repositioning purposes or to search for novel bioactive compounds. Finally, we question the overall lack of discussion and plan observed in academic research in many countries during this crisis and suggest that there is room for improvement.}
}
@article{LASO2018428,
title = {Finding an economic and environmental balance in value chains based on circular economy thinking: An eco-efficiency methodology applied to the fish canning industry},
journal = {Resources, Conservation and Recycling},
volume = {133},
pages = {428-437},
year = {2018},
issn = {0921-3449},
doi = {https://doi.org/10.1016/j.resconrec.2018.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S0921344918300429},
author = {Jara Laso and Isabel García-Herrero and María Margallo and Ian Vázquez-Rowe and Pére Fullana and Alba Bala and Cristina Gazulla and Ángel Irabien and Rubén Aldaco},
keywords = {Life cycle assessment, Life cycle costing, Eco-efficiency, Engraulis encrasicolus, Linear programming},
abstract = {The production of food that is environmentally friendly and presents a high economic return is one of the current concerns for the food industry. Eco-efficiency links the environmental performance of a product to its economic value. In this context, this study combines Life Cycle Assessment (LCA) and Life Cycle Costing (LCC) to propose a two-step eco-efficiency methodology assessment for the fish canning industry. An eco-label rating system based on a descriptive weighting of environmental (Global Warming Potential, Acidification Potential, Eutrophication Potential and the ReCiPe Single Score Endpoint) and economic (Value Added) indicators was applied to the canned anchovy. Secondly, LCA-LCC results were coupled to linear programming (LP) tools in order to define a composite eco-efficiency index. This approach enables translation into economic terms of the environmental damage caused when a given alternative is chosen. In particular, different origins for anchovy species (South American vs. Cantabrian) and related waste management alternatives (landfill, incineration and valorization) were evaluated under this cradle to gate approach. Results indicated that substantial differences can be observed depending on the origin of the fish. Anchovies landed in Cantabria show a higher value added score at the expense of larger environmental impacts, mainly due to fuel use intensity. Moreover, its environmental scores are lowered when fish residues are valorized into marketable products, while increasing the value added. This study demonstrates the environmental and economic benefits of applying circular economy. According to this, it is possible to introduce the cradle-to-cradle concept in the fish canned industry. The methodology proposed is intended to be useful to decision-makers in the anchovy canning sector and can be applied to other regions and industrial sectors.}
}
@article{ANGELAKI2009452,
title = {Multisensory integration: psychophysics, neurophysiology, and computation},
journal = {Current Opinion in Neurobiology},
volume = {19},
number = {4},
pages = {452-458},
year = {2009},
note = {Sensory systems},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2009.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S0959438809000725},
author = {Dora E Angelaki and Yong Gu and Gregory C DeAngelis},
abstract = {Fundamental observations and principles derived from traditional physiological studies of multisensory integration have been difficult to reconcile with computational and psychophysical studies that share the foundation of probabilistic (Bayesian) inference. We review recent work on multisensory integration, focusing on experiments that bridge single-cell electrophysiology, psychophysics, and computational principles. These studies show that multisensory (visual–vestibular) neurons can account for near-optimal cue integration during the perception of self-motion. Unlike the nonlinear (superadditive) interactions emphasized in some previous studies, visual–vestibular neurons accomplish near-optimal cue integration through subadditive linear summation of their inputs, consistent with recent computational theories. Important issues remain to be resolved, including the observation that variations in cue reliability appear to change the weights that neurons apply to their different sensory inputs.}
}
@article{DELOERA20161,
title = {Random sampling in computational algebra: Helly numbers and violator spaces},
journal = {Journal of Symbolic Computation},
volume = {77},
pages = {1-15},
year = {2016},
issn = {0747-7171},
doi = {https://doi.org/10.1016/j.jsc.2016.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S074771711600002X},
author = {Jesús A. {De Loera} and Sonja Petrović and Despina Stasi},
keywords = {Violator spaces, Ideal generators, Solving polynomial systems, Randomized algorithm in algebra, Large sparse systems of equations},
abstract = {This paper transfers a randomized algorithm, originally used in geometric optimization, to computational problems in commutative algebra. We show that Clarkson's sampling algorithm can be applied to two problems in computational algebra: solving large-scale polynomial systems and finding small generating sets of graded ideals. The cornerstone of our work is showing that the theory of violator spaces of Gärtner et al. applies to polynomial ideal problems. To show this, one utilizes a Helly-type result for algebraic varieties. The resulting algorithms have expected runtime linear in the number of input polynomials, making the ideas interesting for handling systems with very large numbers of polynomials, but whose rank in the vector space of polynomials is small (e.g., when the number of variables and degree is constant).}
}
@incollection{THIEL2005559,
title = {Chapter 21 - Semiempirical quantum-chemical methods in computational chemistry},
editor = {Clifford E. Dykstra and Gernot Frenking and Kwang S. Kim and Gustavo E. Scuseria},
booktitle = {Theory and Applications of Computational Chemistry},
publisher = {Elsevier},
address = {Amsterdam},
pages = {559-580},
year = {2005},
isbn = {978-0-444-51719-7},
doi = {https://doi.org/10.1016/B978-044451719-7/50064-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780444517197500640},
author = {Walter Thiel},
abstract = {Publisher Summary
This chapter focuses on semiempirical quantum-chemical methods describing their development over the past 40 years. One of the first semiempirical approaches in quantum chemistry was the p-electron method proposed by Hǖckel (1931) that generates molecular orbitals (MOs) essentially from the connectivity matrix of a molecule and provides valuable qualitative insights into the structure, stability, and spectroscopy of unsaturated molecules. Hoffmann extended this approach to include all valence electrons and applied in many qualitative studies of inorganic and organometallic compounds. These early semiempirical methods had a lasting impact on chemical thinking as they guided the development of qualitative MO theory that is commonly employed for rationalizing chemical phenomena in terms of orbitals interactions. They are normally not used any longer as computational tools. After a survey of the established methods such as MNDO, AM1, and PM3, recent methodological advances are described including the development of improved semiempirical models, new general-purpose and special-purpose parametrizations, and linear scaling approaches.}
}

@article{RASUL2024101041,
title = {Enhancing academic integrity among students in GenAI Era:A holistic framework},
journal = {The International Journal of Management Education},
volume = {22},
number = {3},
pages = {101041},
year = {2024},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2024.101041},
url = {https://www.sciencedirect.com/science/article/pii/S1472811724001125},
author = {Tareq Rasul and Sumesh Nair and Diane Kalendra and M.S. Balaji and Fernando de Oliveira Santini and Wagner Junior Ladeira and Raouf Ahmad Rather and Naveed Yasin and Raul V. Rodriguez and Panagiotis Kokkalis and Md Wahid Murad and Md Uzir Hossain},
keywords = {Generative AI, Academic integrity, Higher education, Students, Stakeholders},
abstract = {The introduction of Artificial Intelligence (AI), specifically Generative AI (GenAI), has significantly transformed the higher education landscape. Despite the opportunities GenAI offers to students, they pose significant challenges for academic integrity. Thus, it is crucial for higher education institutions (HEI) to balance the use of GenAI for enhancing the learning experience of students with its ethical and responsible use in their educational journey. The present study proposes a comprehensive academic integrity framework focusing on three key stakeholders: students, educators, and institutions. We propose eight strategies ranging from collaborative learning for students to developing a comprehensive GenAI policy for institutions in maintaining academic integrity among students in HEI. Furthermore, we identified four challenges, namely financial, strategic, operational, and cultural, in the implementing a comprehensive academic integrity framework in the GenAI era. This study offers significant insights for HEI to maintain academic integrity among students in the GenAI era.}
}
@article{WU2018127,
title = {Single dose testosterone administration modulates emotional reactivity and counterfactual choice in healthy males},
journal = {Psychoneuroendocrinology},
volume = {90},
pages = {127-133},
year = {2018},
issn = {0306-4530},
doi = {https://doi.org/10.1016/j.psyneuen.2018.02.018},
url = {https://www.sciencedirect.com/science/article/pii/S0306453017312532},
author = {Yin Wu and Luke Clark and Samuele Zilioli and Christoph Eisenegger and Claire M. Gillan and Huihua Deng and Hong Li},
keywords = {Testosterone, Reward, Regret, Emotion, Human male, Dual process},
abstract = {Testosterone has been implicated in the regulation of emotional responses and risky decision-making. However, the causal effect of testosterone upon emotional decision-making, especially in non-social settings, is still unclear. The present study investigated the role of testosterone in counterfactual thinking: regret is an intense negative emotion that arises from comparison of an obtained outcome from a decision against a better, non-obtained (i.e. counterfactual) alternative. Healthy male participants (n = 64) received a single-dose of 150 mg testosterone Androgel in a double-blind, placebo-controlled, between-participants design. At 180 min post-administration, participants performed the counterfactual thinking task. We applied a computational model derived from behavioral economic principles to uncover latent decision-making mechanisms that may be invisible in simple choice analyses. Our data showed that testosterone increased the ability to use anticipated regret to guide choice behavior, while reducing choice based on expected value. On affective ratings, testosterone increased sensitivity to both obtained and counterfactual outcomes. These findings provide evidence that testosterone causally modulates emotional decision-making, and highlight the role of testosterone in affective sensitivity.}
}
@article{KHOONG2024124091,
title = {Evaluating the growth of Singapore's solar electricity capacity towards Green Plan 2030 targets and beyond using system dynamics modelling approach},
journal = {Applied Energy},
volume = {376},
pages = {124091},
year = {2024},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2024.124091},
url = {https://www.sciencedirect.com/science/article/pii/S0306261924014740},
author = {Wei Kit Khoong and Sreenivasulu Bellam},
keywords = {Solar electricity capacity, Singapore's energy mix, Systems thinking, System dynamics modelling, Carbon savings, Singapore Green Plan 2030},
abstract = {Having no native energy resources of fossil fuels, with poor wind resource and scarcity of land, the Solar Photovoltaic (PV) roadmap identified solar electricity as the most feasible source of renewable energy for Singapore's energy mix and supply. Moving towards net-zero emissions and to combat climate change, the Singapore government is aiming to achieve 2-Gigawatt-peak (GWp) of solar electricity target by 2030. Accordingly, the share of solar energy in the national grid is targeted to be between ∼2–6% in 2030 and ∼ 3.5–8% in 2040, and carbon emission savings to be ∼0.5–1.4 and ∼ 0.8–2.1 million tonnes per annum in 2030 and 2040 respectively. Although these ambitious targets align with the government's plans for mitigating emissions, Singapore faces great challenge in terms of land availability to install ground-mounted solar PV panels. In this paper, a system dynamics model is developed to study- to what extent can Singapore achieve the targeted solar electricity goals by 2030 or even beyond based on Green Plan 2030, what policies can be identified to achieve these targets, and how much carbon savings can be achieved through Solar electricity deployment. Accordingly, this paper presents systems thinking and system dynamics (ST&SD) methodology to model the growth of Singapore's solar capacity, carbon emission savings and share of electricity demand met by solar electricity while focusing on key complex factors such as area utilisation, subsidies, PV panel efficiency etc. Results of our model simulations and projections, based on the key data and assumptions, and policy scenarios show that Singapore's solar capacity can be accelerated by the implementation of the proposed policies to reach 2GWp goal towards 2030 or even slightly ahead of this timeline. However, should the government revise its solar capacity targets higher for the years past 2030 i.e. to achieve 8% share of total electricity generation, perhaps by 2040, policies such as an increased area utilisation, subsidies and higher panel efficiency need to be introduced. Our model simulations incorporating and evaluating these policy scenarios yielded the results aligning with the projections mentioned above. The results and insights presented in this paper offer useful recommendations to the researchers and policy makers in the field of solar electricity system in Singapore, and to study further for better policy making.}
}
@incollection{CRUZQUIROGA2016103,
title = {Chapter 5 - Neurobiological Computation and Neural Networks},
editor = {Munish Puri and Yashwant Pathak and Vijay Kumar Sutariya and Srinivas Tipparaju and Wilfrido Moreno},
booktitle = {Artificial Neural Network for Drug Design, Delivery and Disposition},
publisher = {Academic Press},
address = {Boston},
pages = {103-120},
year = {2016},
isbn = {978-0-12-801559-9},
doi = {https://doi.org/10.1016/B978-0-12-801559-9.00005-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128015599000053},
author = {Luis Fernando {Cruz Quiroga} and Wilfrido Alejandro Moreno},
keywords = {Complex problem solving, Neural networks, Neurobiology, Neuroscience},
abstract = {This chapter presents the neurobiological basis for the convergence of interdisciplinary work (Nano-Bio-Info-Cogno) in the research of artificial neural networks. The neurobiological study was conducted from neuroscience and technology; the topics explained are genetics and cognition, complexity of information, information processing, brain and problem solving, emotions, and solutions as well as the relationship between the nervous system cells and biological synthesis of information as part of studies to the given problems. The most specific cognitive functions related to decision making and problem solving—attention, time, process, motion, relevance of information, and memory—as well as reasoning processes not typically associated with solving complex problems are reviewed.}
}
@article{PHANG2019100837,
title = {How to derive causal insights for digital commerce in China? A research commentary on computational social science methods},
journal = {Electronic Commerce Research and Applications},
volume = {35},
pages = {100837},
year = {2019},
issn = {1567-4223},
doi = {https://doi.org/10.1016/j.elerap.2019.100837},
url = {https://www.sciencedirect.com/science/article/pii/S1567422319300146},
author = {David C.W. Phang and Kanliang Wang and Qiuhong Wang and Robert J. Kauffman and Maurizio Naldi},
keywords = {Big data, Business insights, Causal inference, Causal methods, Computational social science (CSS), Consumer behavior, China, Data analytics, Digital economy, E-commerce, Emerging markets, Empirical research, Information systems (IS) research, Machine learning (ML), M-commerce, Policy analytics, Research design, Secondary data, Sensor data, Streaming data, Social insights, Theory testing},
abstract = {The transformation of empirical research due to the arrival of big data analytics and data science, as well as the new availability of methods that emphasize causal inference, are moving forward at full speed. In this Research Commentary, we examine the extent to which this has the potential to influence how e-commerce research is conducted. China offers the ultimate in data-at-scale settings, and the construction of real-world natural experiments. Chinese e-commerce includes some of the largest firms involved in e-commerce, mobile commerce, social media and social networks. This article was written to encourage young faculty and doctoral students to engage in research that can be carried out in near real-time, with truly experimental or quasi-experimental research designs, and with the clear intention of establishing causal inferences that relate the precursors and drivers of observable outcomes through various kinds of processes. We discuss: the relevant data sources and research contexts; the methods perspectives that are appropriate which blend Computer Science, Statistics and Econometrics, how the research can be made relevant for China; and what kinds of findings and research directions are available. This article is not a tutorial on big data analytics methods in general though, nor does it cover just those published works that demonstrate big data methods and empirical causality in other disciplines. Instead, the empirical research covered is mostly taken from Electronic Commerce Research and Applications, which has published many articles on Chinese e-commerce. This Research Commentary invites researchers in China and the Asia Pacific region to expand their coverage to bring into their empirical work the new methods and philosophy of causal data science.}
}
@article{JARAETTINGER2016589,
title = {The Naïve Utility Calculus: Computational Principles Underlying Commonsense Psychology},
journal = {Trends in Cognitive Sciences},
volume = {20},
number = {8},
pages = {589-604},
year = {2016},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2016.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S1364661316300535},
author = {Julian Jara-Ettinger and Hyowon Gweon and Laura E. Schulz and Joshua B. Tenenbaum},
abstract = {We propose that human social cognition is structured around a basic understanding of ourselves and others as intuitive utility maximizers: from a young age, humans implicitly assume that agents choose goals and actions to maximize the rewards they expect to obtain relative to the costs they expect to incur. This ‘naïve utility calculus’ allows both children and adults observe the behavior of others and infer their beliefs and desires, their longer-term knowledge and preferences, and even their character: who is knowledgeable or competent, who is praiseworthy or blameworthy, who is friendly, indifferent, or an enemy. We review studies providing support for the naïve utility calculus, and we show how it captures much of the rich social reasoning humans engage in from infancy.}
}
@article{KEITZER20161322,
title = {Thinking outside of the lake: Can controls on nutrient inputs into Lake Erie benefit stream conservation in its watershed?},
journal = {Journal of Great Lakes Research},
volume = {42},
number = {6},
pages = {1322-1331},
year = {2016},
issn = {0380-1330},
doi = {https://doi.org/10.1016/j.jglr.2016.05.012},
url = {https://www.sciencedirect.com/science/article/pii/S0380133016300958},
author = {S. Conor Keitzer and Stuart A. Ludsin and Scott P. Sowa and Gust Annis and Jeff G. Arnold and Prasad Daggupati and August M. Froehlich and Matt E. Herbert and Mari-Vaughn V. Johnson and Anthony M. Sasson and Haw Yen and Mike J. White and Charles A. Rewa},
keywords = {Best management practices, SWAT, Non-point source pollution, Great Lakes, Ecosystem-based management, Index of Biotic Integrity},
abstract = {Investment in agricultural conservation practices (CPs) to address Lake Erie's re-eutrophication may offer benefits that extend beyond the lake, such as improved habitat conditions for fish communities throughout the watershed. If such conditions are not explicitly considered in Lake Erie nutrient management strategies, however, this opportunity might be missed. Herein, we quantify the potential for common CPs that will be used to meet nutrient management goals for Lake Erie to simultaneously improve stream biological conditions throughout the western Lake Erie basin (WLEB) watershed. To do so, we linked a high-resolution watershed-hydrology model to predictive biological models in a conservation scenario framework. Our modeling simulations showed that the implementation of CPs on farm acres in critical and moderate need of treatment, representing nearly half of the watershed, would be needed to reduce spring/early summer total phosphorus loads from the WLEB watershed to acceptable levels. This widespread CP implementation also would improve potential stream biological conditions in >11,000km of streams and reduce the percentage of streams where water quality is limiting biological conditions, from 31% to 20%. Despite these improvements, we found that even with additional treatment of acres in low need of CPs, degraded water quality conditions would limit biological conditions in >3200streamkm. Thus, while we expect CPs to play an important role in mitigating eutrophication problems in the Lake Erie ecosystem, additional strategies and emerging technologies appear necessary to fully reduce water quality limitation throughout the watershed.}
}
@article{ALANZI201713,
title = {Inferring rooted species trees from unrooted gene trees using approximate Bayesian computation},
journal = {Molecular Phylogenetics and Evolution},
volume = {116},
pages = {13-24},
year = {2017},
issn = {1055-7903},
doi = {https://doi.org/10.1016/j.ympev.2017.07.017},
url = {https://www.sciencedirect.com/science/article/pii/S1055790317305390},
author = {Ayed R.A. Alanzi and James H. Degnan},
keywords = {Multispecies coalescent, Outgroup, Midpoint rooting, Molecular clock, Identifiability, Sufficiency},
abstract = {Methods for inferring species trees from gene trees motivated by incomplete lineage sorting typically use either rooted gene trees to infer a rooted species tree, or use unrooted gene trees to infer an unrooted species tree, which is then typically rooted using one or more outgroups. Theoretically, however, it has been known since 2011 that it is possible to consistently infer the root of the species tree directly from unrooted gene trees without assuming an outgroup. Here, we use approximate Bayesian computation to infer the root of the species tree from unrooted gene trees assuming the multispecies coalescent model. It is hoped that this approach will be useful in cases where an appropriate outgroup is difficult to find and gene trees do not follow a molecular clock. We use approximate Bayesian computation to infer the root of the species tree from unrooted gene trees. This approach could also be useful when there is prior information that makes a small number of root locations plausible in an unrooted species tree.}
}
@article{ORTEGA2010171,
title = {Parallel drainage network computation on CUDA},
journal = {Computers & Geosciences},
volume = {36},
number = {2},
pages = {171-178},
year = {2010},
issn = {0098-3004},
doi = {https://doi.org/10.1016/j.cageo.2009.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S0098300409002970},
author = {L. Ortega and A. Rueda},
keywords = {GPU, GPGPU, CUDA, Drainage network, D8 algorithm},
abstract = {Drainage networks determination from digital elevation models (DEM) has been a widely studied problem in the last three decades. During this time, satellite technology has been improving and optimizing digitalized images, and computers have been increasing their capabilities to manage such a huge quantity of information. The rapid growth of CPU power and memory size has concentrated the discussion of DEM algorithms on the accuracy of their results more than their running times. However, obtaining improved running times remains crucial when DEM dimensions and their resolutions increase. Parallel computation provides an opportunity to reduce run times. Recently developed graphics processing units (GPUs) are computationally fast not only in Computer Graphics but in General Purpose Computation, the so-called GPGPU. In this paper we explore the parallel characteristics of these GPUs for drainage network determination, using the C-oriented language of CUDA developed by NVIDIA. The results are simple algorithms that run on low-cost technology with a high performance response, obtaining CPU improvements of up to 8×.}
}
@article{GOK201249,
title = {A philosophical assessment of computational models of consciousness},
journal = {Cognitive Systems Research},
volume = {17-18},
pages = {49-62},
year = {2012},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2011.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S1389041711000635},
author = {Selvi Elif Gök and Erdinç Sayan},
keywords = {Consciousness, Computational cognitive modeling, Clarion, LIDA, ACT-R, Neuronal Work Space Model, ART, GMU-BICA},
abstract = {There has been a recent flurry of activity in consciousness research. Although an operational definition of consciousness has not yet been developed, philosophy has come to identify a set of features and aspects that are thought to be associated with the various elements of consciousness. On the other hand, there have been several recent attempts to develop computational models of consciousness that are claimed to capture or illustrate one or more aspects of consciousness. As a plausible substitute to evaluating how well the current computational models model consciousness, this study examines how the current computational models fare in modeling those aspects and features of consciousness identified by philosophy. Following a review of the literature on the philosophy of consciousness, this study constructs a list of features and aspects that would be expected in any successful model of consciousness. The study then evaluates, from the viewpoint of that list, some of the current self-claimed and implemented computational models of consciousness. The computational models studied are evaluated with respect to each identified aspect and feature of consciousness.}
}
@incollection{BODEN2008741,
title = {INFORMATION, COMPUTATION, AND COGNITIVE SCIENCE},
editor = {Pieter Adriaans and Johan {van Benthem}},
booktitle = {Philosophy of Information},
publisher = {North-Holland},
address = {Amsterdam},
pages = {741-761},
year = {2008},
series = {Handbook of the Philosophy of Science},
issn = {18789846},
doi = {https://doi.org/10.1016/B978-0-444-51726-5.50023-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780444517265500236},
author = {Margaret A. Boden}
}
@article{SHI2018117,
title = {Toward automated reasoning for analog IC design by symbolic computation – A survey},
journal = {Integration},
volume = {60},
pages = {117-131},
year = {2018},
issn = {0167-9260},
doi = {https://doi.org/10.1016/j.vlsi.2017.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S0167926017304182},
author = {Guoyong Shi},
keywords = {Analog integrated circuit (IC), Computer-aided reasoning (CAR), Formal information processing, Graph-pair decision diagram (GPDD), Knowledge representation, Operational amplifier (opamp), Symbolic computation},
abstract = {Analog integrated circuit (IC) design highly depends on reasoning, which distinguishes itself from other areas of IC design. Most of its innovation arises from qualitative reasoning by a pencil and paper. Innovation on the circuit structure needs quick analytical justification. Circuit-level reduced-scale modeling is a popular reasoning means. Circuit simulation tools can only serve partial justification on a design, while design insight still has to be acquired via manual analysis. A basic question has been in existence for many decades: how can we automate the analog IC design process? Many analog synthesis tools proposed decades ago could not make it to this date in the design practice. In this survey the major reason is attributed to the black-box style of the tool design. Human designer's creativity is shielded away from the tool operation while the formal design knowledge hardcoded in those tools remains at a very primitive level. By analyzing the defects of those existing tools, this survey advocates an open tool development philosophy whose major goal is to support human-machine interaction. On the one side a design automation tool is mainly aimed at providing aid for tasks that require analytical deduction while on the other side designers are expected to exercise their creativity based on the machine-generated results. Such human-machine co-working style is believed to be a more feasible solution to analog IC design automation based on the currently available computation technology. In this survey the art of symbolic computation is promoted to be the enabling technology for computer-aided analytical generation. The symbolic computation technology today can support topological and analytical reasoning that is the most demanding need in the analog IC design practice. This survey further calls for more research on the formal methods that are applicable to design knowledge representation, human-machine interaction, and design inference. Some preliminary research results are reviewed and future research directions are pointed out.}
}
@article{KHAN2022200147,
title = {An effective approach to address processing time and computational complexity employing modified CCT for lung disease classification},
journal = {Intelligent Systems with Applications},
volume = {16},
pages = {200147},
year = {2022},
issn = {2667-3053},
doi = {https://doi.org/10.1016/j.iswa.2022.200147},
url = {https://www.sciencedirect.com/science/article/pii/S2667305322000849},
author = {Inam Ullah Khan and Sami Azam and Sidratul Montaha and Abdullah Al Mahmud and A.K.M. Rakibul Haque Rafid and Md. Zahid Hasan and Mirjam Jonkman},
keywords = {COVID-19, Chest X-rays, Image Preprocessing, Modified compact convolutional transformer, Deep convolutional GAN, Hyper-parameter Tuning},
abstract = {Early identification and adequate treatment can help prevent lung disorders from becoming chronic, severe, and life-threatening. X-ray images are commonly used and an automated and effective method involving deep learning techniques can potentially contribute to quick and accurate diagnosis of lung disorders. However, in the study of medical imaging using deep learning, two obstacles limit interpretability. One is an insufficient and imbalanced number of training samples in most medical datasets. The other is excessive training time. Although training time can be reduced by decreasing the number of pixels in the images, training with low resolution images tends to result in poor performance. This study represents a solution to overcome these impediments by balancing the number of images and reducing overall processing time while preserving accuracy. The dataset used in this research contains an unequal number of images in the different classes. The quantity of data in the classes is balanced by creating synthetic images based on the patterns and characteristics of the original images, using a Deep Convolutional Generative Adversarial Network (DCGAN). Unwanted regions are removed from the X-ray images, the brightness and contrast of the images are enhanced, and the abnormalities are highlighted by using different artifact removal, noise reduction, and enhancement techniques. We propose a Modified Compact Convolutional Transformer (MCCT) model using 32 × 32 sized images for the categorization of lung disorders into four classes. An ablation study of eleven cases is employed to adjust several hyper parameters and layer topologies. This reduces training time while preserving accuracy. Six transfer learning models, VGG19, VGG16, ResNet152, ResNet50, ResNet50V2, and MobileNet are applied with the same image size the performance is compared with the proposed MCCT model. Our MCCT model records the greatest test accuracy of 95.37%, requiring a short training time, 10-12 s/epoch, whereas the other models only reach near-moderate performance with accuracies ranging from 43% to 79% and training times of 80-90 s/epoch. The robustness of the model with regards to the number of training samples is validated by training the model multiple times reducing the number of training images gradually from 49621 images to 6204 images. Results suggest that even with a smaller dataset, the performance is sustained. Our proposed approach may contribute to an effective CAD based diagnostic system by addressing the issues of insufficient and imbalanced numbers of medical images, excessive training times and low-resolution images.}
}
@article{BEGGS20091311,
title = {Computations via Newtonian and relativistic kinematic systems},
journal = {Applied Mathematics and Computation},
volume = {215},
number = {4},
pages = {1311-1322},
year = {2009},
note = {Physics and Computation},
issn = {0096-3003},
doi = {https://doi.org/10.1016/j.amc.2009.04.052},
url = {https://www.sciencedirect.com/science/article/pii/S0096300309004214},
author = {E.J. Beggs and J.V. Tucker},
keywords = {Foundations of computation, Computable functions and sets, Newtonian kinematic systems, Relativistic kinematic systems, Foundations of mechanics, Theory of Gedanken experiments, Non-computable physical systems},
abstract = {We are developing a rigorous methodology to analyse experimental computation, by which we mean the idea of computing a set or function by experimenting with some physical equipment. Here we consider experimental computation by kinematic systems under both Newtonian and relativistic kinematics. An experimental procedure, expressed in a language similar to imperative programming languages, is applied to equipment, having the form of a bagatelle, and is interpreted using the two theories. We prove that for any set A of natural numbers there exists a two-dimensional kinematic system BA with a single particle P whose observable behaviour decides n∈A for all n∈N. The procedure can operate under (a) Newtonian mechanics or (b) relativistic mechanics. The proofs show how any information (coded by some A) can be embedded in the structure of a simple kinematic system and retrieved by simple observations of its behaviour. We reflect on the methodology, which seeks a formal theory for performing abstract experiments with physical restrictions on the construction of systems. We conclude with some open problems.}
}
@article{KANAMORI2024103319,
title = {Kunen the expositor},
journal = {Annals of Pure and Applied Logic},
volume = {175},
number = {1, Part B},
pages = {103319},
year = {2024},
note = {Kenneth Kunen (1943-2020)},
issn = {0168-0072},
doi = {https://doi.org/10.1016/j.apal.2023.103319},
url = {https://www.sciencedirect.com/science/article/pii/S0168007223000763},
author = {Akihiro Kanamori},
keywords = {Handbook chapters, Set theory text, Late texts},
abstract = {Kunen's expository work is described, bringing out both his way of assimilating and thinking about set theory and how it had a meaningful hand in its promulgation into the next generations.}
}
@article{PUPKOV2021489,
title = {Dynamic and Information Properties of Intelligent Control Systems},
journal = {Procedia Computer Science},
volume = {186},
pages = {489-494},
year = {2021},
note = {14th International Symposium "Intelligent Systems},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.04.169},
url = {https://www.sciencedirect.com/science/article/pii/S187705092101005X},
author = {K.A. Pupkov and Y.K. Brovarskaya},
keywords = {traffic flow model, optimal control, evolutionary computations, uncertainties},
abstract = {The paper considers the dynamic and informational properties of intelligent systems. The relationship is established between control quality and stability in such systems. The method was developed and a study was conducted of the dependence of the control quality and the time spent by the human operator on the evaluation of the test image. The influence of the clean delay time on the stability margin and the quality of the setting process is studied. The study shows that in intelligent systems that work in connection with a human-operator (a group of people) or independently, the time spent (a latent period) to implement thinking forms affects on the one hand the control quality, on the other the system stability. The desired value clean delay time is set. The research results are presented. The new parameter of information properties of intelligent systems has been introduced – the control quality.}
}
@article{NEUMANN2020281,
title = {Parametrised second-order complexity theory with applications to the study of interval computation},
journal = {Theoretical Computer Science},
volume = {806},
pages = {281-304},
year = {2020},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2019.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S0304397519302889},
author = {Eike Neumann and Florian Steinberg},
keywords = {Second-order complexity, Type two complexity, Interval computation, Computable analysis},
abstract = {We extend the framework for complexity of operators in analysis devised by Kawamura and Cook (2012) to allow for the treatment of a wider class of representations. The main novelty is to endow represented spaces of interest with an additional function on names, called a parameter, which measures the complexity of a given name. This parameter generalises the size function which is usually used in second-order complexity theory and therefore also central to the framework of Kawamura and Cook. The complexity of an algorithm is measured in terms of its running time as a second-order function in the parameter, as well as in terms of how much it increases the complexity of a given name, as measured by the parameters on the input and output side. As an application we develop a rigorous computational complexity theory for interval computation. In the framework of Kawamura and Cook the representation of real numbers based on nested interval enclosures does not yield a reasonable complexity theory. In our new framework this representation is polytime equivalent to the usual Cauchy representation based on dyadic rational approximation. By contrast, the representation of continuous real functions based on interval enclosures is strictly smaller in the polytime reducibility lattice than the usual representation, which encodes a modulus of continuity. Furthermore, the function space representation based on interval enclosures is optimal in the sense that it contains the minimal amount of information amongst those representations which render evaluation polytime computable.}
}
@article{SANGALLI2018117,
title = {Matrix-free weighted quadrature for a computationally efficient isogeometric k-method},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {338},
pages = {117-133},
year = {2018},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2018.04.029},
url = {https://www.sciencedirect.com/science/article/pii/S0045782518302081},
author = {G. Sangalli and M. Tani},
keywords = {Isogeometric analysis, 
               -method, Matrix-free, Weighted quadrature, Preconditioner},
abstract = {The k-method is the isogeometric method based on splines (or NURBS, etc.) with maximum regularity. When implemented following the paradigms of classical finite element methods, the computational resources required by the k-method are prohibitive even for moderate degree. In order to address this issue, we propose a matrix-free strategy combined with weighted quadrature, which is an ad-hoc strategy to compute the integrals of the Galerkin system. Matrix-free weighted quadrature (MF-WQ) speeds up matrix operations, and, perhaps even more important, greatly reduces memory consumption. Our strategy also requires an efficient preconditioner for the linear system iterative solver. In this work we deal with an elliptic model problem, and adopt a preconditioner based on the Fast Diagonalization method, an old idea to solve Sylvester-like equations. Our numerical tests show that the isogeometric solver based on MF-WQ is faster than standard approaches (where the main cost is the matrix formation by standard Gaussian quadrature) even for low degree. But the main achievement is that, with MF-WQ, the k-method gets orders of magnitude faster by increasing the degree, given a target accuracy. Therefore, we are able to show the superiority, in terms of computational efficiency, of the high-degree k-method with respect to low-degree isogeometric discretizations. What we present here is applicable to more complex and realistic differential problems, but its effectiveness will depend on the preconditioner stage, which is as always problem-dependent. This situation is typical of modern high-order methods: the overall performance is mainly related to the quality of the preconditioner.}
}
@article{DUKHANOV20141433,
title = {Double-degree Master's Program in Computational Science: Experiences of ITMO University and University of Amsterdam},
journal = {Procedia Computer Science},
volume = {29},
pages = {1433-1445},
year = {2014},
note = {2014 International Conference on Computational Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.05.130},
url = {https://www.sciencedirect.com/science/article/pii/S187705091400307X},
author = {Alexey V. Dukhanov and Valeria V. Krzhizhanovskaya and Anna Bilyatdinova and Alexander V. Boukhanovsky and Peter M.A. Sloot},
keywords = {teaching computational science, M aster's program, double degree, curriculum, enrollment, student research, funding opportunities},
abstract = {We present a new double-degree graduate (Master's) programme developed together by the ITMO University, Russia and University of Amsterdam, The Netherlands. First, we look into the global aspects of integration of d ifferent educational systems and list some funding opportunities fro m European foundations. Then we describe our double-degree program curricu lu m, suggest the time line of enrollment and studies, and give some e xa mples of student research topics. Finally, we d iscuss the peculiarities of joint progra ms with Russia, re flect on the first lessons learnt, and share our thoughts and experiences that could be of interest to the international community e xpanding the educational ma rkets to the vast countries like Russia, Ch ina or India. The paper is written for education professionals and contains useful information for potential students.}
}
@article{BURTONROBERTS20112089,
title = {On the grounding of syntax and the role of phonology in human cognition},
journal = {Lingua},
volume = {121},
number = {14},
pages = {2089-2102},
year = {2011},
issn = {0024-3841},
doi = {https://doi.org/10.1016/j.lingua.2011.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S002438411100146X},
author = {Noel Burton-Roberts},
keywords = {Syntactic grounding, Interface interpretation, Language faculty, Language of thought, Phonology-free generativity, Phonology in human cognition},
abstract = {Chomskyan generative grammar has long been committed to the ‘double-interface’ assumption that the faculty of language (FL) serves two interfaces, PF and LF, and correlatively that expressions have phonological and semantic properties. The paper argues this gives rise to (a) a grounding problem for syntax – i.e. for the interpretable content of syntax – and (b) a problem for the assumption that FL is a generative computation. It is argued these problems are resolved if we think of syntax as grounded exclusively in semantic/conceptual properties. Since this implies that FL is phonology-free, it is argued that FL should not be distinguished from a generative computation describable as ‘the language of thought’ (LOT). The paper explores to what extent this (FL=LOT) thesis is consistent with Chomsky's thinking. Chomsky's recent work can be seen as pointing in that direction but it is not consistent with the double-interface assumption, which he continues to regard as conceptually necessary. In the light of discussion of the issues, the paper concludes with a speculation on the role of phonology in human cognition and its evolution.}
}
@article{HODGMAN2012261,
title = {Cell-free synthetic biology: Thinking outside the cell},
journal = {Metabolic Engineering},
volume = {14},
number = {3},
pages = {261-269},
year = {2012},
note = {Synthetic Biology: New Methodologies and Applications for Metabolic Engineering},
issn = {1096-7176},
doi = {https://doi.org/10.1016/j.ymben.2011.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S1096717611000929},
author = {C. Eric Hodgman and Michael C. Jewett},
keywords = {Cell-free biology,  protein synthesis, Metabolic engineering, Synthetic biology, Synthetic enzymatic pathways, Biocatalysis},
abstract = {Cell-free synthetic biology is emerging as a powerful approach aimed to understand, harness, and expand the capabilities of natural biological systems without using intact cells. Cell-free systems bypass cell walls and remove genetic regulation to enable direct access to the inner workings of the cell. The unprecedented level of control and freedom of design, relative to in vivo systems, has inspired the rapid development of engineering foundations for cell-free systems in recent years. These efforts have led to programmed circuits, spatially organized pathways, co-activated catalytic ensembles, rational optimization of synthetic multi-enzyme pathways, and linear scalability from the micro-liter to the 100-liter scale. It is now clear that cell-free systems offer a versatile test-bed for understanding why nature's designs work the way they do and also for enabling biosynthetic routes to novel chemicals, sustainable fuels, and new classes of tunable materials. While challenges remain, the emergence of cell-free systems is poised to open the way to novel products that until now have been impractical, if not impossible, to produce by other means.}
}
@incollection{BONSIGNORE2019291,
title = {Chapter 14 - Device Design and Computational Simulation},
editor = {Christopher P. Cheng},
booktitle = {Handbook of Vascular Motion},
publisher = {Academic Press},
pages = {291-312},
year = {2019},
isbn = {978-0-12-815713-8},
doi = {https://doi.org/10.1016/B978-0-12-815713-8.00014-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128157138000140},
author = {C. Bonsignore},
keywords = {Device design, boundary conditions, simulation, stress and strain, finite element analysis, nitinol, prototyping, iteration, design control},
abstract = {Medical device development consists of ideation, prototyping, simulation, preclinical testing, and clinical trials. In the early stages, design and test iterations offer insights to incorporate into subsequent iterations and should be repeated often with only as much complexity as necessary. Computational simulations, in the form of analytic calculations or finite element analysis (FEA), can be utilized for design concept screening all the way to design verification testing under design control. For FEA, while the mathematics is complicated, and the programming is intricate, the utility of the simulation is only as good as the realism of the anatomic loading boundary conditions. While boundary conditions may not be able to be prescribed exactly as they happen in vivo, good engineering intuition and judgment are invaluable for making reasonable approximations.}
}
@article{STENROOS2019116159,
title = {Real-time computation of the TMS-induced electric field in a realistic head model},
journal = {NeuroImage},
volume = {203},
pages = {116159},
year = {2019},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2019.116159},
url = {https://www.sciencedirect.com/science/article/pii/S1053811919307505},
author = {Matti Stenroos and Lari M. Koponen},
keywords = {Transcranial magnetic stimulation (TMS), Navigated transcranial magnetic stimulation, Electric field calculation, Coil model, Volume conductor model},
abstract = {Transcranial magnetic stimulation (TMS) is often targeted using a model of TMS-induced electric field (E). In such navigated TMS, the E-field models have been based on spherical approximation of the head. Such models omit the effects of cerebrospinal fluid (CSF) and gyral folding, leading to potentially large errors in the computed E-field. So far, realistic models have been too slow for interactive TMS navigation. We present computational methods that enable real-time solving of the E-field in a realistic five-compartment (5-C) head model that contains isotropic white matter, gray matter, CSF, skull and scalp. Using reciprocity and Geselowitz integral equation, we separate the computations to coil-dependent and -independent parts. For the Geselowitz integrals, we present a fast numerical quadrature. Further, we present a moment-matching approach for optimizing dipole-based coil models. We verified and benchmarked the new methods using simulations with over 100 coil locations. The new quadrature introduced a relative error (RE) of 0.3–0.6%. For a coil model with 42 dipoles, the total RE of the quadrature and coil model was 0.44–0.72%. Taking also other model errors into account, the contribution of the new approximations to the RE was 0.1%. For comparison, the RE due to omitting the separation of white and gray matter was >11%, and the RE due to omitting also the CSF was >23%. After the coil-independent part of the model has been built, E-fields can be computed very quickly: Using a standard PC and basic GPU, our solver computed the full E-field in a 5-C model in 9000 points on the cortex in 27 coil positions per second (cps). When the separation of white and gray matter was omitted, the speed was 43–65 cps. Solving only one component of the E-field tripled the speed. The presented methods enable real-time solving of the TMS-induced E-field in a realistic head model that contains the CSF and gyral folding. The new methodology allows more accurate targeting and precise adjustment of stimulation intensity during experimental or clinical TMS mapping.}
}
@article{GOLLISCH2010150,
title = {Eye Smarter than Scientists Believed: Neural Computations in Circuits of the Retina},
journal = {Neuron},
volume = {65},
number = {2},
pages = {150-164},
year = {2010},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2009.12.009},
url = {https://www.sciencedirect.com/science/article/pii/S0896627309009994},
author = {Tim Gollisch and Markus Meister},
abstract = {We rely on our visual system to cope with the vast barrage of incoming light patterns and to extract features from the scene that are relevant to our well-being. The necessary reduction of visual information already begins in the eye. In this review, we summarize recent progress in understanding the computations performed in the vertebrate retina and how they are implemented by the neural circuitry. A new picture emerges from these findings that helps resolve a vexing paradox between the retina's structure and function. Whereas the conventional wisdom treats the eye as a simple prefilter for visual images, it now appears that the retina solves a diverse set of specific tasks and provides the results explicitly to downstream brain areas.}
}
@article{SUN2001241,
title = {Computation, reduction, and teleology of consciousness},
journal = {Cognitive Systems Research},
volume = {1},
number = {4},
pages = {241-249},
year = {2001},
issn = {1389-0417},
doi = {https://doi.org/10.1016/S1389-0417(00)00013-9},
url = {https://www.sciencedirect.com/science/article/pii/S1389041700000139},
author = {Ron Sun},
keywords = {Consciousness, Cognition, Qualia, Implicit learning, Computation, Reduction, Teleology},
abstract = {This paper aims to explore mechanistic and teleological explanations of consciousness. In terms of mechanistic explanations, it critiques various existing views, especially those embodied by existing computational cognitive models. In this regard, the paper argues in favor of the explanation based on the distinction between localist (symbolic) representation and distributed representation (as formulated in the connectionist literature), which reduces the phenomenological difference to a mechanistic difference. Furthermore, to establish a teleological explanation of consciousness, the paper discusses the issue of the functional role of consciousness on the basis of the aforementioned mechanistic explanation. A proposal based on synergistic interaction between the conscious and the unconscious is advanced that encompasses various existing views concerning the functional role of consciousness. This two-step deepening explanation has some empirical support, in the form of a cognitive model and various cognitive data that it captures.}
}
@incollection{PETRUZZELLI20121,
title = {1 - Re-thinking the innovation approach},
editor = {ANTONIO MESSENI PETRUZZELLI and VITO ALBINO},
booktitle = {When Tradition Turns Into Innovation},
publisher = {Chandos Publishing},
pages = {1-18},
year = {2012},
isbn = {978-1-84334-664-7},
doi = {https://doi.org/10.1016/B978-1-84334-664-7.50007-0},
url = {https://www.sciencedirect.com/science/article/pii/B9781843346647500070},
author = {ANTONIO MESSENI PETRUZZELLI and VITO ALBINO},
keywords = {triple crisis, innovation, tradition},
abstract = {Abstract
This chapter presents a review and criticism of the actual innovation approaches, highlighting how the social and economic scenario imposes the necessity of rethinking innovation and consumption models. Specifically, we discuss how the recent crises – which together affect finance, food and climate change and their implications for human development – are forcing organisations to find new solutions and models for responding to emerging needs and expectations. In this regard, we elaborate on the important role that may be played by traditional knowledge as a source of inspiration for innovation, since creativity can find a reliable support in what society has found to be suitable in the past for its development needs.}
}
@article{HALEEM2024100006,
title = {Perspective of leadership 4.0 in the era of fourth industrial revolution: A comprehensive view},
journal = {Journal of Industrial Safety},
volume = {1},
number = {1},
pages = {100006},
year = {2024},
issn = {2950-2764},
doi = {https://doi.org/10.1016/j.jinse.2024.100006},
url = {https://www.sciencedirect.com/science/article/pii/S2950276424000060},
author = {Abid Haleem and Mohd Javaid and Ravi Pratap Singh},
keywords = {Leadership 4.0, Industry 4.0, Industrial Safety, Technologies, Management},
abstract = {Leadership 4.0 focuses on leaders developing their digital transformation strategy and ensuring alignment with the organization’s business and development ambitions. This is accomplished by successfully displaying disruptive digital leadership characteristics, which include emotional and social intelligence abilities such as empathy and relationship management, cognitive preparedness, critical thinking, inventive thinking, agility, and resilience. Academics and consultants increasingly use Leadership 4.0 to describe the new leadership style required for the Fourth Industrial Revolution (Industry 4.0). It strategically addresses people’s concerns, which are crucial for the effective integration of Industry 4.0, and plays a significant and crucial role in integrating Industry 4.0 into modern workplaces. The primary purpose of this paper is to explore Leadership 4.0 and its needs. Several quality characteristics associated with Digital Leadership 4.0 are investigated, and two-dimensional style matrix presentations for Leadership 4.0 are briefed. Finally, this study identifies and addresses the role of Leadership 4.0 in upcoming industrial management systems. Because digital technologies now impact the entire business, advancing digital strategies requires strong leadership at all levels. With the increasing prevalence of digital transformation in the business sector and the intensification of the "battle for talent," organizations need to consider a more methodical approach to building a solid leadership pipeline with the capabilities required to lead in the digital era. They may place future leaders in positions that require them to go beyond their current competencies and skills to instruct and motivate them to promptly acquire new digital skills. In a new working setting, effectively managing the dynamic interactions between machines, technology, and people is essential for influential digital leaders. Leadership 4.0 is expected to foster an open and innovative culture that welcomes change and progress. This will encourage and inspire their teams to adapt to the ongoing changes in the market.}
}
@article{PAN2006448,
title = {Human and social behavior in computational modeling and analysis of egress},
journal = {Automation in Construction},
volume = {15},
number = {4},
pages = {448-461},
year = {2006},
note = {The first conference on the Future of the AEC Industry (BFC05)},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2005.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0926580505000737},
author = {Xiaoshan Pan and Charles S. Han and Ken Dauber and Kincho H. Law},
keywords = {Human and social behavior, Decision-making, Egress, Emergency, Computational modeling, Multi-agent system},
abstract = {Safe egress is one of the key design issues identified by facility planners, manager and inspectors. Computational tools are now available for the simulation and design of emergency evacuation and egress. However, these tools rely heavily on assumptions about individual human and social behaviors, which have been found to be oversimplified, inconsistent and even incorrect. Furthermore, the behaviors are usually incorporated into the computational model in an ad hoc manner. This paper presents a framework for studying human and social behavior, from the perspectives of human decision-making and social interaction, and for incorporating such behavior systematically in a dynamic computational model suitable for emergency egress analysis.}
}
@article{QUIANQUIROGA2020994,
title = {No Pattern Separation in the Human Hippocampus},
journal = {Trends in Cognitive Sciences},
volume = {24},
number = {12},
pages = {994-1007},
year = {2020},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2020.09.012},
url = {https://www.sciencedirect.com/science/article/pii/S1364661320302278},
author = {Rodrigo {Quian Quiroga}},
keywords = {episodic memory, Concept Cells, engram, conjunctive coding, neural coding, human intelligence},
abstract = {Pattern separation is a basic principle of neuronal coding that precludes memory interference in the hippocampus. Its existence is supported by numerous theoretical, computational, and experimental findings in different species. However, I argue that recent evidence from single-neuron recordings suggests that pattern separation may not be present in the human hippocampus and that memories are instead coded by the coactivation of invariant and context-independent engrams. This alternative model prompts a reassessment of the definition of episodic memory and its distinction from semantic memory. Furthermore, I propose that a lack of pattern separation in memory coding may have profound implications that could explain cognitive abilities that are uniquely developed in humans, such as our power of generalization and of creative and abstract thinking.}
}
@article{GUPTA2024102882,
title = {“Wayfinding” through the AI wilderness: Mapping rhetorics of ChatGPT prompt writing on X (formerly Twitter) to promote critical AI literacies},
journal = {Computers and Composition},
volume = {74},
pages = {102882},
year = {2024},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2024.102882},
url = {https://www.sciencedirect.com/science/article/pii/S8755461524000586},
author = {Anuj Gupta and Ann Shivers-McNair},
keywords = {AI, ChatGPT, Prompt writing, Prompt engineering, Machine learning, Computational methods, Algorithms, Critical AI literacy, Digital rhetoric},
abstract = {In this paper, we demonstrate how studying the rhetorics of ChatGPT prompt writing on social media can promote critical AI literacies. Prompt writing is the process of writing instructions for generative AI tools like ChatGPT to elicit desired outputs and there has been an upsurge of conversations about it on social media. To study this rhetorical activity, we build on four overlapping traditions of digital writing research in computers and composition that inform how we frame literacies, how we study social media rhetorics, how we engage iteratively and reflexively with methodologies and technologies, and how we blend computational methods with qualitative methods. Drawing on these four traditions, our paper shows our iterative research process through which we gathered and analyzed a dataset of 32,000 posts (formerly known as tweets) from X (formerly Twitter) about prompt writing posted between November 2022 to May 2023. We present five themes about these emerging AI literacy practices: (1) areas of communication impacted by prompt writing, (2) micro-literacy resources shared for prompt writing, (3) market rhetoric shaping prompt writing, (4) rhetorical characteristics of prompts, and (5) definitions of prompt writing. In discussing these themes and our methodologies, we highlight takeaways for digital writing teachers and researchers who are teaching and analyzing critical AI literacies.}
}
@article{ZETTERLUND2023104508,
title = {Computational modelling to advise and inform optimization for aeration and nutrient-dosing in wastewater treatment: Case study from pulp and paper mill in south-central Sweden},
journal = {Journal of Water Process Engineering},
volume = {56},
pages = {104508},
year = {2023},
issn = {2214-7144},
doi = {https://doi.org/10.1016/j.jwpe.2023.104508},
url = {https://www.sciencedirect.com/science/article/pii/S2214714423010280},
author = {Selma Zetterlund and Olivia Schwartz and Maria Sandberg and G. Venkatesh},
keywords = {Aeration, Biological wastewater treatment, Energy use optimisation, Nutrients, Pulp and paper mills},
abstract = {Sweden's pulp and paper sector accounts for a significant proportion of national energy usage, besides generating wastewater that causes eutrophication of nearby sinks. In this paper, the possibility of optimizing biological wastewater treatment at the Stora Enso Skoghall mill south of the city of Karlstad in central Sweden, with respect to electricity usage and the addition of nutrients, has been investigated. A computational model of the treatment process was developed, based on process data obtained from the said mill, and nine different scenarios were compared subsequently, with energy use, environmental impacts and operational expenses, as criteria. The most energy-efficient and cost-effective alternative was a combination of measures such as lowering the oxygen level in the MBBR (Moving Bed Bio-Reactor) from 3 mg/l to 2 mg/l and using the Hyperclassic aerator in the aerated lagoon. This arrangement yielded a 48.5 % reduction in operational expenses, and a 60 % decrease in the energy use, vis-à-vis the reference case, without affecting the efficiency of the treatment process. This also uncovered an opportunity to mitigate the annual global warming and eutrophication impacts, by approximately 100 tons CO2-eq. and 140 kg PO43−-eq. respectively. All attempts to optimise the use of resources and decrease the anthropogenic environmental footprint ought to be made to come closer to the targets set by the United Nations' sustainable development goals (SDGs). The authors' conclusion predicated on the results of the modelling and analysis done in this study is that the potential of seemingly small process modifications, such as lowering the oxygen level in the MBBR, and applying a more optimal dosage of nutrient salts, must not be overlooked by wastewater treatment plants in general (and those in pulp and paper mills in particular).}
}
@article{KHANUM2022131890,
title = {Synthesis, single crystal, characterization and computational study of 2-amino-N-cyclopropyl-5-ethyl-thiophene-3-carboxamide},
journal = {Journal of Molecular Structure},
volume = {1250},
pages = {131890},
year = {2022},
issn = {0022-2860},
doi = {https://doi.org/10.1016/j.molstruc.2021.131890},
url = {https://www.sciencedirect.com/science/article/pii/S0022286021020123},
author = {Ghazala Khanum and Aysha Fatima and Nazia Siddiqui and D.D. Agarwal and R.J. Butcher and Sanjay Kumar Srivastava and Saleem Javed},
keywords = {DFT studies, Fukui function, MEP, ELF, Hirshfeld, Molecular docking},
abstract = {2-amino-N-cyclopropyl-5-ethylthiophene-3-carboxamide (ACPETC) (C10H14N2OS) has been synthesized, characterized via single-crystal X-ray diffraction at 296 K and studied theoretically via DFT approach. The compound crystallizes in tetragonal crystal system, space group I-4 with Z = 8 and the following unit cell dimensions: a = 16.0892(4) Å, b = 16.0892(4) Å, c = 8.4059(2) Å. ACPETC was experimentally characterized by 1H, 13C NMR, FT-IR, UV–Vis and ESI-MS analysis. The molecular structure, vibrational spectra, MEP, ELF, NLO, NBO, NHO, and FMO analysis of ACPETC (C10H14N2OS) in the ground state were estimated using HF, MP2, DFT/B3LYP using the 6–311++G(d,p) basis set. Computed NMR chemical shifts (1H and 13C), as well as discrete regions in IR active vibrations, are in good concurrence with their experimental counterparts. FT-IR spectra of ACPETC were obtained in the ranges of 4000−450 cm−1. The UV–vis spectrum as well as the effects of solvents has been studied. The estimated HOMO and LUMO energies reveal that charge transfer happens within the molecule and MEP surface to be a chemically reactive region suitable for drug action. The O1-atom appears to be more vulnerable to electrophilic assault. The NBO analysis was also performed. It indicates that the greatest second order perturbation energy E(2) = 50.11 kcal/mol associated with electron delocalization from the donor (N15) → π* (C10-O14) acceptor interaction. On the atomic charges of the title chemical, the Fukui function and Mulliken analysis have been calculated. 3-D and 2-D interactions in crystals were studies and Hirshfeld surface analysis was used. To discover the optimum ligand-protein interactions, molecular docking was used using eight protein receptors.}
}
@article{MCLEAN2023104019,
title = {From Anti-doping-I to Anti-doping-II: Toward a paradigm shift for doping prevention in sport},
journal = {International Journal of Drug Policy},
volume = {115},
pages = {104019},
year = {2023},
issn = {0955-3959},
doi = {https://doi.org/10.1016/j.drugpo.2023.104019},
url = {https://www.sciencedirect.com/science/article/pii/S0955395923000683},
author = {Scott McLean and Mitchell Naughton and Hugo Kerhervé and Paul M. Salmon},
keywords = {Sport, Doping, World anti-doping agency, Systems thinking, Systems analysis},
abstract = {Doping remains an intractable issue in sport and occurs in a complex and dynamic environment comprising interactions between individual, situational, and environmental factors. Anti-doping efforts have previously predominantly focused on athlete behaviours and sophisticated detection methods, however, doping issues remain. As such, there is merit in exploring an alternative approach. The aim of this study was to apply a systems thinking approach to model the current anti-doping system for four football codes in Australia, using the Systems Theoretic Accident Model and Processes (STAMP). The STAMP control structure was developed and validated by eighteen subject matter experts across a five-phase validation process. Within the developed model, education was identified as a prominent approach anti-doping authorities use to combat doping. Further, the model suggests that a majority of existing controls are reactive, and hence that there is potential to employ leading indicators to proactively prevent doping and that new incident reporting systems could be developed to capture such information. It is our contention that anti-doping research and practice should consider a shift away from the current reactive and reductionist approach of detection and enforcement to a proactive and systemic approach focused on leading indicators. This will provide anti-doping agencies a new lens to look at doping in sport.}
}
@article{AHLQUIST201584,
title = {Development of a digital framework for the computation of complex material and morphological behavior of biological and technological systems},
journal = {Computer-Aided Design},
volume = {60},
pages = {84-104},
year = {2015},
note = {Material Ecology},
issn = {0010-4485},
doi = {https://doi.org/10.1016/j.cad.2014.01.013},
url = {https://www.sciencedirect.com/science/article/pii/S0010448514000141},
author = {Sean Ahlquist and Tim Kampowski and Omid {Oliyan Torghabehi} and Achim Menges and Thomas Speck},
keywords = {Material behavior, Spring-based simulation, Computational design, Biomimetic research},
abstract = {Research in material behavior involves the study of relationships between material composition and capacities to negotiate internal and external pressures. Tuning material composition for performance allows for the integration of multifaceted functionality and embedded responsiveness within minimal material means. The relationships of material composition and system performance can be dissected into properties of topology (in count, type and association), forces (as the simulation of contextual pressures), and materiality (material properties and constraints of fabrication). When resourcing information about these aspects of material behavior from biological or technological systems, the physical precedents, as specimens and/or models, serve as the primary, and often sole, exemplar. While this is necessary to initiate the study of material make-up as it relates to specific morphological performance, there is an inherent limit when asking how and to what degree the knowledge resourced from that instance applies when alterations from the norm are generated. This research proposes the possibility for testing variants of a morphological system using physical models as the precedent while incorporating multiple means of computational analysis for extensive exploration. The framework begins with the initial stage of deducing principles, regarding material organization and behavior, through comparative physical and computational study. Subsequently, through methods of abduction, new vocabularies of form and potentials in performance are generated primarily through computational exploration. The framework is shaped by research into the design and materialization of complex pre-stressed form- and bending-active architectures. A novel aspect of this framework is the development of a software environment called springFORM. In this environment, material behavior is simulated using basic spring-based (particle system) methods. The novel contribution of this software is in providing means for both manual and algorithmic manipulations of mesh topologies and material properties during the form-finding process. A series of architectural prototypes, which range in scale, define rules for the relationship between topological-material complexity and the sequencing of particular exploratory methods. The studies define the value of the physical precedent as it engenders further material prototypes, spring-based explorations and simulations with finite element analysis. These rules and methods are further elaborated upon through studying the particularly fascinating structural capacity of banana leaf stalks, a material system which is stiff in bending yet highly flexible in torsion. Of interest is a functional robustness which allows for the negotiation of both self-weight and wind loading for a large and fully integrated leaf structure. Methods of simulation and meta-heuristics are developed to address the continual material and topological differentiation of the banana leaf stalk. Case studies are based upon examination of specimens from the species Musa acuminata and Ensete ventricosum. Mechanical properties and geometric descriptions of isolated moments within the stalk provide the basis for computational comparison. Fundamental properties and behaviors are extracted from the plant specimens, yet a full description is not possible because of the plant’s intricate spatial structure. In this case, the computational means serve to elucidate upon the behavior of the complete system as well as provide avenues for exploring its variants. This paper describes an extensible and calibrated framework which can foster enhanced biomimetic insights by explorations which are based upon but extend well beyond initial biological and/or technological precedents.}
}
@article{OESCH2021990,
title = {How REM sleep shapes hypothalamic computations for feeding behavior},
journal = {Trends in Neurosciences},
volume = {44},
number = {12},
pages = {990-1003},
year = {2021},
issn = {0166-2236},
doi = {https://doi.org/10.1016/j.tins.2021.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0166223621001831},
author = {Lukas T. Oesch and Antoine R. Adamantidis},
keywords = {sleep, feeding, goal-directed behavior, hypothalamus, population coding},
abstract = {The electrical activity of diverse brain cells is modulated across states of vigilance, namely wakefulness, non-rapid eye movement (NREM) sleep, and rapid eye movement (REM) sleep. Enhanced activity of neuronal circuits during NREM sleep impacts on subsequent awake behaviors, yet the significance of their activation, or lack thereof, during REM sleep remains unclear. This review focuses on feeding-promoting cells in the lateral hypothalamus (LH) that express the vesicular GABA and glycine transporter (vgat) as a model to further understand the impact of REM sleep on neural encoding of goal-directed behavior. It emphasizes both spatial and temporal aspects of hypothalamic cell dynamics across awake behaviors and REM sleep, and discusses a role for REM sleep in brain plasticity underlying energy homeostasis and behavioral optimization.}
}
@incollection{VOINOV202427,
title = {Participatory Modeling for Sustainability},
editor = {Martin A. Abraham},
booktitle = {Encyclopedia of Sustainable Technologies (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {27-35},
year = {2024},
isbn = {978-0-443-22287-0},
doi = {https://doi.org/10.1016/B978-0-323-90386-8.00020-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780323903868000206},
author = {Alexey Voinov},
keywords = {Biases, Modeling process, Social media, Stakeholders, Wicked problem},
abstract = {Sustainability is a wicked problem, which is hard to define in a unique way. It cannot be solved and should be treated in a participatory approach involving as many stakeholders in the process as possible. Participatory modeling is an efficient method for dealing with wicked problems. It involves stakeholders in an open-ended process of shared learning and can be essential for developing sustainable technologies. While there may be various levels of participation, the process evolves around a model of the system at stake. The model is built in interaction with the stakeholders, it provides to formalism to synchronize stakeholder thinking and knowledge about the system and to move towards consensus about the possible decision-making.}
}
@article{MEACHAM2023103902,
title = {Fire safety of existing residential buildings: Building regulatory system gaps and needs},
journal = {Fire Safety Journal},
volume = {140},
pages = {103902},
year = {2023},
issn = {0379-7112},
doi = {https://doi.org/10.1016/j.firesaf.2023.103902},
url = {https://www.sciencedirect.com/science/article/pii/S0379711223001704},
author = {Brian J. Meacham},
keywords = {Regulatory system, Existing buildings, Fire risk, Systems thinking},
abstract = {Considerable cost and effort are invested in government and private-sector activities aimed at providing a societally tolerable level of fire safety of the built environment. This is particularly true with respect to fire safety of new building construction. On the government side, this includes activities associated with building and fire regulations, material performance and test standards, design guidance, competency requirements, review and approvals, and more. On the private side, activities include product development, analysis and design, construction and installation, as well as education and training of practitioners. In some cases there are overlaps (e.g., private building control). However, once buildings become occupied, the system faces several challenges. Oversight of building use and modification often gets lost. Different actors come into play. Competing objectives become more significant. Occupants often lack understanding and ability to recognize problems and make adjustments. The net result is an increase in fire safety risk over the life of a building, with less opportunities for the regulatory system to make interventions prior to an unwanted fire event. However, this can be changed if the approach to regulating existing buildings changes, and importantly, embodies whole-of-life, multi-agency, holistic, systems-based thinking.}
}
@article{CAI2024102329,
title = {Student learning and instructional tasks in different curricular contexts: A longitudinal study},
journal = {International Journal of Educational Research},
volume = {125},
pages = {102329},
year = {2024},
issn = {0883-0355},
doi = {https://doi.org/10.1016/j.ijer.2024.102329},
url = {https://www.sciencedirect.com/science/article/pii/S0883035524000168},
author = {Jinfa Cai and John C. Moyer and Chuang Wang and Ning Wang and Bikai Nie},
keywords = {Longitudinal study, Problem solving, Instructional tasks, Mathematics learning, Curricular effect},
abstract = {This paper compares the longitudinal effect of instructional tasks on algebra learning that used a Standards-based curriculum [Connected Mathematics Project (CMP)] to that of classrooms that used a traditional curriculum (non-CMP). CMP was developed based on the National Council of Teachers of Mathematics (NCTM) Standards and can be characterized as a problem-based curriculum. CMP teachers were more than three times as likely to implement high-level instructional tasks than non-CMP teachers. Increases in the cognitive demand were associated with enhanced growth rates in problem solving, computation, and equation solving. Notably, when controlling for the cognitive demand of the instructional tasks, the advantage of the CMP curriculum over the non-CMP curricula on students’ growth in problem solving disappeared. However, non-CMP curricula had an advantage on students’ growth over the CMP curriculum after the cognitive demand of the instructional tasks was controlled.}
}
@article{KESICI2011472,
title = {Self-regulated learning strategies in relation with statistics anxiety},
journal = {Learning and Individual Differences},
volume = {21},
number = {4},
pages = {472-477},
year = {2011},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2011.02.006},
url = {https://www.sciencedirect.com/science/article/pii/S1041608011000203},
author = {Şahin Kesici and Mustafa Baloğlu and M. Engin Deniz},
keywords = {Statistical anxiety, Statistics learning, Learning strategies, Metacognition},
abstract = {Dealing with students' attitudinal problems related to statistics is an important aspect of statistics instruction. Employing the appropriate learning strategies may have a relationship with anxiety during the process of statistics learning. Thus, the present study investigated multivariate relationships between self-regulated learning strategies and statistical anxiety using canonical correlation analysis (CCA). Three hundred twenty Turkish college students responded to the Motivated Strategies for Learning Questionnaire and the Statistical Anxiety Rating Scale. Of the group, 189 (59.1%) were women and 131 (40.9%) were men. Participants' ages ranged from 18 to 33years with a mean of 21.28years (SD=1.53). Bivariate correlation coefficients showed significant relationships between the dimensions of learning strategies and statistical anxiety. CCA showed that students who used more rehearsal, elaboration, organization, critical thinking, metacognitive regulation, time and study environment management, and effort regulation strategies experienced lower computational anxiety and had more positive attitudes toward statistics. Additionally, a combination of effort regulation and help seeking strategies is associated with test/class anxiety.}
}
@article{SCHEZSOBRINO2024100648,
title = {MR-LEAP: Mixed-Reality Learning Environment for Aspirational Programmers},
journal = {Software Impacts},
volume = {20},
pages = {100648},
year = {2024},
issn = {2665-9638},
doi = {https://doi.org/10.1016/j.simpa.2024.100648},
url = {https://www.sciencedirect.com/science/article/pii/S2665963824000368},
author = {Santiago Schez-Sobrino and Francisco M. García and Javier A. Albusac and Carlos Glez-Morcillo and Jose J. Castro-Schez and David Vallejo},
keywords = {Programming learning, Mixed reality, Gamification, Computational thinking, Problem solving},
abstract = {This paper presents MR-LEAP (Mixed-Reality Learning Environment for Aspirational Programmers), a framework developed for learning programming through Mixed Reality and gamification mechanics. MR-LEAP’s architecture is designed to facilitate the understanding of basic programming concepts while allowing the gradual incorporation of more complex concepts. The framework provides a simple visual level editor. MR-LEAP is supported by the Mixed Reality Toolkit framework to promote portability to new Mixed Reality devices. Our goal is to facilitate programming education using Mixed Reality technology. MR-LEAP has already been used in both research and educational.}
}
@article{BRAMLEY2023105471,
title = {Active inductive inference in children and adults: A constructivist perspective},
journal = {Cognition},
volume = {238},
pages = {105471},
year = {2023},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2023.105471},
url = {https://www.sciencedirect.com/science/article/pii/S0010027723001051},
author = {Neil R. Bramley and Fei Xu},
keywords = {Hypothesis generation, Active learning, Inductive inference, Developmental change, Concept learning, Program induction},
abstract = {A defining aspect of being human is an ability to reason about the world by generating and adapting ideas and hypotheses. Here we explore how this ability develops by comparing children’s and adults’ active search and explicit hypothesis generation patterns in a task that mimics the open-ended process of scientific induction. In our experiment, 54 children (aged 8.97±1.11) and 50 adults performed inductive inferences about a series of causal rules through active testing. Children were more elaborate in their testing behavior and generated substantially more complex guesses about the hidden rules. We take a ‘computational constructivist’ perspective to explaining these patterns, arguing that these inferences are driven by a combination of thinking (generating and modifying symbolic concepts) and exploring (discovering and investigating patterns in the physical world). We show how this framework and rich new dataset speak to questions about developmental differences in hypothesis generation, active learning and inductive generalization. In particular, we find children’s learning is driven by less fine-tuned construction mechanisms than adults’, resulting in a greater diversity of ideas but less reliable discovery of simple explanations.}
}
@article{BOSSE201239,
title = {A computational model for dynamics of desiring and feeling},
journal = {Cognitive Systems Research},
volume = {19-20},
pages = {39-61},
year = {2012},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2012.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S1389041712000228},
author = {Tibor Bosse and Mark Hoogendoorn and Zulfiqar A. Memon and Jan Treur and Muhammad Umair},
keywords = {Desire, Feeling, Computational model},
abstract = {In this paper a computational model is presented for how a desire triggers responses and feelings. The model shows how these feelings can be biased, for example due to addicting experiences in the past. Both the strength of a response and of the associated feeling result from a converging dynamic pattern modeled by reciprocal causal interactions between the two. The model has been used to conduct a number of simulation experiments under varying circumstances. Moreover, it has been evaluated by formal analysis of emerging patterns entailed by the model. Furthermore, it has been pointed out how the computational model can be applied within an ambient agent system supporting a human in not being tempted. In a simple example scenario it is shown such an ambient agent system is able to predict and assess a human’s desire state, and use this assessment to suggest alternatives to avoid falling for certain temptations.}
}
@article{YAO2018107,
title = {Three-way decision and granular computing},
journal = {International Journal of Approximate Reasoning},
volume = {103},
pages = {107-123},
year = {2018},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2018.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X18302809},
author = {Yiyu Yao},
keywords = {Three-way decision, Three-way computing, Granular computing in threes, Thinking in threes, Magical number three},
abstract = {Based on results from cognitive science, this paper examines the two fields of three-way decision and granular computing, as well as their interplay. The ideas from one field shed new light on the other field. The integration of the two gives rise to three-way granular computing, that is, thinking, problem solving, and information processing in threes. We discuss a wide sense of three-way decision and propose a trisecting–acting–outcome (TAO) model. We explain fundamental notions of granular computing based on the philosophy of three-way decision as thinking in threes. We discuss a model of three-way granular computing by making use of two particular types of granular structures represented, respectively, by three granules and three levels. We use examples across different disciplines to demonstrate the values of the two types. Our investigation suggests that, in many situations, the power of granular computing is indeed the power of three-way decision, i.e., thinking in threes.}
}
@article{AGUIRRE2024101196,
title = {Mathematizing the world: A routine to advance mathematizing in the elementary classroom},
journal = {The Journal of Mathematical Behavior},
volume = {76},
pages = {101196},
year = {2024},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2024.101196},
url = {https://www.sciencedirect.com/science/article/pii/S0732312324000737},
author = {Julia M. Aguirre and Erin E. Turner and Elzena McVicar and Amy Roth McDuffie and Mary Q. Foote and Erin Carll},
keywords = {Mathematizing, Elementary, Mathematical thinking, Problem posing, Culturally responsive},
abstract = {The Mathematizing-the-World routine (MWR) is an efficient culturally responsive instructional routine for mathematizing that explicitly supports problem posing using an image or object. Given the under-representation of problem-posing studies in elementary school settings, our qualitative study analyzed student responses from 56 MWR enactments in grade 3–5 classrooms in two regions of the United States. Our findings include detailed examples of the MWR in action, including how three open-ended prompts engaged younger students in mathematizing and posing problems related to authentic, real-world situations. We summarize findings across the 56 MWR classroom enactments focusing on the understandings about the context and the mathematical ideas evidenced in student responses. Our findings demonstrate the potential of the MWR as a catalyst for eliciting and communicating diverse student ideas while engaged in the problem-posing process. We discuss research and practice implications for this routine to support mathematizing, and specifically problem posing in the elementary classroom.}
}
@article{SUTHAR2023122,
title = {The integrative approach of learning chemical engineering thermodynamics by using simulation-based exercises},
journal = {Education for Chemical Engineers},
volume = {45},
pages = {122-129},
year = {2023},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2023.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S174977282300043X},
author = {Krunal J. Suthar and Milind H. Joshipura},
keywords = {Process simulation, Thermodynamics, Teaching-learning, Fluid package},
abstract = {The active learning integrative approach of simulation-based exercises along with the core course would help undergraduate students with more engaged learning. The present study describes the simulation approach using an open-source process simulator with the help of three simulation-based exercises. The first one exemplifies the importance of the selection of an appropriate fluid package. The second exercise presented in the study shows the effect of using optimized and default values of binary interaction parameters on VLE prediction of alcohol-ester systems. The small interactive simulation-based problems with expected outcomes were presented in the third exercise which makes the learning more engaging and interesting. The current study highlights an integrative approach to inculcating critical thinking and self-learning abilities using small simulation-based exercises while learning chemical engineering thermodynamics. Finally, a survey with closed- and open-ended questions was used to gather the opinions of students on the presented exercises. A short communication is needed that sheds light on the integrative approach of learning process simulation complementing the thermodynamic theory learning.}
}
@article{HUANG201727,
title = {A computational cognitive modeling approach to understand and design mobile crowdsourcing for campus safety reporting},
journal = {International Journal of Human-Computer Studies},
volume = {102},
pages = {27-40},
year = {2017},
note = {Special Issue on Mobile and Situated Crowdsourcing},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2016.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1071581916301549},
author = {Yun Huang and Corey White and Huichuan Xia and Yang Wang},
keywords = {Mobile crowdsourcing, Cognitive computational method, Public safety, User contribution, Drift-diffusion decision model, Nudge mechanism},
abstract = {The under-reporting of public safety incidents is a long-standing issue. In this paper, we propose a computational cognitive modeling approach to understand and design a mobile crowdsourcing system for improving campus safety reporting. In particular, we adopt drift-diffusion models (DDMs) from cognitive psychology to investigate the effect of various factors on users’ reporting tendency for public safety. Our lab experiment and online study show consistent results on how location context impacts people's reporting decisions. This finding informs the design of a novel location-based nudge mechanism, which is tested in another lab experiment with 84 participants and proved to be effective in changing users’ reporting decisions. Our follow-up interview study further suggests that the influence of people's mobility patterns (e.g., expected walking distance) could explain why the nudge design is effective. Our work not only informs the design of mobile crowdsourcing for public safety reporting but also demonstrates the value of applying a computational cognitive modeling approach to address HCI research questions more broadly.}
}
@article{TELIKANI2020318,
title = {A survey of evolutionary computation for association rule mining},
journal = {Information Sciences},
volume = {524},
pages = {318-352},
year = {2020},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2020.02.073},
url = {https://www.sciencedirect.com/science/article/pii/S002002552030164X},
author = {Akbar Telikani and Amir H. Gandomi and Asadollah Shahbahrami},
keywords = {Data mining, Association rule mining, Evolutionary computation, Swarm intelligent},
abstract = {Association Rule Mining (ARM) is a significant task for discovering frequent patterns in data mining. It has achieved great success in a plethora of applications such as market basket, computer networks, recommendation systems, and healthcare. In the past few years, evolutionary computation-based ARM has emerged as one of the most popular research areas for addressing the high computation time of traditional ARM. Although numerous papers have been published, there is no comprehensive analysis of existing evolutionary ARM methodologies. In this paper, we review emerging research of evolutionary computation for ARM. We discuss the applications on evolutionary computations for different types of ARM approaches including numerical rules, fuzzy rules, high-utility itemsets, class association rules, and rare association rules. Evolutionary ARM algorithms were classified into four main groups in terms of the evolutionary approach, including evolution-based, swarm intelligence-based, physics-inspired, and hybrid approaches. Furthermore, we discuss the remaining challenges of evolutionary ARM and discuss its applications and future topics.}
}
@article{FERNYHOUGH20231180,
title = {Inner speech as language process and cognitive tool},
journal = {Trends in Cognitive Sciences},
volume = {27},
number = {12},
pages = {1180-1193},
year = {2023},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2023.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S1364661323002103},
author = {Charles Fernyhough and Anna M. Borghi},
keywords = {inner dialogue, inner monologue, verbal thinking, self-talk, self-regulation, phenomenology},
abstract = {Many people report a form of internal language known as inner speech (IS). This review examines recent growth of research interest in the phenomenon, which has broadly supported a theoretical model in which IS is a functional language process that can confer benefits for cognition in a range of domains. A key insight to have emerged in recent years is that IS is an embodied experience characterized by varied subjective qualities, which can be usefully modeled in artificial systems and whose neural signals have the potential to be decoded through advancing brain–computer interface technologies. Challenges for future research include understanding individual differences in IS and mapping form to function across IS subtypes.}
}
@article{DOGAN2018464,
title = {Differing instructional modalities and cognitive structures: Linear algebra},
journal = {Linear Algebra and its Applications},
volume = {542},
pages = {464-483},
year = {2018},
note = {Proceedings of the 20th ILAS Conference, Leuven, Belgium 2016},
issn = {0024-3795},
doi = {https://doi.org/10.1016/j.laa.2017.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0024379517304172},
author = {Hamide Dogan},
keywords = {Mathematics education, Linear algebra, Thinking modes, Instructional modalities, Cognitive schemes},
abstract = {This paper discusses the aspects of twelve first-year linear algebra students' thinking modes displayed on their interview responses to questions addressing linear independence ideas. Studying thinking modes allowed us to make inferences about the role of differing instructional modalities in shaping one's cognitive structures.}
}
@article{DEUTSCH2018156,
title = {Computational mechanisms in genetic regulation by RNA},
journal = {Journal of Theoretical Biology},
volume = {458},
pages = {156-168},
year = {2018},
issn = {0022-5193},
doi = {https://doi.org/10.1016/j.jtbi.2018.09.016},
url = {https://www.sciencedirect.com/science/article/pii/S0022519318304466},
author = {J.M. Deutsch},
abstract = {The evolution of the genome has led to very sophisticated and complex regulation. Because of the abundance of non-coding RNA (ncRNA) in the cell, different species will promiscuously associate with each other, suggesting collective dynamics similar to artificial neural networks. A simple mechanism is proposed allowing ncRNA to perform computations equivalent to neural network algorithms such as Boltzmann machines and the Hopfield model. The quantities analogous to the neural couplings are the equilibrium constants between different RNA species. The relatively rapid equilibration of RNA binding and unbinding is regulated by a slower process that degrades and creates new RNA. The model requires that the creation rate for each species be an increasing function of the ratio of total to unbound RNA. Similar mechanisms have already been found to exist experimentally for ncRNA regulation. With the overall concentration of RNA regulated, equilibrium constants can be chosen to store many different patterns, or many different input–output relations. The network is also quite insensitive to random mutations in equilibrium constants. Therefore one expects that this kind of mechanism will have a much higher mutation rate than ones typically regarded as being under evolutionary constraint.}
}
@article{ZBOINSKA2019675,
title = {Influence of a hybrid digital toolset on the creative behaviors of designers in early-stage design},
journal = {Journal of Computational Design and Engineering},
volume = {6},
number = {4},
pages = {675-692},
year = {2019},
issn = {2288-4300},
doi = {https://doi.org/10.1016/j.jcde.2018.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S228843001830174X},
author = {Malgorzata A. Zboinska},
keywords = {Early-stage design, Digital design, Computational design, Architectural design, Hybrid digital design systems, Intelligent human-machine integration},
abstract = {The purpose of this research was to investigate how diversification of the repertoire of digital design techniques affects the creative behaviors of designers in the early design phases. The principal results of practice-based pilot experiments on the subject indicate three key properties of the hybrid digital tooling strategy. The strategy features intelligent human-machine integration, facilitating three different types of synergies between the designer and the digital media: human-dominated, machine-dominated, and a balanced human-machine collaboration. This strategy also boosts the cognitive behaviors of the designer by triggering divergent, transformative and convergent design activities and allowing for work on various abstraction levels. In addition, the strategy stimulates the explorative behaviors of the designer by encouraging the production of and interaction with a wide range of design representations, including physical and digital, dynamic and static objects. Thus, working with a broader range of digital modeling techniques can positively influence the creativity of designers in the early conception stages.}
}
@article{GARFIELD19844,
title = {Artificial intelligence: Using computers to think about thinking, part I: Representing knowledge},
journal = {Computer Compacts},
volume = {2},
number = {1},
pages = {4-9},
year = {1984},
issn = {0167-7136},
doi = {https://doi.org/10.1016/0167-7136(84)90071-4},
url = {https://www.sciencedirect.com/science/article/pii/0167713684900714},
author = {Eugene Garfield}
}
@article{NUGRAHA2023406,
title = {A SEM-neural network approach for understanding the entrepreneurial competence development of freshmen engineering and computing students},
journal = {Procedia Computer Science},
volume = {216},
pages = {406-414},
year = {2023},
note = {7th International Conference on Computer Science and Computational Intelligence 2022},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.12.152},
url = {https://www.sciencedirect.com/science/article/pii/S187705092202230X},
author = {Rendika Nugraha and Nanang Ali Sutisna and Adhi Setyo Santoso and Ihsan Hadiansah and Johan Krisnanto Runtuk},
keywords = {Entrepreneurial competence, techno-entrepreneurship, creativity, ethical, sustainable thinking, motivation, perseverance, mobilizing others, learning through experience taking initiative, cope with uncertainty},
abstract = {The discussion of enhancing entrepreneurial competence in Higher Education Institution (HEI), especially in engineering and computing major, has increased for the recent years. This study aims to propose and test a structural model of relationship of Indonesian HEI entrepreneurship education with entrepreneurship competence to assess student entrepreneurship competences especially in undergraduate level. Thus, this study provides the contribution in this stream by creating a subject specialized that fit with specific study program to enhance entrepreneurial competence for freshmen student called Integrative Survival Experience especially in engineering and computing major. We measure its output by using EntreComp questionnaires framework from European Commission. A combination of Structural Equation Modelling (SEM) and neural network was implemented as analytic approach in this study. The results show that the freshmen engineering and computing students develop entrepreneurial competence by enhancing the specific sets of ideas and opportunities as well as the capability to manage resources for taking the action afterwards. Apparently, the entrepreneurial competence development process of engineering and computing students differs with that of business and management students.}
}
@article{PENG2025109960,
title = {LMCodec2: Ultra-low bit rate codec with causal multiple transformers},
journal = {Computers and Electrical Engineering},
volume = {122},
pages = {109960},
year = {2025},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2024.109960},
url = {https://www.sciencedirect.com/science/article/pii/S0045790624008851},
author = {Dingwei Peng and Qizhen Weng and Ningze Zhong and Ting Xie and Can Gong and Xiangwei Zhu and Xuelin Yuan and Mingjun Ouyang},
keywords = {End-to-end codec, VQ-VAE, GAN, Transformer model, Huffman coding},
abstract = {In recent years, the bandwidth constraints in satellite Internet of Things (IoT) applications have spurred the development of novel methods for compressing transmitted speech. For satellite voice communications, it is essential to achieve high-quality codecs with a bit rate below 1 kbps, particularly for channels such as Beidou-3, which often operate under such limitations. Neural network-based vocoders have emerged as a promising solution within the AI community, offering high-fidelity audio compression. In this paper, we propose LMCodec2, a causal speech codec designed to operate across a range of bit rates while delivering high-quality audio at extremely low bit rates, specifically tailored for satellite voice transmission. LMCodec2 utilizes a Transformer-based language model to predict tokens frame by frame, achieving a 25 % reduction in bit rate without compromising decoded audio quality. Our experimental evaluations demonstrate that LMCodec2 produces high-quality decoded audio at 0.76 kbps and 1.15 kbps. Notably, at 0.76 kbps, LMCodec2 achieves a MUSHRA (Multi-Stimulus Test with Hidden Reference and Anchor) score that surpasses Encodec's performance at 1.5 kbps. Audio demonstrations, including real-world self-recorded speech datasets, are available at https://dingweipeng.github.io/JACK.github.io. LMCodec2 provides a new way of thinking to addressing the challenges of bandwidth-limited satellite voice communications.}
}
@article{YAO199959,
title = {Evolutionary computation comes of age},
journal = {Cognitive Systems Research},
volume = {1},
number = {1},
pages = {59-64},
year = {1999},
issn = {1389-0417},
doi = {https://doi.org/10.1016/S1389-0417(99)00006-6},
url = {https://www.sciencedirect.com/science/article/pii/S1389041799000066},
author = {Xin Yao},
abstract = {Evolutionary computation is a field of study of computational systems which uses ideas and gets inspirations from natural evolution and adaptation. Although the history of evolutionary computation can be traced back to 1950s, it was only in the last decade or so that the field started to grow rapidly. In recent years, there have been many successful applications of various evolutionary computation techniques in artificial intelligence, machine learning, numerical optimization, combinatorial optimization, etc. The theory of evolutionary computation has also been enriched greatly. There is a much better understanding of why and how evolutionary computation techniques work (or do not work) than five or six years ago. This article reports some of the latest developments presented at the recent 1999 Congress on Evolutionary Computation (CEC '99).}
}
@article{SHARIF2025101979,
title = {Innovative computation to detect stress in working people based on mode of commute},
journal = {Journal of Transport & Health},
volume = {41},
pages = {101979},
year = {2025},
issn = {2214-1405},
doi = {https://doi.org/10.1016/j.jth.2024.101979},
url = {https://www.sciencedirect.com/science/article/pii/S2214140524002251},
author = {Mhd Saeed Sharif and Madhav Raj Theeng Tamang and Cynthia Fu and Ahmed Ibrahim Alzahrani and Fahad Alblehai},
keywords = {Stress assessment, Blood pressure, Wearable sensors, Commuting, Intelligent transport system, Machine learning},
abstract = {Introduction:
Commuting is an integral part of modern life for many people, shaping daily routines and impacting overall well-being. With various transportation options, including driving, public transport, walking, and cycling, commuters encounter various experiences and challenges in their everyday journeys. Understanding how different modes of commuting affect stress levels is essential for improving public health and informing transportation planning. This study develops advanced machine-learning techniques to explore the connection between commuting methods and stress levels.
Methods:
This research examines how different commuting modes affect stress levels using machine learning methods. The study analyses data collected from 45 individuals who regularly commute to work, focusing on driving, cycling, and public transport modes. Non-invasive wearable sensors were utilised to gather electroencephalography (EEG), blood pressure (BP), and heart rate (HR) data for five consecutive days for each participant. Additionally, qualitative data was collected using the Positive and Negative Affect Schedule (PANAS) questionnaire to assess participants’ emotional responses before and after their commute. The research focuses on developing a machine learning-based model to predict the commute’s impact and monitor the stress level due to the commute mode. In research, objective and subjective factors shape the research process and outcomes. Understanding the interaction between these factors is essential for conducting thorough and reliable research that produces valid results. Our study utilises datasets incorporating qualitative and quantitative data from questionnaires and human bio-signals.
Results:
This research developed various machine learning algorithms to detect stress levels based on commuting mode. The results indicate that the Linear Discriminant Analysis technique achieved an accuracy of 88%, while Logistic Regression reached 90.66% accuracy. The Boosted Tree algorithm produced the best performance, with an accuracy of 91.11%. Furthermore, incorporating personalised parameters into the data improved the accuracy of these algorithms in detecting stress levels. Cross-validation was also utilised to mitigate the risk of overfitting, ensuring robust and reliable model performance.
Conclusion:
The findings reveal that human bio-signals tend to increase following commuting, irrespective of the mode, with driving identified as the most stressful option. Commuters using passive modes of transport experience elevated stress levels compared to those using active modes. This research underscores the importance of understanding the connection between commuting modes and stress, providing key insights into the potential health impacts of daily travel. The development of an intelligent model to predict stress levels based on commuting mode offers valuable contributions to public health and transportation planning, with the goal of enhancing well-being and improving commuters’ quality of life.}
}
@article{LIU2024108212,
title = {Analysis of translation teaching skills in colleges and universities based on deep learning},
journal = {Computers in Human Behavior},
volume = {157},
pages = {108212},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108212},
url = {https://www.sciencedirect.com/science/article/pii/S0747563224000803},
author = {Yan Liu and Shuhua Li and Dan Cui},
keywords = {Deep learning, Colleges and universities, Translation education, Machine learning applications, Teaching strategy},
abstract = {With the progress of the times and the improvement of science and technique, network message technique has occupied a vital position in people's lives. At the same time, society has been implementing university English education reform in recent years, and the “internet plus” wisdom education model is the product of the improvement of the times. This new education model has gradually integrated into the education of various subjects. Introducing the concept of message technique and wisdom education into university translation education can innovate education mode, optimize education content, and integrate high-quality education resources. Cultivating applied translators has become the trend of educational reform. Based on deep learning, this paper studies translation education skills in universities. In-depth education enables learners to acquire systematic knowledge, critical spirit, creative thinking, etc. This kind of learning fully taps individual potential to cultivate a complete personality. According to the research in this paper, wisdom education is 12% better than traditional education, and it is suitable to be widely put into practice.}
}
@article{MANNI2016260,
title = {Numerical study of airfoil stall cells using a very wide computational domain},
journal = {Computers & Fluids},
volume = {140},
pages = {260-269},
year = {2016},
issn = {0045-7930},
doi = {https://doi.org/10.1016/j.compfluid.2016.09.023},
url = {https://www.sciencedirect.com/science/article/pii/S0045793016302894},
author = {Luca Manni and Takafumi Nishino and Pierre-Luc Delafin},
keywords = {Flow separation, 2D/3D transition, High aspect ratio wing, Unsteady RANS, Delayed DES},
abstract = {The formation of stall cells over a NACA 0012 airfoil at a Reynolds number of one million has been investigated numerically, using unsteady Reynolds-averaged Navier–Stokes (URANS) and delayed detached-eddy simulation (DDES) approaches. The simulations are performed with a very wide computational domain (10 chord length) to minimize the influence of spanwise periodic boundary conditions. For the URANS simulations, four different spanwise mesh resolutions are tested to determine the minimum resolution required to capture the formation of stall cells. Both URANS and DDES results show a sudden decrease in lift and increase in drag between 16° and 17° angle of attack, accompanied by a significant change of separated flow patterns. Stall cell structures are observed clearly in the URANS solutions between 17° and 19° with a spanwise spacing of about 1.4 to 1.8 chord length, which agrees well with a theoretical prediction based on the slope of the lift curve in this angle-of-attack range. The DDES results show much more complex flow patterns over the airfoil at these high angles of attack, although the spectral analysis of wall shear stress suggests the existence of flow structures having a similar spanwise length scale to the stall cells.}
}
@article{GERSTEIN200773,
title = {An interdepartmental Ph.D. program in computational biology and bioinformatics: The Yale perspective},
journal = {Journal of Biomedical Informatics},
volume = {40},
number = {1},
pages = {73-79},
year = {2007},
note = {Bio*Medical Informatics},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2006.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S1532046406000335},
author = {Mark Gerstein and Dov Greenbaum and Kei Cheung and Perry L. Miller},
keywords = {Bioinformatics, Computational biology, Educational programs, Curriculum},
abstract = {Computational biology and bioinformatics (CBB), the terms often used interchangeably, represent a rapidly evolving biological discipline. With the clear potential for discovery and innovation, and the need to deal with the deluge of biological data, many academic institutions are committing significant resources to develop CBB research and training programs. Yale formally established an interdepartmental Ph.D. program in CBB in May 2003. This paper describes Yale’s program, discussing the scope of the field, the program’s goals and curriculum, as well as a number of issues that arose in implementing the program. (Further updated information is available from the program’s website, www.cbb.yale.edu.)}
}
@article{BEDEWY2023101299,
title = {STEAM + X - Extending the transdisciplinary of STEAM-based educational approaches: A theoretical contribution},
journal = {Thinking Skills and Creativity},
volume = {48},
pages = {101299},
year = {2023},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2023.101299},
url = {https://www.sciencedirect.com/science/article/pii/S187118712300069X},
author = {Shereen El Bedewy and Zsolt Lavicza},
keywords = {STEAM, Design-based research, Culture, Technology, Design principles},
abstract = {This design-based research methodological paper is proposing a theoretical understanding in the form of STEAM + X framework that emerged from the empirical findings of implementing transdisciplinary STEAM practices featuring architecture, culture, and history. This paper shows how the proposed STEAM practices, involving creativities, to promote the integration of various disciplines with multiple cross-cultural iterations. These STEAM practices allow teachers to integrate cultural, architectural, environmental, or technological options into mathematics teaching and learning. These STEAM practices foster creativity and thinking skills in connecting disciplines in a transdisciplinary learning approach. Moreover, this paper introduces the study outcomes including the developed design principles and a framework that connects the underlying theoretical framework with emerging themes from our qualitative data analysis.}
}
@article{DEBER200449,
title = {Medical savings accounts in a universal system: wishful thinking meets evidence},
journal = {Health Policy},
volume = {70},
number = {1},
pages = {49-66},
year = {2004},
issn = {0168-8510},
doi = {https://doi.org/10.1016/j.healthpol.2004.01.010},
url = {https://www.sciencedirect.com/science/article/pii/S0168851004000119},
author = {Raisa B Deber and Evelyn L Forget and Leslie L Roos},
keywords = {Medical savings accounts, Canada, Health care financing, Distribution of expenditures},
abstract = {Medical savings accounts (MSAs) and similar approaches based on flowing reimbursements through individuals/consumers rather than providers are unsuited for systems with universal coverage. Data from Manitoba, Canada reveal that, because expenditures for physician and hospital services are highly skewed in all age groups, MSAs would substantially increase both public expenditures and out-of-pocket costs for the most ill. The empirical distribution of health expenditures limits the potential impact of many current ‘demand-based’ approaches to cost control. Because most of the population is relatively healthy and uses few hospital and physician services, inducing the general population to spend less will not yield substantial savings.}
}
@article{STARK2021571,
title = {Autistic Cognition: Charting Routes to Anxiety},
journal = {Trends in Cognitive Sciences},
volume = {25},
number = {7},
pages = {571-581},
year = {2021},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2021.03.014},
url = {https://www.sciencedirect.com/science/article/pii/S1364661321000899},
author = {Eloise Stark and James Stacey and Will Mandy and Morten L. Kringelbach and Francesca Happé},
keywords = {autism, cognition, anxiety, predictive processing, intolerance of uncertainty, black and white thinking},
abstract = {Autism Spectrum Conditions are typified by a divergence in cognitive style from that of the non-autistic population. Cognitive differences in autism may underlie significant strengths, but also increase vulnerability to psychopathology such as anxiety, which is a major problem for many autistic people. Many autistic people also do not respond to typical psychotherapeutic interventions, suggesting that autism-specific models and interventions are needed. We advance a theoretical model explaining how three constructs, attenuated predictions, intolerance of uncertainty, and ‘black and white thinking’, may interact to lead to anxiety in autism. We hope to start a dialogue surrounding how we can best address specific autistic cognitive differences that may lead to distress by developing appropriate models, measurements, and psychotherapeutic interventions.}
}
@article{WANG2024119888,
title = {Progressive reinforcement learning for video summarization},
journal = {Information Sciences},
volume = {655},
pages = {119888},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2023.119888},
url = {https://www.sciencedirect.com/science/article/pii/S0020025523014731},
author = {Guolong Wang and Xun Wu and Junchi Yan},
keywords = {Video summarization, Progressive reinforcement learning, Hierarchical strategy},
abstract = {Video summarization addresses generating video summaries to help watchers grasp the content of a video without watching it entirely. Many methods have engaged in automatic video summarization. Although these methods have performed well, they still suffer from limited training data and sparse reward problems. We propose a Progressive Reinforcement Learning Video Summarization structure (PRLVS) with an unsupervised reward. The reward measures the information and quality the selected frames convey without annotations. Striving to earn higher rewards, our PRLVS adopts a “T”-type human thinking paradigm: choosing some key frames and checking if their adjacent frames are better than them. To simulate this paradigm, we decompose the flat strategy into a hierarchical strategy consisting of a horizontal policy and a vertical policy. These two policies are optimized alternatively, which densifies the reward while reducing the exploration space. Their cooperation also makes the agent capture the context information of the whole video at every step. Extensive experimental results on two benchmark databases (i.e., SumMe, TVSum) show that our PRLVS outperforms the comparisons and approaches the supervised methods, which indicates that it is significant to integrate our unsupervised reward into the progressive reinforcement learning structure to address limited annotation and sparse reward problems.}
}
@article{ROLLS2024e31965,
title = {The memory systems of the human brain and generative artificial intelligence},
journal = {Heliyon},
volume = {10},
number = {11},
pages = {e31965},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e31965},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024079969},
author = {Edmund T. Rolls},
keywords = {The brain and AI, Generative Pre-trained Transformer, Generative artificial intelligence, Episodic memory, Semantic memory, Hippocampal memory system, Chat-GPT},
abstract = {Generative Artificial Intelligence foundation models (for example Generative Pre-trained Transformer – GPT – models) can generate the next token given a sequence of tokens. How can this ‘generative AI’ be compared with the ‘real’ intelligence of the human brain, when for example a human generates a whole memory in response to an incomplete retrieval cue, and then generates further prospective thoughts? Here these two types of generative intelligence, artificial in machines and real in the human brain are compared, and it is shown how when whole memories are generated by hippocampal recall in response to an incomplete retrieval cue, what the human brain computes, and how it computes it, are very different from generative AI. Key differences are the use of local associative learning rules in the hippocampal memory system, and of non-local backpropagation of error learning in AI. Indeed, it is argued that the whole operation of the human brain is performed computationally very differently to what is implemented in generative AI. Moreover, it is emphasized that the primate including human hippocampal system includes computations about spatial view and where objects and people are in scenes, whereas in rodents the emphasis is on place cells and path integration by movements between places. This comparison with generative memory and processing in the human brain has interesting implications for the further development of generative AI and for neuroscience research.}
}
@incollection{WARE20221,
title = {Chapter 1 - Visual Queries},
editor = {Colin Ware},
booktitle = {Visual Thinking for Information Design (Second Edition)},
publisher = {Morgan Kaufmann},
edition = {Second Edition},
pages = {1-22},
year = {2022},
isbn = {978-0-12-823567-6},
doi = {https://doi.org/10.1016/B978-0-12-823567-6.00001-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012823567600001X},
author = {Colin Ware},
keywords = {Visual queries, visual search, distributed cognition, predictive cognition, visual system, visual thinking},
abstract = {The mechanisms and processes of visual thinking are introduced together with how this knowledge can help us make design decisions. We begin with a review of the evidence that we actually take in very little information with each glance and the implication that seeing is a process exquisitely tuned to our cognitive task of the moment. As a key part of this process, our brains execute visual queries using eye movements; visual features are detected in parallel to pick out just what is needed to resolve part of a cognitive problem and move on the next step. We begin to understand how seeing can be a distributed cognitive process executed partly in the brain and partly using a visualization as a tool. In particular, when the visualization is part of an interactive computer application, it provides the primary interface between cognitive operations in the human brain and computational operations. The theory of predictive cognition is introduced as a basis for how we should design presentations.}
}
@article{YON2021R1026,
title = {Precision and the Bayesian brain},
journal = {Current Biology},
volume = {31},
number = {17},
pages = {R1026-R1032},
year = {2021},
issn = {0960-9822},
doi = {https://doi.org/10.1016/j.cub.2021.07.044},
url = {https://www.sciencedirect.com/science/article/pii/S0960982221010344},
author = {Daniel Yon and Chris D. Frith},
abstract = {Summary
Scientific thinking about the minds of humans and other animals has been transformed by the idea that the brain is Bayesian. A cornerstone of this idea is that agents set the balance between prior knowledge and incoming evidence based on how reliable or ‘precise’ these different sources of information are — lending the most weight to that which is most reliable. This concept of precision has crept into several branches of cognitive science and is a lynchpin of emerging ideas in computational psychiatry — where unusual beliefs or experiences are explained as abnormalities in how the brain estimates precision. But what precisely is precision? In this Primer we explain how precision has found its way into classic and contemporary models of perception, learning, self-awareness, and social interaction. We also chart how ideas around precision are beginning to change in radical ways, meaning we must get more precise about how precision works.}
}
@incollection{HOUQUN2016155,
title = {Chapter 8 - Research on parallel computation of high arch dam structure seismic motion response},
editor = {Chen Houqun and Wu Shengxin and Dang Faning},
booktitle = {Seismic Safety of High Arch Dams},
publisher = {Academic Press},
address = {Oxford},
pages = {155-205},
year = {2016},
isbn = {978-0-12-803628-0},
doi = {https://doi.org/10.1016/B978-0-12-803628-0.00008-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128036280000082},
author = {Chen Houqun and Wu Shengxin and Dang Faning},
keywords = {seismic response analysis, high arch dam, high-performance parallel computation, component technique, technique of automatically generating programs, FEPG and PFEPG computation programs},
abstract = {The storage capacity and the computation time of dynamic analysis for seismic responses of high concrete arch dam systems are enormous. As a matter of course, the use of high-performance parallel computation for seismic analysis of high-concrete dams must be enforced. The significance and current situation of parallel computation for hydraulic structures using finite element method are briefly described. However, the more difficult task is to develop a parallel program. The EFPG is a finite element program generator using finite element language developed by Chinese Professor Liang Guoping in 1990. The program generated by FEPG can be automatically transformed to corresponding parallel program through the program PFEPG. The parallel computational program by means of FEPG and PFEPG applied in this stage to dynamic analysis for seismic responses of high concrete arch dam system is outlined. The strategy of FEPG is based on component technique and the technique of automatically generating programs. According to the characteristics of domain decomposition method, a finite element program can generally be decomposed to six modules as preprocess partition, start, bft, solv, E, and U programs, in which the subroutines of E and U component are generated by the system based on the scripts VDE or PDE of the partial differential equation describing the physical fields and the corresponding computational algorithms (NFE), other else components are fixed and provided by the FEPG Library. The structures and modules as well as the working operation of FEPG and PFEPG are briefly introduced. The parallel program developed for seismic response analysis of high arch dam by using the FEPG and PFEPG, including the corresponding treatments of dynamic explicit computation process, dynamic contact problem, artificial transmitting, and spring-viscous boundaries, are examined in slight details. The procedure of seismic analysis of arch dam includes three loading cases accomplished successively as follows:1.In case 1, the dam elements were treated as dead elements with zero degree of freedom for nodes, and only the dead load of the foundation rock is considered in the analysis. At the end of calculation, the initial normal compressive force along the contact planes was modified by adding the calculated contact force. All other states of the foundation were recovered to that before loading.2.In case 2, the dead load of dam and other static actions including water pressure, silt pressure, and temperature applied to the dam as well as the seepage pressure in the foundation are considered.3.In case 3, a three-component seismic input is applied to the base of the artificial transmitting boundaries in form of displacement ground motion, or to the spring-viscous boundaries with free field input including boundary stresses, velocities and displacements. In this loading case, the rate effect for dynamic strength and modulus of elasticity are considered.}
}
@article{COMPTON2018392,
title = {The aprosody of schizophrenia: Computationally derived acoustic phonetic underpinnings of monotone speech},
journal = {Schizophrenia Research},
volume = {197},
pages = {392-399},
year = {2018},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2018.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S0920996418300276},
author = {Michael T. Compton and Anya Lunden and Sean D. Cleary and Luca Pauselli and Yazeed Alolayan and Brooke Halpern and Beth Broussard and Anthony Crisafio and Leslie Capulong and Pierfrancesco Maria Balducci and Francesco Bernardini and Michael A. Covington},
keywords = {Acoustic resonance, Aprosody, Linguistics, Negative symptoms, Phonetics, Phonology, Psychosis, Schizophrenia},
abstract = {Objective
Acoustic phonetic methods are useful in examining some symptoms of schizophrenia; we used such methods to understand the underpinnings of aprosody. We hypothesized that, compared to controls and patients without clinically rated aprosody, patients with aprosody would exhibit reduced variability in: pitch (F0), jaw/mouth opening and tongue height (formant F1), tongue front/back position and/or lip rounding (formant F2), and intensity/loudness.
Methods
Audiorecorded speech was obtained from 98 patients (including 25 with clinically rated aprosody and 29 without) and 102 unaffected controls using five tasks: one describing a drawing, two based on spontaneous speech elicited through a question (Tasks 2 and 3), and two based on reading prose excerpts (Tasks 4 and 5). We compared groups on variation in pitch (F0), formant F1 and F2, and intensity/loudness.
Results
Regarding pitch variation, patients with aprosody differed significantly from controls in Task 5 in both unadjusted tests and those adjusted for sociodemographics. For the standard deviation (SD) of F1, no significant differences were found in adjusted tests. Regarding SD of F2, patients with aprosody had lower values than controls in Task 3, 4, and 5. For variation in intensity/loudness, patients with aprosody had lower values than patients without aprosody and controls across the five tasks.
Conclusions
Findings could represent a step toward developing new methods for measuring and tracking the severity of this specific negative symptom using acoustic phonetic parameters; such work is relevant to other psychiatric and neurological disorders.}
}
@article{SKRYD2024,
title = {ChatGPT as a Tool for Medical Education and Clinical Decision-Making on the Wards: Case Study},
journal = {JMIR Formative Research},
volume = {8},
year = {2024},
issn = {2561-326X},
doi = {https://doi.org/10.2196/51346},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X24002671},
author = {Anthony Skryd and Katharine Lawrence},
keywords = {ChatGPT, medical education, large language models, LLMs, clinical decision-making},
abstract = {Background
Large language models (LLMs) are computational artificial intelligence systems with advanced natural language processing capabilities that have recently been popularized among health care students and educators due to their ability to provide real-time access to a vast amount of medical knowledge. The adoption of LLM technology into medical education and training has varied, and little empirical evidence exists to support its use in clinical teaching environments.
Objective
The aim of the study is to identify and qualitatively evaluate potential use cases and limitations of LLM technology for real-time ward-based educational contexts.
Methods
A brief, single-site exploratory evaluation of the publicly available ChatGPT-3.5 (OpenAI) was conducted by implementing the tool into the daily attending rounds of a general internal medicine inpatient service at a large urban academic medical center. ChatGPT was integrated into rounds via both structured and organic use, using the web-based “chatbot” style interface to interact with the LLM through conversational free-text and discrete queries. A qualitative approach using phenomenological inquiry was used to identify key insights related to the use of ChatGPT through analysis of ChatGPT conversation logs and associated shorthand notes from the clinical sessions.
Results
Identified use cases for ChatGPT integration included addressing medical knowledge gaps through discrete medical knowledge inquiries, building differential diagnoses and engaging dual-process thinking, challenging medical axioms, using cognitive aids to support acute care decision-making, and improving complex care management by facilitating conversations with subspecialties. Potential additional uses included engaging in difficult conversations with patients, exploring ethical challenges and general medical ethics teaching, personal continuing medical education resources, developing ward-based teaching tools, supporting and automating clinical documentation, and supporting productivity and task management. LLM biases, misinformation, ethics, and health equity were identified as areas of concern and potential limitations to clinical and training use. A code of conduct on ethical and appropriate use was also developed to guide team usage on the wards.
Conclusions
Overall, ChatGPT offers a novel tool to enhance ward-based learning through rapid information querying, second-order content exploration, and engaged team discussion regarding generated responses. More research is needed to fully understand contexts for educational use, particularly regarding the risks and limitations of the tool in clinical settings and its impacts on trainee development.}
}
@article{RINGACH2009439,
title = {Spontaneous and driven cortical activity: implications for computation},
journal = {Current Opinion in Neurobiology},
volume = {19},
number = {4},
pages = {439-444},
year = {2009},
note = {Sensory systems},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2009.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S0959438809000786},
author = {Dario L Ringach},
abstract = {The traditional view of spontaneous neural activity as ‘noise’ has been challenged by recent findings suggesting that: (a) spontaneous activity in cortical populations is highly structured in both space and time, (b) the spatio-temporal structure of spontaneous activity is linked to the underlying connectivity of the cortical network, (c) spontaneous cortical activity interacts with external stimulation to generate responses to the individual presentations of a stimulus, (d) network connectivity is shaped in part by the statistics of natural signals and (e) ongoing cortical activity represents a continuous top-down prediction/expectation signal that interacts with incoming input to generate an updated representation of the world. These results can be integrated to provide a new framework for the study of cortical computation.}
}
@article{WANG2024102579,
title = {Artificial intelligence in dance education: Using immersive technologies for teaching dance skills},
journal = {Technology in Society},
volume = {77},
pages = {102579},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102579},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24001271},
author = {Zheng Wang},
keywords = {Artificial intelligence, Dance education, Dance mobile applications, Educational ecosystem, Immersive technologies, Intelligent action recognition system, Interactive dance training, Virtual, Augmented and mixed reality, Virtual mentoring},
abstract = {Artificial intelligence (AI) has led to a shift in modern dance education. Immersive technologies have become increasingly common worldwide, helping educators to improve the quality of dance pedagogy and increase the effectiveness of dance training. The article investigates the ways of using immersive technologies powered by artificial intelligence in dance education. The research explores the theoretical literature on dance education and the use of artificial intelligence in dance education and dance choreography. The scholars examine the impact of innovative technology solutions used in dance pedagogical practice on the development of dance skills in students. The study also discusses the functionality of interactive and multimedia dance teaching systems, including AI-powered virtual mentoring and cognitive simulations of human mind operations. The research analysed the use of virtual reality (VR), augmented reality (AR), and mixed reality (MR) in dance education. This research also focuses on mobile applications used for teaching modern dance. The proposed framework for dance education is based on digital technologies, which help to develop dance skills and improve teaching practices. The scholars conclude that the development and improvement of dance skills are possible only if a teacher combines virtual and real environments in everyday practices. The findings can be used by dance teachers, professional dancers, software developers, and researchers who examine the innovative practices and the application of artificial intelligence in dance education. The ecosystem model reframes thinking about approaches to dance education and can serve as the basis for further development of dance courses and dance style teaching modes.}
}
@article{DAVIES2016617,
title = {Computational Screening of All Stoichiometric Inorganic Materials},
journal = {Chem},
volume = {1},
number = {4},
pages = {617-627},
year = {2016},
issn = {2451-9294},
doi = {https://doi.org/10.1016/j.chempr.2016.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S2451929416301553},
author = {Daniel W. Davies and Keith T. Butler and Adam J. Jackson and Andrew Morris and Jarvist M. Frost and Jonathan M. Skelton and Aron Walsh},
keywords = {functional materials, computational chemistry, materials design, solar energy, high-throughput screening, water splitting, perovskites, structure prediction, SDG7: Affordable and clean energy},
abstract = {Summary
Forming a four-component compound from the first 103 elements of the periodic table results in more than 1012 combinations. Such a materials space is intractable to high-throughput experiment or first-principle computation. We introduce a framework to address this problem and quantify how many materials can exist. We apply principles of valency and electronegativity to filter chemically implausible compositions, which reduces the inorganic quaternary space to 1010 combinations. We demonstrate that estimates of band gaps and absolute electron energies can be made simply on the basis of the chemical composition and apply this to the search for new semiconducting materials to support the photoelectrochemical splitting of water. We show the applicability to predicting crystal structure by analogy with known compounds, including exploration of the phase space for ternary combinations that form a perovskite lattice. Computer screening reproduces known perovskite materials and predicts the feasibility of thousands more. Given the simplicity of the approach, large-scale searches can be performed on a single workstation.}
}
@article{SANTOS2015127,
title = {Phenotypic plasticity, the Baldwin effect, and the speeding up of evolution: The computational roots of an illusion},
journal = {Journal of Theoretical Biology},
volume = {371},
pages = {127-136},
year = {2015},
issn = {0022-5193},
doi = {https://doi.org/10.1016/j.jtbi.2015.02.012},
url = {https://www.sciencedirect.com/science/article/pii/S0022519315000715},
author = {Mauro Santos and Eörs Szathmáry and José F. Fontanari},
keywords = {Evolutionary search, Genetic algorithm, Learning, The Baldwin effect, Speed of evolution},
abstract = {An increasing number of dissident voices claim that the standard neo-Darwinian view of genes as ‘leaders’ and phenotypes as ‘followers’ during the process of adaptive evolution should be turned on its head. This idea is older than the rediscovery of Mendel’s laws of inheritance, with the turn-of-the-twentieth-century notion eventually labeled as the ‘Baldwin effect’ as one of the many ways in which the standard neo-Darwinian view can be turned around. A condition for this effect is that environmentally induced variation such as phenotypic plasticity or learning is crucial for the initial establishment of a trait. This gives the additional time for natural selection to act on genetic variation and the adaptive trait can be eventually encoded in the genotype. An influential paper published in the late 1980s claimed the Baldwin effect to happen in computer simulations, and avowed that it was crucial to solve a difficult adaptive task. This generated much excitement among scholars in various disciplines that regard neo-Darwinian accounts to explain the evolutionary emergence of high-order phenotypic traits such as consciousness or language almost hopeless. Here, we use analytical and computational approaches to show that a standard population genetics treatment can easily crack what the scientific community has granted as an unsolvable adaptive problem without learning. Evolutionary psychologists and linguists have invoked the (claimed) Baldwin effect to make wild assertions that should not be taken seriously. What the Baldwin effect needs are plausible case-histories.}
}
@article{LI20203666,
title = {The computational approaches of lncRNA identification based on coding potential: Status quo and challenges},
journal = {Computational and Structural Biotechnology Journal},
volume = {18},
pages = {3666-3677},
year = {2020},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2020.11.030},
url = {https://www.sciencedirect.com/science/article/pii/S2001037020304979},
author = {Jing Li and Xuan Zhang and Changning Liu},
keywords = {LncRNA identification, , Algorithm, Feature, Coding potential, sORF},
abstract = {Long noncoding RNAs (lncRNAs) make up a large proportion of transcriptome in eukaryotes, and have been revealed with many regulatory functions in various biological processes. When studying lncRNAs, the first step is to accurately and specifically distinguish them from the colossal transcriptome data with complicated composition, which contains mRNAs, lncRNAs, small RNAs and their primary transcripts. In the face of such a huge and progressively expanding transcriptome data, the in-silico approaches provide a practicable scheme for effectively and rapidly filtering out lncRNA targets, using machine learning and probability statistics. In this review, we mainly discussed the characteristics of algorithms and features on currently developed approaches. We also outlined the traits of some state-of-the-art tools for ease of operation. Finally, we pointed out the underlying challenges in lncRNA identification with the advent of new experimental data.}
}
@incollection{ELNAKIB202159,
title = {3 - Computational methods for identifying left ventricle heart pathologies},
editor = {Ayman S. El-Baz and Jasjit S. Suri},
booktitle = {Diabetes and Cardiovascular Disease},
publisher = {Elsevier},
pages = {59-93},
year = {2021},
volume = {3},
series = {Computer-Assisted Diagnosis},
isbn = {978-0-12-817428-9},
doi = {https://doi.org/10.1016/B978-0-12-817428-9.00003-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128174289000036},
author = {Ahmed Elnakib and Mohammed Ghazal and Fatma Taher and Ali H. Mahmoud and Ayman El-Baz},
keywords = {Computational methods, Left ventricle, Heart, Pathologies, Cardiac MRI (CMRI), Segmentation},
abstract = {Globally, the cardiovascular diseases are the first cause of death. The early detection and quantification of these diseases can significantly reduce the mortality rate. Recent advances in cardiac MRI (CMRI) enable the detection of the left ventricle (LV) wall pathologies and the estimation of different quantification metrics that characterize the working of the heart. Examples of these metrics include the area of pathological tissue in the LV wall, the transmural extent of pathology, and other indexes such as wall thickening, functional strain, and the ejection fraction metrics. In the literature, several computational methods have been proposed in order to estimate these metrics based on using different CMRI acquisition techniques, such as cardiac-enhanced CMRI (CE-CMRI) and cine CMRI. This chapter overviews these computational methods and explains their basic ideas, focusing on the metrics extracted using CE-CMRI and cine CMRI.}
}
@article{MAHMOUDZAKIALI2022100579,
title = {The computation intelligent in teaching using digital communication},
journal = {Measurement: Sensors},
volume = {24},
pages = {100579},
year = {2022},
issn = {2665-9174},
doi = {https://doi.org/10.1016/j.measen.2022.100579},
url = {https://www.sciencedirect.com/science/article/pii/S2665917422002136},
author = {Hossam {Mahmoud Zaki Ali} and Mohammed Hasan Ali Al-Abyadh},
keywords = {Computation intelligent, Digital communication, Skills, Non-verbal communication skills, School health promotion, Teachers},
abstract = {Teaching is all about communication. Teachers who sharpen their communication skills are prepared to instruct, advise, and mentor their students. They communicate well to effectively collaborate within a healthy educational process. This research aims to Make sure the communication scale prepared for the current research has statistical validity to be applied in the current research, identify the teachers' verbal non-verbal communication skills level, to explore the differences in these variables due to gender. A sample of (376) elementary and preparatory stage teachers, Minia Governorate, Egypt (188 male, 188 female) was chosen. For data collection, the researchers utilized the verbal and non-verbal communication scale (prepared by the researchers). They were applied electronically during the 2020 academic year. The research was a descriptive research design. Results demonstrated The communication scale prepared for the current research has statistical validity to be applied in the current research, there was a high level of verbal and nonverbal communication skills among the research sample. Besides, there were no statistically significant differences between male and female teachers in the levels of verbal communication skills, non-verbal communication skills. Some recommendations regarding the necessity to specify courses for pre-service teachers on verbal communication skills, nonverbal communication skills, were presented. Also, suggestions for those in charge of the educational administration process to improve teachers and school health promotion were illustrated.}
}
@article{MACCORMAC1984207,
title = {Men and machines: The computational metaphor},
journal = {Technology in Society},
volume = {6},
number = {3},
pages = {207-216},
year = {1984},
note = {Special Issue Technology and Philosophy},
issn = {0160-791X},
doi = {https://doi.org/10.1016/0160-791X(84)90033-2},
url = {https://www.sciencedirect.com/science/article/pii/0160791X84900332},
author = {Earl R. MacCormac},
abstract = {In the 20th century the interpretation of the human mind and brain as a computer has replaced the 18th century metaphor of “man as a machine”. This paper traces the development of the computational metaphor with some attention to its 18th century roots, and then argues that its employment need not lead to the mechanization of thinking and the autonomy of technique. An awareness of the metaphoric and, therefore, hypothetical status of the computational metaphor will prevent technique from escaping intentional human control. This is a shortened version of a paper included in C. Mitcham and Alois Huning, eds., Philosophy and Technology II: Information Technology and Computers in Theory and Practice (Boston: D. Reidel, in press), and is included here with permission.}
}
@article{BICER2021100823,
title = {Investigating creativity-directed tasks in middle school mathematics curricula},
journal = {Thinking Skills and Creativity},
volume = {40},
pages = {100823},
year = {2021},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2021.100823},
url = {https://www.sciencedirect.com/science/article/pii/S1871187121000389},
author = {Ali Bicer and Aylin Marquez and Karla Valesca Matute Colindres and Angela Ann Schanke and Libni Berenice Castellon and Luke M. Audette and Celal Perihan and Yujin Lee},
keywords = {Creativity-directed tasks, Creativity in mathematics textbooks, Creativity in mathematics curricula, Creative thinking in mathematics},
abstract = {Developing students’ creative thinking abilities while learning mathematics has been recently emphasized by many scholars, with many nations including creative thinking in mathematics as one of their overarching curriculum goals. The first purpose of the present study is to develop a framework to identify what type of mathematical tasks promote the mathematical creativity of students. The second purpose is to analyze to what degree the most commonly used three middle school curricula (i.e., Eureka, The Go Math!, and CPM) in the U.S. include creativity-directed tasks in their textbooks using this framework. Analyzing 1,500 mathematical tasks in each curriculum revealed that different curricula emphasize different dimensions of the creativity-directed tasks categories (i.e., open-ended tasks, problem-posing, connections, extensions, visualizations, and communication) presented in the framework. The result also revealed that open-ended problems are more common in the 6th grade textbooks than 7th and 8th grade textbooks regardless of the three selected middle school mathematics curricula. The implication of this study is to guide teachers with the strength and weakness of textbooks in terms of their inclusiveness of creativity-directed tasks to inform their teaching. Additionally, it is critical for curriculum developers to pay particular attention in including tasks that supporting each category and subcategory proportionately across the three years of middle school rather than emphasizing a few of them in one grade and almost completely ignoring them in previous or later years.}
}
@article{PU2023102577,
title = {Generative adversarial one-shot diagnosis of transmission faults for industrial robots},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {83},
pages = {102577},
year = {2023},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2023.102577},
url = {https://www.sciencedirect.com/science/article/pii/S0736584523000534},
author = {Ziqiang Pu and Diego Cabrera and Yun Bai and Chuan Li},
keywords = {One-shot diagnosis, Bi-directional generative adversarial network, Random forest, Industrial robot, Transmission system},
abstract = {Transmission systems of industrial robots are prone to get failures due to harsh operating environments. Fault diagnosis is of great significance for realizing safe operations for industrial robots. However, it is difficult to obtain faulty data in real applications. To migrate this issue, a generative adversarial one-shot diagnosis (GAOSD) approach is proposed to diagnose robot transmission faults with only one sample per faulty pattern. Signals representing kinematical characteristics were acquired by an attitude sensor. A bidirectional generative adversarial network (Bi-GAN) was then trained using healthy signals. Inspired by way of human thinking, the trained encoder in Bi-GAN was taken out to perform information abstraction for all signals. Finally, the abstracted signals were sent to a random forest for the one-shot diagnosis. The performance of the present technique was evaluated on an industrial robot experimental setup. Experimental results show that the proposed GAOSD has promising performance on the fault diagnosis of robot transmission systems.}
}
@article{ARASTOOPOURIRGENS2024100699,
title = {User experience testing and co-designing a digital game for broadening participation in computing with and for elementary school children},
journal = {International Journal of Child-Computer Interaction},
volume = {42},
pages = {100699},
year = {2024},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2024.100699},
url = {https://www.sciencedirect.com/science/article/pii/S2212868924000680},
author = {Golnaz {Arastoopour Irgens} and Cinamon Bailey and Tolulope Famaye and Atefeh Behboudi},
keywords = {Elementary education, User experience testing, Game-based learning, Culturally sustaining pedagogies, Intersectionality},
abstract = {Broadening participation in computing is more than providing access to computing for students; it requires reimagining and transforming teaching and learning to be more inclusive and culturally sustaining and it begins with elementary school children. In this study, we report on the fourth cycle of a participatory design-based research project in which researchers and children co-design culturally responsive-sustaining computational learning environments. We conducted user experience testing and co-design sessions with seven children on one level of a game-based learning environment in development. We model children's discourse through Epistemic Network Analysis models to investigate their feedback on character design, game narratives, and introductory activities. Our findings reveal 1) children's positive response to characters with counternarratives and visible intersectional identities in computing, 2) positive and negative experiences and feedback from children on game activities and narratives, and 3) suggestions for improvement.}
}
@article{DOGANDUNLAP20102141,
title = {Linear algebra students’ modes of reasoning: Geometric representations},
journal = {Linear Algebra and its Applications},
volume = {432},
number = {8},
pages = {2141-2159},
year = {2010},
note = {Special issue devoted to the 15th ILAS Conference at Cancun, Mexico, June 16-20, 2008},
issn = {0024-3795},
doi = {https://doi.org/10.1016/j.laa.2009.08.037},
url = {https://www.sciencedirect.com/science/article/pii/S0024379509004728},
author = {Hamide Dogan-Dunlap},
keywords = {Mathematics education, Linear algebra, Thinking modes, Geometric representations},
abstract = {Main goal of our research was to document differences on the types of modes linear algebra students displayed in their responses to the questions of linear independence from two different assignments. In this paper, modes from the second assignment are discussed in detail. Second assignment was administered with the support of graphical representations through an interactive web-module. Additionally, for comparison purposes, we briefly talk about the modes from the first assignment. First assignment was administered with the support of computational devices such as calculators providing the row reduced echelon form (rref) of matrices. Sierpinska’s framework on thinking modes (2000) was considered while qualitatively documenting the aspects of 45 matrix algebra students’ modes of reasoning. Our analysis revealed 17 categories of the modes of reasoning for the second assignment, and 15 categories for the first assignment. In conclusion, the findings of our analysis support the view of the geometric representations not replacing one’s arithmetic or algebraic modes but encouraging students to utilize multiple modes in their reasoning. Specifically, geometric representations in the presence of algebraic and arithmetic modes appear to help learners begin to consider the diverse representational aspects of a concept flexibly.}
}
@article{KALELIOGLU2015200,
title = {A new way of teaching programming skills to K-12 students: Code.org},
journal = {Computers in Human Behavior},
volume = {52},
pages = {200-210},
year = {2015},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2015.05.047},
url = {https://www.sciencedirect.com/science/article/pii/S0747563215004288},
author = {Filiz Kalelioğlu},
keywords = {Improving classroom teaching, Programming and programming languages, Elementary education},
abstract = {This study attempts to investigate the effect of teaching code.org site on reflective thinking skills towards problem solving. More specifically, this study attempts to investigate whether there is a gender difference in terms of students’ reflective thinking skills towards problem solving. This triangulation study was conducted with 32 primary school students. The quantitative part of the study was conducted in pre-test/post-test comparison design of quasi-experimental design. The scores of reflective problem solving skills were gathered through the reflective thinking skill scale towards problem solving and the students’ performances in the code-org site were examined. In the qualitative part of the research, after the five-week experimental process, focus group interviews were conducted with ten students and a reflection paper from the IT teacher was analysed. According to the t-test results, teaching programming to primary school students in the code.org site did not cause any differences in reflective thinking skills towards problem solving. However, there is a slight increment in the means of female students’ reflective thinking skills towards problem solving over the males’ reflective thinking skills towards problem solving. On the other hand, qualitative data provided more information about the students’ experiences. Students developed a positive attitude towards programming, and female students showed that they were as successful as their male counterparts, and that programming could be part of their future plans.}
}
@article{PESKIN201213,
title = {Fostering symbolic interpretation during adolescence},
journal = {Journal of Applied Developmental Psychology},
volume = {33},
number = {1},
pages = {13-23},
year = {2012},
issn = {0193-3973},
doi = {https://doi.org/10.1016/j.appdev.2011.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S0193397311000931},
author = {Joan Peskin and Rebecca Wells-Jopling},
keywords = {Adolescence, Symbolic interpretation, Domain-specific knowledge, Poetry, Concrete scaffolds, Computational skills},
abstract = {Although by 11years children demonstrate impressive performance on various tasks that assess symbolic thinking in language development, research suggests that few young adolescents demonstrate evidence of symbolic processing when reading literature. This study investigated whether the difficulty might be due to a lack of adequate exposure to domain-specific knowledge. Students in the experimental groups in three age groups — preadolescence, middle adolescence and later adolescence — received concrete scaffolds designed to foster domain-specific knowledge of the symbolic process. A comparison of the experimental and control groups showed that students at all three ages who had experienced the scaffolds demonstrated significantly greater symbolic interpretation. Furthermore, despite concerns that the scaffolds might dampen the readers' personal response, the experimental groups at all three ages provided significantly higher enjoyment ratings of the test poems.}
}
@incollection{REIN2013199,
title = {Chapter 16 - Re-thinking Standardization for Interagency Information Sharing},
editor = {Babak Akhgar and Simeon Yates},
booktitle = {Strategic Intelligence Management},
publisher = {Butterworth-Heinemann},
pages = {199-211},
year = {2013},
isbn = {978-0-12-407191-9},
doi = {https://doi.org/10.1016/B978-0-12-407191-9.00016-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780124071919000168},
author = {Kellyn Rein},
keywords = {agencies, analysis, data, fusion, human, intelligence, language, management, national, security, sources, text},
abstract = {Abstracts:
The collection and analysis of data for intelligence purposes is vital to national security. There are a number of hurdles including the exponentially increasing volume of available data, the need for increased cooperation between national and international agencies due to the increasingly globalized nature of threats to citizens and nations, and the need to be flexible in identifying new threats. Increasing reliance on computers is necessary, but complications arise due to such issues as incompatible data formats, multiple natural languages, and data privacy concerns. However, a potential solution to solving some of these problems for national security and law enforcement agencies is C2LG (Command and Control Lexical Grammar), which was originally developed for use within NATO, and is being adapted for use in crisis management and the fight against international organized crime.}
}
@article{KUO201232,
title = {Conceptual study of micro-tab device in airframe noise reduction: (II) 3D computation},
journal = {Aerospace Science and Technology},
volume = {17},
number = {1},
pages = {32-39},
year = {2012},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2011.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S127096381100040X},
author = {Brian C. Kuo and Nesrin Sarigul-Klijn},
keywords = {Computational aeroacoustics, High-lift devices, Micro-tab, Airframe noise},
abstract = {A three-dimensional numerical study is conducted to better understand noise reduction results seen in the previous two-dimensional investigation of the acoustic effects of micro-tab device on airframe noise reduction. Without sacrificing the aerodynamic performance, it is possible to achieve high-lift noise reduction with the application of the micro-tab device attached to the pressure side of the flap surface near its trailing-edge. This study was carried out by numerical hybrid method, which combines Computational Fluid Dynamics and acoustic analogy to predict the farfield noise spectrum. The near-full-scale computational results show that the micro-tab device with reduced deflection of the high-lift devices achieves noise reduction in mid-to-high frequency domain, in particular the range that human beings are most sensitive to. In addition, a parametric study in terms of geometric variation of the micro-tab was also investigated and reported. The three-dimensional results obtained thus far show reduction in noise levels with use of micro-tab.}
}
@article{FITRIANI2023e14769,
title = {The differential item functioning (DIF) testing for the WOCC (Ways of Coping Checklist) instrument based on gender},
journal = {Heliyon},
volume = {9},
number = {4},
pages = {e14769},
year = {2023},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2023.e14769},
url = {https://www.sciencedirect.com/science/article/pii/S240584402301976X},
author = {Arbania Fitriani and Dominikus David {Biondi Situmorang}},
keywords = {Differential item functioning, DIF, IRT, Stress, Coping stress, Psychometry},
abstract = {This study examined the Item Response Theory (IRT) method with statistical analysis to determine Differential Item Functioning (DIF) between men and women on the Ways of Coping Checklist (WOCC) Instruments revised by Vitaliano, Russo, Carr, Mauiro, and Becker (1985). Furthermore, it utilized primary data from 722 respondents with educational backgrounds ranging from senior high school, diplomas, and doctorates. The software packages QUEST, BILOG-MG, LISREL, and ITEMAN were used for analysis to address the concerns. Meanwhile, several items on the WOCC instrument indicated the presence of the DIF based on the calculation results using the IRT method with the QUEST and BILOG-MG software. According to the overall calculation for 1 PL and 2 PL using both tools, 8 items containing the DIF are distributed over the dimensions of problem solving, seeking social support, blaming self, and wishful thinking.}
}
@article{SAUNDERS20121024,
title = {Children without parents in the TANF caseload: Thinking beyond the child-only label},
journal = {Children and Youth Services Review},
volume = {34},
number = {5},
pages = {1024-1034},
year = {2012},
issn = {0190-7409},
doi = {https://doi.org/10.1016/j.childyouth.2012.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0190740912000771},
author = {Correne Saunders and Andrea Hetling and Pamela C. Ovwigho and Catherine E. Born},
keywords = {Kinship care, Child-only cases, Temporary Assistance for Needy Families, Relative caregiver, Child welfare policy},
abstract = {Child welfare policy has historically emphasized the positive impact relative caregivers can have on foster children. This emphasis coupled with recent changes in the composition of the Temporary Assistance for Needy Families (TANF) caseload has led to interest in child-only, relative caregiver cases. Child-only research, however, ignores cases in which the relative caregiver is also receiving benefits. Using the universe of welfare cases in Maryland in October 2005, this article compares and contrasts the demographic and case characteristics of parental and relative caregiver cases, also analyzing differences between cases with and without an adult receiving benefits. Findings indicate that relative caregivers have service needs that differ from those of parents and that recipient relative caregivers are more disadvantaged than child-only cases.}
}
@article{ESTRELLA20221,
title = {Early statistics in kindergarten: analysis of an educator's pedagogical content knowledge in lessons promoting informal inferential reasoning},
journal = {International Journal for Lesson and Learning Studies},
volume = {11},
number = {1},
pages = {1-13},
year = {2022},
issn = {2046-8253},
doi = {https://doi.org/10.1108/IJLLS-07-2021-0061},
url = {https://www.sciencedirect.com/science/article/pii/S2046825322000348},
author = {Soledad Estrella and Maritza Mendez-Reina and Raimundo Olfos and Jocelyn Aguilera},
keywords = {Pedagogical content knowledge, Early statistics, Informal inferential reasoning, Lesson study},
abstract = {Purpose
This study aims to describe the pedagogical content knowledge (PCK) of a kindergarten educator who implements a lesson plan about informal inferential reasoning designed in a lesson study group.
Design/methodology/approach
To this end, we analyzed teaching interventions in two kindergarten lessons focused on the playful task of tossing two coins, associated with inferential statistical reasoning. The study highlights the importance of arguing and promoting this reasoning to develop statistical thinking. It is crucial to recognize how early students can be subject to learning experiences that promote a language of uncertainty, assess the evidence provided by the data, and make generalizations.
Findings
The results reveal that while the educator demonstrated knowledge and skills relevant to the curriculum and conceptual teaching strategies, the understanding of the content by the students and the integration of the PCK components still present a challenge.
Practical implications
The lesson study collaborative teaching practices that promote PCK have proven effective for informing the design and implementation of instructional practices supporting the development of early statistical thinking in young children.
Originality/value
The study enriches the knowledge regarding the potential of the lesson study (LS) in the professional learning of kindergarten educators. It also contributes to a comprehensive approach based on authentic playful experiences in grade K that supports the development of early statistical thinking in young children.}
}
@incollection{BOSSE2017311,
title = {Chapter 13 - On Computational Models of Emotion Regulation and Their Applications Within HCI},
editor = {Myounghoon Jeon},
booktitle = {Emotions and Affect in Human Factors and Human-Computer Interaction},
publisher = {Academic Press},
address = {San Diego},
pages = {311-337},
year = {2017},
isbn = {978-0-12-801851-4},
doi = {https://doi.org/10.1016/B978-0-12-801851-4.00013-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128018514000136},
author = {Tibor Bosse},
keywords = {emotion regulation, computational modeling, dynamics, virtual characters, simulation-based training},
abstract = {Emotion regulation, or the ability to regulate one’s own and other people’s emotions, is an important skill for human beings, enabling them to function adequately in their social environment. The development of computational models of emotion regulation opens up a range of interesting applications in human–computer interaction, varying from virtual characters to simulation-based training systems. To provide more insight in the underlying mechanisms as well as the application areas of computational emotion regulation models, the current chapter provides an overview of the state-of-the-art in this area. After briefly reviewing the psychological literature on emotion generation and regulation, I will explain how these phenomena can be formalized into computational models. Next, a computational model of emotion regulation is presented in detail, and a number of resulting simulation runs are shown. The chapter concludes with a discussion of potential applications of such models.}
}
@article{KOUZALIS2024105312,
title = {Advanced technologies and mathematical metacognition: The present and future orientation},
journal = {BioSystems},
volume = {245},
pages = {105312},
year = {2024},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2024.105312},
url = {https://www.sciencedirect.com/science/article/pii/S0303264724001977},
author = {Alexios Kouzalis and Antonios Antoniou and Nicos Rossides and Rita Panaoura and Priyanka Yadav},
keywords = {Mathematical cognition, Metacognition, Cognition, Artificial intelligence, Machine learning, Robotics, Boolean logic, Bayesian inference, Fuzzy logic, Chemical artificial intelligence},
abstract = {The intersection of mathematical cognition, metacognition, and advanced technologies presents a frontier with profound implications for human learning and artificial intelligence. This paper traces the historical roots of these concepts from the Pythagoreans and Aristotle to modern cognitive science and explores their relevance to contemporary technological applications. We examine how the Pythagoreans' view of mathematics as fundamental to understanding the universe and Aristotle's contributions to logic and categorization have shaped our current understanding of mathematical cognition and metacognition. The paper investigates the role of Boolean logic in computational processes and its relationship to human logical reasoning, as well as the significance of Bayesian inference and fuzzy logic in modelling uncertainty in human cognition and decision-making. We also explore the emerging field of Chemical Artificial Intelligence and its potential applications. We argue for unifying mathematical metacognition with advanced technologies, including artificial intelligence and robotics, while identifying the multifaceted benefits and challenges of such unification. The present paper examines essential research directions for integrating cognitive sciences and advanced technologies, discussing applications in education, healthcare, and business management. We provide suggestions for developing cognitive robots using specific cognitive tasks and explore the ethical implications of these advancements. Our analysis underscores the need for interdisciplinary collaboration to realize the full potential of this integration while mitigating potential risks.}
}
@article{NEGI2022100096,
title = {A deep dive into metacognition: Insightful tool for moral reasoning and emotional maturity},
journal = {Neuroscience Informatics},
volume = {2},
number = {4},
pages = {100096},
year = {2022},
issn = {2772-5286},
doi = {https://doi.org/10.1016/j.neuri.2022.100096},
url = {https://www.sciencedirect.com/science/article/pii/S2772528622000589},
author = {Sunder Kala Negi and Yaisna Rajkumari and Minakshi Rana},
keywords = {Metacognitive thinking, Moral reasoning, Emotional maturity, Artificial intelligence},
abstract = {The impact of metacognition on pupils' moral ideals and emotional development was investigated as well as it highlights on a collaborative research between metacognition and artificial intelligence that can bridge the gap (emotional, ethical, moral reasoning, common sense) existing in AI. A total of 200 pupils were selected in the study's sample. Participants (100 high metacognitive students and 100 low metacognitive students) were chosen at random and ranged in age from 17 to 21 years old. The influence of metacognition on students' moral ideals and emotional development was studied using a t-test. The outcome reveals that the mean score of moral reasoning on high metacognitive students as 66.77 and for low metacognitive students as 63.08, t value = 3.21, at the 0.01 level, statistically highly significant. The mean emotional maturity score for high metacognitive students was 29.99, while for low metacognitive students was 33.01, t value as 2.81, shows statistically significant at the 0.05 level. This demonstrates that the higher the score, the less emotionally stable the pupils are. The current findings show that metacognitive thinking has a major impact on moral reasoning and emotional maturity, and that as metacognition levels rise, so do moral reasoning and emotional maturity. Metacognition can strengthen the humanistic qualities which are majorly lacking in AI. In addition, there are new avenues being opened in the study of artificial intelligence via metacognitive study which is significant and futuristic.}
}
@article{CHANG2024103484,
title = {Evaluating AI's impact on self-regulated language learning: A systematic review},
journal = {System},
volume = {126},
pages = {103484},
year = {2024},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2024.103484},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X24002665},
author = {Wenli-Li Chang and Jerry Chih-Yuan Sun},
keywords = {Self-regulated language learning, AI mediation, Learning partner, Systematic review},
abstract = {AI technology is reshaping language classrooms, prompting students to adopt flexible roles exhibiting linguistic competence and self-regulated learning (SRL) skills. Considerable studies explore the necessary integrated learning perspectives, emphasizing AI's adaptive role as a mind tool. In AI-mediated language learning, the technology's metacognitive importance enables students to learn with AI as a partner, encouraging independent critical thinking. Within Zimmerman's SRL model, AI as a mind tool is integrated for improving language students' strategic employment in a cyclical process. A systematic review, following PRISMA protocols, examines the intersection of AI and self-regulated language learning (SRLL) over 2000–2022. Findings highlight AI's evolving role, predominantly through algorithms and systems, aiming for micro and macro integration. Interactive AI has not fully engaged in two-way directions, despite a familiar process approach in reviewed studies. In the favored ESL/EFL research context, task-specific AI is utilized to encourage cyclical improvement with learner autonomy enhancement mainly among higher education students at intermediate level or above. Pedagogical values are possible when major SRL phases are fully practiced, even without highly autonomous AI. Future research is directed toward adaptive personalized technology by exploring the dynamic interplay between AI technologies and SRLL as educational practices under Education 4.0 principles.}
}
@article{AHMED20191,
title = {Computational intelligence based prediction of drilling rate of penetration: A comparative study},
journal = {Journal of Petroleum Science and Engineering},
volume = {172},
pages = {1-12},
year = {2019},
issn = {0920-4105},
doi = {https://doi.org/10.1016/j.petrol.2018.09.027},
url = {https://www.sciencedirect.com/science/article/pii/S0920410518307824},
author = {Omogbolahan S. Ahmed and Ahmed A. Adeniran and Ariffin Samsuri},
keywords = {ROP prediction, Neural network, Least square support vector regression, Specific energy, Drilling efficiency, Extreme learning machine},
abstract = {Application of artificial intelligence in the accurate prediction of the rate of penetration (ROP), an important measure of drilling performance, has lately gained significant interest in oil and gas well drilling operations. Consequently, several computational intelligence techniques (CITs) for the prediction of ROP have been explored in the literature. This study explores the predictive capabilities of four commonly used CITs in the prediction of ROP and experimentally compare their predictive performance. The CIT algorithm utilizes predictors which are easily accessible continuous drilling data that have physical but complex relationship with ROP based on hydro-mechanical specific energy ROP model. The four CITs compared are the artificial neural network (ANN), extreme learning machine, support vector Regression and least-square support vector regression (LS-SVR). Two experiments were carried out; the first experiment investigates the comparative performance of the CITs while the second investigates the effect of reduced number of predictors on the performance of the models. The results show that all the CITs perform within acceptable accuracy with testing root mean square error range (RMSE) of 18.27–28.84 and testing correlation coefficient (CC) range of 0.71–0.94. LS-SVR has the best predictive performance in terms of accuracy with RMSE of 18.27 and CC of 0.94 while ANN has the best testing execution time at 0.03 s. Also utilizing the specific energy concept in chosen drilling parameters to be included among the predictors shows improved performance with five drilling parameters showing an improvement of 3%–9% in RMSE for LS-SVR in the two well studied. The utilization of the specific energy concept in the selection of the predictors in this study has demonstrated that the easily accessible drilling parameters have immense value to provide acceptable performance in the development of ROP model with CITs.}
}
@article{DAVELAAR2018175,
title = {Mechanisms of Neurofeedback: A Computation-theoretic Approach},
journal = {Neuroscience},
volume = {378},
pages = {175-188},
year = {2018},
note = {Neurofeedback and Functional Enhancement: Mechanisms, Methodology, Behavioral and Clinical Applications},
issn = {0306-4522},
doi = {https://doi.org/10.1016/j.neuroscience.2017.05.052},
url = {https://www.sciencedirect.com/science/article/pii/S030645221730386X},
author = {Eddy J. Davelaar},
keywords = {neurofeedback, electroencephalography, computational neuroscience, computer model},
abstract = {Neurofeedback training is a form of brain training in which information about a neural measure is fed back to the trainee who is instructed to increase or decrease the value of that particular measure. This paper focuses on electroencephalography (EEG) neurofeedback in which the neural measures of interest are the brain oscillations. To date, the neural mechanisms that underlie successful neurofeedback training are still unexplained. Such an understanding would benefit researchers, funding agencies, clinicians, regulatory bodies, and insurance firms. Based on recent empirical work, an emerging theory couched firmly within computational neuroscience is proposed that advocates a critical role of the striatum in modulating EEG frequencies. The theory is implemented as a computer simulation of peak alpha upregulation, but in principle any frequency band at one or more electrode sites could be addressed. The simulation successfully learns to increase its peak alpha frequency and demonstrates the influence of threshold setting – the threshold that determines whether positive or negative feedback is provided. Analyses of the model suggest that neurofeedback can be likened to a search process that uses importance sampling to estimate the posterior probability distribution over striatal representational space, with each representation being associated with a distribution of values of the target EEG band. The model provides an important proof of concept to address pertinent methodological questions about how to understand and improve EEG neurofeedback success.}
}
@article{KAY20231697,
title = {Tasks and their role in visual neuroscience},
journal = {Neuron},
volume = {111},
number = {11},
pages = {1697-1713},
year = {2023},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2023.03.022},
url = {https://www.sciencedirect.com/science/article/pii/S0896627323002180},
author = {Kendrick Kay and Kathryn Bonnen and Rachel N. Denison and Mike J. Arcaro and David L. Barack},
keywords = {task, brain, behavior, visual cortex, information processing, modeling},
abstract = {Summary
Vision is widely used as a model system to gain insights into how sensory inputs are processed and interpreted by the brain. Historically, careful quantification and control of visual stimuli have served as the backbone of visual neuroscience. There has been less emphasis, however, on how an observer’s task influences the processing of sensory inputs. Motivated by diverse observations of task-dependent activity in the visual system, we propose a framework for thinking about tasks, their role in sensory processing, and how we might formally incorporate tasks into our models of vision.}
}
@article{CUADRA20161223,
title = {Computational intelligence in wave energy: Comprehensive review and case study},
journal = {Renewable and Sustainable Energy Reviews},
volume = {58},
pages = {1223-1246},
year = {2016},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2015.12.253},
url = {https://www.sciencedirect.com/science/article/pii/S1364032115016366},
author = {L. Cuadra and S. Salcedo-Sanz and J.C. Nieto-Borge and E. Alexandre and G. Rodríguez},
keywords = {Computational intelligence techniques, Wave energy, Renewable energy, Wave energy converters, Environmental impact},
abstract = {Wind-generated wave energy is a renewable energy source that exhibits a huge potential for sustainable growth. The design and deployment of wave energy converters at a given location require the prediction of the amount of available wave energy flux. This and other wave parameters can be estimated by means of Computational Intelligence techniques (Neural, Fuzzy, and Evolutionary Computation). This paper reviews those used in wave energy applications, both in the resource estimation and in the design and control of wave energy converters. In particular, most of the applications of Neural Computation techniques, considered here in a broad sense, focus on the prediction of a variety of wave energy parameters by means of Multilayer Perceptrons and, at a lesser extent, by Support Vector Machines, and Extreme Learning Machines. Fuzzy Computation is also applied to estimate wave parameters and control floating wave energy converter. Evolutionary Computation algorithms are used to estimate parameters and design wave energy collectors. We complete this paper with a case study that illustrates, for the first time to the best of our knowledge, the potential of hybridizing a Coral Reefs Optimization algorithm with an Extreme Learning Machine to tackle the problem of significant wave height reconstruction.}
}
@article{SAYHAN201714166,
title = {Computational investigation and comparison of hydrogen storage properties of B24N24 and Al24N24 nanocages},
journal = {International Journal of Hydrogen Energy},
volume = {42},
number = {20},
pages = {14166-14180},
year = {2017},
issn = {0360-3199},
doi = {https://doi.org/10.1016/j.ijhydene.2017.04.069},
url = {https://www.sciencedirect.com/science/article/pii/S0360319917314490},
author = {Sinan Sayhan and Armağan Kinal},
keywords = {Boron nitride nanocages, Aluminum nitride nanocages, Hyrdogen storage materials, BN, AlN, The DFT methods},
abstract = {In this study, hydrogen storage properties of the B24N24 and Al24N24 nanocages have been computationally investigated by the DFT method whose suitability was determined with a thorough methodological analysis. This analysis includes comparison of the performances of a number of DFT functionals against the CCSD(T) method for the determination of the best DFT method that is able to accurately model H2-BN and H2-AlN systems. The ɷB97X-D, B3LYP-D2, PBEPBE-D2, BHandH methods produced results close to that of the reference CCSD(T) method. Of all methods studied, ɷB97X-D, showing the best performance, is found to be the most appropriate DFT method for H2-B24N24 and Al24N24 systems including dispersive interactions between hydrogen and the host molecule. The ɷB97X-D calculations result in that H2 molecule make the tightest adsorptive bond with Al atom in Al24N24 having an adsorption energy of −0.116 eV, by forming much more stable complex than the H2-B24N24 one. This indicates that Al24N24 has better exohedral hydrogen storage properties. The calculations also revealed that H2 molecules cannot pass through hexagonal rings of B24N24 instead they chemisorb on the cage atoms by breaking BN bond while they can pass through hexagonal rings of Al24N24 without making any damage in the Al–N bond, leading the fact that the Al–N bond is stronger than the B–N bond. Moreover, endohedral addition of H2 molecules up to three can form thermodynamically stable nH2@Al24N24 complexes while endohedral hydrogen addition to B24N24 destabilizes the complexes. Thus, the Al24N24 nanocage is not only structurally more stable than B24N24 nanocage, but also it can accommodate more hydrogen molecules, so it is better candidate for both endohedrally and exohedrally hydrogen storage compared to B24N24.}
}
@article{NESI2024,
title = {Enactivism: A contemporary perspective of a reconceptualization of osteopathy},
journal = {Advances in Integrative Medicine},
year = {2024},
issn = {2212-9588},
doi = {https://doi.org/10.1016/j.aimed.2024.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S2212958824001186},
author = {Jacson Nesi and Michele Benites and Filipe Boeira Schedler},
keywords = {Enactivism, Osteopathy, Medical rationalities, Reconceptualization},
abstract = {Enactivism is a philosophical and scientific approach that emphasizes the role of the body and its interactions with the environment in shaping cognitive processes and subjective experiences. Meanwhile, osteopathy is a person-centered health care discipline, highlighting the structure-function interrelationship of the body and its selfregulation mechanisms. Both approaches value the body and the environment in health. Several authors have been discussing the urgent need for a reconceptualization of osteopathy and also suggesting integrate biological, psychological and social aspects. Thinking osteopathy as a Therapeutic Rationality, implies recognize its fundamental dimensions: Human Morphology, Vital Dynamics, Medical Doctrine, Diagnostic System and Therapeutic System, all integrated by a philosophical Cosmology, as the original term Medical rationality states, but also embrace a broader perspective allowing an individual and unique process of each person, reflecting the transformation of contemporary medicine to a person approach. Enactivism principles can serve as a basis for a reconceptualization of osteopathy, integrating environmental, psychological, social, and spiritual factors. Osteopathic concepts can probably be updated through the convergence between enactivism and osteopathy, promoting more meaningful and evidence-based clinical practice. Advancing in this direction requires a collaborative dialogue between researchers, health professionals and interested people, seeking an integrated understanding of the relationship between body, mind, environment and health.}
}
@article{GIOT2013788,
title = {Fast computation of the performance evaluation of biometric systems: Application to multibiometrics},
journal = {Future Generation Computer Systems},
volume = {29},
number = {3},
pages = {788-799},
year = {2013},
note = {Special Section: Recent Developments in High Performance Computing and Security},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2012.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X12000362},
author = {Romain Giot and Mohamad El-Abed and Christophe Rosenberger},
keywords = {Biometrics, Authentication, Error estimation, Access control},
abstract = {The performance evaluation of biometric systems is a crucial step when designing and evaluating such systems. The evaluation process uses the Equal Error Rate (EER) metric proposed by the International Organization for Standardization (ISO/IEC). The EER metric is a powerful metric which allows easily comparing and evaluating biometric systems. However, the computation time of the EER is, most of the time, very intensive. In this paper, we propose a fast method which computes an approximated value of the EER. We illustrate the benefit of the proposed method on two applications: the computing of non parametric confidence intervals and the use of genetic algorithms to compute the parameters of fusion functions. Experimental results show the superiority of the proposed EER approximation method in term of computing time, and the interest of its use to reduce the learning of parameters with genetic algorithms. The proposed method opens new perspectives for the development of secure multibiometrics systems by speeding up their computation time.}
}
@article{LORD2023490,
title = {The sustainability of the gig economy food delivery system (Deliveroo, UberEATS and Just-Eat): Histories and futures of rebound, lock-in and path dependency},
journal = {International Journal of Sustainable Transportation},
volume = {17},
number = {5},
pages = {490-502},
year = {2023},
issn = {1556-8318},
doi = {https://doi.org/10.1080/15568318.2022.2066583},
url = {https://www.sciencedirect.com/science/article/pii/S1556831822007018},
author = {Carolynne Lord and Oliver Bates and Adrian Friday and Fraser McLeod and Tom Cherrett and Antonio Martinez-Sykora and Andy Oakey},
keywords = {Gig economy couriers, path dependence, rebounds, sustainability, systems thinking},
abstract = {ABSTRACT
Online food delivery has transformed the last-mile of food and grocery delivery, with unnoticed yet often significant impacts upon the transport and logistics network. This new model of food delivery is not just increasing congestion in urban centers though, it is also changing the contours and qualities of those doing delivery—namely through gig economy work. This new system of food consumption and provision is rapidly gaining traction, but assessments around its current and future sustainability tend to hold separate the notions of social, environmental and economic sustainability—with few to date working to understand how these can interact, influence and be in conflict with one another. This paper seeks to work with this broader understanding of sustainability, whilst also foregrounding the perspectives of gig economy couriers who are often marginalized in such assessments of the online food delivery system. We make use of systems thinking and Campbell’s conflict model of sustainability to do this. In assessing the online food delivery in this way, we seek to not only provide a counternarrative to some of these previous assessments, but to also challenge those proposing the use of gig economy couriers as an environmentally sustainable logistics intervention in other areas of last-mile logistics to consider how this might impact the broader sustainability of their system, now and in the future.}
}

@article{SANKARANARAYANAN20151,
title = {Genome-based, mechanism-driven computational modeling of risks of ionizing radiation: The next frontier in genetic risk estimation?},
journal = {Mutation Research/Reviews in Mutation Research},
volume = {764},
pages = {1-15},
year = {2015},
issn = {1383-5742},
doi = {https://doi.org/10.1016/j.mrrev.2014.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S138357421400091X},
author = {K. Sankaranarayanan and H. Nikjoo},
keywords = {Radiation risk, DNA damage, DNA repair, Biophysical models},
abstract = {Research activity in the field of estimation of genetic risks of ionizing radiation to human populations started in the late 1940s and now appears to be passing through a plateau phase. This paper provides a background to the concepts, findings and methods of risk estimation that guided the field through the period of its growth to the beginning of the 21st century. It draws attention to several key facts: (a) thus far, genetic risk estimates have been made indirectly using mutation data collected in mouse radiation studies; (b) important uncertainties and unsolved problems remain, one notable example being that we still do not know the sensitivity of human female germ cells to radiation-induced mutations; and (c) the concept that dominated the field thus far, namely, that radiation exposures to germ cells can result in single gene diseases in the descendants of those exposed has been replaced by the concept that radiation exposure can cause DNA deletions, often involving more than one gene. Genetic risk estimation now encompasses work devoted to studies on DNA deletions induced in human germ cells, their expected frequencies, and phenotypes and associated clinical consequences in the progeny. We argue that the time is ripe to embark on a human genome-based, mechanism-driven, computational modeling of genetic risks of ionizing radiation, and we present a provisional framework for catalyzing research in the field in the 21st century.}
}
@incollection{DASILVASOARES202349,
title = {Chapter Three - Exploring the potential of eye tracking on personalized learning and real-time feedback in modern education},
editor = {Mariuche Gomides and Isabela Starling-Alves and Flávia H. Santos},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {282},
pages = {49-70},
year = {2023},
booktitle = {Brain and Maths in Ibero-America},
issn = {0079-6123},
doi = {https://doi.org/10.1016/bs.pbr.2023.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0079612323000936},
author = {Raimundo {da Silva Soares} and Amanda Yumi Ambriola Oku and Cândida da Silva Ferreira Barreto and João Ricardo Sato},
keywords = {Mathematics education, Eye tracking, Teaching practice, Student gaze},
abstract = {Eye tracking is one of the techniques used to investigate cognitive mechanisms involved in the school context, such as joint attention and visual perception. Eye tracker has portability, straightforward application, cost-effectiveness, and infant-friendly neuroimaging measures of cognitive processes such as attention, engagement, and learning. Furthermore, the ongoing software enhancements coupled with the implementation of artificial intelligence algorithms have improved the precision of collecting eye movement data and simplified the calibration process. These characteristics make it plausible to consider eye-tracking technology a promising tool to assist the teaching-learning process in school routines. However, eye tracking needs to be explored more as an educational instrument for real-time classroom activities and teachers' feedback. This perspective article briefly presents the fundamentals of the eye-tracking technique and four illustrative examples of employing this method in everyday school life. The first application shows how eye tracker information may contribute to teacher assessment of students' computational thinking in coding classes. In the second and third illustrations, we discuss the additional information provided by the eye-tracker to the teacher assessing the student's strategies to solve fraction problems and chart interpretation. The last illustration demonstrates the potential of eye tracking to provide Real-time feedback on learning difficulties/disabilities. Thus, we highlight the potential of the eye tracker as a complementary tool to promote personalized education and discuss future perspectives. In conclusion, we suggest that an eye-tracking system could be helpful by providing real-time student gaze leading to immediate teacher interventions and metacognition strategies.}
}
@article{ANDRADE2017111,
title = {Exact posterior computation in non-conjugate Gaussian location-scale parameters models},
journal = {Communications in Nonlinear Science and Numerical Simulation},
volume = {53},
pages = {111-129},
year = {2017},
issn = {1007-5704},
doi = {https://doi.org/10.1016/j.cnsns.2017.04.036},
url = {https://www.sciencedirect.com/science/article/pii/S100757041730151X},
author = {J.A.A. Andrade and P.N. Rathie},
keywords = {Bayesian computation, Exact posterior distribution, Non-conjugate models, Special functions, H-function},
abstract = {In Bayesian analysis the class of conjugate models allows to obtain exact posterior distributions, however this class quite restrictive in the sense that it involves only a few distributions. In fact, most of the practical applications involves non-conjugate models, thus approximate methods, such as the MCMC algorithms, are required. Although these methods can deal with quite complex structures, some practical problems can make their applications quite time demanding, for example, when we use heavy-tailed distributions, convergence may be difficult, also the Metropolis-Hastings algorithm can become very slow, in addition to the extra work inevitably required on choosing efficient candidate generator distributions. In this work, we draw attention to the special functions as a tools for Bayesian computation, we propose an alternative method for obtaining the posterior distribution in Gaussian non-conjugate models in an exact form. We use complex integration methods based on the H-function in order to obtain the posterior distribution and some of its posterior quantities in an explicit computable form. Two examples are provided in order to illustrate the theory.}
}
@article{HUANG2022209,
title = {A Framework for Collaborative Artificial Intelligence in Marketing},
journal = {Journal of Retailing},
volume = {98},
number = {2},
pages = {209-223},
year = {2022},
issn = {0022-4359},
doi = {https://doi.org/10.1016/j.jretai.2021.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0022435921000142},
author = {Ming-Hui Huang and Roland T. Rust},
keywords = {Artificial intelligence, Collaborative AI, Collaborative intelligence, Augmentation, Replacement},
abstract = {We develop a conceptual framework for collaborative artificial intelligence (AI) in marketing, providing systematic guidance for how human marketers and consumers can team up with AI, which has profound implications for retailing, which is the interface between marketers and consumers. Drawing from the multiple intelligences view that AI advances from mechanical, to thinking, to feeling intelligence (based on how difficult for AI to mimic human intelligences), the framework posits that collaboration between AI and HI (human marketers and consumers) can be achieved by 1) recognizing the respective strengths of AI and HI, 2) having lower-level AI augmenting higher-level HI, and 3) moving HI to a higher intelligence level when AI automates the lower level. Implications for marketers, consumers, and researchers are derived. Marketers should optimize the mix and timing of AI-HI marketing team, consumers should understand the complementarity between AI and HI strengths for informed consumption decisions, and researchers can investigate innovative approaches to and boundary conditions of collaborative intelligence.}
}
@article{RUBENSTEIN2022101030,
title = {Exploring creativity's complex relationship with learning in early elementary students},
journal = {Thinking Skills and Creativity},
volume = {44},
pages = {101030},
year = {2022},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2022.101030},
url = {https://www.sciencedirect.com/science/article/pii/S1871187122000335},
author = {Lisa DaVia Rubenstein and Jenna Thomas and W. Holmes Finch and Lisa M. Ridgley},
keywords = {Creativity, Learning, Early elementary, Academic achievement, Kindergarten},
abstract = {The purpose of this study was to examine the relationship between learning and creativity in early elementary students using both static and growth achievement scores in reading and mathematics. Participants were kindergarten and first grade students from the Midwestern United States. Initial correlations demonstrated significant positive relationships between students’ performance on the Torrance Test of Creative Thinking –Figural (TTCT-F) and static academic achievement scores in both reading and mathematics, but that same relationship did not exist with academic growth scores. Specifically, when academic growth was examined further using Generalized Additive Models (GAMs), a complex picture emerged, such that grade level (i.e., kindergarten v. first grade) and subscale type (e.g., Fluency v. Originality) influenced the significance and nature of the relationship (i.e., linear v. nonlinear). In general, as students increased in creativity performance, they demonstrated less academic growth. Future work should explore the underlying mechanisms explaining these relationships to better help students leverage their creative abilities for positive academic gains in the classroom setting.}
}
@article{YOUSIF201880,
title = {Fuzzy logic computational model for performance evaluation of Sudanese Universities and academic staff},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {30},
number = {1},
pages = {80-119},
year = {2018},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2016.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S1319157816300556},
author = {Mohamed Khalid Yousif and Adnan Shaout},
keywords = {Evaluation criteria, Performance evaluation, Sudanese universities, Survey design, Fuzzy computational model, Consistency checking},
abstract = {The excellence of a Sudanese universities and academic staff member can be effectively classified by systematic and objective design criteria, which participates in developing the learning outcomes in Sudan. In the first phase of this study, we reviewed the literatures, determined and defined the suitable quantitative and qualitative criteria and then designed & exploited pairwise comparison and evaluation forms through a survey to get experts opinions/preference on the evaluation criteria that are used to measure the universities and academic staff performance. This paper presents a fuzzy logic computational model based on this survey to measure and classify the performance of Sudanese universities and academic staff, which includes computation of criteria weights and overall evaluation of Sudanese universities and academic staff using AHP and TOPSIS techniques.}
}
@article{JIA2024101456,
title = {Memory backtracking strategy: An evolutionary updating mechanism for meta-heuristic algorithms},
journal = {Swarm and Evolutionary Computation},
volume = {84},
pages = {101456},
year = {2024},
issn = {2210-6502},
doi = {https://doi.org/10.1016/j.swevo.2023.101456},
url = {https://www.sciencedirect.com/science/article/pii/S2210650223002286},
author = {Heming Jia and Chenghao Lu and Zhikai Xing},
keywords = {Memory backtracking strategies, New evolutionary updating strategy, Meta-heuristic optimization algorithm},
abstract = {The search domain of meta-heuristic algorithms is always constantly changing, which make it difficult to adapt the diverse optimization issues. To overcome above issue, an evolutionary updating mechanism called Memory Backtracking Strategy (MBS) is proposed, which contains thinking stage, recall stage, and memory stage. Overall, the adoption of the MBS enhances the efficiency of MHSs by incorporating group memory, clue recall, and memory forgetting mechanisms. These strategies improve the algorithm's ability to explore the search space, optimize the search process, and escape local optima. MBS will be applied to three different types of MHS algorithms: evolutionary based (LSHADE_SPACMA), physical based (Stochastic Fractal Search, SFS), and biological based (Marine Predators Algorithmnm, MPA) to demonstrate the universality of MBS. In the experimental section including 57 engineering problems, algorithm complexity analysis, CEC2020 Friedman ranking, convergence curve, Wilcoxon statistical, and box plot. Among them, 21 algorithms participated in the Friedman experiment, including MBS_LSHADE_SPACMA ranked first, LSHADE_SPACMA ranked second, MBS_MPA ranked 6th, MPA ranked 8th, MBS_SFS ranked 9th and SFS ranked 12th. Combined with the analysis of "MBS testing analysis" and the experimental results of engineering problems, it has proven that MBS has universality and good ability to improve optimization algorithm performance. The source codes of the proposed MBS (MBS_MPA) can be accessed by https://github.com/luchenghao2022/Memory-Backtracking-Strategy}
}
@article{ARJMANDI202350,
title = {Embedding computer programming into a chemical engineering course: The impact on experiential learning},
journal = {Education for Chemical Engineers},
volume = {43},
pages = {50-57},
year = {2023},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2023.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S1749772823000064},
author = {Mohammadreza Arjmandi and Meng Wai Woo and Cody Mankelow and Thomas Loho and Kaveh Shahbaz and Amar Auckaili and Ashvin Thambyah},
keywords = {Engineering education, Qualitative study, Programming with MATLAB, Problem-based learning, Student experience},
abstract = {The need for autonomous engineering graduates who demonstrate hands-on skills has increased in the industry. Computer programming helps engineering students solve real-world problems systematically and accurately by applying governing physical and mathematical models into a format that a computer can read and execute. This study describes the pedagogical approach of incorporating programming workshops and assessments into a second-year chemical engineering course. The impact of this intervention on experiential learning amongst the students was then evaluated by analysing the feedback provided by voluntary participants during several focus group sessions. The feedback gave further insight into teaching pedagogy with respect to Kolb's experiential learning cycle. It was found the programming background of an individual clearly affects the phase of the learning cycle they predominantly experience during the workshops. Furthermore, programming background affected an individual's critical thinking while approaching an engineering problem. Constructive feedback provided by the student participants offered an invaluable opportunity for the teaching team to reflect on what went well and the areas for improvement in future iterations. The findings of this study can advance knowledge around design and implementation of a programming module within an engineering course.}
}
@article{KONDINSKI20226397,
title = {Composition-driven archetype dynamics in polyoxovanadates††Electronic supplementary information (ESI) available. CCDC 2128841 and 2130016. For ESI and crystallographic data in CIF or other electronic format see https://doi.org/10.1039/d2sc01004f},
journal = {Chemical Science},
volume = {13},
number = {21},
pages = {6397-6412},
year = {2022},
issn = {2041-6520},
doi = {https://doi.org/10.1039/d2sc01004f},
url = {https://www.sciencedirect.com/science/article/pii/S2041652023011690},
author = {Aleksandar Kondinski and Maren Rasmussen and Sebastian Mangelsen and Nicole Pienack and Viktor Simjanoski and Christian Näther and Daniel L. Stares and Christoph A. Schalley and Wolfgang Bensch},
abstract = {ABSTRACT
Molecular metal oxides often adopt common structural frameworks (i.e. archetypes), many of them boasting impressive structural robustness and stability. However, the ability to adapt and to undergo transformations between different structural archetypes is a desirable material design feature offering applicability in different environments. Using systems thinking approach that integrates synthetic, analytical and computational techniques, we explore the transformations governing the chemistry of polyoxovanadates (POVs) constructed of arsenate and vanadate building units. The water-soluble salt of the low nuclearity polyanion [V6As8O26]4− can be effectively used for the synthesis of the larger spherical (i.e. kegginoidal) mixed-valent [V12As8O40]4− precipitate, while the novel [V10As12O40]8− POVs having tubular cyclic structures are another, well soluble product. Surprisingly, in contrast to the common observation that high-nuclearity polyoxometalate (POM) clusters are fragmented to form smaller moieties in solution, the low nuclearity [V6As8O26]4− anion is in situ transformed into the higher nuclearity cluster anions. The obtained products support a conceptually new model that is outlined in this article and that describes a continuous evolution between spherical and cyclic POV assemblies. This new model represents a milestone on the way to rational and designable POV self-assemblies.}
}
@article{VALLEETOURANGEAU2020100812,
title = {Mapping systemic resources in problem solving},
journal = {New Ideas in Psychology},
volume = {59},
pages = {100812},
year = {2020},
issn = {0732-118X},
doi = {https://doi.org/10.1016/j.newideapsych.2020.100812},
url = {https://www.sciencedirect.com/science/article/pii/S0732118X17300272},
author = {Frédéric Vallée-Tourangeau and Gaëlle Vallée-Tourangeau},
abstract = {In the wild, thinking demonstrably uses interactive processes that draw on a wide range of external resources, spanning multiple time scales. As Malafouris (2015, p. 361) puts it, “cognition is not a within property; it is an in-between process”. Interactive processes configure extended systems within which each human agent is embedded. Yet much research on higher cognition, such as problem solving, reflects an implicit but deep commitment to methodological individualism that casts the agent as the ontological locus of cognition, and largely dictates the nature of the research enterprise. Thus, tasks to measure capacities and gauge reasoning performance are designed in a manner that reduces or eliminates the possibility of interacting with the problem presentation; if thinking takes place in the head, there is no need or reason to engineer procedures wherein agents can interact with the task's physical constituents. Conversely, a methodological interactivism forces one to acknowledge the participative yet not all-encompassing role of capacities such as working memory and thinking dispositions; it also encourages the granular mapping of the cognitive ecosystem from which new ideas emerge. To adopt an interactivist perspective is thus to focus on the cognitive resources of the extended system inviting a careful description of how these resources are dynamically configured over time and space to promote the development of new ideas in problem solving. In turn, a systemic perspective encourages the development of interventions that promote cognitive performance through the optimisation of systemic rather than individualist cognitive resources.}
}
@article{CHEN20121,
title = {Varieties of agents in agent-based computational economics: A historical and an interdisciplinary perspective},
journal = {Journal of Economic Dynamics and Control},
volume = {36},
number = {1},
pages = {1-25},
year = {2012},
issn = {0165-1889},
doi = {https://doi.org/10.1016/j.jedc.2011.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0165188911001692},
author = {Shu-Heng Chen},
keywords = {Cellular automata, Autonomous agents, Tournaments, Genetic algorithms, Genetic programming, Cognitive capacity},
abstract = {In this paper, we trace four origins of agent-based computational economics (ACE), namely, the markets origin, the cellular-automata origin, the tournaments origin, and the experiments origin. Along with this trace, we examine how these origins have motivated different concepts and designs of agents in ACE, which starts from the early work on simple programmed agents, randomly behaving agents, zero-intelligence agents, human-written programmed agents, autonomous agents, and empirically calibrated agents, and extends to the newly developing cognitive agents, psychological agents, and culturally sensitive agents. The review also shows that the intellectual ideas underlying these varieties of agents cross several disciplines, which may be considered as a part of a general attempt to study humans (and their behavior) with an integrated interdisciplinary foundation.}
}
@article{SILAGHI20121303,
title = {A time-constrained SLA negotiation strategy in competitive computational grids},
journal = {Future Generation Computer Systems},
volume = {28},
number = {8},
pages = {1303-1315},
year = {2012},
note = {Including Special sections SS: Trusting Software Behavior and SS: Economics of Computing Services},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2011.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X11002251},
author = {Gheorghe Cosmin Silaghi and Liviu Dan Şerban and Cristian Marius Litan},
keywords = {SLA negotiation, Intelligent strategies, Bayesian learning, Time constraints},
abstract = {Automated and intelligent negotiation solutions for reaching service level agreements (SLA) represent a hot research topic in computational grids. Previous work regarding SLA negotiation in grids focuses on devising bargaining models where service providers and consumers can meet and exchange SLA offers and counteroffers. Recent developments in agent research introduce strategies based on opponent learning for contract negotiation. In this paper we design a generic framework for strategical negotiation of service level values under time constraints and exemplify the usage of our framework by extending the Bayesian learning agent to cope with the limited duration of a negotiation session. We prove that opponent learning strategies are worth for consideration in open competitive computational grids, leading towards an optimal allocation of resources and fair satisfaction of participants.}
}
@article{LOHSE2012236,
title = {Thinking about muscles: The neuromuscular effects of attentional focus on accuracy and fatigue},
journal = {Acta Psychologica},
volume = {140},
number = {3},
pages = {236-245},
year = {2012},
issn = {0001-6918},
doi = {https://doi.org/10.1016/j.actpsy.2012.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S0001691812000807},
author = {Keith R. Lohse and David E. Sherwood},
keywords = {Attention, Force production, Motor control, Fatigue},
abstract = {Although the effects of attention on movement execution are well documented behaviorally, much less research has been done on the neurophysiological changes that underlie attentional focus effects. This study presents two experiments exploring effects of attention during an isometric plantar-flexion task using surface electromyography (sEMG). Participants' attention was directed either externally (towards the force plate they were pushing against) or internally (towards their own leg, specifically the agonist muscle). Experiment 1 tested the effects of attention on accuracy and efficiency of force produced at three target forces (30, 60, and 100% of the maximum voluntary contraction; MVC). An internal focus of attention reduced the accuracy of force being produced and increased cocontraction of the antagonist muscle. Error on a given trial was positively correlated with the magnitude of cocontraction on that trial. Experiment 2 tested the effects of attention on muscular fatigue at 30, 60 and 100%MVC. An internal focus of attention led to less efficient intermuscular coordination, especially early in the contraction. These results suggest that an internal focus of attention disrupts efficient motor control in force production resulting in increased cocontraction, which potentially explains other neuromechanical findings (e.g. reduced functional variability with an internal focus).}
}
@incollection{DIBBLE20061511,
title = {Chapter 31 Computational Laboratories for Spatial Agent-Based Models},
editor = {L. Tesfatsion and K.L. Judd},
series = {Handbook of Computational Economics},
publisher = {Elsevier},
volume = {2},
pages = {1511-1548},
year = {2006},
issn = {1574-0021},
doi = {https://doi.org/10.1016/S1574-0021(05)02031-9},
url = {https://www.sciencedirect.com/science/article/pii/S1574002105020319},
author = {Catherine Dibble},
keywords = {agent-based simulation, computational laboratory, computational social science, computational economics, spatial economics, spatial social science, spatial networks, small-world networks, scale-free networks, synthetic landscape, inference},
abstract = {An agent-based model is a virtual world comprising distributed heterogeneous agents who interact over time. In a spatial agent-based model the agents are situated in a spatial environment and are typically assumed to be able to move in various ways across this environment. Some kinds of social or organizational systems may also be modeled as spatial environments, where agents move from one group or department to another and where communications or mobility among groups may be structured according to implicit or explicit channels or transactions costs. This chapter focuses on the potential usefulness of computational laboratories for spatial agent-based modeling. Speaking broadly, a computational laboratory is any computational framework permitting the exploration of the behaviors of complex systems through systematic and replicable simulation experiments. By that definition, most of the research discussed in this handbook would be considered to be work with computational laboratories. A narrower definition of computational laboratory (or comp lab for short) refers specifically to specialized software tools to support the full range of agent-based modeling and complementary tasks. These tasks include model development, model evaluation through controlled experimentation, and both the descriptive and normative analysis of model outcomes. The objective of this chapter is to explore how comp lab tools and activities facilitate the systematic exploration of spatial agent-based models embodying complex social processes critical for social welfare. Examples include the spatial and temporal coordination of human activities, the diffusion of new ideas or of infectious diseases, and the emergence and ecological dynamics of innovative ideas or of deadly new diseases.}
}
@article{WELLS1998269,
title = {Turing's analysis of computation and theories of cognitive architecture},
journal = {Cognitive Science},
volume = {22},
number = {3},
pages = {269-294},
year = {1998},
issn = {0364-0213},
doi = {https://doi.org/10.1016/S0364-0213(99)80041-X},
url = {https://www.sciencedirect.com/science/article/pii/S036402139980041X},
author = {A.J. Wells},
abstract = {Turing's analysis of computation is a fundamental part of the background of cognitive science. In this paper it is argued that a re-interpretation of Turing's work is required to underpin theorizing about cognitive architecture. It is claimed that the symbol systems view of the mind, which is the conventional way of understanding how Turing's work impacts on cognitive science, is deeply flawed. There is an alternative interpretation that is more faithful to Turing's original insights, avoids the criticisms made of the symbol systems approach and is compatible with the growing interest in agent-environment interaction. It is argued that this interpretation should form the basis for theories of cognitive architecture.}
}
@article{GOLDSMITH198815,
title = {Idiots savants — Thinking about remembering: A response to White},
journal = {New Ideas in Psychology},
volume = {6},
number = {1},
pages = {15-23},
year = {1988},
issn = {0732-118X},
doi = {https://doi.org/10.1016/0732-118X(88)90020-7},
url = {https://www.sciencedirect.com/science/article/pii/0732118X88900207},
author = {Lynn T. Goldsmith and David Henry Feldman}
}
@article{ZHANG2024109147,
title = {Three-phase multi-criteria ranking considering three-way decision framework and criterion fuzzy concept},
journal = {International Journal of Approximate Reasoning},
volume = {168},
pages = {109147},
year = {2024},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2024.109147},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X24000343},
author = {Kai Zhang and Jianhua Dai},
keywords = {Three-way decision, Criterion fuzzy concept, Three-phase ranking, Multi-criteria ranking},
abstract = {The criterion fuzzy concept refers to a fuzzy set that represents the decision-maker's subjective preference for each criterion within the universe of criteria. Addressing the challenge of ranking all alternatives based on a given criterion fuzzy concept is a novel research direction in the field of fuzzy multi-criteria ranking issues. This paper proposes a three-phase approach for multi-criteria ranking in fuzzy environments, which combines the criterion fuzzy concept and three-way decision thinking. The proposed approach not only analyzes the decision-making characteristics of all alternatives but also facilitates their ranking. During the first phase, a qualitative classification method based on the criterion fuzzy concept and ideal solutions is defined, which divides all alternatives into three independent decision sub-regions. During the second phase, by analyzing the priority relationships among the alternatives within every sub-region, three local ranking rules for alternatives are proposed to determine the ranking of alternatives in each classification region. During the third phase, the semantic relations among three classification regions are considered to give an overall ranking of all alternatives. Finally, combined with two existing quantitative ranking indicators, multiple data sets are employed to verify the feasibility and superiority of the proposed three-phase multi-criteria ranking approach.}
}
@article{SIMMONS2012311,
title = {Bats use a neuronally implemented computational acoustic model to form sonar images},
journal = {Current Opinion in Neurobiology},
volume = {22},
number = {2},
pages = {311-319},
year = {2012},
note = {Neuroethology},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2012.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S0959438812000293},
author = {James A Simmons},
abstract = {This paper reexamines neurophysiological results from echolocating big brown bats to propose a new perspective on FM biosonar processing in the auditory system. Individual auditory neurons are frequency-tuned and respond to brief, 2–10ms FM sweeps with an average of one spike per sound to register their tuned frequencies, to detect echo arrival, or to register a local null in the echo spectrum. When initiated by the broadcast, these responses comprise a cascade of single spikes distributed across time in neurons tuned to different frequencies that persists for 30–50ms, long after the sound has ended. Their progress mirrors the broadcast's propagation away from the bat and the return of echoes for distances out to 5–8m. Each returning echo evokes a similar pattern of single spikes that coincide with ongoing responses to the broadcast to register the target's distance and shape. The hypothesis advanced here is that this flow of responses over time acts as an internal model of sonar acoustics that the bat executes using neuronal computations distributed across many neurons to accumulate a dynamic image of the bat's surroundings.}
}
@article{OXMAN1999105,
title = {Educating the designerly thinker},
journal = {Design Studies},
volume = {20},
number = {2},
pages = {105-122},
year = {1999},
issn = {0142-694X},
doi = {https://doi.org/10.1016/S0142-694X(98)00029-5},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X98000295},
author = {Rivka Oxman},
keywords = {design education, design cognition, design knowledge, conceptual design, computational models},
abstract = {This paper presents a hypothesis about design education that is framed within and derived from cognitive theories of learning. The relevance of design thinking and cognitive approaches to the development of pedagogical approaches in design education is presented and discussed. A conceptual model for design education that emphasizes the acquisition of explicit knowledge of design is proposed. The acquisition of knowledge is achieved through the explication of cognitive structures and strategies of design thinking. The explication process is constructed by exploiting a representational formalism, and a computational medium which supports both the learning process as well as the potential re-use of this knowledge. Finally, an argument is presented that the measure of learning, generally equated with the evaluation of the product of designing, can instead be based upon evaluating learning increments of acquired knowledge.}
}
@article{SCHULZ2024210,
title = {Political reinforcement learners},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {3},
pages = {210-222},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2023.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S1364661323002875},
author = {Lion Schulz and Rahul Bhui},
keywords = {computational models, reinforcement learning, political psychology},
abstract = {Politics can seem home to the most calculating and yet least rational elements of humanity. How might we systematically characterize this spectrum of political cognition? Here, we propose reinforcement learning (RL) as a unified framework to dissect the political mind. RL describes how agents algorithmically navigate complex and uncertain domains like politics. Through this computational lens, we outline three routes to political differences, stemming from variability in agents’ conceptions of a problem, the cognitive operations applied to solve the problem, or the backdrop of information available from the environment. A computational vantage on maladies of the political mind offers enhanced precision in assessing their causes, consequences, and cures.}
}
@article{GOLIGHER20241067,
title = {Bayesian statistics for clinical research},
journal = {The Lancet},
volume = {404},
number = {10457},
pages = {1067-1076},
year = {2024},
issn = {0140-6736},
doi = {https://doi.org/10.1016/S0140-6736(24)01295-9},
url = {https://www.sciencedirect.com/science/article/pii/S0140673624012959},
author = {Ewan C Goligher and Anna Heath and Michael O Harhay},
abstract = {Summary
Frequentist and Bayesian statistics represent two differing paradigms for the analysis of data. Frequentism became the dominant mode of statistical thinking in medical practice during the 20th century. The advent of modern computing has made Bayesian analysis increasingly accessible, enabling growing use of Bayesian methods in a range of disciplines, including medical research. Rather than conceiving of probability as the expected frequency of an event (purported to be measurable and objective), Bayesian thinking conceives of probability as a measure of strength of belief (an explicitly subjective concept). Bayesian analysis combines previous information (represented by a mathematical probability distribution, the prior) with information from the study (the likelihood function) to generate an updated probability distribution (the posterior) representing the information available for clinical decision making. Owing to its fundamentally different conception of probability, Bayesian statistics offers an intuitive, flexible, and informative approach that facilitates the design, analysis, and interpretation of clinical trials. In this Review, we provide a brief account of the philosophical and methodological differences between Bayesian and frequentist approaches and survey the use of Bayesian methods for the design and analysis of clinical research.}
}
@article{VAZQUEZ2017550,
title = {Price computation in electricity auctions with complex rules: An analysis of investment signals},
journal = {Energy Policy},
volume = {105},
pages = {550-561},
year = {2017},
issn = {0301-4215},
doi = {https://doi.org/10.1016/j.enpol.2017.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0301421517300770},
author = {Carlos Vazquez and Michelle Hallack and Miguel Vazquez},
keywords = {Electricity auctions, Investment signals, Side payments, Integer decisions, Marginal cost},
abstract = {This paper discusses the problem of defining marginal costs when integer variables are present, in the context of short-term power auctions. Most of the proposals for price computation existing in the literature are concerned with short-term competitive equilibrium (generators should not be willing to change the dispatch assigned to them by the auctioneer), which implies operational-cost recovery for all of the generators accepted in the auction. However, this is in general not enough to choose between the different pricing schemes. We propose to include an additional criterion in order to discriminate among different pricing schemes: prices have to be also signals for generation expansion. Using this condition, we arrive to a single solution to the problem of defining prices, where they are computed as the shadow prices of the balance equations in a linear version of the unit commitment problem. Importantly, not every linearization of the unit commitment is valid; we develop the conditions for this linear model to provide adequate investment signals. Compared to other proposals in the literature, our results provide a strong motivation for the pricing scheme and a simple method for price computation.}
}
@article{TIBURU201836,
title = {Investigating the Conformation of S100β Protein Under Physiological Parameters Using Computational Modeling: A Clue for Rational Drug Design},
journal = {The Open Biomedical Engineering Journal},
volume = {12},
pages = {36-50},
year = {2018},
issn = {1874-1207},
doi = {https://doi.org/10.2174/1874120701812010036},
url = {https://www.sciencedirect.com/science/article/pii/S1874120718000036},
author = {Elvis K. Tiburu and Ibrahim Issah and Mabel Darko and Robert E. Armah-Sekum and Stephen O. A. Gyampo and Nadia K. Amoateng and Samuel K. Kwofie and Gordon Awandare},
keywords = {S100β Protein, Molecular Dynamics, Cofactors, Energy Minimization, Physiological Parameters, Alzheimer's},
abstract = {Background
Physiochemical factors such as temperature, pH and cofactors are well known parameters that confer conformational changes in a protein structure. With S100β protein being a metal binding brain-specific receptor for both extracellular and intracellular functions, a change in conformation due to the above-mentioned factors, can compromise their cellular functions and therefore result in several pathological conditions such as Alzheimer’s disease, Ischemic stroke, as well as Myocardial Infarction.
Objective
The studies conducted sought to elucidate the effect of these physiological factors on the conformational dynamics of S100β protein using computational modeling approaches.
Method
Temperature-dependent and protein-cofactor complexes molecular dynamics simulations were conducted by varying the temperature from 100 to 400K using GROMACS 5.0.3. Additionally, the conformational dynamics of the protein was studied by varying the pH at 5.0, 7.4 and 9.0 using Ambertools17. This was done by preparing the protein molecule, solvating and minimizing its energy level as well as heating it to the required temperature, equilibrating and simulating under desired conditions (NVT and NPT ensembles).
Results
The results show that the protein misfolds as a function of increasing temperature with alpha helical content at 100K and 400K being 57.8% and 43.3%, respectively. However, the binding sites of the protein were not appreciably affected by temperature variations. The protein displayed high conformational instability in acidic medium (pH ~5.0). The binding sites of Ca2+, Mg2+ and Zn2+ were identified and each exhibited different groupings of the secondary structural elements (binding motifs). The secondary structure analysis revealed different conformational changes with the characteristic appearance of two beta hairpins in the presence of Zn2+and Mg2+.
Conclusion
High temperatures, different cofactors and acidic pH confer conformational changes to the S100β structure and these results may indicate the design of novel drugs against the protein.}
}
@article{SAHADEVAN2025103141,
title = {Knowledge augmented generalizer specializer: A framework for early stage design exploration},
journal = {Advanced Engineering Informatics},
volume = {65},
pages = {103141},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103141},
url = {https://www.sciencedirect.com/science/article/pii/S1474034625000345},
author = {Vijayalaxmi Sahadevan and Rohin Joshi and Kane Borg and Vishal Singh and Abhishek Raj Singh and Bilal Muhammed and Soban Babu Beemaraj and Amol Joshi},
abstract = {In non-routine engineering design projects, the design outcome is determined by how the problem is formulated and represented in the early conceptual stage. The problem representation comprises schemas, ontologies, variables, and parameters relevant to the given problem class. Despite the critical role of early conceptual decisions in shaping the eventual design outcome, most of the computational support and automation are focused on the latter stages of parametric modelling, problem-solving, and optimization. There is inadequate support for aiding and automating problem formulation, variable and parameter identification and representation, and early-stage conceptual decisions. Therefore, this paper presents an innovative, transparent, and explainable method employing semantic reasoning to automate the step-by-step conceptual design generation process, including problem formulation, identification and representation of the variables and parameters and their dependencies. The method is realized through a novel framework called Knowledge Augmented Generalizer Specializer (KAGS). KAGS employs the Function-Behavior-Structure (FBS) ontology and the Graph-of-Thought (GoT) mechanism to enable automated reasoning with a Large Language Model (LLM). The workflow comprises various stages: problem breakdown, design prototype creation, assessment, and prototype merging. The framework is implemented and tested on a Subsea Layout (SSL) planning problem, a special class of infrastructure planning projects in deep-sea oil and gas production systems. The experimentations with KAGS demonstrate its capacity to support problem formulation, hierarchical decomposition, and solution generation. The research also provides new insights into the FBS framework and meta-level reasoning in early design stages.}
}
@article{KALPOKIENE2023102197,
title = {Creative encounters of a posthuman kind – anthropocentric law, artificial intelligence, and art},
journal = {Technology in Society},
volume = {72},
pages = {102197},
year = {2023},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2023.102197},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X23000027},
author = {Julija Kalpokiene and Ignas Kalpokas},
keywords = {Anthropocentrism, Artificial intelligence, Creativity, Copyright},
abstract = {Artificial Intelligence (AI) is becoming an increasingly transformative force in human life. Crucially, its impact is already extending beyond automation of routine tasks and encroaching on creativity – a domain once seen as exclusively human. Hence, this article first surveys the discriminatory and exploitative underpinnings of the anthropocentric thinking that lies beyond attempts at sidelining the creative capacities of AI. Next, four different approaches to creativity and art are analyzed, ultimately conceptualizing art-ness as externally ascribed. Ultimately, the article moves to one way of such ascription – copyrightability – demonstrating the anthropocentric thinking behind attempts to both deny and award copyright protection to AI-generated content. Moreover, it transpires that human authors are under threat whichever of such strategies ends up dominant.}
}
@article{EGRINAGY2008135,
title = {Algebraic properties of automata associated to Petri nets and applications to computation in biological systems},
journal = {Biosystems},
volume = {94},
number = {1},
pages = {135-144},
year = {2008},
note = {Seventh International Workshop on Information Processing in Cells and Tissues},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2008.05.019},
url = {https://www.sciencedirect.com/science/article/pii/S0303264708001366},
author = {Attila Egri-Nagy and Chrystopher L. Nehaniv},
keywords = {Algebraic automata theory, Petri nets, Krohn-Rhodes theorem, Algebraic biology},
abstract = {Biochemical and genetic regulatory networks are often modeled by Petri nets. We study the algebraic structure of the computations carried out by Petri nets from the viewpoint of algebraic automata theory. Petri nets comprise a formalized graphical modeling language, often used to describe computation occurring within biochemical and genetic regulatory networks, but the semantics may be interpreted in different ways in the realm of automata. Therefore, there are several different ways to turn a Petri net into a state-transition automaton. Here, we systematically investigate different conversion methods and describe cases where they may yield radically different algebraic structures. We focus on the existence of group components of the corresponding transformation semigroups, as these reflect symmetries of the computation occurring within the biological system under study. Results are illustrated by applications to the Petri net modelling of intermediary metabolism. Petri nets with inhibition are shown to be computationally rich, regardless of the particular interpretation method. Along these lines we provide a mathematical argument suggesting a reason for the apparent all-pervasiveness of inhibitory connections in living systems.}
}
@article{KENNEDY198538,
title = {Thinking of opening your own business? Be prepared!},
journal = {Business Horizons},
volume = {28},
number = {5},
pages = {38-42},
year = {1985},
issn = {0007-6813},
doi = {https://doi.org/10.1016/0007-6813(85)90066-7},
url = {https://www.sciencedirect.com/science/article/pii/0007681385900667},
author = {Carson R. Kennedy},
abstract = {The good news is that new businesses are booming. The bad news is that many are going bust. Careful preparation prior to opening your own business is the best way to forestall failure.}
}
@incollection{MOLE2022367,
title = {Executive/Cognitive Control},
editor = {Sergio {Della Sala}},
booktitle = {Encyclopedia of Behavioral Neuroscience, 2nd edition (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {367-376},
year = {2022},
isbn = {978-0-12-821636-1},
doi = {https://doi.org/10.1016/B978-0-12-819641-0.00111-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128196410001110},
author = {Joseph Mole and Lisa Cipolotti},
keywords = {Frontal lobes, Active thought, Executive functioning, Fluid intelligence, Language, Focal lesions, Neuropsychology, Supervisory system, Reasoning, Lateralization of function},
abstract = {The capacity for active thought is arguably one of humanity's defining features. The frontal lobes are critically involved in active thinking. In this article we will consider what can be learned from the effects of frontal lobe lesions about: (1) the relationship between active thought and intelligence, (2) whether active thought can occur without language, and (3) the processes involved in active thinking. The evidence reviewed reveals that different forms of active thought and their essential pre-requisites can be fractionated and appear to be underpinned by different frontal areas. Hence, active thinking may be achieved by distinct, interacting cognitive processes.}
}
@article{BATISTA2003189,
title = {A Computational Basis to Object?},
journal = {Neuron},
volume = {37},
number = {2},
pages = {189-190},
year = {2003},
issn = {0896-6273},
doi = {https://doi.org/10.1016/S0896-6273(03)00029-1},
url = {https://www.sciencedirect.com/science/article/pii/S0896627303000291},
author = {Aaron P. Batista},
abstract = {To use an object, we must be able to perceive the spatial relationship between the object's parts. The accepted view of how the brain coherently encodes an object is that some neurons in the frontal cortex employ an object-centered coordinate frame. A new computational model challenges this view, using the rich conceptual framework of neural basis functions.}
}
@article{MOORE202542,
title = {Considerations for using participatory systems modeling as a tool for implementation mapping in chronic disease prevention},
journal = {Annals of Epidemiology},
volume = {101},
pages = {42-51},
year = {2025},
issn = {1047-2797},
doi = {https://doi.org/10.1016/j.annepidem.2024.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S1047279724002758},
author = {Travis R. Moore and Erin Hennessy and Yuilyn Chang Chusan and Laura Ellen Ashcraft and Christina D. Economos},
keywords = {Implementation science, Implementation mapping, Community-engaged research, Systems thinking, Epidemiology, Systems science},
abstract = {Effective chronic disease prevention requires a systems approach to the design, implementation, and refinement of interventions that account for the complexity and interdependence of factors influencing health outcomes. This paper proposes the Participatory Implementation Systems Mapping (PISM) process, which combines participatory systems modeling with implementation strategy development to enhance intervention design and implementation planning. PISM leverages the collaborative efforts of researchers and community partners to analyze complex health systems, identify key determinants, and develop tailored interventions and strategies that are both adaptive and contextually relevant. The phases of the PISM process include strategize, innovate, operationalize, and assess. We describe and demonstrate how each phase contributes to the overall goal of effective and sustainable intervention implementation. We also address the challenges of data availability, model complexity, and resource constraints. We offer solutions such as innovative data collection methods and participatory model development to enhance the robustness and applicability of systems models. Through a case study on the development of a chronic disease prevention intervention, the paper illustrates the practical application of PISM and highlights its potential to guide epidemiologists and implementation scientists in developing interventions that are responsive to the complexities of real-world health systems. The conclusion calls for further research to refine participatory systems modeling techniques, overcome existing challenges in data availability, and expand the use of PISM in diverse public health contexts.}
}
@article{VIGNONCLEMENTEL20103,
title = {A primer on computational simulation in congenital heart disease for the clinician},
journal = {Progress in Pediatric Cardiology},
volume = {30},
number = {1},
pages = {3-13},
year = {2010},
note = {Proceedings of the 1st International Conference on Computational Simulation in Congenital Heart Disease},
issn = {1058-9813},
doi = {https://doi.org/10.1016/j.ppedcard.2010.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S1058981310000767},
author = {Irene E. Vignon-Clementel and Alison L. Marsden and Jeffrey A. Feinstein},
keywords = {Hemodynamics, Computer modeling, Boundary conditions, Clinical data, Congenital heart disease},
abstract = {Interest in the application of engineering methods to problems in congenital heart disease has gained increased popularity over the past decade. The use of computational simulation to examine common clinical problems including single ventricle physiology and the associated surgical approaches, the effects of pacemaker implantation on vascular occlusion, or delineation of the biomechanical effects of implanted medical devices is now routinely appearing in clinical journals within all pediatric cardiovascular subspecialties. In practice, such collaboration can only work if both communities understand each other's methods and their limitations. This paper is intended to facilitate this communication by presenting in the context of congenital heart disease (CHD) the main steps involved in performing computational simulation—from the selection of an appropriate clinical question/problem to understanding the computational results, and all of the “black boxes” in between. We examine the current state of the art and areas in need of continued development. For example, medical image-based model-building software has been developed based on numerous different methods. However, none of them can be used to construct a model with a simple “click of a button.” The creation of a faithful, representative anatomic model, especially in pediatric subjects, often requires skilled manual intervention. In addition, information from a second imaging modality is often required to facilitate this process. We describe the technical aspects of model building, provide a definition of some of the most commonly used terms and techniques (e.g. meshes, mesh convergence, Navier-Stokes equations, and boundary conditions), and the assumptions used in running the simulations. Particular attention is paid to the assignment of boundary conditions as this point is of critical importance in the current areas of research within the realm of congenital heart disease. Finally, examples are provided demonstrating how computer simulations can provide an opportunity to “acquire” data currently unobtainable by other modalities, with essentially no risk to patients. To illustrate these points, novel simulation examples of virtual Fontan conversion (from preoperative data to predicted postoperative state) and outcomes of different surgical designs are presented. The need for validation of the currently employed techniques and predicted results are required and the methods remain in their infancy. While the daily application of these technologies to patient-specific clinical scenarios likely remains years away, the ever increasing interest in this area among both clinicians and engineers makes its eventual use far more likely than ever before and, some could argue, only a matter of [computing] time.}
}
@article{JOHNSON20241037,
title = {Minds and markets as complex systems: an emerging approach to cognitive economics},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {11},
pages = {1037-1050},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S1364661324001748},
author = {Samuel G.B. Johnson and Patrick R. Schotanus and J.A. Scott Kelso},
keywords = {decision-making, behavioral economics, narratives, agent-based models, extended mind, Coordination Dynamics},
abstract = {Cognitive economics is an emerging interdisciplinary field that uses the tools of cognitive science to study economic and social decision-making. Although most strains of cognitive economics share commitments to bridging levels of analysis (cognitive, behavioral, and systems) and embracing interdisciplinary approaches, we review a newer strand of cognitive economic thinking with a further commitment: conceptualizing minds and markets each as complex adaptive systems. We describe three ongoing research programs that strive toward these goals: (i) studying narratives as a cognitive and social representation used to guide decision-making; (ii) building cognitively informed agent-based models; and (iii) understanding markets as an extended mind – the Market Mind Hypothesis – analyzed using the concepts, methods, and tools of Coordination Dynamics.}
}
@article{HOGENDOORN2022128,
title = {Perception in real-time: predicting the present, reconstructing the past},
journal = {Trends in Cognitive Sciences},
volume = {26},
number = {2},
pages = {128-141},
year = {2022},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2021.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1364661321002886},
author = {Hinze Hogendoorn},
keywords = {perception, time, prediction, real-time, neural delays},
abstract = {We feel that we perceive events in the environment as they unfold in real-time. However, this intuitive view of perception is impossible to implement in the nervous system due to biological constraints such as neural transmission delays. I propose a new way of thinking about real-time perception: at any given moment, instead of representing a single timepoint, perceptual mechanisms represent an entire timeline. On this timeline, predictive mechanisms predict ahead to compensate for delays in incoming sensory input, and reconstruction mechanisms retroactively revise perception when those predictions do not come true. This proposal integrates and extends previous work to address a crucial gap in our understanding of a fundamental aspect of our everyday life: the experience of perceiving the present.}
}
@article{WANG2013226,
title = {A Computational Knowledge Elicitation and Sharing System for mental health case management of the social service industry},
journal = {Computers in Industry},
volume = {64},
number = {3},
pages = {226-234},
year = {2013},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2012.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S0166361512001777},
author = {W.M. Wang and C.F. Cheung},
keywords = {Narratives, Knowledge management, Concept mapping, Knowledge-based system, Natural language processing},
abstract = {Narrative data provide rich information and knowledge to the workers. However, existing systems mainly served as a workflow system, a reporting system, or a database system for storing this kind of information. The massive amount of unstructured narrative data makes it extremely difficult to be shared and reused. Actual knowledge sharing and reuse among the workers is still limited. This paper presents a Computational Knowledge Elicitation and Sharing System which attempts to elicit knowledge from individuals as well as a team and converts it into a structured format and shared among the team. The proposed system accomplishes several current technologies in knowledge-based system, artificial intelligence and natural language processing, which converts the narrative knowledge of knowledge workers into a concept mapping representation. With a sufficient number of narratives, patterns are revealed and an aggregate concept map for all participating members is produced. It converts the unstructured text into a more structured format which helps to summarize and share the knowledge that can be taken in handling different case management issues. Such integration is considered to be novel. A prototype system has been implemented based on the method successfully in the mental healthcare of a social service organization for handling their case management issues. An experiment has been carried out for measuring the accuracy for converting the unstructured data into the structured format. The theoretical results are found to agree well with the experimental results.}
}
@article{RUSSO2020745,
title = {Neural Trajectories in the Supplementary Motor Area and Motor Cortex Exhibit Distinct Geometries, Compatible with Different Classes of Computation},
journal = {Neuron},
volume = {107},
number = {4},
pages = {745-758.e6},
year = {2020},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2020.05.020},
url = {https://www.sciencedirect.com/science/article/pii/S0896627320303664},
author = {Abigail A. Russo and Ramin Khajeh and Sean R. Bittner and Sean M. Perkins and John P. Cunningham and L.F. Abbott and Mark M. Churchland},
keywords = {supplementary motor area, motor control, motor cortex, population coding, recurrent neural network, neural dynamics, neural computation, population geometry},
abstract = {Summary
The supplementary motor area (SMA) is believed to contribute to higher order aspects of motor control. We considered a key higher order role: tracking progress throughout an action. We propose that doing so requires population activity to display low "trajectory divergence": situations with different future motor outputs should be distinct, even when present motor output is identical. We examined neural activity in SMA and primary motor cortex (M1) as monkeys cycled various distances through a virtual environment. SMA exhibited multiple response features that were absent in M1. At the single-neuron level, these included ramping firing rates and cycle-specific responses. At the population level, they included a helical population-trajectory geometry with shifts in the occupied subspace as movement unfolded. These diverse features all served to reduce trajectory divergence, which was much lower in SMA versus M1. Analogous population-trajectory geometry, also with low divergence, naturally arose in networks trained to internally guide multi-cycle movement.}
}
@article{SNAIDER201259,
title = {Time production and representation in a conceptual and computational cognitive model},
journal = {Cognitive Systems Research},
volume = {13},
number = {1},
pages = {59-71},
year = {2012},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2010.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S1389041710000781},
author = {Javier Snaider and Ryan McCall and Stan Franklin},
keywords = {Time, Time perception, Cognitive architecture, Event, Duration},
abstract = {Time perception and inferences there from are of critical importance to many autonomous agents. But time is not perceived directly by any sensory organ. We argue that time is constructed by cognitive processes. Here we present a model for time perception that concentrates on succession and duration, and that generates these concepts and others, such as continuity, immediate present duration, and lengths of time. These concepts are grounded through the perceptual process itself. We also address event representation, event hierarchy and expectations, as issues intimately related with time. The LIDA cognitive model is used to illustrate these ideas.}
}
@incollection{RUNCO2023115,
title = {Chapter 4 - Biological Perspectives on Creativity},
editor = {Mark A. Runco},
booktitle = {Creativity (Third Edition)},
publisher = {Academic Press},
edition = {Third Edition},
pages = {115-154},
year = {2023},
isbn = {978-0-08-102617-5},
doi = {https://doi.org/10.1016/B978-0-08-102617-5.00005-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780081026175000059},
author = {Mark A. Runco},
keywords = {Adoption studies, Altered states of consciousness, Cerebellum, Corpus callosum, Dopamine, Dreams, Drugs, Exercise, Genealogies, Genetics, Prefrontal cortex, Split brain, Stress},
abstract = {This chapter discusses biological perspectives on creativity. Some of the research on creativity as of late involves the brain and biological correlates of originality, novelty, and insight. Handedness has long been used as an indication of hemispheric dominance or hemisphericity, with right-handed people being compared with left-handed people. There are several reports of left-handed persons outnumbering the right-handed ones in creative and eminent samples. Hemisphericity and other important brain structures and processes contributing to creative thinking and behavior have more recently been studied with electroencephalogram (EEG), positron emission topography (PET), cerebral blood flow, and magnetic resonance imaging (MRI) techniques. Numerous EEG studies suggest that there are particular brain wave patterns and brain structures that are associated with creative problem-solving or at least with specific phases within the problem-solving process. EEGs suggest a complex kind of activity while individuals work on tasks indicative of creative potential. Much of the complexity disappears when those same individuals work on convergent thinking tasks. Research suggests that the prefrontal cortex plays an important role in creative thinking and behaviour.}
}
@incollection{MADIAJAGAN20191,
title = {Chapter 1 - Parallel Computing, Graphics Processing Unit (GPU) and New Hardware for Deep Learning in Computational Intelligence Research},
editor = {Arun Kumar Sangaiah},
booktitle = {Deep Learning and Parallel Computing Environment for Bioengineering Systems},
publisher = {Academic Press},
pages = {1-15},
year = {2019},
isbn = {978-0-12-816718-2},
doi = {https://doi.org/10.1016/B978-0-12-816718-2.00008-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128167182000087},
author = {M. Madiajagan and S. Sridhar Raj},
keywords = {Deep learning, Parallelization, Graphics processing unit, Hardware architecture, Memory optimization, Computational intelligence},
abstract = {Graphics processing unit (GPU) is an electronic circuit which manipulates and modifies the memory for better image output. Deep learning involves huge amounts of matrix multiplications and other operations which can be massively parallelized and thus sped up on GPUs. A single GPU might have thousands of cores while a CPU usually has no more than 12 cores. GPU's practical applicability is affected by two issues: long training time and limited GPU memory, which is greatly influenced as the neural network size grows. In order to overcome these issues, this chapter presents various technologies in distributed parallel processing which improve the training time and optimize the memory, and hardware engine architectures will be explored for data size reduction. The GPUs generally used for deep learning are limited in memory size compared to CPUs, so even the latest Tesla GPU has only 16 GB of memory. Therefore, GPU memory cannot be increased to that extent easily, so networks must be designed to fit within the available memory. This could be a factor limiting progress, overcoming which would be highly beneficiary to the computational intelligence area.}
}
@incollection{VERDICCHIO2025,
title = {Language of Artificial Intelligence Discourses},
booktitle = {Reference Module in Social Sciences},
publisher = {Elsevier},
year = {2025},
isbn = {978-0-443-15785-1},
doi = {https://doi.org/10.1016/B978-0-323-95504-1.00392-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780323955041003926},
author = {Mario Verdicchio},
keywords = {Artificial intelligence, Figures of speech, Machine learning, Philosophy of mind},
abstract = {Language has played a fundamental role in Artificial Intelligence discourses from the very beginning of the establishment of the field. An early assumption was that every aspect of intelligence could be described in a manner compatible with machine operation. This assumption is critical for comparing humans and machines, given that, on the one hand, our understanding of how human brains work is insufficient to define intelligence clearly, and on the other hand, a focus on computational artifacts may lead to a limited conceptualization that overlooks significant aspects of what it means to be conscious and conscientious humans. A mindful analysis of the metaphors used to describe AI systems is key to navigating the intricate entanglements between society and technology that contribute to this endeavor.}
}
@article{CLEMENTZ2023143,
title = {Clinical characterization and differentiation of B-SNIP psychosis Biotypes: Algorithmic Diagnostics for Efficient Prescription of Treatments (ADEPT)-1},
journal = {Schizophrenia Research},
volume = {260},
pages = {143-151},
year = {2023},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2023.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0920996423002645},
author = {Brett A. Clementz and Ishanu Chattopadhyay and Rebekah L. Trotti and David A. Parker and Elliot S. Gershon and S. Kristian Hill and Elena I. Ivleva and Sarah K. Keedy and Matcheri S. Keshavan and Jennifer E. McDowell and Godfrey D. Pearlson and Carol A. Tamminga and Robert D. Gibbons},
abstract = {Clinically defined psychosis diagnoses are neurobiologically heterogeneous. The B-SNIP consortium identified and validated more neurobiologically homogeneous psychosis Biotypes using an extensive battery of neurocognitive and psychophysiological laboratory measures. However, typically the first step in any diagnostic evaluation is the clinical interview. In this project, we evaluated if psychosis Biotypes have clinical characteristics that can support their differentiation in addition to obtaining laboratory testing. Clinical interview data from 1907 individuals with a psychosis Biotype were used to create a diagnostic algorithm. The features were 58 ratings from standard clinical scales. Extremely randomized tree algorithms were used to evaluate sensitivity, specificity, and overall classification success. Biotype classification accuracy peaked at 91 % with the use of 57 items on average. A reduced feature set of 28 items, though, also showed 81 % classification accuracy. Using this reduced item set, we found that only 10–11 items achieved a one-vs-all (Biotype-1 or not, Biotype-2 or not, Biotype-3 or not) area under the sensitivity-specificity curve of .78 to .81. The top clinical characteristics for differentiating psychosis Biotypes, in order of importance, were (i) difficulty in abstract thinking, (ii) multiple indicators of social functioning, (iii) conceptual disorganization, (iv) severity of hallucinations, (v) stereotyped thinking, (vi) suspiciousness, (vii) unusual thought content, (viii) lack of spontaneous speech, and (ix) severity of delusions. These features were remarkably different from those that differentiated DSM psychosis diagnoses. This low-burden adaptive algorithm achieved reasonable classification accuracy and will support Biotype-specific etiological and treatment investigations even in under-resourced clinical and research environments.}
}
@incollection{TOPLAK20221,
title = {1 - Defining cognitive sophistication in the development of judgment and decision-making},
editor = {Maggie E. Toplak},
booktitle = {Cognitive Sophistication and the Development of Judgment and Decision-Making},
publisher = {Academic Press},
pages = {1-22},
year = {2022},
isbn = {978-0-12-816636-9},
doi = {https://doi.org/10.1016/B978-0-12-816636-9.00010-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780128166369000104},
author = {Maggie E. Toplak},
keywords = {Judgment and decision-making, Children and youth, Development, Cognitive sophistication, Critical thinking, Rationality, Stimulus equivalence, Miserly processing},
abstract = {Judgment and decision-making paradigms have been relatively well-studied in developmental samples. The measurement of these competencies in developmental samples has been of scientific interest. They have been recognized as having important implications for defining rational thinking in children and youth but also for teaching and training (such as, critical thinking in education). The origin of the theories and paradigms come from the adult literature, which has also undergone considerable progress in theoretical advancements and empirical studies over the last several years. The integration of our understanding from the work conducted in adults with consideration of developmental factors provides a way to advance our understanding of judgment and decision-making in children and youth. To accomplish this, establishing stimulus equivalence will be important given that these paradigms were first designed for adult samples. In addition, taking into account the rapid growth and change in cognitive capacities, that happen in development, are central for understanding performance on these paradigms. Using a working taxonomy of rational thinking based on adult samples, data from a longitudinal developmental study were used to empirically examine performance patterns on these paradigms.}
}
@article{SAIDI20091467,
title = {PLR-based heuristic for backup path computation in MPLS networks},
journal = {Computer Networks},
volume = {53},
number = {9},
pages = {1467-1479},
year = {2009},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2009.01.009},
url = {https://www.sciencedirect.com/science/article/pii/S1389128609000292},
author = {Mohand Yazid Saidi and Bernard Cousin and Jean-Louis {Le Roux}},
keywords = {Recovery, Local protection, Backup LSP, Failure risk, SRLG, MPLS, Bandwidth sharing, Path computation, Network},
abstract = {To ensure service continuity in networks, local protection pre-configuring the backup paths is preferred to global protection. Under the practical hypothesis of single physical failures in the network, the backup paths which protect against different logical failure risks (node, link and shared risk link group (SRLG)) cannot be active at the same time. Thus, sharing bandwidth between such backup paths is crucial to increase the bandwidth availability. In this article, we focus on the optimal on-line distributed computation of the bandwidth-guaranteed backup paths in MPLS networks. As the requests for connection establishment and release arrive dynamically without knowledge of future arrivals, we choose to use the on-line mode to avoid LSP reconfigurations. We also selected a distributed computation to offer scalability and decrease the LSP setup time. Finally, the optimization of bandwidth utilization can be achieved thanks to the flexibility of the path choice offered by MPLS and to the bandwidth sharing. For a good bandwidth sharing, the backup path computation entities (BPCEs) require the knowledge and maintenance of a great quantity of bandwidth information (e.g. non aggregated link information or per path information) which is undesirable in distributed environments. To get around this problem, we propose here a PLR (point of local repair)-based heuristic (PLRH) which aggregates and noticeably decreases the size of the bandwidth information advertised in the network while offering a high bandwidth sharing. PLRH permits an efficient computation of backup paths. It is scalable, easy to be deployed and balances equitably computations on the network nodes. Simulations show that with the transmission of a small quantity of aggregated information per link, the ratio of rejected backup paths is low and close to the optimum.}
}
@article{MILOVANOVIC2021101044,
title = {Characterization of concept generation for engineering design through temporal brain network analysis},
journal = {Design Studies},
volume = {76},
pages = {101044},
year = {2021},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2021.101044},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X21000557},
author = {Julie Milovanovic and Mo Hu and Tripp Shealy and John Gero},
keywords = {design cognition, design process, problem solving, conceptual design, design neurocognition},
abstract = {This research explores the effect of the structuredness of design concept generation techniques on temporal network neurocognition. Engineering graduate students (n = 30) completed three concept generation tasks using techniques with different levels of structuredness: brainstorming, morphological analysis, and TRIZ. Students’ brain activation in their prefrontal cortex (PFC) was measured using functional near-infrared spectroscopy (fNIRS). The temporal dynamic of central regions in brain networks were compared between tasks. Central regions facilitate functional interaction and imply information flow through the brain. A consistent central region appears in the medial PFC. Consistent network connections occurred across both hemispheres suggesting a concurrent dual processing of divergent and convergent thinking. This study offers novel insights into the underlying neurophysiological mechanism when using these concept generation techniques.}
}
@article{BALAHUR20141,
title = {Computational approaches to subjectivity and sentiment analysis: Present and envisaged methods and applications},
journal = {Computer Speech & Language},
volume = {28},
number = {1},
pages = {1-6},
year = {2014},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2013.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0885230813000697},
author = {Alexandra Balahur and Rada Mihalcea and Andrés Montoyo},
keywords = {Subjectivity analysis, Sentiment analysis, Multilingual resources, Social Media mining, Chat analysis},
abstract = {Recent years have witnessed a surge of interest in computational methods for affect, ranging from opinion mining, to subjectivity detection, to sentiment and emotion analysis. This article presents a brief overview of the latest trends in the field and describes the manner in which the articles contained in the special issue contribute to the advancement of the area. Finally, we comment on the current challenges and envisaged developments of the subjectivity and sentiment analysis fields, as well as their application to other Natural Language Processing tasks and related domains.}
}
@article{KUO2010307,
title = {Conceptual study of micro-tab device in airframe noise reduction: (I) 2D computation},
journal = {Aerospace Science and Technology},
volume = {14},
number = {5},
pages = {307-315},
year = {2010},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2010.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S1270963810000210},
author = {Brian C. Kuo and Nesrin Sarigul-Klijn},
keywords = {Computational aeroacoustics, High-lift device, Micro-tab, Airframe noise},
abstract = {A two-dimensional numerical study was performed to investigate the acoustic effects of micro-tab device on airframe noise reduction. As the noise generated by leading-edge slat and trailing-edge flap rise with their increased deflection angles, it is possible to mitigate such high-lift noise by using reduced settings without sacrificing the aerodynamic performance during approach. In this paper, micro-tab device attached to the pressure side of the flap surface is envisioned as a mean to achieve this goal. Hybrid method involving Computational Fluid Dynamics and acoustic analogy was used to predict the far-field noise spectrum. Results illustrate that the micro-tab device with reduced deflection angles of the high-lift settings provides lower noise signature at far-field positions, comparing to the baseline configuration, while the aerodynamic performance is maintained. In addition, two parametric studies which investigated the effects of micro-tab location and micro-tab height on acoustic spectra were also included.}
}
@article{LOURENCO2020258,
title = {Synaptic inhibition in the neocortex: Orchestration and computation through canonical circuits and variations on the theme},
journal = {Cortex},
volume = {132},
pages = {258-280},
year = {2020},
issn = {0010-9452},
doi = {https://doi.org/10.1016/j.cortex.2020.08.015},
url = {https://www.sciencedirect.com/science/article/pii/S001094522030318X},
author = {Joana Lourenço and Fani Koukouli and Alberto Bacci},
keywords = {Neocortex, Inhibition, Interneurons, Cortical circuits, Synaptic transmission},
abstract = {The neocortex plays a crucial role in all basic and abstract cognitive functions. Conscious mental processes are achieved through a correct flow of information within and across neocortical networks, whose particular activity state results from a tight balance between excitation and inhibition. The proper equilibrium between these indissoluble forces is operated with multiscale organization: along the dendro–somatic axis of single neurons and at the network level. Fast synaptic inhibition is assured by a multitude of inhibitory interneurons. During cortical activities, these cells operate a finely tuned division of labor that is epitomized by their detailed connectivity scheme. Recent results combining the use of mouse genetics, cutting-edge optical and neurophysiological approaches have highlighted the role of fast synaptic inhibition in driving cognition-related activity through a canonical cortical circuit, involving several major interneuron subtypes and principal neurons. Here we detail the organization of this cortical blueprint and we highlight the crucial role played by different neuron types in fundamental cortical computations. In addition, we argue that this canonical circuit is prone to many variations on the theme, depending on the resolution of the classification of neuronal types, and the cortical area investigated. Finally, we discuss how specific alterations of distinct inhibitory circuits can underlie several devastating brain diseases.}
}
@article{DAW2006199,
title = {The computational neurobiology of learning and reward},
journal = {Current Opinion in Neurobiology},
volume = {16},
number = {2},
pages = {199-204},
year = {2006},
note = {Cognitive neuroscience},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2006.03.006},
url = {https://www.sciencedirect.com/science/article/pii/S0959438806000316},
author = {Nathaniel D Daw and Kenji Doya},
abstract = {Following the suggestion that midbrain dopaminergic neurons encode a signal, known as a ‘reward prediction error’, used by artificial intelligence algorithms for learning to choose advantageous actions, the study of the neural substrates for reward-based learning has been strongly influenced by computational theories. In recent work, such theories have been increasingly integrated into experimental design and analysis. Such hybrid approaches have offered detailed new insights into the function of a number of brain areas, especially the cortex and basal ganglia. In part this is because these approaches enable the study of neural correlates of subjective factors (such as a participant's beliefs about the reward to be received for performing some action) that the computational theories purport to quantify.}
}
@article{FAUL2024255,
title = {Update on “Emotion and autobiographical memory”: 14 years of advances in understanding functions, constructions, and consequences},
journal = {Physics of Life Reviews},
volume = {51},
pages = {255-272},
year = {2024},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2024.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S1571064524001301},
author = {Leonard Faul and Jaclyn H. Ford and Elizabeth A. Kensinger},
abstract = {Holland and Kensinger (2010) reviewed the literature on “Emotion and autobiographical memory.” They focused on two broad ways that emotions influence memory: (1) emotion during an event influences how the event is remembered, and (2) emotion and emotional goals during memory retrieval influence how past events are remembered. We begin by providing a brief update on the key points from that review. Holland and Kensinger (2010) also had noted a number of important avenues for future work. Here, we describe what has been learned about the functions of autobiographical memory and their reconstructive nature. Relatedly, we review more recent research on memory reconstruction in the context of visual perspective shifts, counterfactual thinking, nostalgia, and morality. This research has emphasized the reciprocal nature of the interactions between emotion and autobiographical memory: Not only do emotions influence memory, memories influence emotions. Next, we discuss advances that have been made in understanding the reciprocal relations between stress, mood, and autobiographical memory. Finally, we discuss the research that is situating emotional autobiographical memories within a social framework, providing a bedrock for collective memories. Despite the many advances of the past 14 years, many open questions remain; throughout the review we note domains in which we hope to see advances over the next decades.}
}
@article{LONG201855,
title = {Data-driven decision making for supply chain networks with agent-based computational experiment},
journal = {Knowledge-Based Systems},
volume = {141},
pages = {55-66},
year = {2018},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2017.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S0950705117305294},
author = {Qingqi Long},
keywords = {Data-driven decision making, Supply chain network, Business analytics, Data-granularity model, Four-dimensional-flow model, Agent-based computational experiment},
abstract = {The complicated micro structures, macro emergences and dynamic evolutions in a supply chain network pose challenges to decision making for solving operational problems for the network's performance improvement. Most of these problems are complicated since various factors and their complicated relationships are involved. Success of this decision making relies on efficient business analytics based on the comprehensive and multi-dimensional data related to the static attributes and dynamic operations of the network. To confront the challenges, this paper proposes to explore a methodology of data-driven decision making for supply chain networks. In this methodology, a data-granularity model of a supply chain network is developed to standardize the data form for decision making. A four-dimensional-flow model of a supply chain network is proposed to satisfy the data requirements for decision making that are defined in the data-granularity model. Agent-based computational experiment is employed to support the generation of a comprehensive operational dataset of a supply chain network and to verify the solutions generated in decision making. Integrating these models, a data-driven decision-making framework for supply chain networks is proposed. In the framework, a new decision-making mode of “problem definition - business analytics - solution verification - parameter adjustment” is proposed. Oriented towards domain knowledge in supply chain networks, two approaches of business analytics—mapping analysis and correlation analysis—are presented. Finally, a case of a five-echelon manufacturing supply chain network is studied with the methodology. The findings indicate that the proposed methodology, models and framework are effective in supporting the data-centric decision making for solving complicated operational problems in supply chain networks and provide the networks’ managers or member enterprises with an effective tool to generate unbiased and efficient decisions for the networks’ performance improvement.}
}
@incollection{WILLETT2018231,
title = {Chapter 8 - Application of Mathematical Models and Computation in Plant Metabolomics},
editor = {Satyajit D. Sarker and Lutfun Nahar},
booktitle = {Computational Phytochemistry},
publisher = {Elsevier},
pages = {231-254},
year = {2018},
isbn = {978-0-12-812364-5},
doi = {https://doi.org/10.1016/B978-0-12-812364-5.00008-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128123645000080},
author = {Denis S. Willett and Caitlin C. Rering and Dominique A. Ardura and John J. Beck},
keywords = {Big data, Machine learning, Data science, Agriculture},
abstract = {The investigation and reporting of plant chemical constituents has greatly evolved over the course of natural products and phytochemical research. Starting from the extraction and identification of plant-based bioactive components, such as historical salicin or more recent paclitaxel, phytochemistry-based research now includes plant metabolomics that help delineate chemotaxonomy, phylogenetic biomarkers and the functional genetics of a plant’s response to biotic or abiotic stressors. Here, we examine the invaluable contributions of mathematical models and computation for analysing plant metabolomics data and discuss the analytics mindset, highlight best practices, provide example workflows, as well as introduce future opportunities. Important in this chapter is the application of statistical methods for the improved visualization and interpretation of plant metabolomics data and their relevance for future project planning.}
}
@article{FEKETE2011807,
title = {Towards a computational theory of experience},
journal = {Consciousness and Cognition},
volume = {20},
number = {3},
pages = {807-827},
year = {2011},
issn = {1053-8100},
doi = {https://doi.org/10.1016/j.concog.2011.02.010},
url = {https://www.sciencedirect.com/science/article/pii/S1053810011000365},
author = {Tomer Fekete and Shimon Edelman},
keywords = {Representation, Experience, Qualia, Computation, State space, Trajectory, Dynamics, Brain activation, Concept, Clustering},
abstract = {A standing challenge for the science of mind is to account for the datum that every mind faces in the most immediate – that is, unmediated – fashion: its phenomenal experience. The complementary tasks of explaining what it means for a system to give rise to experience and what constitutes the content of experience (qualia) in computational terms are particularly challenging, given the multiple realizability of computation. In this paper, we identify a set of conditions that a computational theory must satisfy for it to constitute not just a sufficient but a necessary, and therefore naturalistic and intrinsic, explanation of qualia. We show that a common assumption behind many neurocomputational theories of the mind, according to which mind states can be formalized solely in terms of instantaneous vectors of activities of representational units such as neurons, does not meet the requisite conditions, in part because it relies on inactive units to shape presently experienced qualia and implies a homogeneous representation space, which is devoid of intrinsic structure. We then sketch a naturalistic computational theory of qualia, which posits that experience is realized by dynamical activity-space trajectories (rather than points) and that its richness is measured by the representational capacity of the trajectory space in which it unfolds.}
}
@article{RONEZRA2021100896,
title = {Engaging a third-grade student with autism spectrum disorder in an error finding activity},
journal = {The Journal of Mathematical Behavior},
volume = {63},
pages = {100896},
year = {2021},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2021.100896},
url = {https://www.sciencedirect.com/science/article/pii/S0732312321000572},
author = {Maya Ron-Ezra and Esther S. Levenson},
keywords = {Autism spectrum disorder, Two-digit addition, Error analysis, Mathematical explanations},
abstract = {This paper describes a case study of one mainstreamed third grade student with autism spectrum disorder (ASD) and his ability to explain his solutions for two-digit addition problems, and find and explain the mistake when presented with incorrectly solved addition problems. The study is presented as a counterexample to deficit views of ASD, views that focus on lack of communication skills, not being able to see someone else’s point of view, and poor executive functions. Each encounter with the student is analyzed in two ways, first analyzing his mathematical knowledge, and then analyzing obstacles the student faces that are associated with ASD. Some obstacles are overcome by the student on his own and others are overcome with the help of the researcher, who responds to the student’s thinking, and supports his endeavor to engage with a challenging activity.}
}
@article{KISS2020106823,
title = {Process systems engineering developments in Europe from an industrial and academic perspective},
journal = {Computers & Chemical Engineering},
volume = {138},
pages = {106823},
year = {2020},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2020.106823},
url = {https://www.sciencedirect.com/science/article/pii/S0098135420303069},
author = {Anton A. Kiss and Johan Grievink},
keywords = {Process systems engineering, Industry, Education, Research, Interface, Perspectives},
abstract = {Process Systems Engineering (PSE) is a discipline that deals with decision-making, at all levels and scales, by understanding any complex process system using a holistic view and a systems thinking framework. A closely related discipline (considered usually a part of PSE) is the Computer Aided Process Engineering (CAPE) which is a complementary field that focuses on developing methods and providing solution through systematic computer aided techniques for problems related to the design, control and operation of chemical systems. Nowadays, the ‘PSE’ term suffers from a branding issue to the point that PSE no longer gets the recognition that it deserves. In chemical engineering education the integrative systems frame for process design, control and operations is virtually absent. Its application potential in process industry lags relative to academic research progress and results. This work aims to provide an informative industrial and academic perspective on PSE (focused on the European region), arguing that the ‘systems thinking’ and ‘systems problem solving’ have to be given priority over just applications of computational problem solving methods. A multi-level view of the PSE field is provided within the academic and industrial context, and enhancements for PSE are suggested at their industrial and academic interfaces to create win-win situations.}
}
@article{TARIM2011563,
title = {An efficient computational method for a stochastic dynamic lot-sizing problem under service-level constraints},
journal = {European Journal of Operational Research},
volume = {215},
number = {3},
pages = {563-571},
year = {2011},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2011.06.034},
url = {https://www.sciencedirect.com/science/article/pii/S0377221711005637},
author = {S. Armagan Tarim and Mustafa K. Dogˇru and Ulaş Özen and Roberto Rossi},
keywords = {Inventory, Relaxation, Stochastic non-stationary demand, Mixed integer programming, Service level, Static–dynamic uncertainty},
abstract = {We provide an efficient computational approach to solve the mixed integer programming (MIP) model developed by Tarim and Kingsman [8] for solving a stochastic lot-sizing problem with service level constraints under the static–dynamic uncertainty strategy. The effectiveness of the proposed method hinges on three novelties: (i) the proposed relaxation is computationally efficient and provides an optimal solution most of the time, (ii) if the relaxation produces an infeasible solution, then this solution yields a tight lower bound for the optimal cost, and (iii) it can be modified easily to obtain a feasible solution, which yields an upper bound. In case of infeasibility, the relaxation approach is implemented at each node of the search tree in a branch-and-bound procedure to efficiently search for an optimal solution. Extensive numerical tests show that our method dominates the MIP solution approach and can handle real-life size problems in trivial time.}
}
@incollection{SILVA20203,
title = {Chapter 1 - Introduction and overview of using computational fluid dynamics tools},
editor = {Valter Bruno Reis E. Silva and João Cardoso},
booktitle = {Computational Fluid Dynamics Applied to Waste-to-Energy Processes},
publisher = {Butterworth-Heinemann},
pages = {3-28},
year = {2020},
isbn = {978-0-12-817540-8},
doi = {https://doi.org/10.1016/B978-0-12-817540-8.00001-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128175408000017},
author = {Valter Bruno Reis E. Silva and João Cardoso},
keywords = {Computer fluid dynamics, Waste-to-energy, Simulation workflow, Fluid dynamics history},
abstract = {Over the last decades, with the increasing computational power and numerical solvers efficiency, computational fluid dynamics (CFD) is broadly used to design, optimize, and predict the physical-chemical phenomena regarding energy-related processes. A set of elaborate mathematical models is governed by partial differential equations representing conservation laws for mass, momentum, and energy, alongside with theoretical and empirical correlation. Therefore, CFD simulation is a crucial asset to understand the influence of parameters of interest in these processes and related operation and optimization of the technology involved. This chapter discusses how CFD can be used advantageously over waste-to-energy processes, also outlining advantages, disadvantages, and main setbacks with such an approach.}
}
@article{ALPUENTE20153,
title = {Exploring conditional rewriting logic computations},
journal = {Journal of Symbolic Computation},
volume = {69},
pages = {3-39},
year = {2015},
note = {Symbolic Computation in Software Science},
issn = {0747-7171},
doi = {https://doi.org/10.1016/j.jsc.2014.09.028},
url = {https://www.sciencedirect.com/science/article/pii/S0747717114000960},
author = {M. Alpuente and D. Ballis and F. Frechina and J. Sapiña},
keywords = {Rewriting logic, Trace exploration, Maude, Conditional rewrite theories},
abstract = {Trace exploration is concerned with techniques that allow computation traces to be dynamically searched for specific contents. Depending on whether the exploration is carried backward or forward, trace exploration techniques allow provenance tracking or impact tracking to be done. The aim of provenance tracking is to show how (parts of) a program output depends on (parts of) its input and to help estimate which input data need to be modified to accomplish a change in the outcome. The aim of impact tracking is to identify the scope and potential consequences of changing the program input. Rewriting Logic (RWL) is a logic of change that supplements (an extension of) the equational logic by adding rewrite rules that are used to describe (nondeterministic) transitions between states. In this paper, we present a rich and highly dynamic, parameterized technique for the forward inspection of RWL computations that allows the nondeterministic execution of a given conditional rewrite theory to be followed up in different ways. With this technique, an analyst can browse, slice, filter, or search the traces as they come to life during the program execution. The navigation of the trace is driven by a user-defined, inspection criterion that specifies the required exploration mode. By selecting different inspection criteria, one can automatically derive a family of practical algorithms such as program steppers and more sophisticated dynamic trace slicers that compute summaries of the computation tree, thereby facilitating the dynamic detection of control and data dependencies across the tree. Our methodology, which is implemented in the Anima graphical tool, allows users to evaluate the effects of a given statement or instruction in isolation, track input change impact, and gain insight into program behavior (or misbehavior).}
}
@article{BASU2021135660,
title = {Integrative STEM education for undergraduate neuroscience: Design and implementation},
journal = {Neuroscience Letters},
volume = {746},
pages = {135660},
year = {2021},
issn = {0304-3940},
doi = {https://doi.org/10.1016/j.neulet.2021.135660},
url = {https://www.sciencedirect.com/science/article/pii/S0304394021000380},
author = {Alo C. Basu and Alexis S. Hill and André K. Isaacs and Michelle A. Mondoux and Ryan E.B. Mruczek and Tomohiko Narita},
keywords = {Integrative thinking, Spiral curriculum, Active learning, Inclusive pedagogy, Inclusive excellence, Anti-deficit},
abstract = {As an integrative discipline, neuroscience can serve as a vehicle for the development of integrative thinking skills and broad-based scientific proficiency in undergraduate students. Undergraduate neuroscience curricula incorporate fundamental concepts from multiple disciplines. Deepening the explicit exploration of these connections in a neuroscience core curriculum has the potential to support more meaningful and successful undergraduate STEM learning for neuroscience students. Curriculum and faculty development activities related to an integrative core curriculum can provide opportunities for faculty across disciplines and departments to advance common goals of inclusive excellence in STEM. These efforts facilitate analysis of the institutional STEM curriculum from the student perspective, and assist in creating an internal locus of accountability for diversity, equity, and inclusion within the institution. Faculty at the College of the Holy Cross have undertaken the collaborative design and implementation of an integrative core curriculum for neuroscience that embraces principles of inclusive pedagogy, emphasizes the connections between neuroscience and other disciplines, and guides students to develop broad proficiency in fundamental STEM concepts and skills.}
}
@article{CSILLERY2010410,
title = {Approximate Bayesian Computation (ABC) in practice},
journal = {Trends in Ecology & Evolution},
volume = {25},
number = {7},
pages = {410-418},
year = {2010},
issn = {0169-5347},
doi = {https://doi.org/10.1016/j.tree.2010.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0169534710000662},
author = {Katalin Csilléry and Michael G.B. Blum and Oscar E. Gaggiotti and Olivier François},
abstract = {Understanding the forces that influence natural variation within and among populations has been a major objective of evolutionary biologists for decades. Motivated by the growth in computational power and data complexity, modern approaches to this question make intensive use of simulation methods. Approximate Bayesian Computation (ABC) is one of these methods. Here we review the foundations of ABC, its recent algorithmic developments, and its applications in evolutionary biology and ecology. We argue that the use of ABC should incorporate all aspects of Bayesian data analysis: formulation, fitting, and improvement of a model. ABC can be a powerful tool to make inferences with complex models if these principles are carefully applied.}
}
@article{GROTH20211712,
title = {A systems-based framework to computationally describe putative transcription factors and signaling pathways regulating glycan biosynthesis},
journal = {Beilstein Journal of Organic Chemistry},
volume = {17},
pages = {1712-1724},
year = {2021},
issn = {1860-5397},
doi = {https://doi.org/10.3762/bjoc.17.119},
url = {https://www.sciencedirect.com/science/article/pii/S186053972102209X},
author = {Theodore Groth and Rudiyanto Gunawan and Sriram Neelamegham},
keywords = {ChIP-Seq, glycoinformatics, glycosylation, TCGA transcription factor},
abstract = {Glycosylation is a common posttranslational modification, and glycan biosynthesis is regulated by a set of glycogenes. The role of transcription factors (TFs) in regulating the glycogenes and related glycosylation pathways is largely unknown. In this work, we performed data mining of TF–glycogene relationships from the Cistrome Cancer database (DB), which integrates chromatin immunoprecipitation sequencing (ChIP-Seq) and RNA-Seq data to constitute regulatory relationships. In total, we observed 22,654 potentially significant TF–glycogene relationships, which include interactions involving 526 unique TFs and 341 glycogenes that span 29 the Cancer Genome Atlas (TCGA) cancer types. Here, TF–glycogene interactions appeared in clusters or so-called communities, suggesting that changes in single TF expression during both health and disease may affect multiple carbohydrate structures. Upon applying the Fisher’s exact test along with glycogene pathway classification, we identified TFs that may specifically regulate the biosynthesis of individual glycan types. Integration with Reactome DB knowledge provided an avenue to relate cell-signaling pathways to TFs and cellular glycosylation state. Whereas analysis results are presented for all 29 cancer types, specific focus is placed on human luminal and basal breast cancer disease progression. Overall, the article presents a computational approach to describe TF–glycogene relationships, the starting point for experimental system-wide validation.}
}
@article{SCHERER2020106349,
title = {A meta-analysis of teaching and learning computer programming: Effective instructional approaches and conditions},
journal = {Computers in Human Behavior},
volume = {109},
pages = {106349},
year = {2020},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2020.106349},
url = {https://www.sciencedirect.com/science/article/pii/S0747563220301023},
author = {Ronny Scherer and Fazilat Siddiq and Bárbara {Sánchez Viveros}},
keywords = {Computational thinking, Computer programming, Intervention studies, Multilevel meta-analysis, Scratch programming},
abstract = {This meta-analysis maps the evidence on the effectiveness of instructional approaches and conditions for learning computer programming under three study conditions: (a) Studies focusing on the effectiveness of programming interventions per se, (b) studies focusing on the effectiveness of visualization and physicality, and (c) studies focusing on the effectiveness of dominant instructional approaches. Utilizing the data from 139 interventions and 375 effect sizes, we found (a) a strong effect of learning computer programming per se (Hedges’ g‾ = 0.81, 95% CI [0.42, 1.21]), (b) moderate to large effect sizes of visualization (g‾ = 0.44, 95% CI [0.29, 0.58]) and physicality interventions (g‾ = 0.72, 95% CI [0.23, 1.21]), and (c) moderate to large effect sizes for studies focusing on dominant instructional approaches (g‾s = 0.49–1.02). Moderator analyses indicated that the effect sizes differed only marginally between the instructional approaches and conditions—however, collaboration in metacognition instruction, problem solving instruction outside of regular lessons, short-term interventions focusing on physicality, and interventions focusing on visualization through Scratch were especially effective. Our meta-analysis synthesizes the existing research evidence on the effectiveness of computer programming instruction and, ultimately, provides references with which the effects of future studies could be compared.}
}
@incollection{GARDNER20243,
title = {Chapter 1 - Scaling the smart city},
editor = {Nicole Gardner},
booktitle = {Scaling the Smart City},
publisher = {Elsevier},
pages = {3-25},
year = {2024},
series = {Smart Cities},
isbn = {978-0-443-18452-9},
doi = {https://doi.org/10.1016/B978-0-443-18452-9.00001-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044318452900001X},
author = {Nicole Gardner},
keywords = {Cyber-physical system, Design, Interaction, IoT, Scalar, Scale, Scaling, Smart city, Techno-urban imaginary, Urban design, Urban technology},
abstract = {This chapter explores the smart city through the conceptual lens of scale, as a scale-making project and as a project that is subject to scaling processes. It explores how scalar notions figure in smart city discourses, and how the drive to scale shapes the prevailing approach to digital technology and urban space integration. It argues that deprioritizing the smart city's scalability logic can bring into view different ways of designing the integration of digital technologies and urban space that can better connect with the contextual and material specificities of local contexts and less attended to dimensions of urban livability. Rescaling the smart city to the local urban precinct scale and paying close attention to life-technology relations is further reasoned as a way to productively re-orient and extend thinking on the ethical significance of the smart city.}
}
@article{JI20074338,
title = {A fuzzy logic-based computational recognition-primed decision model},
journal = {Information Sciences},
volume = {177},
number = {20},
pages = {4338-4353},
year = {2007},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2007.02.026},
url = {https://www.sciencedirect.com/science/article/pii/S0020025507001193},
author = {Yanqing Ji and R. Michael Massanari and Joel Ager and John Yen and Richard E. Miller and Hao Ying},
keywords = {Medical decision-making, Naturalistic decision-making, Recognition-primed decision model, Computational recognition-primed decision model, Experience-based reasoning, Adverse drug reactions, Fuzzy logic, Similarity measure},
abstract = {The recognition-primed decision (RPD) model is a primary naturalistic decision-making approach which seeks to explicitly recognize how human decision makers handle complex tasks and environment based on their experience. Motivated by the need for quantitative computer modeling and simulation of human decision processes in various application domains, including medicine, we have developed a general-purpose computational fuzzy RPD model that utilizes fuzzy sets, fuzzy rules, and fuzzy reasoning to represent, interpret, and compute imprecise and subjective information in every aspect of the model. Experiences acquired by solicitation with experts are stored in experience knowledge bases. New local and global similarity measures have been developed to identify the experience that is most applicable to the current situation in a specific decision-making context. Furthermore, an action evaluation strategy has been developed to select the workable course of action. The proposed fuzzy RPD model has been preliminarily validated by using it to calculate the extent of causality between a drug (Cisapride, withdrawn by the FDA from the market in 2000) and some of its adverse effects for 100 hypothetical patients. The simulated patients were created based on the profiles of over 1000 actual patients treated with the drug at our medical center before its withdrawal. The model validity was demonstrated by comparing the decisions made by the proposed model and those by two independent internists. The levels of agreement were established by the weighted Kappa statistic and the results suggested good to excellent agreement.}
}
@article{DORKO2023101036,
title = {Is it a function? Generalizing from single- to multivariable settings},
journal = {The Journal of Mathematical Behavior},
volume = {70},
pages = {101036},
year = {2023},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2023.101036},
url = {https://www.sciencedirect.com/science/article/pii/S0732312323000068},
author = {Allison Dorko},
keywords = {Actor-oriented transfer, Generalization, Multivariable calculus, Functions of two variables, Multivariable functions},
abstract = {Generalizing is a hallmark of mathematical thinking. The term ‘generalization’ is used to mean both the process of generalizing and the product of that process. This paper reports on five calculus students’ generalizing activity and what they generalized about multivariable functions. The study makes two contributions. The first is a fine-grained, actor-oriented characterization of the ways undergraduates generalized. This adds to knowledge in two areas: the use of the actor-oriented perspective and generalization in advanced mathematics. The second contribution is the products of students’ generalizing: what they generalized about what it means for a multivariable relation to represent a function). This adds to the literature about student reasoning regarding multivariable topics by characterizing the powerful ways of reasoning students possess pre-instruction.}
}
@article{SHAHZAD2022102190,
title = {Thermal cooling process by nanofluid flowing near stagnating point of expanding surface under induced magnetism force: A computational case study},
journal = {Case Studies in Thermal Engineering},
volume = {36},
pages = {102190},
year = {2022},
issn = {2214-157X},
doi = {https://doi.org/10.1016/j.csite.2022.102190},
url = {https://www.sciencedirect.com/science/article/pii/S2214157X22004361},
author = {Faisal Shahzad and Wasim Jamshed and Amjad Ali Pasha and Rabia Safdar and Md. Mottahir Alam and Misbah Arshad and Syed M. Hussain and Muhammad Bilal Hafeez and Marek Krawczuk},
keywords = {, , , , },
abstract = {This paper is dedicated to the exam of entropy age and research of the effect of mixing nanosolid additives over an extending sheet. In this review, Newtonian nanofluid version turned into researched at the actuated appealing field, heat radiation and variable heat conductivity results. With becoming modifications, the proven PDEs are moved into popular differential situations and paintings mathematically making use of a specific mathematical plan called the Keller box method (KBM). The ranges of different dimensionless parameters used in our study are volume fraction of nanoparticles 0.01≤φ≤0.04, magnetic parameter 0.5≤Λ≤2, thermal radiation 0.1≤Nr≤0.3, heat source/sink parameter 0.5≤Q0≤2, Prandtl number 5.7≤Pr≤6.2, variable thermal conductivity 0.1≤ε≤0.3, reciprocal magnetic Prandtl number 0.6≤λ∗≤1, Brinkman number 5≤Br≤15, Reynolds number 5≤Re≤15, which shows up during mathematical arrangement are shown as tables and charts.Positive modifications in heat radiation and heat conductivity affects increment the hotness pass coefficient of solar primarily based totally plane wings. Titanium alloy primarily based totally water (H2O) are taken into consideration for our research. We will likewise alternate the grouping of nanoparticles to pay attention on their impact on numerous dynamic barriers of the framework. We can see that because the Reynolds range and Brinkman range increment, the entropy increments. The thermodynamic exhibition of Titanium alloy-water (Ti6Al4V–H2O) nanofluid has been portrayed higher that of base nanofluid with comparable situations. Recorded hypothetical reproductions may be greater beneficial to similarly increase daylight primarily based totally nuclear strength frameworks.}
}
@article{KAWITI2025100213,
title = {Indigenous knowledge, architecture, and nature in the context of Oceania},
journal = {Nature-Based Solutions},
volume = {7},
pages = {100213},
year = {2025},
issn = {2772-4115},
doi = {https://doi.org/10.1016/j.nbsj.2025.100213},
url = {https://www.sciencedirect.com/science/article/pii/S2772411525000035},
author = {Derek Kawiti and Albert Refiti and Amanda Yates and Elisapeta Heta and Sibyl Bloomfield and Victoria Chanse and Maibritt Pedersen Zari},
keywords = {Pacific, Indigenous, Architecture, Ecology, Climate change adaptation, Māori, Samoan},
abstract = {This perspective article is derived from conversations between leading Indigenous academics and practitioners in the fields of architecture and urban design recorded at a keynote panel at the 2023 NUWAO International Symposium on Nature-based Urban Climate Adaptation for Wellbeing, held at Te Herenga Waka Victoria University of Wellington, Aotearoa New Zealand. The focus of the discussion was Indigenous design for adaptation to climate change in Moananui Oceania with an emphasis on relationships to nature. Given the diversity of Moananui Oceania in terms of languages, cultures, histories, and worldviews, this discussion represented a unique convergence of Indigenous leadership and thought in the field. It highlighted key themes related to Indigenous design for climate change adaptation and offered a novel, distinctive perspective aimed at advancing thinking around nature-based solutions (NbS). It is important to recognise and integrate Indigenous values and approaches to knowledge generation, particularly within academic settings. In the context of Moananui Oceania this can require adapting oral traditions and formats, such as talanoa, and hui or kōrero, into conventional Western-based research formats such as the journal article. This paper is an attempt to capture important Indigenous knowledge and discussion in a western format to enable further dissemination and sharing. This means the format and methodologies described in the paper do not align exactly with traditional scientific journal article formats, however the discussions and findings help to meet the motivation of the authors, which is to transform traditional Indigenous ways of sharing information into a perspective article format and share insights with a wider audience. This methodology aligns well with the special issue call that this paper resides in (Just, Socio-ecological Urban Transformation: Nature-based Solutions and Traditional Ecological Knowledge), underpinning the relevance and potential contribution to the field. Two key themes were explored within the context of the importance of working with nature; relationships between ecologies and tikanga (customary practices), and looking backwards to generate innovation and resilience.}
}
@article{BAWDEN1984205,
title = {Systems thinking and practices in the education of agriculturalists},
journal = {Agricultural Systems},
volume = {13},
number = {4},
pages = {205-225},
year = {1984},
issn = {0308-521X},
doi = {https://doi.org/10.1016/0308-521X(84)90074-X},
url = {https://www.sciencedirect.com/science/article/pii/0308521X8490074X},
author = {Richard J. Bawden and Robert D. Macadam and Roger J. Packham and Ian Valentine},
abstract = {A systems approach has been taken to a review of agricultural education programmes and as the essential theme of resultant curricula at Hawkesbury Agricultural College in Australia. The systems thinking and practices which have guided, and been shaped by, the innovations are outlined, and the rationale and framework of the major programme are described. The subsequent emphasis has been placed on effective learning for agricultural managers and their technologist advisors. It is argued that problem solving and learning are essentially the same psychological processes and that taking a systems approach to investigating problem situations provides a more useful paradigm for learning about agriculture than reductionist, discipline-based approaches. Experiential learning and autonomy in learning are seen as consistent with this and are basic features of the programmes. A conceptual framework for problem solving that incorporates soft and hard systems and scientific reductionist methodologies has been developed. A contingency approach to situation improving is emerging as a less restrictive and more realistic alternative to a normative approach to problem solving.}
}
@article{AGGARWAL2023110458,
title = {Quantum healthcare computing using precision based granular approach},
journal = {Applied Soft Computing},
volume = {144},
pages = {110458},
year = {2023},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2023.110458},
url = {https://www.sciencedirect.com/science/article/pii/S1568494623004763},
author = {Lakshita Aggarwal and Shelly Sachdeva and Puneet Goswami},
keywords = {Quantum computing, Qubits, Healthcare, Diagnosis, Classical computing, Precision},
abstract = {Previously, doctors interpreted diseases and their outcomes according to their experience in diagnosis. However, with the rapid increase in technology and population, the task of examining the patient becomes cumbersome and sometimes human efforts produce inconsistent results. Several research is being done for healthcare in terms of improving visualization and accuracy by using machine learning models. The current research targets to explore quantum computing as a different way of processing information compared to classical computer systems such as the use of quantum bits (qubits) along with superposition and entanglement for extending the computation capabilities at an unprecedented level of thinking in the healthcare domain. Quantum computing systems provide exponential benefits in terms of high-speed processing, faster and easier diagnostic assistance, unimaginable reduction in processing throughput, and many more. An extensive comparative analysis of existing approaches has been made which benchmarks the need for quantum healthcare computing. The objective of this work is to interpret whether Quantum computers prove to be more trusted when it comes to patient diagnosis, and faster analysis leading to cost optimization. In order to accelerate patient diagnosis, different approaches have been presented. The authors have proposed a precision-based granular approach for patient diagnosis that incorporates diagnosing the disease with enhanced precision and granularity. It involves reporting symptoms by the patient, encountering by healthcare expert on multiple factors, precise examination, granular health status (understanding past and present medical history), followed by a precise intervention by understanding biomolecular simulations. The algorithm has been presented to describe the flow process for patient diagnosis modeling using quantum computing. It involves qubits initialization, pairing the values, assigning probabilistic values, cross-validation, and quantum circuit formation. Precision-based granular approach has been implemented for a scenario (consisting of medical parameters such as oxygen and heart rate level, with the functionality of diagnosing oxygen level and heart range which lies as either normal or not normal (high/low)). Precision-based granular approach deals specifically with the individual ‘biomolecular simulation by understanding variations in the individual body whereas the umbrella-based approach does not deal with specifically to individual mechanisms. Granular level of encounter is not possible in umbrella-based treatment. Python Jupyter notebook and IBM Composer tool is used for the implementation of results. Bloch sphere and computational state graph are obtained as an output for better visualization and understanding. Falcon r5.11H processor is used with the version of 1.0.24 of IBM Composer to simulate the experiment. The methodology using precision based granular approach provides timely encounter of disease along with umbrella diagnosis and precise treatment. The time is taken and frequency of qubits have been presented with promising results. The diagnosis process and optimizing cost efficiency can aid in an early detection of the disease.}
}
@article{GANUTHULA2016216,
title = {Rationality and the reflective mind: A case for typical performance measure of cognitive ability},
journal = {Learning and Individual Differences},
volume = {49},
pages = {216-223},
year = {2016},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2016.06.019},
url = {https://www.sciencedirect.com/science/article/pii/S1041608016301029},
author = {Venkat Ram Reddy Ganuthula and Lata Dyaram},
keywords = {Typical performance measure of cognitive ability, Thinking dispositions, Rationality, Tripartite model of mind},
abstract = {Intelligence and cognitive abilities often denoted good thinking. However, critics of intelligence tests have long pointed out that the failures of rational judgments and decision-making imperfectly correlate with intelligence. Reviewing the work of Keith Stanovich and his colleagues, paper highlights the role of individual differences in judgment and decision-making. Paper presents a case for typical performance measure of cognitive ability besides thinking dispositions to explain variations in rational thought. Specifically, we examine and model the relationship between need for cognition (a measure of thinking dispositions), absorptive capacity (typical performance measure of intelligence) and normative decision-making tasks.}
}
@article{CARROLL1999111,
title = {Invented Computational Procedures of Students in a Standards-Based Curriculum},
journal = {The Journal of Mathematical Behavior},
volume = {18},
number = {2},
pages = {111-121},
year = {1999},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(99)00024-3},
url = {https://www.sciencedirect.com/science/article/pii/S0732312399000243},
author = {William M. Carroll},
abstract = {Fourth graders who had been in a standards-based elementary curriculum since kindergarten were individually interviewed and administered a whole-class test that probed their knowledge of facts and multidigit computation. Standard algorithms are not taught as part of the curriculum, which instead emphasizes student-invented procedures and discussions of solution methods. Of interest were the types of student-invented procedures that were used as well as their computational accuracy. Students used several procedures that involved sophisticated mental calculation strategies, such as decomposing numbers or adding from left to right. Many students also used the standard written algorithms. Both invented and standard algorithms used by the students were highly accurate, although invented procedures often indicated better mental flexibility and awareness of place value. On the written test, students' computational abilities were above national normative levels.}
}
@article{BOTTEGONI201223,
title = {The role of fragment-based and computational methods in polypharmacology},
journal = {Drug Discovery Today},
volume = {17},
number = {1},
pages = {23-34},
year = {2012},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2011.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S1359644611002534},
author = {Giovanni Bottegoni and Angelo D. Favia and Maurizio Recanatini and Andrea Cavalli},
abstract = {Polypharmacology-based strategies are gaining increased attention as a novel approach to obtaining potentially innovative medicines for multifactorial diseases. However, some within the pharmaceutical community have resisted these strategies because they can be resource-hungry in the early stages of the drug discovery process. Here, we report on fragment-based and computational methods that might accelerate and optimize the discovery of multitarget drugs. In particular, we illustrate that fragment-based approaches can be particularly suited for polypharmacology, owing to the inherent promiscuous nature of fragments. In parallel, we explain how computer-assisted protocols can provide invaluable insights into how to unveil compounds theoretically able to bind to more than one protein. Furthermore, several pragmatic aspects related to the use of these approaches are covered, thus offering the reader practical insights on multitarget-oriented drug discovery projects.}
}
@incollection{SLEPIAN2024516,
title = {4.01 - Synergistic Approaches of Cross-Fertilization and Feedback Together Driving and Advancing Health for All},
editor = {Kenneth S. Ramos},
booktitle = {Comprehensive Precision Medicine (First Edition)},
publisher = {Elsevier},
edition = {First Edition},
address = {Oxford},
pages = {516-523},
year = {2024},
isbn = {978-0-12-824256-8},
doi = {https://doi.org/10.1016/B978-0-12-824010-6.00081-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128240106000812},
author = {Marvin J. Slepian},
keywords = {Digital Health, Multiscale, Nested pots, Personalized medicine, Pharmacogenomics, Point-of-care, Precision medicine, System synergies, Systems biology, Wearable technologies},
abstract = {We are at a point in time with rapid advances occurring in digital technologies, developing a range of new quantifiable markers termed “digital biomarkers,” which are increasingly utilized for diagnostics, as well as defining new operative mechanisms of health and disease. In parallel, significant advances have occurred in precision medicine, utilizing breakthroughs in “omics biology,” coupled with our understanding of their impact across systems in “systems biology.” Contemporaneously, a new approach to thinking of how health and disease evolve and impact an individual has emerged—that of considering mechanisms and impact across scales, i.e. on a “multi-scale” level, extending from the patient down to the molecule, and similarly from the patient up to society. In this chapter details of each of these approaches, their evolution and key current concepts are outlined. Moreover, the main theme and postulate developed in this chapter outlines the interconnectedness and the way in which each approach informs each other. In essence a cyclic, reinforcing, feedback loop exists, connecting digital technologies with precision and personalization approaches, across systems and scales, leading to enhanced diagnostics, the potential for new therapeutics and increasing insight into mechanisms. This cyclic flow of information will lead to new, more exacting technologies, with the ultimate outcome of enhanced efficacy, safety and improved health outcomes for patients and society.}
}
@article{BAR202135,
title = {Wanted: Architecture for changing minds: A comment on “The growth of cognition: Free energy minimization and the embryogenesis of cortical computation”},
journal = {Physics of Life Reviews},
volume = {36},
pages = {35-36},
year = {2021},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2020.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S1571064520300683},
author = {Moshe Bar}
}
@article{CRAWFORD202180,
title = {Efficient mechanisms for level-k bilateral trading},
journal = {Games and Economic Behavior},
volume = {127},
pages = {80-101},
year = {2021},
issn = {0899-8256},
doi = {https://doi.org/10.1016/j.geb.2021.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S0899825621000282},
author = {Vincent P. Crawford},
keywords = {Mechanism design, Bilateral trading, Level- thinking, Behavioral game theory},
abstract = {This paper revisits Myerson and Satterthwaite's (1983) classic analysis of mechanism design for bilateral trading, replacing equilibrium with a level-k model of strategic thinking and focusing on direct mechanisms. The revelation principle fails for level-k models, so restricting attention to direct mechanisms and imposing incentive-compatibility are not without loss of generality. If, however, only direct, level-k-incentive-compatible mechanisms are feasible and traders' levels are observable, Myerson and Satterthwaite's characterization of mechanisms that maximize traders' total surplus subject to incentive constraints generalizes qualitatively to level-k models. If only direct, level-k-incentive-compatible mechanisms are feasible but traders' levels are not observable, generically a particular posted-price mechanism maximizes traders' total expected surplus subject to incentive constraints. If direct, non-level-k-incentive-compatible mechanisms are feasible and traders best respond to them, total expected surplus-maximizing mechanisms may take completely different forms.}
}
@article{BOND200481,
title = {A computational model for the primate neocortex based on its functional architecture},
journal = {Journal of Theoretical Biology},
volume = {227},
number = {1},
pages = {81-102},
year = {2004},
issn = {0022-5193},
doi = {https://doi.org/10.1016/j.jtbi.2003.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S0022519303003825},
author = {Alan H Bond},
keywords = {Brain architecture, Perception-action hierarchy, Computational model, Logic programming, Primate social behavior},
abstract = {Experimental evidence has shown that the primate neocortex consists in the main of a set of cortical regions which form a perception hierarchy, an action hierarchy and connections between them. By using a computer science analysis, we develop a computational architecture for the brain in which each cortical region is represented by a computational module with processing and storage abilities. Modules are interconnected according to the connectivity of the corresponding cortical regions. We develop computational principles for designing such a hierarchical and parallel computing system. We demonstrate this approach by proposing a causal functioning model of the brain. We report on results obtained with an implementation of this model. We conclude with a brief discussion of some consequences and predictions of our work.}
}
@article{WEBB2010903,
title = {Troubleshooting assessment: an authentic problem solving activity for it education},
journal = {Procedia - Social and Behavioral Sciences},
volume = {9},
pages = {903-907},
year = {2010},
note = {World Conference on Learning, Teaching and Administration Papers},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2010.12.256},
url = {https://www.sciencedirect.com/science/article/pii/S187704281002361X},
author = {David C. Webb},
keywords = {authentic assessment, computational thinking, computer programming, game design, problem solving, STEM education, technologybased assessment},
abstract = {To evaluate the effectiveness of an instructional unit for game design and computer programming, we designed an authentic assessment with five troubleshooting scenarios. This assessment was completed by 24 middle grades students (age 12 – 14 years) after 10hours of instruction using a visual programming environment. Students successfully completed most of the tasks in 45minutes. Results from the Troubleshooting Assessment demonstrated that students developed sufficient fluency with programming to be able to apply their knowledge to new problems. These results suggest that troubleshooting scenarios can be used to assess student fluency in computer programming and computer-based problem solving.}
}
@article{SALVATORE2024143,
title = {The affective grounds of the mind. The Affective Pertinentization (APER) model},
journal = {Physics of Life Reviews},
volume = {50},
pages = {143-165},
year = {2024},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2024.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S1571064524000903},
author = {Sergio Salvatore and Arianna Palmieri and Raffaele {De Luca Picione} and Vincenzo Bochicchio and Matteo Reho and Maria Rita Serio and Giampaolo Salvatore},
keywords = {Affective Pertinentization model, Affective Landscape, Phase Space of Meaning, Meaning dimensionality},
abstract = {The paper presents the Affective Pertinentization model (APER), a theory of the affect and its role it plays in meaning-making. APER views the affect as the basic form of making sense of reality. It consists of a global, bipolar pattern of neurophysiological activity through which the organism maps the instant-by-instant variation of its environment. Such a pattern of neuropsychological activity is constituted by a plurality of bipolar affective dimensions, each of which maps a component of the environmental variability. The affect has a pluri-componential structure defining a multidimensional affective landscape that foregrounds (i.e., makes pertinent) a certain pattern of facets of the environment (e.g., its pleasantness/unpleasantness) relevant to survival, while backgrounding the others. Doing so, the affect grounds the following cognitive processes. Accordingly, meaning-making can be modeled as a function of the dimensionality of the affective landscape. The greater the dimensionality of the affective landscape, the more differentiated the system of meaning is. Following a brief review of current theories pertaining to the affect, the paper proceeds discussing the APER's core tenets – the multidimensional view of the affect, its semiotic function, and the concepts of Affective Landscape and Phase Space of Meaning. The paper then proceeds deepening the relationship between the APER model and other theories, highlighting how the APER succeeds in framing original conceptualizations of several challenging issues – the intertwinement between affect and sensory modalities, the manner in which the mind constitutes the content of the experience, the determinants of psychopathology, the intertwinement of mind and culture, and the spreading of affective forms of thinking and behaving in society. Finally, the unsolved issues and future developments of the model are briefly envisaged.}
}
@article{LITTLE20031285,
title = {The computational science major at SUNY Brockport},
journal = {Future Generation Computer Systems},
volume = {19},
number = {8},
pages = {1285-1292},
year = {2003},
note = {Selected papers from the Workshop on Education in Computational Sciences held at the International Conference on Computational Science},
issn = {0167-739X},
doi = {https://doi.org/10.1016/S0167-739X(03)00086-4},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X03000864},
author = {Leigh J. Little},
keywords = {Computational science, Education, Undergraduate, Graduate},
abstract = {The field of computational science is a recent addition to academic study. While the content of such an education is generally agreed upon, effective methods for imparting this knowledge are still being investigated. This paper describes the current state of the computational science degree programs at SUNY Brockport and the successes that have been obtained. Issues relating to the implementation of such programs in the context of a small, liberal arts college are also discussed.}
}
@article{OLTETEANU201615,
title = {Object replacement and object composition in a creative cognitive system. Towards a computational solver of the Alternative Uses Test},
journal = {Cognitive Systems Research},
volume = {39},
pages = {15-32},
year = {2016},
note = {From human to artificial cognition (and back): new perspectives of cognitively inspired AI systems},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2015.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S1389041716000073},
author = {Ana-Maria Olteţeanu and Zoe Falomir},
keywords = {Cognitive systems, Computational creativity, Creative object replacement, Creative object composition, Alternative uses test},
abstract = {In creative problem solving, humans perform object replacement and object composition to improvise tools in order to carry out tasks in everyday situations. In this paper, an approach to perform Object Replacement and Object Composition (OROC) inside a Creative Cognitive framework (CreaCogs) is proposed. Multi-feature correspondence is used to define similarity between objects in an everyday object domain. This enables the cognitive system OROC to perform creative replacement of objects and creative object composition. The generative properties of OROC are analysed and proof-of-concept experiments with OROC are reported. An evaluation of the results is carried out by human judges and compared to human performance in the Alternative Uses Test.}
}
@article{DEOLIVEIRA2023133,
title = {Transdisciplinary competency-based development in the process engineering subjects: A case study in Brazil},
journal = {Education for Chemical Engineers},
volume = {44},
pages = {133-154},
year = {2023},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2023.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S1749772823000246},
author = {Roger Assis {de Oliveira} and Giovanna Milena Borges Hipólito and Ricardo de Freitas Fernandes Pontes and Paulo Henrique Nascimento Ferreira and Ricardo Sanz Moreira and José Plácido and Carlos Alexandre Moreira da Silva and Laura Plazas Tovar},
keywords = {Chemical engineering education, Competency, Learning outcome, Lifelong learning, Process systems engineering, Sustainability},
abstract = {Recently, the Brazilian Ministry of Education issued New Curriculum Guidelines for engineering programs. This paper encompasses a pedagogical intervention reflecting our efforts to incorporate these new guidelines into our engineering program. Specifically, this work has led to the competency-based rework of the following subjects offered in the Chemical Engineering Undergraduate Program at the Federal University of São Paulo (Unifesp): I) Modeling and Systems Analysis; II) Synthesis and Optimization of Chemical Processes; III) Chemical Process Simulation; IV) Process Analysis and Control; V) Chemical Process Design; and VI) Chemical Installations Design. Thirteen transdisciplinary competencies are integrated throughout the six subjects. Students highlighted design thinking, lifelong knowledge/learning, openness to act autonomously, teamwork, communication, and cooperation as essential qualities. Moreover, the greater focus on the process systems engineering approach involving the analysis, synthesis, design, and control of sustainable processes helps chemical engineers to face new challenges using renewable resources.}
}
@article{JAGER2014117,
title = {Thinking outside the channel: Timing pulse flows to benefit salmon via indirect pathways},
journal = {Ecological Modelling},
volume = {273},
pages = {117-127},
year = {2014},
issn = {0304-3800},
doi = {https://doi.org/10.1016/j.ecolmodel.2013.11.007},
url = {https://www.sciencedirect.com/science/article/pii/S0304380013005437},
author = {Henriette I. Jager},
keywords = {Reservoir releases, Environmental flows, Natural flow paradigm, Optimization, Quantile model, Pulse flows},
abstract = {Using models to represent relationships between flow and fishes has important practical applications for managing reservoir releases. Attempts to model such relationships often neglect indirect mechanisms by which flow influences fish. For example, growth of salmon juveniles is measurably faster when flows inundate floodplain and promote higher production of invertebrate prey, but out-of-channel flows have not yet been incorporated into models. The QUANTUS model developed here represents indirect linkages between flow and freshwater survival, mediated by temperature and prey availability, for fall Chinook salmon (Oncorhynchus tshawytscha). Quantiles of spawning time and place were used to define cohorts of salmon in a regulated Central Valley, California river. Survival of these quantile-cohorts was simulated through incubation, juvenile growth, and eventual downstream migration. A genetic algorithm was used to optimize the seasonal timing of pulse flows. Simulated survival was highest for flow regimes that provided a modest, temperature-moderating pulse flow in early summer and, for wetter years, a second, larger pulse of over-bank flow in late winter. For many rivers of the Pacific coast that support fall Chinook salmon, the thermal window of opportunity for spawning and rearing is narrow. Optimized flows made the most of this window by providing access to accelerated juvenile growth and early survival in floodplain habitat, a result that should be verified with field experiments. Timing of optimized pulse flows differed in some respects from the region's natural hydrograph, dominated by spring runoff. This suggests that understanding the mechanisms by which flow influences fishes can be important when shaping flows in the changed context of a regulated river.}
}
@incollection{VASSILOPOULOS2020349,
title = {10 - Computational intelligence methods for the fatigue life modeling of composite materials},
editor = {Anastasios P. Vassilopoulos},
booktitle = {Fatigue Life Prediction of Composites and Composite Structures (Second Edition)},
publisher = {Woodhead Publishing},
edition = {Second Edition},
pages = {349-383},
year = {2020},
series = {Woodhead Publishing Series in Composites Science and Engineering},
isbn = {978-0-08-102575-8},
doi = {https://doi.org/10.1016/B978-0-08-102575-8.00010-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780081025758000103},
author = {Anastasios P. Vassilopoulos and Efstratios F. Georgopoulos},
keywords = {Fatigue, Composites, Artificial neural network, Genetic programming, ANFIS, S-N curves},
abstract = {Novel computational methods such as artificial neural networks, adaptive neuro-fuzzy inference systems and genetic programming are used in this chapter for the modeling of the nonlinear behavior of composite laminates subjected to constant amplitude loading. The examined computational methods are stochastic nonlinear regression tools, and can therefore be used to model the fatigue behavior of any material, provided that sufficient data are available for training. They are material independent methods that simply follow the trend of the available data, in each case giving the best estimate of their behavior. Application on a wide range of experimental data gathered after fatigue testing glass/epoxy and glass/polyester laminates proved that their modeling ability compares favorably with, and is to some extent superior to, other modeling techniques.}
}
@article{DELORME2019133,
title = {When the meditating mind wanders},
journal = {Current Opinion in Psychology},
volume = {28},
pages = {133-137},
year = {2019},
note = {Mindfulness},
issn = {2352-250X},
doi = {https://doi.org/10.1016/j.copsyc.2018.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S2352250X1830157X},
author = {Arnaud Delorme and Tracy Brandmeyer},
abstract = {The capacity for thought and the ability to assemble and manipulate concepts are cognitive features unique to humans. Spontaneous thoughts often occur when we are engaged in attention-demanding tasks, with an increased frequency predicting negative affect. Meditation does not require thinking; however, thinking occurs naturally during meditation. We develop the hypothesis that chronic thinking associated with strong emotional arousal during meditation practice might be detrimental to meditation practice and well-being. One goal of meditation is to identify the arousal of emotions and thoughts, and remain equanimous with them. Over time, meditation may help dampen the attention-grabbing power of these thoughts both during practice and in daily life, which may consequently help deepen meditation practice. However, when meditators fail to remain equanimous, the effects of these thoughts may be deleterious. We discuss how this hypothesis may help guide future research on meditation.}
}
@article{BRIMKOV2005233,
title = {Exact Image Reconstruction from a Single Projection through Real Computation},
journal = {Electronic Notes in Discrete Mathematics},
volume = {20},
pages = {233-246},
year = {2005},
note = {Proceedings of the Workshop on Discrete Tomography and its Applications},
issn = {1571-0653},
doi = {https://doi.org/10.1016/j.endm.2005.05.066},
url = {https://www.sciencedirect.com/science/article/pii/S1571065305050705},
author = {Valentin E. Brimkov and Reneta P. Barneva},
keywords = {Discrete tomography, Computed tomography, Algebraic computation model, Algebraic complexity, Linear Diophantine equation},
abstract = {In Discrete Tomography one aims to reconstruct a function (image) with a known discrete range from its projection along certain directions. By modern electron-microscopy techniques, one can count the number of atoms laying on a line representing, e.g., an X-ray. The so obtained data is used in the integer programming formulation. However, in real applications the size of the problem, that is well-known to be NP-hard, is so large that no method seems to be applicable to it. Other natural restrictions can make the problem even harder. In an attempt to avoid such kind of difficulties, we present an alternative approach to the problem. With this, we also aim to shed more light on the theoretical limitations for efficient computation in Discrete Tomography. Our approach is based on image reconstruction from a single projection, under the hypothesis that all computations take place in an algebraic computation model. In terms of computational efficiency, the proposed algorithm is significantly superior to the known algorithms for the problem. We also discuss on the possibilities for practical implementation of our method.}
}
@article{GOLDBERG2011171,
title = {Computational physiology of the neural networks of the primate globus pallidus: function and dysfunction},
journal = {Neuroscience},
volume = {198},
pages = {171-192},
year = {2011},
note = {Function and Dysfunction of the Basal Ganglia},
issn = {0306-4522},
doi = {https://doi.org/10.1016/j.neuroscience.2011.08.068},
url = {https://www.sciencedirect.com/science/article/pii/S0306452211010268},
author = {J.A. Goldberg and H. Bergman},
keywords = {basal ganglia, primate, neurons, correlations, oscillations, Parkinson's disease},
abstract = {The dorsal pallidal complex is made up of the external and internal segments of the globus pallidus (GPe and GPi respectively). It is part of the main axis of the basal ganglia (BG) that connects the thalamo-cortical networks to the BG input stages (striatum and subthalamic nucleus) and continues directly, and indirectly through the GPe, to the BG output stages (GPi and substantia nigra reticulata). Here we review the unique anatomical and physiological features of the pallidal complex and argue that they support the main computational goal of the BG main axis (actor); namely, a behavioral policy that maximizes future cumulative gains and minimizes costs. The three mono-layer competitive networks of the BG main axis flexibly extract relevant features from the current state of the thalamo-cortical activity to control current (ongoing) and future actions. We hypothesize that the striatal and the subthalamic projections neurons act as mono-stable integrators (class I excitability) and the in-vivo pallidal neurons act as bi-stable resonators (class II excitability). GPe neurons exhibit pausing behavior because their membrane potential lingers in the vicinity of an unstable equilibrium point and bi-stability, and these pauses enable a less-greedy exploratory behavioral policy. Finally, degeneration of midbrain dopaminergic neurons and striatal dopamine depletion (as in Parkinson's disease) lead to augmentation of striatal excitability and competitive dynamics. As a consequence the pallidal network, whose elements tend to synchronize as a result of their bi-stable resonance behavior, shifts from a Poissonian-like non-correlated to synchronous oscillatory discharge mode. This article is part of a Special Issue entitled: Function and Dysfunction of the Basal Ganglia.}
}
@article{EKINS201165,
title = {Computational databases, pathway and cheminformatics tools for tuberculosis drug discovery},
journal = {Trends in Microbiology},
volume = {19},
number = {2},
pages = {65-74},
year = {2011},
issn = {0966-842X},
doi = {https://doi.org/10.1016/j.tim.2010.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0966842X10001939},
author = {Sean Ekins and Joel S. Freundlich and Inhee Choi and Malabika Sarker and Carolyn Talcott},
abstract = {We are witnessing the growing menace of both increasing cases of drug-sensitive and drug-resistant Mycobacterium tuberculosis strains and the challenge to produce the first new tuberculosis (TB) drug in well over 40 years. The TB community, having invested in extensive high-throughput screening efforts, is faced with the question of how to optimally leverage these data to move from a hit to a lead to a clinical candidate and potentially, a new drug. Complementing this approach, yet conducted on a much smaller scale, cheminformatic techniques have been leveraged and are examined in this review. We suggest that these computational approaches should be optimally integrated within a workflow with experimental approaches to accelerate TB drug discovery.}
}
@article{HAMED2018112,
title = {Quantitative modeling of gene networks of biological systems using fuzzy Petri nets and fuzzy sets},
journal = {Journal of King Saud University - Science},
volume = {30},
number = {1},
pages = {112-119},
year = {2018},
issn = {1018-3647},
doi = {https://doi.org/10.1016/j.jksus.2017.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S1018364716307819},
author = {Raed I. Hamed},
keywords = {FPNs, Fuzzy sets, Uncertain data, GRNs, Quantitative modeling},
abstract = {Quantitative demonstrating of organic frameworks has turned into an essential computational methodology in the configuration of novel and investigation of existing natural frameworks. Be that as it may, active information that portrays the framework's elements should be known keeping in mind the end goal to get pertinent results with the routine displaying strategies. This information is frequently robust or even difficult to get. Here, we exhibit a model of quantitative fuzzy rational demonstrating approach that can adapt to obscure motor information and hence deliver applicable results despite the fact that dynamic information is fragmented or just dubiously characterized. Besides, the methodology can be utilized as a part of the blend with the current cutting edge quantitative demonstrating strategies just in specific parts of the framework, i.e., where the data are absent. The contextual analysis of the methodology suggested in this paper is performed on the model of nine-quality genes. We propose a kind of FPN model in light of fuzzy sets to manage the quantitative modeling of biological systems. The tests of our model appear that the model is practical and entirely powerful for information impersonation and thinking of fuzzy expert frameworks.}
}
@article{BLOOM2001453,
title = {Novel thinking},
journal = {Trends in Cognitive Sciences},
volume = {5},
number = {10},
pages = {453-454},
year = {2001},
issn = {1364-6613},
doi = {https://doi.org/10.1016/S1364-6613(00)01758-7},
url = {https://www.sciencedirect.com/science/article/pii/S1364661300017587},
author = {Paul Bloom}
}
@incollection{ZOHURI202225,
title = {Chapter 2 - A general approach to business resilience system (BRS)},
editor = {Bahman Zohuri and Farhang Mossavar-Rahmani and Farahnaz Behgounia},
booktitle = {Knowledge is Power in Four Dimensions: Models to Forecast Future Paradigm},
publisher = {Academic Press},
pages = {25-57},
year = {2022},
isbn = {978-0-323-95112-8},
doi = {https://doi.org/10.1016/B978-0-323-95112-8.00003-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780323951128000039},
author = {Bahman Zohuri and Farhang Mossavar-Rahmani and Farahnaz Behgounia},
keywords = {Artificial intelligence, Data analysis and information, Market and market share, Predictive analytics, Super artificial intelligence},
abstract = {The business resilience system (BRS) with its risk atom and processing data point is based on fuzzy logic and cloud computation in real time. Its purpose and objectives define a clear set of expectations for organizations and enterprises, so their network system and supply chain are totally resilient and protected against cyberattacks, man-made threats, and natural disasters. These enterprises include financial, organizational, homeland security, and supply chain operations with multipoint manufacturing across the world. Market share and marketing advantages are expected to result from the implementation of the system. The collected information and defined objectives provide the basis to monitor and analyze the data through cloud computation and will guarantee the success of their survivability against any unexpected threats. Putting this kind of operation in place allows the executive and stakeholders within those organizations and enterprises to make the right decision when encountering threats that interrupt their normal day-to-day operations, as well as, in cases such as defense and homeland security, to predict the next move of an adversary. Given the fact that the BRS, as part of its functionality, processes the incoming data and information if not real time, then near real time with the help of superartificial intelligence in place, this gives the stakeholder an edge against and threats as well as predicting issues with operational intelligence. Artificial intelligence (AI) is one of those technologies that seem to be expanding in every direction. This technology will take center stage at Think 2018. Resilience thinking is inevitably systems thinking, at least as much as sustainable development is. In fact, “when considering systems of humans and nature (social-ecological systems), it is important to consider the system as a whole.” The term “resilience” originated in the 1970s in the field of ecology from the research of C.S. Holling, who defined resilience as “a measure of the persistence of systems and of their ability to absorb change and disturbance and still maintain the same relationships between populations or state variables.” In short, resilience is best defined as “the ability of a system to absorb disturbances and still retain its basic function and structure.” In this chapter, we explain the BRS and how it works. Please note that the with minor editing and manipulation, the materials presented in this chapter have been borrowed from the book published from Zohuri and Moghaddam10 with permission from both authors and publisher as well.}
}
@article{IWENDI20225016,
title = {Combined power generation and electricity storage device using deep learning and internet of things technologies},
journal = {Energy Reports},
volume = {8},
pages = {5016-5025},
year = {2022},
issn = {2352-4847},
doi = {https://doi.org/10.1016/j.egyr.2022.02.304},
url = {https://www.sciencedirect.com/science/article/pii/S2352484722005510},
author = {Celestine Iwendi and Gai-Ge Wang},
keywords = {Energy storage, Machine learning, Internet of things, Fuzzy logic, Electricity storage device, Power generation},
abstract = {In microgrids, residential customers play a significant part in the operation. An alternative to client administration should be to utilize smart houses to deal with demand and implement demand responsiveness measures. A power generation and electricity storage device (PGESD) for next-generation technologies is proposed in this article. The current research provides an intelligent home load control system that promotes reaction to demand thinking about this circumstance. The technology is adapted to scenarios where users can charge fluctuating electric power and transmit microgeneration devices. The suggested system utilizes deep learning technology and a fuzzy logic model for better computation and lesser complexity. The choice process involves monitoring environmental information, power production, and battery storage. This article proposes a next-generation power generation and electricity storage device (PGESD). To create Smart Buildings and Microgrids, the proposed system employs technologies and techniques that have become increasingly important. With a precision and accuracy ratio of 89% and 92%, respectively, the proposed PGESD method yields precise numerical results.}
}
@incollection{HOUSE2018335,
title = {Chapter 14 - Comments on Computational Methods},
editor = {J.E. House},
booktitle = {Fundamentals of Quantum Mechanics (Third Edition)},
publisher = {Academic Press},
edition = {Third Edition},
pages = {335-347},
year = {2018},
isbn = {978-0-12-809242-2},
doi = {https://doi.org/10.1016/B978-0-12-809242-2.00014-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128092422000140},
author = {J.E. House},
keywords = {Basis set, Slater-type orbitals, Gaussian orbitals, Extended Hückel, Wolfsberg-Helmoltz approximation, Ballhausen-Gray approximation, Cusachs' approximation, Self-consistent field, Density functional theory},
abstract = {There are numerous types of molecular orbital calculations that are routinely performed. One of the early versions is the extended Hückel method that begins with the approach used in the Hückel method, but with the overlap and exchange integrals (approximated by the Wolfsberg-Helmholtz, Ballhausen-Gray, or Cusachs' method) included. A more robust type of calculation is that in which an electron is presumed to move in a field generated by the nucleus and other electrons. A trial wave function with some adjustable parameter(s) is taken, and the energy calculated. The wave function improves and the calculations continue until there is no additional improvement (i.e., a “self-consistent field” has been obtained). There are numerous variations of this approach that differ in the trial wave function chosen, extent of electron-electron interaction included, etc. Density functional theory is a newer approach that uses less computational capacity. These types of molecular orbital calculations are surveyed briefly in this chapter.}
}
@article{ZHANG2022116187,
title = {Tri-level attribute reduction in rough set theory},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116187},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116187},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421015050},
author = {Xianyong Zhang and Yiyu Yao},
keywords = {Attribute reduction, Three-way decision, Tri-level analysis, Object-specific attribute reducts, Tri-level attribute reducts, Granular computing},
abstract = {Attribute reduction serves as a pivotal topic of rough set theory for data analysis. The ideas of tri-level thinking from three-way decision can shed new light on three-level attribute reduction. Existing classification-specific and class-specific attribute reducts consider only macro-top and meso-middle levels. This paper introduces a micro-bottom level of object-specific reducts. The existing two types of reducts apply to the global classification with all objects and a local class with partial objects, respectively. The new type applies to an individual object. These three types of reducts constitute tri-level attribute reducts. Their development and hierarchy are worthy of systematical explorations. Firstly, object-specific reducts are defined by object consistency from dependency, and they improve both classification-specific and class-specific reducts. Secondly, tri-level reducts are unified by tri-level consistency. Hierarchical relationships between object-specific reducts and class-specific, classification-specific reducts are analyzed, and relevant connections of three-way classifications of attributes are given. Finally, tri-level reducts are systematically analyzed, and two approaches, i.e., the direct calculation and hierarchical transition, are suggested for constructing a specific reduct. We build a framework of tri-level thinking and analysis of attribute reduction to enrich three-way granular computing. Tri-level reducts lead to the sequential development and hierarchical deepening of attribute reduction, and their results profit intelligence processing and system reasoning.}
}
@article{BELLEMAREPEPIN2022105103,
title = {Processing visual ambiguity in fractal patterns: Pareidolia as a sign of creativity},
journal = {iScience},
volume = {25},
number = {10},
pages = {105103},
year = {2022},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2022.105103},
url = {https://www.sciencedirect.com/science/article/pii/S258900422201375X},
author = {Antoine Bellemare-Pepin and Yann Harel and Jordan O’Byrne and Geneviève Mageau and Arne Dietrich and Karim Jerbi},
keywords = {Cognitive neuroscience, Social sciences, Psychology},
abstract = {Summary
Creativity is a highly valued and beneficial skill that empirical research typically probes using “divergent thinking” (DT) tasks such as problem solving and novel idea generation. Here, in contrast, we examine the perceptual aspect of creativity by asking whether creative individuals are more likely to perceive recognizable forms in ambiguous stimuli –a phenomenon known as pareidolia. To this end, we designed a visual task in which participants were asked to identify as many recognizable forms as possible in cloud-like fractal images. We found that pareidolic perceptions arise more often and more rapidly in highly creative individuals. Furthermore, high-creatives report pareidolia across a broader range of image contrasts and fractal dimensions than do low creatives. These results extend the established body of work on DT by introducing divergent perception as a complementary manifestation of the creative mind, thus clarifying the perception-creation link while opening new paths for studying creative behavior in humans.}
}
@article{BROCAS2021105366,
title = {Value computation and modulation: A neuroeconomic theory of self-control as constrained optimization},
journal = {Journal of Economic Theory},
volume = {198},
pages = {105366},
year = {2021},
issn = {0022-0531},
doi = {https://doi.org/10.1016/j.jet.2021.105366},
url = {https://www.sciencedirect.com/science/article/pii/S0022053121001836},
author = {Isabelle Brocas and Juan D. Carrillo},
keywords = {Neuroeconomic theory, Multiple brain systems, Self-control, Cue-triggered behavior, Self-regulation},
abstract = {We develop a theory based on the evidence reported in Hare et al. (2009) to explain consumption of goods that feature a low-order attribute (e.g., taste) and a high-order attribute (e.g., health). One brain system with access to the low-order attribute computes the goal value of consumption while another brain system can modulate this value, at a cost, by transmitting information regarding the high-order attribute. We determine the optimal modulation and consumption strategy as a function of the cost of information transmission and the environment. We show that in healthy environments, modulation is used to signal surprisingly unhealthy goods so as to trigger abstinence when consumption would ordinarily occur. Conversely, in unhealthy environments, modulation is used to signal surprisingly healthy choices so as to trigger consumption when abstinence would ordinarily occur. From an outside perspective, individuals may appear to under-regulate their choices (self-indulgence) but also to over-regulate them (self-restraint). Both modulation and decisions are affected by factors orthogonal to the decision problem. In particular, taxing executive functions results in less modulation and more inefficient behavior. Finally, the model can shed light on issues related to eating disorders, present-biased preferences, habit formation and compulsive behavior.}
}
@article{PEZZANO2024100078,
title = {Are we done with (Wordy) manifestos? Towards an introverted digital humanism},
journal = {Journal of Responsible Technology},
volume = {17},
pages = {100078},
year = {2024},
issn = {2666-6596},
doi = {https://doi.org/10.1016/j.jrt.2024.100078},
url = {https://www.sciencedirect.com/science/article/pii/S2666659624000040},
author = {Giacomo Pezzano},
keywords = {Mediatic turn, Philosophy of technology, Learning, Book, Video game},
abstract = {Beginning with a reconstruction of the anthropological paradigms underlying The Vienna Manifesto and The Onlife Manifesto (§ 1.1), this paper distinguishes between two possible approaches to digital humanism: an extroverted one, principally engaged in finding a way to humanize digital technologies, and an introverted one, pointing instead attention to how digital technologies can re-humanize us, particularly our “mindframe” (§ 1.2). On this basis, I stress that if we take seriously the consequences of the “mediatic turn”, according to which human reason is finally recognized as mediatically contingent (§ 2.1), then we should accept that just as the book created the poietic context for the development of traditional humanism and its “bookish” idea of private and public reason, so too digital psycho-technologies today provide the conditions for the rise of a new humanism (§ 2.2). I then discuss the possible humanizing potential of digital simulated worlds: I compare the symbolic-reconstructive mindset to the sensorimotor mindset (§ 3.1), and I highlight their respective mediological association with the book and the video game, advocating for the peculiar thinking and reasoning affordances now offered by the new digital psycho-technologies (§ 3.2).}
}
@article{CHIN20201054,
title = {Rethinking Cancer Immunotherapy by Embracing and Engineering Complexity},
journal = {Trends in Biotechnology},
volume = {38},
number = {10},
pages = {1054-1065},
year = {2020},
note = {Special Issue: Therapeutic Biomanufacturing},
issn = {0167-7799},
doi = {https://doi.org/10.1016/j.tibtech.2020.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167779920301244},
author = {Matthew H.W. Chin and Eileen Gentleman and Marc-Olivier Coppens and Richard M. Day},
keywords = {bioengineering, complex systems, holism, immunotherapy, process intensification},
abstract = {The meteoric rise of cancer immunotherapy in the past decade has led to promising treatments for a number of hard-to-treat malignancies. In particular, adoptive T cell therapy has recently reached a major milestone with two products approved by the US FDA. However, the inherent complexity of cell-based immunotherapies means that their manufacturing time, cost, and controllability limit their effectiveness and geographic reach. One way to address these issues may lie in complementing the dominant, reductionistic mentality in modern medicine with complex systems thinking. In this opinion article, we identify key concepts from complexity theory to address manufacturing challenges in cell-based immunotherapies and raise the possibility of a unifying framework upon which future bioprocessing strategies may be designed.}
}
@article{JANES200673,
title = {A biological approach to computational models of proteomic networks},
journal = {Current Opinion in Chemical Biology},
volume = {10},
number = {1},
pages = {73-80},
year = {2006},
note = {Proteomics and genomics},
issn = {1367-5931},
doi = {https://doi.org/10.1016/j.cbpa.2005.12.016},
url = {https://www.sciencedirect.com/science/article/pii/S1367593105001687},
author = {Kevin A Janes and Douglas A Lauffenburger},
abstract = {Computational modeling is useful as a means to assemble and test what we know about proteins and networks. Models can help address key questions about the measurement, definition and function of proteomic networks. Here, we place these biological questions at the forefront in reviewing the computational strategies that are available to analyze proteomic networks. Recent examples illustrate how models can extract more information from proteomic data, test possible interactions between network proteins and link networks to cellular behavior. No single model can achieve all these goals, however, which is why it is critical to prioritize biological questions before specifying a particular modeling approach.}
}
@article{YANG2023106838,
title = {Neuromorphic electronics for robotic perception, navigation and control: A survey},
journal = {Engineering Applications of Artificial Intelligence},
volume = {126},
pages = {106838},
year = {2023},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2023.106838},
url = {https://www.sciencedirect.com/science/article/pii/S0952197623010229},
author = {Yi Yang and Chiara Bartolozzi and Haiyan H. Zhang and Robert A. Nawrocki},
keywords = {Neuromorphic electronics, Organic and flexible electronic materials, Neuromorphic robot, Perception, Navigation, Control, SLAM, Path planning},
abstract = {Neuromorphic electronics have great potential in the emulation of the sensory, cognitive, self-learning, and actuating functions of robots. While typically implemented in rigid silicon, emerging technologies in organic and flexible electronic materials have also led to tremendous advances in the development of neuromorphic perception systems. However, a comprehensive review of the contribution/role of organic neuromorphic electronics for robotic applications is still missing. This review presents advancements in silicon-based and organic neuromorphic electronics for intelligent robot development, focusing on perception, navigation, and learning-based control. Organic synaptic devices, along with dynamic vision sensors, enable diverse forms of sensory-enabled computational perception, offering tunability, stability, low power consumption, and conformal substrates. Integration of simultaneous localization and mapping techniques and path planning algorithms empowers robots to efficiently navigate, build accurate maps, and make informed decisions. Different learning algorithms and their hardware implementations in neuromorphic robotic control are explored, enabling robots to learn and adapt to dynamic environments. The review highlights the potential of neuromorphic electronics for sensing, thinking, and acting in advanced robotic systems. Organic, inorganic, and hybrid materials are discussed for implementing perception, navigation, and control in robots. Future research directions in the field are outlined. Leveraging various neuromorphic electronics unlocks the full potential of intelligent robotic systems for diverse applications.}
}
@article{CHEN2005121,
title = {Computational intelligence in economics and finance: Carrying on the legacy of Herbert Simon},
journal = {Information Sciences},
volume = {170},
number = {1},
pages = {121-131},
year = {2005},
note = {Computational Intelligence in Economics and Finance},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2003.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S0020025503004444},
author = {Shu-Heng Chen},
keywords = {Computational intelligence, Artificial intelligence, Agent-based computational economics, Autonomous agents, Stock price-volume relation, Micro-macro relation},
abstract = {This is an editorial guide for the special issue on computational intelligence (CI) in economics and finance. A historical introduction to the background is given. This research paradigm is traced back to Herbert Simon, who, as a founder of artificial intelligence, pioneered the applications of AI to economics. The move from the classical AI to CI indicates a continuation of the legacy of Herbert Simon. Computational intelligence has proved to be a constructive foundation for economics. In responding to what Herbert Simon referred as procedural rationality, our study of bounded rationality has been enriched by bringing autonomous agents into the economic analysis.}
}
@article{GOODSELL2020472,
title = {Art and Science of the Cellular Mesoscale},
journal = {Trends in Biochemical Sciences},
volume = {45},
number = {6},
pages = {472-483},
year = {2020},
issn = {0968-0004},
doi = {https://doi.org/10.1016/j.tibs.2020.02.010},
url = {https://www.sciencedirect.com/science/article/pii/S0968000420300566},
author = {David S. Goodsell and Arthur J. Olson and Stefano Forli},
keywords = {mesoscale modeling, integrative structural biology, drug discovery, drug design, cell structure, cell function, molecular structure, molecular function},
abstract = {Experimental information from microscopy, structural biology, and bioinformatics may be integrated to build structural models of entire cells with molecular detail. This integrative modeling is challenging in several ways: the intrinsic complexity of biology results in models with many closely packed and heterogeneous components; the wealth of available experimental data is scattered among multiple resources and must be gathered, reconciled, and curated; and computational infrastructure is only now gaining the capability of modeling and visualizing systems of this complexity. We present recent efforts to address these challenges, both with artistic approaches to depicting the cellular mesoscale, and development and application of methods to build quantitative models.}
}
@article{AMADORHIDALGO2021103694,
title = {Cognitive abilities and risk-taking: Errors, not preferences},
journal = {European Economic Review},
volume = {134},
pages = {103694},
year = {2021},
issn = {0014-2921},
doi = {https://doi.org/10.1016/j.euroecorev.2021.103694},
url = {https://www.sciencedirect.com/science/article/pii/S0014292121000477},
author = {Luis Amador-Hidalgo and Pablo Brañas-Garza and Antonio M. Espín and Teresa García-Muñoz and Ana Hernández-Román},
keywords = {Decision making under uncertainty, Cognitive abilities, Online experiment, Risk and loss aversion, Factor analysis},
abstract = {There is an intense debate whether risk-taking behavior is partially driven by cognitive abilities. The critical issue is whether choices arising from subjects with lower cognitive abilities are more likely driven by errors or lack of understanding than pure preferences for risk. The latter implies that the often-argued link between risk preferences and cognitive abilities (a common finding is that abilities relate negatively to risk aversion and positively to loss aversion) might be a spurious correlation. This experiment reports evidence from a sample of 556 participants who made choices in two risk-related tasks and completed three cognitive tasks, all with real monetary incentives: number-additions (including incentive-compatible expected number of correct additions), the Cognitive Reflection Test (to measure analytical/reflective thinking) and the Remote Associates Test (for convergent thinking). Results are unambiguous: none of our cognition measures plays any systematic role on risky decision making. Using structural equation modeling and factor analysis, we show that cognitive abilities are negatively associated with noisy, inconsistent choices and this effect may make higher ability individuals appear to be less risk averse and more loss averse. Yet we show that errors are more likely to appear when the two payoffs in a given decision exhibit similar probability. Therefore, our results suggest that failing to account for noisy decision making might have led to erroneously inferring a correlation between cognitive abilities and risk preferences in previous studies.}
}

@article{SUPPES2004457,
title = {Semantic computations of truth based on associations already learned},
journal = {Journal of Applied Logic},
volume = {2},
number = {4},
pages = {457-467},
year = {2004},
note = {CMSRA},
issn = {1570-8683},
doi = {https://doi.org/10.1016/j.jal.2004.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S1570868304000461},
author = {Patrick Suppes and Jean-Yves Béziau},
keywords = {Truth, Computaton, Empirical statements, Associative networks, Spreading activation},
abstract = {This article sets forth a detailed theoretical proposal of how the truth of ordinary empirical statements, often atomic in form, is computed. The method of computation draws on psychological concepts such as those of associative networks and spreading activation, rather that the concepts of philosophical or logical theories of truth. Axioms for a restricted class of cases are given, as well as some detailed examples.}
}
@article{WANG20098093,
title = {A computational narrative construction method with applications in organizational learning of social service organizations},
journal = {Expert Systems with Applications},
volume = {36},
number = {4},
pages = {8093-8102},
year = {2009},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2008.10.035},
url = {https://www.sciencedirect.com/science/article/pii/S0957417408007495},
author = {W.M. Wang and C.F. Cheung and W.B. Lee and S.K. Kwok},
keywords = {Narrative construction, Knowledge management, Concept mapping, Knowledge-based systems, Computational, Reflective learning, Narrative simulation},
abstract = {Acquisition of knowledge must be interwoven with the process of applying it. However, traditional training methods which provide abstract knowledge have shown ineffective for gaining experience of the work. In order to solve this problem, more and more researchers have included narrative in simulation, which is known as narrative simulation. By providing the narratives, participants recognize the choices, decisions, and experience that lead to the consequences of those decisions. It has been proven that narrative simulation is very useful in facilitating in-depth learning and reflective learning. However, conventional methods of data collection and narrative construction for narrative simulation are labor intensive and time consuming. They make use of previous narratives manually and directly. They are inadequate to cope with the fast moving world where knowledge is changing rapidly. In order to provide a way for facilitating the construction of narrative simulation, a novel computational narrative construction method is proposed. By incorporating technologies of knowledge-based system (KBS), computational linguistics, and artificial intelligence (AI), the proposed method provides an efficient and effective way for collecting narratives and automating the construction of narratives. The method converts the unstructured narratives into a structural representation for abstraction and facilitating computing processing. Moreover, it constructs the narratives that combine multiple narratives into a single narrative by applying a forecasting algorithm. The proposed method was successfully implemented in early intervention in mental health care of a social service company in Hong Kong since the case records in that process have structural similarities to narrative. The accuracies of data conversion and predictive function were measured based on recall and precision and encouraging results were obtained. High recall and precision are achieved in the data conversion function, and high recall for the predictive function when new concepts are excluded. The results show that it is possible for converting multiple narratives into a single narrative automatically. Based on the approach, it helps to stimulate knowledge workers to explore new problem solving methods so as to increase the quality of their solutions.}
}
@article{HADIMOGAVI2024100027,
title = {ChatGPT in education: A blessing or a curse? A qualitative study exploring early adopters’ utilization and perceptions},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {2},
number = {1},
pages = {100027},
year = {2024},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2023.100027},
url = {https://www.sciencedirect.com/science/article/pii/S2949882123000270},
author = {Reza {Hadi Mogavi} and Chao Deng and Justin {Juho Kim} and Pengyuan Zhou and Young {D. Kwon} and Ahmed {Hosny Saleh Metwally} and Ahmed Tlili and Simone Bassanelli and Antonio Bucchiarone and Sujit Gujar and Lennart E. Nacke and Pan Hui},
keywords = {Artificial intelligence (AI), Generative AI, ChatGPT, Education, Human-computer interaction (HCI),, Early adopters, Social media, Qualitative research},
abstract = {To foster the development of pedagogically potent and ethically sound AI-integrated learning landscapes, it is pivotal to critically explore the perceptions and experiences of the users immersed in these contexts. In this study, we perform a thorough qualitative content analysis across four key social media platforms. Our goal is to understand the user experience (UX) and views of early adopters of ChatGPT across different educational sectors. The results of our research show that ChatGPT is most commonly used in the domains of higher education, K-12 education, and practical skills training. In social media dialogues, the topics most frequently associated with ChatGPT are productivity, efficiency, and ethics. Early adopters' attitudes towards ChatGPT are multifaceted. On one hand, some users view it as a transformative tool capable of amplifying student self-efficacy and learning motivation. On the other hand, there is a degree of apprehension among concerned users. They worry about a potential overdependence on the AI system, which they fear might encourage superficial learning habits and erode students’ social and critical thinking skills. This dichotomy of opinions underscores the complexity of Human-AI Interaction in educational contexts. Our investigation adds depth to this ongoing discourse, providing crowd-sourced insights for educators and learners who are considering incorporating ChatGPT or similar generative AI tools into their pedagogical strategies.}
}
@article{PAL20133944,
title = {Title Paper: Natural computing: A problem solving paradigm with granular information processing},
journal = {Applied Soft Computing},
volume = {13},
number = {9},
pages = {3944-3955},
year = {2013},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2013.06.026},
url = {https://www.sciencedirect.com/science/article/pii/S1568494613002159},
author = {Sankar K. Pal and Saroj K. Meher},
keywords = {Natural computing, Granular computing, Soft computing, Hybrid model, Decision systems},
abstract = {Natural computing, inspired by biological course of action, is an interdisciplinary field that formalizes processes observed in living organisms to design computational methods for solving complex problems, or designing artificial systems with more natural behaviour. Based on the tasks abstracted from natural phenomena, such as brain modelling, self-organization, self-repetition, self evaluation, Darwinian survival, granulation and perception, nature serves as a source of inspiration for the development of computational tools or systems that are used for solving complex problems. Nature inspired main computing paradigms used for such development include artificial neural networks, fuzzy logic, rough sets, evolutionary algorithms, fractal geometry, DNA computing, artificial life and granular or perception-based computing. Information granulation in granular computing is an inherent characteristic of human thinking and reasoning process performed in everyday life. The present article provides an overview of the significance of natural computing with respect to the granulation-based information processing models, such as neural networks, fuzzy sets and rough sets, and their hybridization. We emphasize on the biological motivation, design principles, application areas, open research problems and challenging issues of these models.}
}
@incollection{LUCHINI2023195,
title = {Chapter 13 - Brain networks of creative cognition},
editor = {Roni Reiter-Palmon and Sam Hunter},
booktitle = {Handbook of Organizational Creativity (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
pages = {195-207},
year = {2023},
isbn = {978-0-323-91840-4},
doi = {https://doi.org/10.1016/B978-0-323-91840-4.00021-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780323918404000219},
author = {Simone Luchini and Roger E. Beaty},
keywords = {Creativity, Default network, Divergent thinking, Executive control network, Functional connectivity, Network neuroscience},
abstract = {In recent years there has been an increasing interest in the role of brain networks supporting creative thinking. This chapter provides a summary of the literature on the network neuroscience of creativity, providing a twofold argument by separately detailing research in domain-general and domain-specific creativity. The first section will concern two main lines of research on domain-general creativity: (1) the neurocognitive mechanisms of creative cognition (how brain networks map onto specific cognitive processes involved in creative thinking), and (2) the individual differences in brain network connectivity and creative ability (how brain networks relate to differences in creative abilities). The second section, on domain-specific creativity, will then consider three domains of artistic creativity: (1) music improvisation, (2) figural creativity, and (3) literary creativity. Throughout this chapter we discuss common themes and shared findings between domain-general and domain-specific creativity. We will then conclude by outlining some of the limitations in the literature and by providing some directions for future research.}
}
@article{PEREZRIVEROL2013134,
title = {Computational proteomics pitfalls and challenges: HavanaBioinfo 2012 Workshop report},
journal = {Journal of Proteomics},
volume = {87},
pages = {134-138},
year = {2013},
issn = {1874-3919},
doi = {https://doi.org/10.1016/j.jprot.2013.01.019},
url = {https://www.sciencedirect.com/science/article/pii/S1874391913000493},
author = {Yasset Perez-Riverol and Henning Hermjakob and Oliver Kohlbacher and Lennart Martens and David Creasy and Jürgen Cox and Felipe Leprevost and Baozhen Paul Shan and Violeta I. Pérez-Nueno and Michal Blazejczyk and Marco Punta and Klemens Vierlinger and Pedro A. Valiente and Kalet Leon and Glay Chinea and Osmany Guirola and Ricardo Bringas and Gleysin Cabrera and Gerardo Guillen and Gabriel Padron and Luis Javier Gonzalez and Vladimir Besada},
keywords = {Bioinformatics workshop, Mass spectrometry, Course, Protein identification, Database searching, Proteomic repositories},
abstract = {The workshop “Bioinformatics for Biotechnology Applications (HavanaBioinfo 2012)”, held December 8–11, 2012 in Havana, aimed at exploring new bioinformatics tools and approaches for large-scale proteomics, genomics and chemoinformatics. Major conclusions of the workshop include the following: (i) development of new applications and bioinformatics tools for proteomic repository analysis is crucial; current proteomic repositories contain enough data (spectra/identifications) that can be used to increase the annotations in protein databases and to generate new tools for protein identification; (ii) spectral libraries, de novo sequencing and database search tools should be combined to increase the number of protein identifications; (iii) protein probabilities and FDR are not yet sufficiently mature; (iv) computational proteomics software needs to become more intuitive; and at the same time appropriate education and training should be provided to help in the efficient exchange of knowledge between mass spectrometrists and experimental biologists and bioinformaticians in order to increase their bioinformatics background, especially statistics knowledge.}
}
@article{SAVIN2021106878,
title = {Free associations of citizens and scientists with economic and green growth: A computational-linguistics analysis},
journal = {Ecological Economics},
volume = {180},
pages = {106878},
year = {2021},
issn = {0921-8009},
doi = {https://doi.org/10.1016/j.ecolecon.2020.106878},
url = {https://www.sciencedirect.com/science/article/pii/S0921800920309484},
author = {Ivan Savin and Stefan Drews and Jeroen {van den Bergh}},
keywords = {Structural topic modelling, Growth-vs-environment debate, Public opinion, Scientific opinion, Green growth},
abstract = {The debate about the relationship between economic growth and environmental sustainability triggers a range of associations. Here we analyze open-ended textual responses of citizens and scientists concerning their associations with the terms “economic growth” and “green growth”. We derive from the responses a number of topics and examine how associations differ across distinct opinion segments of people, namely supporters of Green growth, Agrowth and Degrowth. The results indicate that the general public is more critical of the notion of economic growth than academic researchers. Citizens stress problems of corruption, social inequality, unemployment and poverty, with less variation among the three opinion segments compared to scientists. The latter more strongly emphasize the environmental consequences of economic growth. Concerning associations of scientists with the term “green growth”, we find topics questioning its feasibility to be more likely expressed by Degrowth supporters, while topics stressing the possibility of sustainable economic growth by Green growth supporters. We find that topic polarization is stronger for scientists than citizens. Our results provide further validation for opinion clusters identified in previous studies and uncover additional insights about related views on growth and sustainability.}
}
@incollection{YANG20161,
title = {Chapter 1 - Bio-inspired computation and its applications in image processing: an overview},
editor = {Xin-She Yang and João Paulo Papa},
booktitle = {Bio-Inspired Computation and Applications in Image Processing},
publisher = {Academic Press},
pages = {1-24},
year = {2016},
isbn = {978-0-12-804536-7},
doi = {https://doi.org/10.1016/B978-0-12-804536-7.00001-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128045367000016},
author = {X.-S. Yang and J.P. Papa},
keywords = {algorithm, ant algorithm, artificial neural networks, bee algorithm, bat algorithm, bio-inspired computation, cuckoo search, firefly algorithm, harmony search, particle swarm optimization, metaheuristics, swarm intelligence, support vector machine, signal and image processing},
abstract = {Almost all design problems in the sciences and engineering can be formulated as optimization problems, and many image processing problems can also be related to or formulated as optimization problems. These optimization problems can be solved by optimization techniques. However, these problems are often highly nonlinear and are subject to multiple nonlinear constraints, which makes them very challenging to solve. The further complication to these challenges is the stringent time requirements and high dimensionality, which means that traditional optimization techniques, such as gradient-based methods cannot deal with such kinds of problems well. Recent trends tend to use bio-inspired optimization techniques as a promising alternative, and it is usually combined with traditional methods, especially in the area of image processing. These bio-inspired computational methods are usually based on swarm intelligence and can be very effective in coping with nonlinearity in real-world problems. This chapter presents an overview of bio-inspired computation and its application in image processing, including some current trends and important issues, such as efficiency and time constraints.}
}
@article{OTOOLE2024100080,
title = {Extending human creativity with AI},
journal = {Journal of Creativity},
volume = {34},
number = {2},
pages = {100080},
year = {2024},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2024.100080},
url = {https://www.sciencedirect.com/science/article/pii/S2713374524000062},
author = {Katherine O'Toole and Emőke-Ágnes Horvát},
keywords = {Computational creativity, Generative AI, HCI},
abstract = {The development of generative AI has led to novel ways that technology can be integrated into creative activities. However, this has also raised concerns about how human creators will be affected, and what impact it may have on creative industries. As a result, there has been research into how we can design AI tools that work with human creators, rather than replacing them. In this paper we review approaches utilized to build AI tools that facilitate human creativity and allow users to engage fully and authentically in the creative process. These include leveraging AI models to help us shed light on elements of the creative process, building interfaces that encourage exploration of ideas, and designing technological affordances that can support the development of new creative practices.}
}
@incollection{VANCOUVER2020463,
title = {Chapter 12 - Perceptions of control theory in industrial-organizational psychology: disturbances and counter-disturbances},
editor = {Warren Mansell},
booktitle = {The Interdisciplinary Handbook of Perceptual Control Theory},
publisher = {Academic Press},
pages = {463-501},
year = {2020},
isbn = {978-0-12-818948-1},
doi = {https://doi.org/10.1016/B978-0-12-818948-1.00012-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128189481000125},
author = {Jeffrey B. Vancouver},
keywords = {Control theory, Self-regulation, Self-efficacy, Computational modeling},
abstract = {The history of perceptual control theory's growing influence in the field of Industrial-Organizational Psychology is described. This history began in the early 1980's and included mostly conceptual work that described how control theory concepts might be used to understand applied phenomena. Both conceptual and empirical work on control theory ideas continued throughout the 1990's despite a substantial backlash against the theory by prominent scholars in the field. However, it was conceptual and empirical work in the 21st century that defined its potential integrative value and its theoretical rigor. Moreover, research regarding self-efficacy demonstrated how informal theories of human behavior might be better understood from a control theory perspective. Much of the current work with perceptual control theory involves the construction and testing of computational models that represent the links among perceptual, learning, and thinking modes of self-regulation and control.}
}
@article{KUMAR20224712,
title = {Efficient computational stochastic framework for performance optimization of E-waste management plant},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {34},
number = {8, Part A},
pages = {4712-4728},
year = {2022},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2022.05.018},
url = {https://www.sciencedirect.com/science/article/pii/S1319157822001677},
author = {Naveen Kumar and Deepak Sinwar and Monika Saini and Dinesh Kumar Saini and Ashish Kumar and Manjit Kaur and Dilbag Singh and Heung-No Lee},
keywords = {E-waste management plant, Availability, Maintainability, Genetic Algorithm, Differential Evolution, Particle Swarm Optimization, Markov Birth-Death Process},
abstract = {Purpose
Reliability and maintainability are the key system effectiveness measures in process and manufacturing industries, and treatment plants, especially in E-waste management plants. The present work is proposed with a motto to develop a stochastic framework for the e-waste management plant to optimize its availability integrated with reliability, availability, maintainability, and dependability (RAMD) measures and Markovian analysis to estimate the steady-state availability of the E-waste management plant. In the analysis an effort is also made to identify the best performing algorithm for availability optimization of the e-waste plant.
Methodology
A stochastic model for a particular plant is developed and its availability is optimized using various metaheuristic approaches like a genetic algorithm (GA), particle swarm optimization (PSO), and differential evolutions (DE). The most sensitive component is identified using RAMD methodology while the effect of deviation in various failure and repair rates are observed by the proposed model. The failure and repair rates follow an exponential distribution. All time-dependent random variables are statistically independent.
Originality/Novelties
A novel stochastic model is presented for an e-waste management plant and optimum availability is obtained using metaheuristic approaches. The proposed methodology is not so far discussed in the reliability analysis of process industries.
Findings
The numerical results of the proposed model compared to identify the most efficient algorithm. It is observed that genetic algorithm provides the maximum value (0.92330969) of availability at a population size 2500 after 500 iterations. PSO algorithm attained the maximum value (0.99996744) of availability just after 50 iterations and 100 population size. So, its rate of convergence is faster than GA. The optimum value of availability is 0.99997 using differential evolution after 500 iterations and population size of more than 1000. These findings are very beneficial for system designers.
Practical Implications
The proposed methodology can be utilized to find the reliability measures of other process industries.}
}
@article{HONG2006255,
title = {Bruno Buchberger — A life devoted to symbolic computation},
journal = {Journal of Symbolic Computation},
volume = {41},
number = {3},
pages = {255-258},
year = {2006},
note = {Logic, Mathematics and Computer Science: Interactions in honor of Bruno Buchberger (60th birthday)},
issn = {0747-7171},
doi = {https://doi.org/10.1016/j.jsc.2005.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S0747717105001306},
author = {Hoon Hong and Deepak Kapur and Peter Paule and Franz Winkler and  {Faculty of RISC-Linz}}
}
@article{SAND2022100955,
title = {Three cases that demonstrate how students connect the domains of mathematics and computing},
journal = {The Journal of Mathematical Behavior},
volume = {67},
pages = {100955},
year = {2022},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2022.100955},
url = {https://www.sciencedirect.com/science/article/pii/S0732312322000232},
author = {Odd Petter Sand and Elise Lockwood and Marcos D. Caballero and Knut Mørken},
keywords = {Computing, Modeling, Programming, Thinking and learning, Connections, Undergraduate students},
abstract = {This study uses actor-oriented transfer perspective to investigate different ways in which students make connections across the domains of mathematics and computing. We interview first-year students at the University of Oslo as they work with a set of tutorials that we designed to integrate knowledge from both domains. The cases we present here demonstrate four different types of cross-domain connections: (a) mathematically reproducing the work of a computer program, (b) cyclically improving a program to produce better output, (c) coupling math to output to justify program improvements and (d) coupling math to code to justify program design. We provide rich examples of the ways in which students make these connections and discuss affordances for mathematical learning in this context.}
}
@article{MUKTI2024117407,
title = {Computer aided sketching in the early-stage design of complex vessels},
journal = {Ocean Engineering},
volume = {305},
pages = {117407},
year = {2024},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2024.117407},
url = {https://www.sciencedirect.com/science/article/pii/S0029801824007443},
author = {M.H. Mukti and R.J. Pawling and D.J. Andrews},
abstract = {Various methods have been developed for automated and semi-automated architecture generation in the computer aided ship design processes. The question remains as to how this can speed up the design process without losing the requirement elucidation intent for concept phase. This paper presents a novel approach with a software toolset to develop design and analysis approaches to early stage ship design and provide a sketching tool. This was done by enhancing the user interface and experience of the UCL Network Block Approach to achieve a “thinking sketch” in a way that is “quick” and “fluid” enough to promote inventive and creative sketching comparable to hand sketching. The UCL Network Block Approach draws on the UCL Design Building Block (DBB) approach and uses network methods applied to the synthesis of distributed ship service systems (DS3) and Computer Aided Ship Design (CASD) to expand DS3 definition in early stage ship design. The UCL originated inside-out/DBB approach to sketch driven synthesis has been made translatable to both DBB ship descriptions and ensuring early stage naval architectural “balance”. The proposed approach has been used for the first time successfully to not only carry out a rapid sketching exercise for a naval ship design but also enable quick preliminary analysis of a set of DS3 networks.}
}
@incollection{DIBBLE20061511,
title = {Chapter 31 Computational Laboratories for Spatial Agent-Based Models},
editor = {L. Tesfatsion and K.L. Judd},
series = {Handbook of Computational Economics},
publisher = {Elsevier},
volume = {2},
pages = {1511-1548},
year = {2006},
issn = {1574-0021},
doi = {https://doi.org/10.1016/S1574-0021(05)02031-9},
url = {https://www.sciencedirect.com/science/article/pii/S1574002105020319},
author = {Catherine Dibble},
keywords = {agent-based simulation, computational laboratory, computational social science, computational economics, spatial economics, spatial social science, spatial networks, small-world networks, scale-free networks, synthetic landscape, inference},
abstract = {An agent-based model is a virtual world comprising distributed heterogeneous agents who interact over time. In a spatial agent-based model the agents are situated in a spatial environment and are typically assumed to be able to move in various ways across this environment. Some kinds of social or organizational systems may also be modeled as spatial environments, where agents move from one group or department to another and where communications or mobility among groups may be structured according to implicit or explicit channels or transactions costs. This chapter focuses on the potential usefulness of computational laboratories for spatial agent-based modeling. Speaking broadly, a computational laboratory is any computational framework permitting the exploration of the behaviors of complex systems through systematic and replicable simulation experiments. By that definition, most of the research discussed in this handbook would be considered to be work with computational laboratories. A narrower definition of computational laboratory (or comp lab for short) refers specifically to specialized software tools to support the full range of agent-based modeling and complementary tasks. These tasks include model development, model evaluation through controlled experimentation, and both the descriptive and normative analysis of model outcomes. The objective of this chapter is to explore how comp lab tools and activities facilitate the systematic exploration of spatial agent-based models embodying complex social processes critical for social welfare. Examples include the spatial and temporal coordination of human activities, the diffusion of new ideas or of infectious diseases, and the emergence and ecological dynamics of innovative ideas or of deadly new diseases.}
}
@article{BHADURI2025100723,
title = {Community partnership design of a maker-related camp for underserved youth: Impacts on youths’ present and future learning trajectories},
journal = {International Journal of Child-Computer Interaction},
pages = {100723},
year = {2025},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2025.100723},
url = {https://www.sciencedirect.com/science/article/pii/S2212868925000030},
author = {Srinjita Bhaduri and Mimi Recker and Quentin Biddy and Melissa Rummel},
keywords = {Computational literacies, Maker technologies, 3D modeling and printing, Community partnership, Informal learning, Middle school youth},
abstract = {This paper describes the design of Science, Technology, Engineering, and Mathematics (STEM) maker-related activities offered to middle school youth as part of a free, four-week summer camp. The camp was aimed at academically at-risk youth in a rural, tourism-oriented mountain community with significant income disparities. Guided by an educational model focused on enhancing youths’ present and future interests in and visions of STEM and computing fields, camp activities were collaboratively designed by a community partnership comprised of a local camp provider, the local school district, and researchers. Situating design in a community partnership helped highlight and integrate locally relevant resources, careers, and community opportunities. The paper also reports findings from a study examining how the STEM maker camp activities, which leveraged 3D modeling and printing practices, impacted youths’ perceptions of their disciplinary identity, engagement, and their present and future visions of the relevance of these STEM practices to themselves and their communities. The study also explores design tensions that emerged during the camp design process and identified barriers and opportunities that arose from balancing the needs of each partner, the research team’s focus on youth-centered learning, and the overall program goals.}
}
@article{TESCH2001633,
title = {Applying optimal control theory for elements of quantum computation in molecular systems},
journal = {Chemical Physics Letters},
volume = {343},
number = {5},
pages = {633-641},
year = {2001},
issn = {0009-2614},
doi = {https://doi.org/10.1016/S0009-2614(01)00748-5},
url = {https://www.sciencedirect.com/science/article/pii/S0009261401007485},
author = {Carmen M. Tesch and Lukas Kurtz and Regina {de Vivie-Riedle}},
abstract = {Elements of quantum computation are implemented in a vibrationally excited molecule applying optimal control theory. The two different IR-active modes of acetylene are taken as a two-qubit-system. Optimal control theory is used to design laser pulses that allow transitions within each qubit separately. Calculations for initial state preparation and basic quantum gates are presented.}
}
@article{OLTETEANU201581,
title = {comRAT-C: A computational compound Remote Associates Test solver based on language data and its comparison to human performance},
journal = {Pattern Recognition Letters},
volume = {67},
pages = {81-90},
year = {2015},
note = {Cognitive Systems for Knowledge Discovery},
issn = {0167-8655},
doi = {https://doi.org/10.1016/j.patrec.2015.05.015},
url = {https://www.sciencedirect.com/science/article/pii/S0167865515001609},
author = {Ana-Maria Olteţeanu and Zoe Falomir},
keywords = {Computational creativity, Remote Associates Test, Cognitive systems, Knowledge base, Language corpus, Cognitive modeling},
abstract = {Discovering the processes and types of knowledge organization which are involved in the creative process is a challenge up to this date. Human creativity is usually measured by psychological tests, such as the Remote Associates Test (RAT). In this paper, an approach based on a specific type of knowledge organization and processes which enables automatic solving of RAT queries is implemented (comRAT) as a part of a more general cognitive theoretical framework for creative problem-solving (CreaCogs). This aims to study: (a) whether a convergence process can be used to solve such queries and (b) if frequency of appearance of the test items in language data may influence knowledge association or discovery in solving such problems. The comRAT uses a knowledge base of language data extracted from the Corpus of Contemporary American English. The results obtained are compared to results obtained in empirical tests with humans. In order to explain why some answers might be preferred over others, frequencies of appearance of the queries and solutions are analyzed. The difficulty encountered by humans when solving RAT queries is expressed in response times and percentage of participants solving the query, and a significant moderate correlation between human data on query difficulty and the data provided by this approach is obtained.}
}
@article{PROSPERETTI20031089,
title = {Appendix 3: Report of study group on computational physics},
journal = {International Journal of Multiphase Flow},
volume = {29},
number = {7},
pages = {1089-1099},
year = {2003},
issn = {0301-9322},
doi = {https://doi.org/10.1016/S0301-9322(03)00081-8},
url = {https://www.sciencedirect.com/science/article/pii/S0301932203000818},
author = {Andrea Prosperetti and Grétar Tryggvason},
keywords = {Computational multiphase flow, Direct numerical simulations, Numerical methods},
abstract = {The great improvement of algorithms and computing hardware in the last few years must be ranked as one of the most important turning points in the history of multiphase flow research. After a brief review of some of this recent progress, it is pointed out that, besides its application to solving actual problems, computational physics plays other key roles: (1) As a tool to develop and understand basic physics and as a guide toward asking more penetrating questions; (2) As an aid in closing the averaged equations; (3) As a means to learn to compute better. Roadblocks toward greater effectiveness are the huge complexity of many of the necessary computational tasks but also, at a more practical level, the transmission of “computational knowledge” from one researcher to another, much in the same way as experimentalists can rely on readily available equipment (e.g., lasers, etc.), without having to build each item themselves. The solution to this problem will require a cultural shift––from a “cottage industry” to a “big science” mentality––which can be aided by a different attitude on the part of the funding agencies. Great synergism can be achieved by a closer integration of the multiphase computational physics enterprise with both Applied Mathematics and Computer Science.}
}
@article{DAUCE20101,
title = {Computational neuroscience, from multiple levels to multi-level},
journal = {Journal of Physiology-Paris},
volume = {104},
number = {1},
pages = {1-4},
year = {2010},
note = {Computational Neuroscience, from Multiple Levels to Multi-level},
issn = {0928-4257},
doi = {https://doi.org/10.1016/j.jphysparis.2009.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0928425709000837},
author = {Emmanuel Daucé and Laurent Perrinet}
}
@article{DANOS200773,
title = {Distributed Measurement-based Quantum Computation},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {170},
pages = {73-94},
year = {2007},
note = {Proceedings of the 3rd International Workshop on Quantum Programming Languages (QPL 2005)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2006.12.012},
url = {https://www.sciencedirect.com/science/article/pii/S1571066107000564},
author = {Vincent Danos and Ellie D'Hondt and Elham Kashefi and Prakash Panangaden},
keywords = {Formal language, quantum communication, quantum computing, semantics},
abstract = {We develop a formal model for distributed measurement-based quantum computations, adopting an agent-based view, such that computations are described locally where possible. Because the network quantum state is in general entangled, we need to model it as a global structure, reminiscent of global memory in classical agent systems. Local quantum computations are described as measurement patterns. Since measurement-based quantum computation is inherently distributed, this allows us to extend naturally several concepts of the measurement calculus [V. Danos, E. Kashefi and P. Panangaden, The measurement calculus (2004), arXiv:quant-ph/0412135], a formal model for such computations. Our goal is to define an assembly language, i.e. we assume that computations are well-defined and we do not concern ourselves with verification techniques. The operational semantics for systems of agents is given by a probabilistic transition system, and we define operational equivalence in a way that it corresponds to the notion of bisimilarity. With this in place, we prove that teleportation is bisimilar to a direct quantum channel, and this also within the context of larger networks.}
}
@article{CORDASCO201152,
title = {Efficient on-line algorithms for Euler diagram region computation},
journal = {Computational Geometry},
volume = {44},
number = {1},
pages = {52-68},
year = {2011},
issn = {0925-7721},
doi = {https://doi.org/10.1016/j.comgeo.2010.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S0925772110000581},
author = {Gennaro Cordasco and Rosario {De Chiara} and Andrew Fish},
keywords = {Euler diagrams, Region computation, Diagram generation},
abstract = {Euler diagrams are an accessible and effective visualisation of data involving simple set-theoretic relationships. Sets are represented by closed curves in the plane and often have wellformedness conditions placed on them in order to enhance comprehensibility. The theoretical underpinning for tool support has usually focussed on the problem of generating an Euler diagram from an abstract model. However, the problem of efficient computation of the abstract model from the concrete diagram has not been addressed before, despite this computation being a necessity for computer interpretations of user drawn diagrams. This may be used, together with automated manipulations of the abstract model, for purposes such as semantic information presentation or diagrammatic theorem proving. Furthermore, in interactive settings, the user may update diagrams “on-line” by adding and removing curves, for example, in which case a system requirement is the update of the abstract model (without the necessity of recomputation of the entire abstract model). We define the notion of marked Euler diagrams, together with a method for associating marked points on the diagram with regions in the plane. Utilising these, we provide on-line algorithms which quickly compute the abstract model of a weakly reducible wellformed Euler diagram (constructible as a sequence of additions or removals of curves, keeping a wellformed diagram at each step), and quickly updates both the set of curves in the plane as well as the abstract model according to the on-line operations. Efficiency is demonstrated by comparison with a common, naive algorithm. Furthermore, the methodology enables a straightforward implementation which has subsequently been realised as an application for the user classification domain.}
}
@article{BANDOPADHAYA2020100378,
title = {Integrated healthcare monitoring solutions for soldier using the internet of things with distributed computing},
journal = {Sustainable Computing: Informatics and Systems},
volume = {26},
pages = {100378},
year = {2020},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2020.100378},
url = {https://www.sciencedirect.com/science/article/pii/S2210537919304081},
author = {Shuvabrata Bandopadhaya and Rajiv Dey and Ashok Suhag},
keywords = {Healthcare monitoring system, Internet of things (IoT), Distributed computing, Fuzzy classification, Partten recognistion, Long Range wide area network (LoRaWAN)},
abstract = {This paper has proposed an integrated healthcare monitoring solution for the soldiers deployed in adverse environmental conditions, using the internet of things (IoT) with distributed computing. For these soldiers, the health parameters of every individual need to be monitored on a real-time basis and subsequent analysis of the dataset to be made for initiating appropriate medical support with the lowest possible delay. In this paper, a three-layer service-oriented IoT architecture has been proposed where the computational functionalities are distributed among all the layers. The proposed distributed computing mechanism has implemented two levels of filtration of redundant information that belongs to safe soldiers. The first level of filtering is done at the end-node using the Fuzzy classification approach and the second level of filtering is done at the intermediate node using the time-series pattern analysis approach. This layer-wise filtration process results in a reduction in data flooding and computational burden on the cloud due to which system response time improves to suit emergency applications. A prototype has been developed to validate the effectiveness of the proposed solution.}
}
@article{GIANNOPULU2022e09017,
title = {Synchronised neural signature of creative mental imagery in reality and augmented reality},
journal = {Heliyon},
volume = {8},
number = {3},
pages = {e09017},
year = {2022},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2022.e09017},
url = {https://www.sciencedirect.com/science/article/pii/S240584402200305X},
author = {I. Giannopulu and G. Brotto and T.J. Lee and A. Frangos and D. To},
keywords = {Creativity, Synchronisation, Mental imagery, Real environment, Augmented reality, Complexity},
abstract = {Creativity, transforming imaginative thinking into reality, is a mental imagery simulation in essence. It can be incorporeal, concerns sophisticated and/or substantial thinking, and involves objects. In the present study, a mental imagery task consisting of creating a scene using familiar (FA) or abstract (AB) physical or virtual objects in real (RMI) and augmented reality (VMI) environments, and an execution task involving effectively creating a scene in augmented reality (VE), were utilised. The beta and gamma neural oscillations of healthy participants were recorded via a 32 channel wireless 10/20 international EGG system. In real and augmented environments and for both the mental imagery and execution tasks, the participants displayed a similar cortico-cortical neural signature essentially based on synchronous vs asynchronous beta and gamma oscillatory activities between anterior (i.e. frontal) and posterior (i.e. parietal, occipito-parietal and occipito-temporal) areas bilaterally. The findings revealed a transient synchronised neural architecture that appears to be consistent with the hypothesis according to which, creativity, because of its inherent complexity, cannot be confined to a single brain area but engages various interconnected networks.}
}
@article{YAMAGUCHI2023427,
title = {Equitable STEM+CS learning experiences for girls of color: nurturing an independent learning approach via a learning ecosystem},
journal = {Journal for Multicultural Education},
volume = {17},
number = {4},
pages = {427-442},
year = {2023},
issn = {2053-535X},
doi = {https://doi.org/10.1108/JME-01-2023-0004},
url = {https://www.sciencedirect.com/science/article/pii/S2053535X23000368},
author = {Ryoko Yamaguchi and Veronica {Hankerson Madrigal} and Cyntrica N. Eaton and Jamika D. Burge},
keywords = {Black girls, Computer science, Computational thinking, Dependent learning, Equity, Independent learning, Learning behaviors, Learning ecosystem, Middle school girls, STEM, STEM+CS},
abstract = {Purpose
There is a critical need to understand how to attract Black girls and other girls of color to the science, technology, engineering, math, and computer science (STEM+CS) field. This study aims to look at the design and implementation of a CS learning ecosystem that supports girls of color in acquiring critical CS skills starting in middle school.
Design/methodology/approach
This mixed-method case study included 53 girls, between the ages of 11 and 13, in four US middle schools. Study methods included the analysis of a pre-program student survey, longitudinal interviews and focus groups, weekly observations and computing artifacts.
Findings
Program participants were interested in CS, were confident in their ability to learn CS, had prior coding and CS experience and had parents and teachers who encouraged them to learn CS. But some students showed dependent learning behaviors while engaging in CS activities. These included relying on instructors and being reticent to make mistakes–behaviors that limit learning. The CS learning ecosystem supported students as they shifted from applying dependent learning approaches to applying independent learning approaches. Instructors sustained a growth mindset and supported productive struggle as students learned CS skills.
Originality/value
A CS learning system supported equitable learning experiences and helped students develop independent learning behaviors that led to deeper engagement in CS.}
}
@article{MINGERS201767,
title = {Back to the future: A critique of Demetis and Lee's “Crafting theory to satisfy the requirements of systems science”},
journal = {Information and Organization},
volume = {27},
number = {1},
pages = {67-71},
year = {2017},
issn = {1471-7727},
doi = {https://doi.org/10.1016/j.infoandorg.2017.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S1471772717300118},
author = {John Mingers},
abstract = {Demetis and Lee's paper outlines criteria for constructing theory in accordance with systems science. This is a laudable aim but in this comment I suggest that their view of systems thinking is both narrow and somewhat dated. Demetis and Lee equate systems science with only one aspect of it – General Systems Thinking (GST) – and they discuss in detail only one theorist – Niklas Luhmann. I draw attention to a range of other systems approaches including system dynamics, soft systems methodology, complexity theory, critical systems thinking, critical realism and multimethodology. I conclude with tentative guidelines of my own.}
}
@incollection{MARINESCU20171,
title = {Chapter 1 - Complex Systems},
editor = {Dan C. Marinescu},
booktitle = {Complex Systems and Clouds},
publisher = {Elsevier},
address = {Boston},
pages = {1-32},
year = {2017},
series = {Computer Science Reviews and Trends},
isbn = {978-0-12-804041-6},
doi = {https://doi.org/10.1016/B978-0-12-804041-6.00001-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128040416000013},
author = {Dan C. Marinescu},
keywords = {Complexity, Emergence, Phase transitions, Open systems, Nondeterminism, Self-similarity, Fractal geometry, Power Law distribution},
abstract = {After a brief review of the evolution of thinking about systems, consisting of an ensemble of components, the chapter analyzes the nondeterminism, nonlinearity, and phase transitions in complex systems. A range of topics pertinent to complexity, such as self-organization, self-organized criticality, power law distributions, computational irreducibility, and quantitative characterization of complexity are then covered. Cybernetics and the interdisciplinary nature of complexity conclude the chapter.}
}
@article{ASCENZI2020115295,
title = {Theoretical mathematics, polarized light microscopy and computational models in healthy and pathological bone},
journal = {Bone},
volume = {134},
pages = {115295},
year = {2020},
issn = {8756-3282},
doi = {https://doi.org/10.1016/j.bone.2020.115295},
url = {https://www.sciencedirect.com/science/article/pii/S8756328220300752},
author = {Maria-Grazia Ascenzi},
keywords = {Biomechanics, Lamella, Low-trauma fracture, Mathematics, Osteon, Pathology},
abstract = {The needs of everyday life, such as counting and measuring, are roots of theoretical mathematics. I believe these roots are why mathematical ideas ground research so amazingly well within many scientific fields. Initially trained as a theoretical mathematician and having collaborated with non-mathematicians in the field of bone research, I address the advantages and challenges of collaborations across fields of research among investigators trained in different disciplines. I report on the mathematical ideas that have guided my research on the mechanics of bone tissue. I explain how the mathematical ideas of local vs. global properties influence my research. Polarized light microscopy (PLM) is a tool that I use consistently, in association with other microscopy techniques, to investigate bone in its healthy state and in the presence of bone disease, in humans and in animal models. I review the results that I and investigators around the world have obtained with PLM. Applied to thin bone sections, PLM yields extinct (black) and bright (white) signals that are interpreted in terms of the orientation of collagen type I, by means of other microscopy techniques. Collagen type I is an elementary component of bone tissue. Its orientation is important for the mechanical function of bone. Images obtained by PLM at a specific bone site yield big data sets regarding collagen orientation. Multiple data sets in respect of multiple sites are often needed for research because the bone tissue differs by location in response to the distinct forces acting on it. Mathematics, defined by philosophers as the theory of patterns, offers the backdrop for pattern identification in the big data sets regarding collagen orientation. I also discuss the computational aspect of the research, pursuant to which the patterns identified are incorporated in simulations of mechanical behaviors of bone. These mathematical ideas serve to understand the role of collagen orientation in bone fracture risk.}
}
@article{FLOWERS2025119061,
title = {Context matters: Modeling thermochronologic data in geologic frameworks using the Great Unconformity as a case study},
journal = {Earth and Planetary Science Letters},
volume = {650},
pages = {119061},
year = {2025},
issn = {0012-821X},
doi = {https://doi.org/10.1016/j.epsl.2024.119061},
url = {https://www.sciencedirect.com/science/article/pii/S0012821X2400493X},
author = {R.M. Flowers and B.A. Peak},
keywords = {Geologic context approach, (U-Th)/He, Thermal history, Great Unconformity, Pikes Peak, Tava},
abstract = {The critical importance of sample context and geologic information for interpreting geochronologic data has long been fundamental to the Earth sciences. However, the lack of quantitative uncertainties associated with contextual, observational information means that much geologic data cannot be statistically treated in computational models using the same approaches as quantitative datasets. This challenge is showcased by the current debate over whether and how geologic data should be used when modeling thermochronologic results, which has important implications for deriving time-temperature (tT) paths from which burial and exhumation histories are interpreted. Holistically leveraging observational data to test hypotheses and determine the set of geologically reasonable thermal histories that can explain thermochronologic results has a longstanding history, but some recent studies have criticized this approach as one that arbitrarily limits tT solutions. Here, a geologic context approach to thermal history modeling, in which observational and thermochronologic datasets are combined to design geologically valid models and reach the most geologically likely interpretation, is illustrated using an example of constraining Great Unconformity exhumation in Colorado where this modeling philosophy has been questioned. Although the quality of geologic data and their applicability to modeled samples can vary and be debated, this does not mean that all geologic data are inherently unreliable and therefore discardable. Exploring models with varying or minimal constraints can be useful to test different hypotheses and determine the resolving power of the data, but using an endmember context-blind approach to interpret thermochronologic results can produce outcomes that violate fundamental aspects of the geology. The strategy outlined here is not the only valid approach to modeling thermochronologic data, but if the purpose of the modeling is to derive meaningful interpretations about sample tT paths in order to better illuminate the geologic history, then critical thinking about the sample context, first order geologic observations, and primary relationships should be integral components of the modeling process.}
}
@article{EDELMAN2007253,
title = {Behavioral and computational aspects of language and its acquisition},
journal = {Physics of Life Reviews},
volume = {4},
number = {4},
pages = {253-277},
year = {2007},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2007.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S1571064507000255},
author = {Shimon Edelman and Heidi Waterfall},
keywords = {Computational cognitive linguistics, Psycholinguistics, Machine learning, Language acquisition},
abstract = {One of the greatest challenges facing the cognitive sciences is to explain what it means to know a language, and how the knowledge of language is acquired. The dominant approach to this challenge within linguistics has been to seek an efficient characterization of the wealth of documented structural properties of language in terms of a compact generative grammar—ideally, the minimal necessary set of innate, universal, exception-less, highly abstract rules that jointly generate all and only the observed phenomena and are common to all human languages. We review developmental, behavioral, and computational evidence that seems to favor an alternative view of language, according to which linguistic structures are generated by a large, open set of constructions of varying degrees of abstraction and complexity, which embody both form and meaning and are acquired through socially situated experience in a given language community, by probabilistic learning algorithms that resemble those at work in other cognitive modalities.}
}
@article{MANALU2023641,
title = {Developing Nusantara Mobile Application to Support Local Tourism in Indonesia},
journal = {Procedia Computer Science},
volume = {227},
pages = {641-650},
year = {2023},
note = {8th International Conference on Computer Science and Computational Intelligence (ICCSCI 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.568},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923017350},
author = {Daniella Oktalina Manalu and Yudhistya Ayu Kusumawati and Cuk Tho},
keywords = {mobile application, tourism, local tourism},
abstract = {Tourism is a very important sector and has a major influence on development and national income. Moreover, Indonesia has thousands of tourist destinations that are very beautiful and interesting to visit, both for Indonesians and foreigners. It's just that, there are still many local tours, such as tourist villages, which are still not well known by most people. In fact, there are many cultures, customs, places of recreation, or characteristics of an area that need to be seen and introduced to outsiders, even to Indonesians themselves. Therefore, this study aims to explain the problems that occur in the field of tourism, as well as provide solutions in the form of tourism applications that aim to help promote local Indonesian tourism, as well as make it easy for travel enthusiasts to organize their travel plans. The process of making this travel application is also carried out through various research and interviews with potential users and IT people in order to produce an attractive and effective application. This study uses the design thinking method. Researchers collected data sources from literature studies and surveys through questionnaires, where the results of the data obtained from the questionnaires were numerical or quantitative. The aim is to determine the level of public interest in tourism, as well as determine the level of potential users of this tourism application. That way, the goals of this application will be achieved and effective in helping solve tourism problems.}
}
@article{MARINHO2021e06079,
title = {Quantum computational investigations and molecular docking studies on amentoflavone},
journal = {Heliyon},
volume = {7},
number = {1},
pages = {e06079},
year = {2021},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2021.e06079},
url = {https://www.sciencedirect.com/science/article/pii/S2405844021001845},
author = {Márcia M. Marinho and Francisco Wagner Q. Almeida-Neto and Emanuelle M. Marinho and Leonardo P. {da Silva} and Ramon R.P.P.B. Menezes and Ricardo P. {dos Santos} and Emmanuel S. Marinho and Pedro {de Lima-Neto} and Alice M.C. Martins},
keywords = {Antichagasic agent, Biflavonoid, DFT, Fukui analysis, NLO},
abstract = {Chagas disease is a neglected tropical disease caused by the protozoan parasite Trypanosoma cruzi, with approximately 6–7 million people infected worldwide, becoming a public health problem in tropical countries, thus generating an increasing demand for the development of more effective drugs, due to the low efficiency of the existing drugs. Aiming at the development of a new antichagasic pharmacological tool, the density functional theory was used to calculate the reactivity descriptors of amentoflavone, a biflavonoid with proven anti-trypanosomal activity in vitro, as well as to perform a study of interactions with the enzyme cruzain, an enzyme key in the evolutionary process of T-cruzi. Structural properties (in solvents with different values of dielectric constant), the infrared spectrum, the frontier orbitals, Fukui analysis, thermodynamic properties were the parameters calculated from DFT method with the monomeric structure of the apigenin used for comparison. Furthermore, molecular docking studies were performed to assess the potential use of this biflavonoid as a pharmacological antichagasic tool. The frontier orbitals (HOMO-LUMO) study to find the band gap of compound has been extended to calculate electron affinity, ionization energy, electronegativity electrophilicity index, chemical potential, global chemical hardness and global chemical softness to study the chemical behaviour of compound. The optimized structure was subjected to molecular Docking to characterize the interaction between amentoflavone and cruzain enzyme, a classic pharmacological target for substances with anti-gas activity, where significant interactions were observed with amino acid residues from each one's catalytic sites enzyme. These results suggest that amentoflavone has the potential to interfere with the enzymatic activity of cruzain, thus being an indicative of being a promising antichagasic agent.}
}
@incollection{PRIETOMARTINEZ201919,
title = {Chapter 2 - Computational Drug Design Methods—Current and Future Perspectives},
editor = {Kunal Roy},
booktitle = {In Silico Drug Design},
publisher = {Academic Press},
pages = {19-44},
year = {2019},
isbn = {978-0-12-816125-8},
doi = {https://doi.org/10.1016/B978-0-12-816125-8.00002-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012816125800002X},
author = {Fernando D. Prieto-Martínez and Edgar López-López and K. {Eurídice Juárez-Mercado} and José L. Medina-Franco},
keywords = {Artificial intelligence, Big data, Chemical space, Chemoinformatics, Deep learning, Molecular modeling, Polypharmacology, SmART, Target fishing, Virtual screening},
abstract = {Computer-aided drug design (CADD) comprises a broad range of theoretical and computational approaches that are part of modern drug discovery. CADD methods have made key contributions to the development of drugs that are in clinical use or in clinical trials. Such methods have emerged and evolved along with experimental approaches used in drug design. In this chapter we discuss the major CADD methods and examples of recent applications to drugs that have advanced in clinical trials or that have been approved for clinical use. We also comment on representative trends in current drug discovery that are shaping the development of novel methods, such as computer-aided drug repurposing. Similarly we present emerging concepts and technologies in molecular modeling and chemoinformatics. Furthermore, this chapter discusses the authors’ point of view of the challenges of traditional and novel CADD methods to increase their positive impact in drug discovery.}
}
@article{LIEFGREEN2020101332,
title = {Strategies for selecting and evaluating information},
journal = {Cognitive Psychology},
volume = {123},
pages = {101332},
year = {2020},
issn = {0010-0285},
doi = {https://doi.org/10.1016/j.cogpsych.2020.101332},
url = {https://www.sciencedirect.com/science/article/pii/S001002852030061X},
author = {Alice Liefgreen and Toby Pilditch and David Lagnado},
keywords = {Information search, OED framework, Utility functions, Inquiry, Question asking, Strategies, Probabilistic reasoning, Bayesian Networks},
abstract = {Within the domain of psychology, Optimal Experimental Design (OED) principles have been used to model how people seek and evaluate information. Despite proving valuable as computational-level methods to account for people’s behaviour, their descriptive and explanatory powers remain largely unexplored. In a series of experiments, we used a naturalistic crime investigation scenario to examine how people evaluate queries, as well as outcomes, in probabilistic contexts. We aimed to uncover the psychological strategies that people use, not just to assess whether they deviated from OED principles. In addition, we explored the adaptiveness of the identified strategies across both one-shot and stepwise information search tasks. We found that people do not always evaluate queries strictly in OED terms and use distinct strategies, such as by identifying a leading contender at the outset. Moreover, we identified aspects of zero-sum thinking and risk aversion that interact with people’s information search strategies. Our findings have implications for building a descriptive account of information seeking and evaluation, accounting for factors that currently lie outside the realm of information-theoretic OED measures, such as context and the learner’s own preferences.}
}
@article{WENG20072303,
title = {On developmental mental architectures},
journal = {Neurocomputing},
volume = {70},
number = {13},
pages = {2303-2323},
year = {2007},
note = {Selected papers from the 3rd International Conference on Development and Learning (ICDL 2004) Time series prediction competition: the CATS benchmark},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2006.07.017},
url = {https://www.sciencedirect.com/science/article/pii/S0925231206005194},
author = {Juyang Weng},
keywords = {Mental architecture, Agent architecture, Computational neural science, Cognitive development, Autonomous mental development, Developmental robots, Learning types, Developmental vision, Speech recognition, Language acquisition, Thinking, Reasoning, Autonomous planning},
abstract = {This paper presents a computational theory of developmental mental architectures for artificial and natural systems, motivated by neuroscience. The work is an attempt to approximately model biological mental architectures using mathematical tools. Six types of architecture are presented, beginning with the observation-driven Markov decision process as Type-1. From Type-1 to Type-6, the architecture progressively becomes more complete toward the necessary functions of autonomous mental development. Properties of each type are presented. Experiments are discussed with emphasis on their architectures.}
}
@article{DYER2021101055,
title = {Uncertainty and disciplinary difference: Mapping attitudes towards uncertainty across discipline boundaries},
journal = {Design Studies},
volume = {77},
pages = {101055},
year = {2021},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2021.101055},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X21000661},
author = {Loren Dyer and Jacqueline Power and Andrew Steen and Louise Wallis and Aidan Davison},
keywords = {design processes, design thinking, epistemology, interdisciplinarity, uncertainty},
abstract = {This article investigates the different ways that uncertainty is understood and approached across design disciplines. Structural attitudes toward uncertainty are assessed in design thinking literature before other possible ways of viewing uncertainty in the design process are introduced. Uncertainty is then presented as a source of epistemological difference between design disciplines, and this difference is explicated through a project that uses literature survey and analytical diagramming to map differences between discipline attitudes to uncertainty. Our review identifies uncertainty as a prevalent source of discipline difference with the goal of better describing barriers, and effective responses to them, in inter- and trans-disciplinary design agendas.}
}
@incollection{MADIAJAGAN20191,
title = {Chapter 1 - Parallel Computing, Graphics Processing Unit (GPU) and New Hardware for Deep Learning in Computational Intelligence Research},
editor = {Arun Kumar Sangaiah},
booktitle = {Deep Learning and Parallel Computing Environment for Bioengineering Systems},
publisher = {Academic Press},
pages = {1-15},
year = {2019},
isbn = {978-0-12-816718-2},
doi = {https://doi.org/10.1016/B978-0-12-816718-2.00008-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128167182000087},
author = {M. Madiajagan and S. Sridhar Raj},
keywords = {Deep learning, Parallelization, Graphics processing unit, Hardware architecture, Memory optimization, Computational intelligence},
abstract = {Graphics processing unit (GPU) is an electronic circuit which manipulates and modifies the memory for better image output. Deep learning involves huge amounts of matrix multiplications and other operations which can be massively parallelized and thus sped up on GPUs. A single GPU might have thousands of cores while a CPU usually has no more than 12 cores. GPU's practical applicability is affected by two issues: long training time and limited GPU memory, which is greatly influenced as the neural network size grows. In order to overcome these issues, this chapter presents various technologies in distributed parallel processing which improve the training time and optimize the memory, and hardware engine architectures will be explored for data size reduction. The GPUs generally used for deep learning are limited in memory size compared to CPUs, so even the latest Tesla GPU has only 16 GB of memory. Therefore, GPU memory cannot be increased to that extent easily, so networks must be designed to fit within the available memory. This could be a factor limiting progress, overcoming which would be highly beneficiary to the computational intelligence area.}
}
@article{HERBET2015413,
title = {Rethinking voxel-wise lesion-deficit analysis: A new challenge for computational neuropsychology},
journal = {Cortex},
volume = {64},
pages = {413-416},
year = {2015},
issn = {0010-9452},
doi = {https://doi.org/10.1016/j.cortex.2014.10.021},
url = {https://www.sciencedirect.com/science/article/pii/S0010945214003517},
author = {Guillaume Herbet and Gilles Lafargue and Hugues Duffau}
}
@article{PAPAVLASOPOULOU2019415,
title = {Exploring children's learning experience in constructionism-based coding activities through design-based research},
journal = {Computers in Human Behavior},
volume = {99},
pages = {415-427},
year = {2019},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2019.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S0747563219300184},
author = {Sofia Papavlasopoulou and Michail N. Giannakos and Letizia Jaccheri},
keywords = {Constructionism, Coding, Computational thinking, Engagement, Children, Design-based research},
abstract = {Over the last few years, the integration of coding activities for children in K-12 education has flourished. In addition, novel technological tools and programming environments have offered new opportunities and increased the need to design effective learning experiences. This paper presents a design-based research (DBR) approach conducted over two years, based on constructionism-based coding experiences for children, following the four stages of DBR. Three iterations (cycles) were designed and examined in total, with participants aged 8–17 years old, using mixed methods. Over the two years, we conducted workshops in which students used a block-based programming environment (i.e., Scratch) and collaboratively created a socially meaningful artifact (i.e., a game). The study identifies nine design principles that can help us to achieve higher engagement during the coding activity. Moreover, positive attitudes and high motivation were found to result in the better management of cognitive load. Our contribution lies in the theoretical grounding of the results in constructionism and the emerging design principles. In this way, we provide both theoretical and practical evidence of the value of constructionism-based coding activities.}
}
@article{SCHWARTZ20192047,
title = {Biophysics and the Genomic Sciences},
journal = {Biophysical Journal},
volume = {117},
number = {11},
pages = {2047-2053},
year = {2019},
issn = {0006-3495},
doi = {https://doi.org/10.1016/j.bpj.2019.07.038},
url = {https://www.sciencedirect.com/science/article/pii/S0006349519306277},
author = {David C. Schwartz},
abstract = {It is now rare to find biological, or genetic investigations that do not rely on the tools, data, and thinking drawn from the genomic sciences. Much of this revolution is powered by contemporary sequencing approaches that readily deliver large, genome-wide data sets that not only provide genetic insights but also uniquely report molecular outcomes from experiments that biophysicists are increasingly using for potentiating structural and mechanistic investigations. In this perspective, I describe a path of how biophysical thinking greatly contributed to this revolution in ways that parallel advancements in computer science through discussion of several key inventions, described as “foundational devices.” These discussions also point at the future of how biophysics and the genomic sciences may become more finely integrated for empowering new measurement paradigms for biological investigations.}
}
@article{ROTH2023101278,
title = {Reset and restoration. The looming conservative turn of management theory: An extension of Foss et al.},
journal = {Scandinavian Journal of Management},
volume = {39},
number = {3},
pages = {101278},
year = {2023},
issn = {0956-5221},
doi = {https://doi.org/10.1016/j.scaman.2023.101278},
url = {https://www.sciencedirect.com/science/article/pii/S0956522123000192},
author = {Steffen Roth},
keywords = {The Great Reset, Management theory, Cronyism, Stratification, Conservatism, Restorism},
abstract = {This article is a reply to Foss et al.’s (2022) contribution to the special issue of the Scandinavian Journal of Management on The Great Reset of management and organization theory. In their article, the authors make a strong case that “reset thinking” geared towards a more “sustainable” redesign of the global economy promotes extensive state interventionism and cronyism capitalism, and therefore reject the idea of a need for “a fundamental rethink of existing management theory”. Whereas I do agree with the authors on most points, I am less convinced that “existing management theory” will suffice to address the problem of “reset thinking”. In this article, I demonstrate that the economy-bias of existing theories is a gateway for “reset thinking” geared towards an allegedly necessary re-/socialisation of management and organisation. A research agenda on cronyism must therefore be complemented by one on privilege and hierarchy not only as undesirable side-effects of cronyism, but also as desired outcomes of advocacy for specific minorities or missions. As self-identifications with group interests or calls for missions have become popular in management theory, I conclude that this new appetite for privilege might undermine not only the higher ideals of many management theorists, but also the foundations of modern society.}
}
@article{XIA20025,
title = {Applications of computational fluid dynamics (cfd) in the food industry: a review},
journal = {Computers and Electronics in Agriculture},
volume = {34},
number = {1},
pages = {5-24},
year = {2002},
issn = {0168-1699},
doi = {https://doi.org/10.1016/S0168-1699(01)00177-6},
url = {https://www.sciencedirect.com/science/article/pii/S0168169901001776},
author = {Bin Xia and Da-Wen Sun},
keywords = {Computational fluid dynamics, , Food, Refrigeration, Cooling, Drying, Sterilisation, Mixing, Chilling, Modelling, Simulation},
abstract = {Computational fluid dynamics (cfd) is a simulation tool, which uses powerful computer and applied mathematics to model fluid flow situations for the prediction of heat, mass and momentum transfer and optimal design in industrial processes. It is only in recent years that cfd has been applied in the food processing industry. This paper reviews the application of cfd in food processing industries including drying, sterilisation, refrigeration and mixing. The advantages of using cfd are discussed and the future of cfd applications is also outlined.}
}
@article{WANG20073776,
title = {Maximum likelihood computation based on the Fisher scoring and Gauss–Newton quadratic approximations},
journal = {Computational Statistics & Data Analysis},
volume = {51},
number = {8},
pages = {3776-3787},
year = {2007},
issn = {0167-9473},
doi = {https://doi.org/10.1016/j.csda.2006.12.037},
url = {https://www.sciencedirect.com/science/article/pii/S0167947306005147},
author = {Yong Wang},
keywords = {Maximum likelihood computation, Fisher scoring, Gauss–Newton method, Constrained optimization, Iteratively reweighted least-squares},
abstract = {The Fisher scoring and Gauss–Newton methods are two known methods for maximum likelihood computation. This paper provides a generalization for each method in a unified manner so that they can be used for some difficult maximum likelihood computation, when, for example, there exist constraints on the parameters. A generalized method does not use directly the Newton-type iteration formulas of these methods, but, instead, uses the corresponding quadratic functions transformed from them. It proceeds by repeatedly approximating the log-likelihood function with the quadratic functions in the neighborhoods of the current iterates and optimizing each quadratic function within the parameter space. It is shown that each quadratic function has a weighted linear regression formulation, which can be conveniently solved. This generalization also extends the applicability of the Fisher scoring method to situations when the expected Fisher information matrices are unavailable in closed form. Fast computation can generally be anticipated, owing to their small rates of convergence and a rapid solution of each linear regression problem. While the generalized Gauss–Newton method may sometimes suffer for the so-called large residual problem, the generalized Fisher scoring method has performed consistently well in the numerical experiments we conducted.}
}
@incollection{NAGURNEY1996335,
title = {Chapter 7 Parallel computation},
series = {Handbook of Computational Economics},
publisher = {Elsevier},
volume = {1},
pages = {335-404},
year = {1996},
issn = {1574-0021},
doi = {https://doi.org/10.1016/S1574-0021(96)01009-X},
url = {https://www.sciencedirect.com/science/article/pii/S157400219601009X},
author = {Anna Nagurney},
abstract = {Publisher Summary
Parallel computation represents not only a new mode of computation, but, a new intellectual paradigm. This chapter provides an overview of the technology of parallel computation in terms of hardware and programming languages; presents some of the fundamental classes of problems encountered in economics and the associated numerical methodologies for their solution; discusses the state-of-the-art computational techniques and focuses on parallel techniques and contrasts them with serial techniques for illumination and instructive purposes; and presents applications of the classes of problems and associated numerical methods to econometrics, microeconomics, macroeconomics, and finance. The emergence of computation as a basic scientific methodology in economics has given access to solutions of fundamental problems that pure analysis, observation, or experimentation could not have achieved. Parallel computation represents the wave of the future. It is considered to be cheaper and faster than serial computing and the only approach to faster computation currently foreseeable. Parallel computation is appealing, hence, for the economies of scale that are possible, for the potentially faster solution of large-scale problems, and also for the possibilities that it presents for imitating adjustment or tatonnement processes.}
}
@article{SUMAR20103980,
title = {Computational intelligence approach to PID controller design using the universal model},
journal = {Information Sciences},
volume = {180},
number = {20},
pages = {3980-3991},
year = {2010},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2010.06.026},
url = {https://www.sciencedirect.com/science/article/pii/S0020025510002872},
author = {Rodrigo Rodrigues Sumar and Antonio Augusto Rodrigues Coelho and Leandro dos Santos Coelho},
keywords = {PID control, Nonlinear systems, Fuzzy systems, Neural networks, Differential evolution, Optimization},
abstract = {Despite the popularity of PID (Proportional-Integral-Derivative) controllers, their tuning aspect continues to present challenges for researches and plant operators. Various control design methodologies have been proposed in the literature, such as auto-tuning, self-tuning, and pattern recognition. The main drawback of these methodologies in the industrial environment is the number of tuning parameters to be selected. In this paper, the design of a PID controller, based on the universal model of the plant, is derived, in which there is only one parameter to be tuned. This is an attractive feature from the viewpoint of plant operators. Fuzzy and neural approaches – bio-inspired methods in the field of computational intelligence – are used to design and assess the efficiency of the PID controller design based on differential evolution optimization in nonlinear plants. The numerical results presented herein indicate that the proposed bio-inspired design is effective for the nonlinear control of nonlinear plants.}
}
@incollection{TSATSE20212033,
title = {Reflections on the development of scenario and problem-based chemical engineering projects},
editor = {Metin Türkay and Rafiqul Gani},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {50},
pages = {2033-2038},
year = {2021},
booktitle = {31st European Symposium on Computer Aided Process Engineering},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-323-88506-5.50314-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780323885065503144},
author = {A. Tsatse and E. Sorensen},
keywords = {problem-based learning, Scenarios, Process Systems Engineering},
abstract = { Abstract
This work reflects on the use of scenario- and problem-based learning as a way of conveying not only fundamental knowledge, but also to provide training in the use of computational Process Systems Engineering (PSE) tools applied to open-ended real world problems. The teaching framework also has a strong emphasis on the development of professional skills and to evaluate the recommended design solutions considering multiple perspectives such as economics, safety, environment and societal context. The framework is implemented through week-long group projects called Scenarios, taking place mainly in the first two years of study, and examples are given of different variations of Scenarios. This teaching approach has multiple benefits, including but not limited to, students’ understanding of PSE tools and the development of their critical engineering thinking.}
}
@article{SCHMID2022,
title = {Mendelian or Multifactorial? Current Undergraduate Genetics Assessments Focus on Genes and Rarely Include the Environment},
journal = {Journal of Microbiology & Biology Education},
volume = {23},
number = {3},
year = {2022},
issn = {1935-7877},
doi = {https://doi.org/10.1128/jmbe.00093-22},
url = {https://www.sciencedirect.com/science/article/pii/S1935787722000302},
author = {Kelly M. Schmid and Dennis Lee and Monica Weindling and Awais Syed and Stephanie-Louise Yacoba Agyemang and Brian Donovan and Gregory Radick and Michelle K. Smith and L. Kate Wright},
keywords = {assessment, curriculum, environment, genes, genetics, undergraduate},
abstract = {Undergraduate genetics courses have historically focused on simple genetic models, rather than taking a more multifactorial approach where students explore how traits are influenced by a combination of genes, the environment, and gene-by-environment interactions. While a focus on simple genetic models can provide straightforward examples to promote student learning, they do not match the current scientific understanding and can result in deterministic thinking among students.
ABSTRACT
Undergraduate genetics courses have historically focused on simple genetic models, rather than taking a more multifactorial approach where students explore how traits are influenced by a combination of genes, the environment, and gene-by-environment interactions. While a focus on simple genetic models can provide straightforward examples to promote student learning, they do not match the current scientific understanding and can result in deterministic thinking among students. In addition, undergraduates are often interested in complex human traits that are influenced by the environment, and national curriculum standards include learning objectives that focus on multifactorial concepts. This research aims to discover to what extent multifactorial genetics is currently being assessed in undergraduate genetics courses. To address this, we analyzed over 1,000 assessment questions from a commonly used undergraduate genetics textbook; published concept assessments; and open-source, peer-reviewed curriculum materials. Our findings show that current genetics assessment questions overwhelmingly emphasize the impact of genes on phenotypes and that the effect of the environment is rarely addressed. These results indicate a need for the inclusion of more multifactorial genetics concepts, and we suggest ways to introduce them into undergraduate courses.}
}
@article{MALDONADO2014177,
title = {Synchronicity among Biological and Computational Levels of an Organism: Quantum Biology and Complexity},
journal = {Procedia Computer Science},
volume = {36},
pages = {177-184},
year = {2014},
note = {Complex Adaptive Systems Philadelphia, PA November 3-5, 2014},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.09.076},
url = {https://www.sciencedirect.com/science/article/pii/S1877050914013258},
author = {Carlos E. Maldonado and Nelson A. Gómez-Cruz},
keywords = {quantum biology, living systems, non-linear systems, complexity science, theory, health.},
abstract = {This paper argues that there is a synchronicity among biological and computational levels on an organism and provides arguments and proofs based on experimental research gathered in the literature. The leading thread is the interplay between quantum biology (QB) and complexity. As the paper asks whether QB does contribute to complexity science (CS), five arguments are provided: (i) Firstly a state-of-the art of QB and its relationship to CS is sketched out. Thereafter, the attention is directed to answering the question set out; (ii) Secondly, it digs into the understanding of life toward deeper levels of reality; (iii) It is shown that non-trivial quantum effects shed insightful lights on the information processing of and within living beings; (iv) Once the distinction is made between increasing levels of complexity and increasing levels of organization, the focus lies in the importance of QB for organization, and not so much for complexity as such; (v) The role of information rises at the center of all concerns, and the intertwining of complexity and information processing. At the end some conclusions are drawn.}
}
@article{POST1987339,
title = {Latest thinking on the Malpasset accident},
journal = {Engineering Geology},
volume = {24},
number = {1},
pages = {339-353},
year = {1987},
note = {Dam Failures},
issn = {0013-7952},
doi = {https://doi.org/10.1016/0013-7952(87)90071-8},
url = {https://www.sciencedirect.com/science/article/pii/0013795287900718},
author = {G. Post and D. Bonazzi}
}
@article{ROSEN20211,
title = {A word is worth a thousand pictures: A 20-year comparative analysis of aberrant abstraction in schizophrenia, affective psychosis, and non-psychotic depression},
journal = {Schizophrenia Research},
volume = {238},
pages = {1-9},
year = {2021},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2021.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S0920996421003674},
author = {Cherise Rosen and Martin Harrow and Liping Tong and Thomas H. Jobe and Helen Harrow},
keywords = {Abstraction, Concretism, Aberrant abstraction, Schizophrenia, Affective psychosis, Unipolar depression non-psychotic},
abstract = {Abstract thinking is a cognitive process that involves the assimilation of concepts reduced from diffuse sensory input, organized, and interpreted in a manner beyond the obvious. There are multiple facets by which abstraction is measured that include semantic, visual-spatial and social comprehension. This study examined the prevalence and course of abstract and concrete responses to semantic proverbs and aberrant abstraction (composite score of semantic, visual-spatial, and social comprehension) over 20 years in 352 participants diagnosed with schizophrenia, affective psychosis, and unipolar non-psychotic depression. We utilized linear models, two-way ANOVA and contrasts to compare groups and change over time. Linear models with Generalized Estimation Equation (GEE) to determine association. Our findings show that regardless of diagnosis, semantic proverb interpretation improves over time. Participants with schizophrenia give more concrete responses to proverbs when compared to affective psychosis and unipolar depressed without psychosis. We also show that the underlying structure of concretism encompasses increased conceptual overinclusion at index hospitalization and idiosyncratic associations at follow-up; whereas, abstract thinking overtime encompasses increased visual-spatial abstraction at index and rich associations with increased social comprehension scores at follow-up. Regardless of diagnosis, premorbid functioning, descriptive characteristics, and IQ were not associated with aberrant abstraction. Delusions are highly and positively related to aberrant abstraction scores, while hallucinations are mildly and positively related to this score. Lastly, our data point to the importance of examining the underlying interconnected structures of ‘established’ constructs vis-à-vis mixed methods to provide a description of the rich interior world that may not always map onto current quantitative measures.}
}
@article{ALONSO20092683,
title = {A method to generate computationally efficient reduced order models},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {198},
number = {33},
pages = {2683-2691},
year = {2009},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2009.03.012},
url = {https://www.sciencedirect.com/science/article/pii/S0045782509001376},
author = {D. Alonso and A. Velazquez and J.M. Vega},
keywords = {Reduced order model, Proper Orthogonal Decomposition, Incompressible nonisothermal flow},
abstract = {A new method is presented to generate reduced order models (ROMs) in Fluid Dynamics problems. The method is based on the expansion of the flow variables on a Proper Orthogonal Decomposition (POD) basis, calculated from a limited number of snapshots, which are obtained via Computational Fluid Dynamics (CFD). Then, the POD-mode amplitudes are calculated as minimizers of a properly defined overall residual of the equations and boundary conditions. The residual can be calculated using only a limited number of points in the flow field, which can be scattered either all over the whole computational domain or over a smaller projection window. This means that the process is both computationally efficient (reconstructed flow fields require less than 1% of the time needed to compute a full CFD solution) and flexible (the projection window can avoid regions of large localized CFD errors). Also, various definitions of the residual are briefly discussed, along with the number and distribution of snapshots, the number of retained modes, and the effect of CFD errors, to conclude that the method is numerically robust. This is because the results are largely insensitive to the definition of the residual, to CFD errors, and to the CFD method itself, which may contain artificial stabilizing terms. Thus, the method is amenable for practical engineering applications.}
}
@article{KERBER2012239,
title = {A worst-case bound for topology computation of algebraic curves},
journal = {Journal of Symbolic Computation},
volume = {47},
number = {3},
pages = {239-258},
year = {2012},
issn = {0747-7171},
doi = {https://doi.org/10.1016/j.jsc.2011.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0747717111001775},
author = {Michael Kerber and Michael Sagraloff},
keywords = {Topology computation, Algebraic curve, Amortized analysis, Complexity analysis},
abstract = {Computing the topology of an algebraic plane curve C means computing a combinatorial graph that is isotopic to C and thus represents its topology in R2. We prove that, for a polynomial of degree n with integer coefficients bounded by 2ρ, the topology of the induced curve can be computed with Õ(n8ρ(n+ρ)) bit operations (Õ indicates that we omit logarithmic factors). Our analysis improves the previous best known complexity bounds by a factor of n2. The improvement is based on new techniques to compute and refine isolating intervals for the real roots of polynomials, and on the consequent amortized analysis of the critical fibers of the algebraic curve.}
}
@article{CORBIN2023100645,
title = {A comparison of linguistic patterns between individuals with current major depressive disorder, past major depressive disorder, and controls in a virtual, psychiatric research interview},
journal = {Journal of Affective Disorders Reports},
volume = {14},
pages = {100645},
year = {2023},
issn = {2666-9153},
doi = {https://doi.org/10.1016/j.jadr.2023.100645},
url = {https://www.sciencedirect.com/science/article/pii/S266691532300183X},
author = {Lisette Corbin and Emily Griner and Salman Seyedi and Zifan Jiang and Kailey Roberts and Mina Boazak and Ali {Bahrami Rad} and Gari D. Clifford and Robert O. Cotes},
keywords = {Depression, LIWC, Psychiatric interview, Computational linguistics},
abstract = {Major Depressive Disorder (MDD) is a leading health burden worldwide. Previous research has demonstrated that linguistic analysis of depressed individuals’ written and oral speech has potential as a diagnostic and monitoring biomarker. We sought to determine if the semantic content of speech differs between individuals with current MDD, past MDD, and controls. We recruited 53 volunteers for a simulated telehealth psychiatric intake interview. The sample included 14 individuals with current MDD, 21 with past MDD, and 18controls, all confirmed using a semi-structured diagnostic interview. The manually-transcribed interview transcripts were analyzed utilizing the LIWC-22 dictionary and statistical tests were applied to identify differences in the linguistic patterns between each clinical categorization. When comparing depressed subjects (either current or past) versus controls, significant differences were found for emotional tone, total function words, auxiliary verbs, negative tone, negative emotion, anxiety, sadness, attention, and visual. Individuals with past MDD only differed from those with current MDD in use of analytical thinking and auxiliary verbs. These results indicate that LIWC categories could differentiate current or past depressed subjects from controls, but fewer differences emerged when comparing current and past MDD. Further prospective studies with larger sample sizes are needed to confirm these findings.}
}
@article{METHLING2022100013,
title = {Heuristics in multi-criteria decision-making: The cost of fast and frugal decisions},
journal = {EURO Journal on Decision Processes},
volume = {10},
pages = {100013},
year = {2022},
issn = {2193-9438},
doi = {https://doi.org/10.1016/j.ejdp.2022.100013},
url = {https://www.sciencedirect.com/science/article/pii/S2193943822000024},
author = {Florian Methling and Sara J.M. Abdeen and Rüdiger {von Nitzsch}},
keywords = {MCDM, Decision support, Heuristics, Utility theory, Value-focused thinking},
abstract = {There has been an ongoing debate in research regarding the use of heuristics in decision-making. Advocators have succeeded in showing that applying heuristics not only reduces effort but can even be more accurate than analytical approaches under certain conditions. Others point out the biases and cognitive distortions inherent in disregarding information. Researchers have used both simulations and experiments to study how the use of heuristics affects the decision's outcome. However, a good decision is determined by the process and not a lucky outcome. It is a conscious reflection on the decision-maker's information and preferences. Therefore, a heuristic must be assessed by its ability to match a structured decision processing all available information. Thus, the question remains: how often does the reduction of information considered in heuristic decisions lead to a different recommended alternative? We applied different heuristics to a dataset of 945 real, personal decisions. We have found that by using heuristics instead of a fully developed decision structure, in 60.34% of cases, a different alternative would have been recommended to the decision-maker leading to a mean relative utility loss for the deviating decisions of 34.58%. This shows that a continuous effort to reflect on the weighing of objectives and alternatives leads to better decisions.}
}
@article{SHU2025117791,
title = {MSFPSO: Multi-algorithm integrated particle swarm optimization with novel strategies for solving complex engineering design problems},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {437},
pages = {117791},
year = {2025},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2025.117791},
url = {https://www.sciencedirect.com/science/article/pii/S0045782525000635},
author = {Bin Shu and Gang Hu and Mao Cheng and Cunxia Zhang},
keywords = {Particle swarm optimization, Cauchy variation, Joint adversarial selection, Differential creative search, Attraction-rejection, Algorithm fusion},
abstract = {Particle swarm optimization (PSO) is considered among the best seminal meta-heuristic algorithms,boasting merits of minimal parameter requirements, straightforward implementation, and highly accelerated convergence capacity, lower computational complexity, etc. Nevertheless, it also has drawbacks, for instance, it tends to converge prematurely at local optima, lack of diversity, and low accuracy. In order to effectively overcome these shortcomings, this paper presents a multi-strategy fusion enhanced PSO called MSFPSO algorithm. Firstly,It motivated by the black-winged kite algorithm, a migration mechanism based on Cauchy's variation is introduced. This mechanism contributes to the efficiency and effectiveness of the algorithm in exploiting the present search area. Also, it effectively balances the dynamics relationship between exploration and exploitation, boosting the algorithm's global and local search capabilities.Second, a joint-opposition selection strategy is introduced for expanding the solution search range. Our approach is designed to avoid getting stuck in local optima. Specifically, selective opposition obtains the proximity dimension of a candidate solution through a linearly decreasing threshold. Dynamic opposition further extends the process of investigating the solution space. The algorithm is fully incorporated with the differential creative search algorithm for dual-strategy scenarios to enhance the performance of the decision-making effectiveness, population diversity, exploitation capability of the PSO. Finally, an attraction-rejection optimization strategy is introduced to further obtain a good exploitation-exploration balance capability and avoid stagnation of the algorithm. In addition, the comparison results with eight advanced optimization algorithms and six improved particle swarm optimization algorithms on CEC2020 test sets, and the statistical analysis was conducted by Wilcoxon rank sum test. It illustrate the features of the MSFPSO developed within this research strong competitiveness. The convergence of the algorithm was verified at maximum iterations of 10000 on the CEC2017 test set. Meanwhile, the experimental outcomes of applying MSFPSO to 50 practical engineering design challenges prove its effectiveness and strong applicability. The test results and numerical computations manifest that the MSFPSO algorithm with strong competitiveness will become a preferred class of meta-heuristic algorithms to tackle issues within the realm of engineering optimization.}
}
@article{GUPTA2009481,
title = {Does phonological short-term memory causally determine vocabulary learning? Toward a computational resolution of the debate},
journal = {Journal of Memory and Language},
volume = {61},
number = {4},
pages = {481-502},
year = {2009},
issn = {0749-596X},
doi = {https://doi.org/10.1016/j.jml.2009.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0749596X09000825},
author = {Prahlad Gupta and Jamie Tisdale},
keywords = {Nonword repetition, Vocabulary learning, Computational modeling, Phonological memory, Word learning, Short-term memory, Language},
abstract = {The relationship between nonword repetition ability and vocabulary size and vocabulary learning has been a topic of intense research interest and investigation over the last two decades, following the demonstration that nonword repetition accuracy is predictive of vocabulary size (Gathercole & Baddeley, 1989). However, the nature of this relationship is not well understood. One prominent account posits that phonological short-term memory (PSTM) is a causal determinant both of nonword repetition ability and of phonological vocabulary learning, with the observed correlation between the two reflecting the effect of this underlying third variable (e.g., Baddeley, Gathercole, & Papagno, 1998). An alternative account proposes the opposite causality: that it is phonological vocabulary size that causally determines nonword repetition ability (e.g., Snowling, Chiat, & Hulme, 1991). We present a theory of phonological vocabulary learning, instantiated as a computational model. The model offers a precise account of the construct of PSTM, of performance in the nonword repetition task, of novel word form learning, and of the relationship between all of these. We show through simulation not only that PSTM causally affects both nonword repetition accuracy and phonological vocabulary size, but also that phonological vocabulary size causally affects nonword repetition ability. The plausibility of the model is supported by the fact that its nonword repetition accuracy displays effects of phonotactic probability and of nonword length, which have been taken as evidence for causal effects on nonword repetition accuracy of phonological vocabulary knowledge and PSTM, respectively. Thus the model makes explicit how the causal links posited by the two theoretical perspectives are both valid, in the process reconciling the two perspectives, and indicating that an opposition between them is unnecessary.}
}
@article{FOLLI2022102458,
title = {Biases in belief reports},
journal = {Journal of Economic Psychology},
volume = {88},
pages = {102458},
year = {2022},
issn = {0167-4870},
doi = {https://doi.org/10.1016/j.joep.2021.102458},
url = {https://www.sciencedirect.com/science/article/pii/S016748702100088X},
author = {Dominik Folli and Irenaeus Wolff},
keywords = {Belief elicitation, Belief formation, Belief-action consistency, Framing effects, Projection, Consensus effect, Wishful thinking,  rationalization},
abstract = {Belief elicitation is important in many different fields of economic research. We show that how a researcher elicits such beliefs – in particular, whether the belief is about the participant’s opponent, an unrelated other, or the population of others – strongly affects the belief reports. We study the underlying processes and find a clear consensus effect. Yet, when matching the opponent’s action would lead to a low payoff and the researcher asks for the belief about this opponent, ex-post rationalization kicks in and beliefs are re-adjusted again. Hence, we recommend to ask about unrelated others or about the population in such cases, as ‘opponent beliefs’ are even more detached from the beliefs participants had when deciding about their actions in the corresponding game. We find no evidence of wishful thinking in any of the treatments.}
}
@incollection{HUDEDAGADDI2017233,
title = {Chapter 7 - Quantum inspired computational intelligent techniques in image segmentation},
editor = {Siddhartha Bhattacharyya and Ujjwal Maulik and Paramartha Dutta},
booktitle = {Quantum Inspired Computational Intelligence},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {233-258},
year = {2017},
isbn = {978-0-12-804409-4},
doi = {https://doi.org/10.1016/B978-0-12-804409-4.00007-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128044094000073},
author = {D.P. Hudedagaddi and B.K. Tripathy},
keywords = {Quantum computing, Computing intelligence, Image segmentation, Evolutionary algorithms},
abstract = {Quantum computing (QC) is a new area of research which incorporates elements from mathematics, physics, and computing. Quantum computing has generated a growing interest among scientists, technologists, and industrialists. Over the past decade it provided a platform for research to people in the scientific, technical, and industrial fields. Quantum physics concepts have been used in developing the basics of QC. In QC, the parallel processing feature has reduced the algorithm complexities which are being used. This feature helped find solutions to several optimization problems and issues that were related to it. Quantum inspired intelligent computational methods have been used in several application areas. Image segmentation is one such area and the exploration of this feature in image segmentation is the primary focus of this chapter.}
}
@incollection{SEJNOWSKI20012460,
title = {Computational Neuroscience},
editor = {Neil J. Smelser and Paul B. Baltes},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences},
publisher = {Pergamon},
address = {Oxford},
pages = {2460-2465},
year = {2001},
isbn = {978-0-08-043076-8},
doi = {https://doi.org/10.1016/B0-08-043076-7/03419-7},
url = {https://www.sciencedirect.com/science/article/pii/B0080430767034197},
author = {T.J. Sejnowski},
abstract = {The goal of computational neuroscience is to explain in computational terms how brains generate behaviors. Computational models of the brain explore how populations of highly interconnected neurons are formed during development and how they come to represent, process, store, act upon, and become altered by, information present in the environment. Techniques from computer science and mathematics are used to simulate and analyze these computational models and provide links between the widely ranging levels of investigation, from the molecular to the systems levels. Computational neuroscience is a relatively young discipline that is growing rapidly. Most of the models that have been developed thus far have been aimed at interpreting experimental data and providing a conceptual framework for the dynamic properties of neural systems. A more comprehensive theory of brain function should arise as we gain a broader understanding of the computational resources of nervous systems at all levels of organization.}
}
@article{HAMALAINEN2024100050,
title = {Generating policy alternatives for decision making: A process model, behavioural issues, and an experiment},
journal = {EURO Journal on Decision Processes},
volume = {12},
pages = {100050},
year = {2024},
issn = {2193-9438},
doi = {https://doi.org/10.1016/j.ejdp.2024.100050},
url = {https://www.sciencedirect.com/science/article/pii/S2193943824000062},
author = {Raimo P. Hämäläinen and Tuomas J. Lahtinen and Kai Virtanen},
keywords = {Policy decision, Generation of policy alternatives, Portfolio decision analysis, Path dependence, Cognitive biases and heuristics},
abstract = {The generation of alternative policies is essential in complex decision tasks with multiple interests and stakeholders. A diverse set of policies is typically desirable to cover the range of options and objectives. Decision modelling literature has often assumed that clearly defined decision alternatives are readily available. This is not a realistic assumption in practice. We present a structured process model for the generation of policy alternatives in settings that include non-quantifiable elements and where portfolio optimisation approaches are not applicable. Behavioural issues and path dependence as well as heuristics and biases which can occur during the process are discussed. The behavioural experiment compares policy alternatives obtained by using two different portfolio generation techniques. The results of the experiment demonstrate that path dependence can occur in policy generation. We report thinking patterns of subjects which relate to biases and heuristics.}
}
@article{POPAT2019365,
title = {Learning to code or coding to learn? A systematic review},
journal = {Computers & Education},
volume = {128},
pages = {365-376},
year = {2019},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2018.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0360131518302768},
author = {Shahira Popat and Louise Starkey},
keywords = {Coding, Programming, School, Computer, Outcome, Skills},
abstract = {The resurgence of computer programming in the school curriculum brings a promise of preparing students for the future that goes beyond just learning how to code. This study reviewed research to analyse educational outcomes for children learning to code at school. A systematic review was applied to identify relevant articles and a thematic analysis to synthesise the findings. Ten articles were included in the synthesis and an overarching model was developed which depicts the themes. The results demonstrate that although students are learning to code, a range of other educational outcomes can be learnt or practiced through the teaching of coding. These included mathematical problem-solving, critical thinking, social skills, self-management and academic skills. The review also identified the importance of instructional design for developing these educational outcomes through coding.}
}
@article{PALMERI2004378,
title = {Computational approaches to the development of perceptual expertise},
journal = {Trends in Cognitive Sciences},
volume = {8},
number = {8},
pages = {378-386},
year = {2004},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2004.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S1364661304001603},
author = {Thomas J. Palmeri and Alan C-N. Wong and Isabel Gauthier},
abstract = {Dog experts, ornithologists, radiologists and other specialists are noted for their remarkable abilities at categorizing, identifying and recognizing objects within their domain of expertise. A complete understanding of the development of perceptual expertise requires a combination of thorough empirical research and carefully articulated computational theories that formalize specific hypotheses about the acquisition of expertise. A comprehensive computational theory of the development of perceptual expertise remains elusive, but we can look to existing computational models from the object-recognition, perceptual-categorization, automaticity and related literatures for possible starting points. Arguably, hypotheses about the development of perceptual expertise should first be explored within the context of existing computational models of visual object understanding before considering the creation of highly modularized adaptations for particular domains of perceptual expertise.}
}
@article{NUNES2020117761,
title = {Thinking the future of membranes: Perspectives for advanced and new membrane materials and manufacturing processes},
journal = {Journal of Membrane Science},
volume = {598},
pages = {117761},
year = {2020},
issn = {0376-7388},
doi = {https://doi.org/10.1016/j.memsci.2019.117761},
url = {https://www.sciencedirect.com/science/article/pii/S0376738819333113},
author = {Suzana P. Nunes and P. Zeynep Culfaz-Emecen and Guy Z. Ramon and Tymen Visser and Geert Henk Koops and Wanqin Jin and Mathias Ulbricht},
abstract = {The state-of-the-art of membrane technology is characterized by a number of mature applications such as sterile filtration, hemodialysis, water purification and gas separation, as well as many more niche applications of successful membrane-based separation and processing of fluid mixtures. The membrane industry is currently employing a portfolio of established materials, mostly standard polymers or inorganic materials (not originally developed for membranes), and easily scalable manufacturing processes such as phase inversion, interfacial polymerization and coating. Innovations in membranes and their manufacturing processes must meet the desired intrinsic properties that determine selectivity and flux, for specific applications. However, tunable and stable performance, as well as sustainability over the entire life cycle of membrane products are becoming increasingly important. Membrane manufacturers are progressively required to share the carbon footprint of their membrane modules with their customers. Environmental awareness among the world's population is a growing phenomenon and finds its reflection in product development and manufacturing processes. In membrane technology one can see initial steps in this direction with the replacement of hazardous solvents, the utilization of renewable materials for membrane production and the reuse of membrane modules. Other examples include increasing the stability of organic membrane polymers and lowering the cost of inorganic membranes. In a long-term perspective, many more developments in materials science will be required for making new, advanced membranes. These include “tools” such as self-assembly or micro- and nano-fabrication, and “building blocks”, e.g. tailored block copolymers or 1D, 2D and 3D materials. Such membranes must be fabricated in a simpler manner and be more versatile than existing ones. In this perspective paper, a vision of such LEGO®-like membranes with precisely adjustable properties will be illustrated with, where possible, examples that already demonstrate feasibility. These include the possibility to switch properties using an external stimulus, adapting a membrane's selectivity to a given separation, or providing the ability to assemble, disassemble and reassemble the membrane on a suitable support as scaffold, in situ, in place and on-demand. Overall, it is foreseen that the scope of future membrane applications will become much wider, based on improved existing membrane materials and manufacturing processes, as well as the combination of novel, tailor-made “building blocks” and “tools” for the fabrication of next-generation membranes tuned to specific applications.}
}
@article{ARLE2014642,
title = {Mechanism of Dorsal Column Stimulation to Treat Neuropathic but not Nociceptive Pain: Analysis With a Computational Model},
journal = {Neuromodulation: Technology at the Neural Interface},
volume = {17},
number = {7},
pages = {642-655},
year = {2014},
issn = {1094-7159},
doi = {https://doi.org/10.1111/ner.12178},
url = {https://www.sciencedirect.com/science/article/pii/S1094715914601410},
author = {Jeffrey E. Arle and Kristen W. Carlson and Longzhi Mei and Nicolae Iftimia and Jay L. Shils},
keywords = {Chronic pain, dorsal column stimulation, gate control theory of pain, neural circuitry modeling, neuromodulation mechanism, neuropathic pain, spinal cord stimulation},
abstract = {Objective:
Stimulation of axons within the dorsal columns of the human spinal cord has become a widely used therapy to treat refractory neuropathic pain. The mechanisms have yet to be fully elucidated and may even be contrary to standard “gate control theory.” Our hypothesis is that a computational model provides a plausible description of the mechanism by which dorsal column stimulation (DCS) inhibits wide dynamic range (WDR) cell output in a neuropathic model but not in a nociceptive pain model.
Materials and Methods:
We created a computational model of the human spinal cord involving approximately 360,000 individual neurons and dendritic processing of some 60 million synapses—the most elaborate dynamic computational model of the human spinal cord to date. Neuropathic and nociceptive “pain” signals were created by activating topographically isolated regions of excitatory interneurons and high-threshold nociceptive fiber inputs, driving analogous regions of WDR neurons. Dorsal column fiber activity was then added at clinically relevant levels (e.g., Aβ firing rate between 0 and 110 Hz by using a 210-μsec pulse width, 50–150 Hz frequency, at 1–3 V amplitude).
Results:
Analysis of the nociceptive pain, neuropathic pain, and modulated circuits shows that, in contradiction to gate control theory, 1) nociceptive and neuropathic pain signaling must be distinct, and 2) DCS neuromodulation predominantly affects the neuropathic signal only, inhibiting centrally sensitized pathological neuron groups and ultimately the WDR pain transmission cells.
Conclusion:
We offer a different set of necessary premises than gate control theory to explain neuropathic pain inhibition and the relative lack of nociceptive pain inhibition by using retrograde DCS. Hypotheses regarding not only the pain relief mechanisms of DCS were made but also regarding the circuitry of pain itself, both nociceptive and neuropathic. These hypotheses and further use of the model may lead to novel stimulation paradigms.}
}
@article{RIESENFELD20151054,
title = {Initiating a CAD renaissance: Multidisciplinary analysis driven design: Framework for a new generation of advanced computational design, engineering and manufacturing environments},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {284},
pages = {1054-1072},
year = {2015},
note = {Isogeometric Analysis Special Issue},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2014.11.024},
url = {https://www.sciencedirect.com/science/article/pii/S0045782514004502},
author = {Richard F. Riesenfeld and Robert Haimes and Elaine Cohen},
keywords = {Multidisciplinary analysis driven design, Integrated computational engineering, CAD/CAE/CAM/IGA},
abstract = {We present a critical analysis of the effectiveness of the current field of CAD, and discuss some of the forces that have taken it so far off course from its strikingly foresighted origins. Armed with the ensuing understanding of the operational forces that have taken CAD adrift, we conclude that the disparity between CAD’s mired state-of-the-art condition relative to more appropriate, inspired and achievable goals for CAD calls for more drastic measures. It is asserted that, well beyond the evolutionary progression of incremental steps characteristic of next version system releases, the field is overdue for developing a class of genuine design-centric, ab initio, CAD systems architectures effecting the original CAD vision through the powerful instruments of contemporary computing tools and technologies.}
}
@article{ANDERSON2015309,
title = {Reading visually embodied meaning from the brain: Visually grounded computational models decode visual-object mental imagery induced by written text},
journal = {NeuroImage},
volume = {120},
pages = {309-322},
year = {2015},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2015.06.093},
url = {https://www.sciencedirect.com/science/article/pii/S1053811915006345},
author = {Andrew James Anderson and Elia Bruni and Alessandro Lopopolo and Massimo Poesio and Marco Baroni},
keywords = {Concept representation, Embodiment, Mental imagery, Perceptual simulation, Language, Multimodal semantic models, Representational similarity},
abstract = {Embodiment theory predicts that mental imagery of object words recruits neural circuits involved in object perception. The degree of visual imagery present in routine thought and how it is encoded in the brain is largely unknown. We test whether fMRI activity patterns elicited by participants reading objects' names include embodied visual-object representations, and whether we can decode the representations using novel computational image-based semantic models. We first apply the image models in conjunction with text-based semantic models to test predictions of visual-specificity of semantic representations in different brain regions. Representational similarity analysis confirms that fMRI structure within ventral-temporal and lateral-occipital regions correlates most strongly with the image models and conversely text models correlate better with posterior-parietal/lateral-temporal/inferior-frontal regions. We use an unsupervised decoding algorithm that exploits commonalities in representational similarity structure found within both image model and brain data sets to classify embodied visual representations with high accuracy (8/10) and then extend it to exploit model combinations to robustly decode different brain regions in parallel. By capturing latent visual-semantic structure our models provide a route into analyzing neural representations derived from past perceptual experience rather than stimulus-driven brain activity. Our results also verify the benefit of combining multimodal data to model human-like semantic representations.}
}
@incollection{VALERIO201385,
title = {Chapter 6 - Computational Translation and Integration of Test Data to Meet Risk Assessment Goals},
editor = {Bruce A. Fowler},
booktitle = {Computational Toxicology},
publisher = {Academic Press},
address = {San Diego},
pages = {85-112},
year = {2013},
isbn = {978-0-12-396461-8},
doi = {https://doi.org/10.1016/B978-0-12-396461-8.00008-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780123964618000087},
author = {Luis G. Valerio},
keywords = { toxicology,  methods, translational research, QSAR, computational toxicology, drug safety, safety assessment},
abstract = {The remarkable advances of high-performance computing to facilitate and increase efficiency in helping to resolve or support assessments on the toxic effects of chemicals on tissues and genomic material have led to development of novel in silico methods. These methods can support risk assessment via integration of study data that can be translated into meaningful predictive information. This chapter describes some methods in computational toxicology and how to integrate experimental data with computational assessments for supporting risk assessment.}
}
@article{IOANNIDOU2009236,
title = {AgentCubes: Incremental 3D end-user development},
journal = {Journal of Visual Languages & Computing},
volume = {20},
number = {4},
pages = {236-251},
year = {2009},
note = {Special Issue on Best Papers from VL/HCC2008},
issn = {1045-926X},
doi = {https://doi.org/10.1016/j.jvlc.2009.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S1045926X09000238},
author = {Andri Ioannidou and Alexander Repenning and David C. Webb},
keywords = {Incremental 3D, Game design, Visual programming, End-user development, IT fluency, Computational thinking},
abstract = {3D game development can be an enticing way to attract K-12 students to computer science, but designing and programming 3D games is far from trivial. Students need to achieve a certain level of 3D fluency in modeling, animation, and programming to be able to create compelling 3D content. The combination of innovative end-user development tools and standards-based curriculum that promotes IT fluency by shifting the pedagogical focus from programming to design, can address motivational aspects without sacrificing principled educational goals. The AgentCubes 3D game-authoring environment raises the ceiling of end-user development without raising the threshold. Our formal user study shows that with Incremental 3D, the gradual approach to transition from 2D to 3D authoring, middle school students can build sophisticated 3D games including 3D models, animations, and programming.}
}
@article{ANDERSON201738,
title = {Isolating blocks as computational tools in the circular restricted three-body problem},
journal = {Physica D: Nonlinear Phenomena},
volume = {343},
pages = {38-50},
year = {2017},
issn = {0167-2789},
doi = {https://doi.org/10.1016/j.physd.2016.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S0167278916303013},
author = {Rodney L. Anderson and Robert W. Easton and Martin W. Lo},
keywords = {Circular restricted three-body problem, Isolating blocks, Invariant manifolds, Invariant 3-sphere},
abstract = {Isolating blocks may be used as computational tools to search for the invariant manifolds of orbits and hyperbolic invariant sets associated with libration points while also giving additional insight into the dynamics of the flow in these regions. We use isolating blocks to investigate the dynamics of objects entering the Earth–Moon system in the circular restricted three-body problem with energies close to the energy of the L2 libration point. Specifically, the stable and unstable manifolds of Lyapunov orbits and the hyperbolic invariant set around the libration points are obtained by numerically computing the way orbits exit from an isolating block in combination with a bisection method. Invariant spheres of solutions in the spatial problem may then be located using the resulting manifolds.}
}
@article{HUANG2006567,
title = {An integrated computational intelligence approach to product concept generation and evaluation},
journal = {Mechanism and Machine Theory},
volume = {41},
number = {5},
pages = {567-583},
year = {2006},
issn = {0094-114X},
doi = {https://doi.org/10.1016/j.mechmachtheory.2005.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S0094114X05001333},
author = {Hong-Zhong Huang and Ruifeng Bo and Wei Chen},
keywords = {Conceptual design, Computational intelligence, Optimal concept, Genetic algorithm, Fuzzy neural network},
abstract = {Product concept generation and evaluation are two major activities for obtaining an optimal concept in conceptual design. In this paper, an integrated computational intelligence approach is proposed for dealing with these two aspects. A group of satisfactory concepts are generated first by using genetic algorithm and incorporating the information from knowledge base. Then concept evaluation and decision making are implemented using fuzzy neural network to obtain an optimal concept. Our procedure of using computational intelligence in conceptual design is described. The key issues in implementing the proposed approach are discussed, and finally the applicability of the proposed method is illustrated with an engineering example.}
}
@article{RAHMAN201872,
title = {Hybrid bio-Inspired computational intelligence techniques for solving power system optimization problems: A comprehensive survey},
journal = {Applied Soft Computing},
volume = {69},
pages = {72-130},
year = {2018},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2018.04.051},
url = {https://www.sciencedirect.com/science/article/pii/S1568494618302424},
author = {Imran Rahman and Junita Mohamad-Saleh},
keywords = {Computational intelligence, Hybrid optimization, Optimization, Bio-inspired computation, Power system},
abstract = {Optimization problems of modern day power system are very challenging to resolve because of its design complexity, wide geographical dispersion and influence from many unpredictable factors. For that reason, it is essential to apply most effective optimization techniques by taking full benefits of simplified formulation and execution of a particular problem. This study presents a summary of significant hybrid bio-inspired computational intelligence (CI) techniques utilized for power system optimization. Authors have reviewed an extensive range of hybrid CI techniques and examined the motivations behind their improvements. Various applications of hybrid bio-inspired CI algorithms have been highlighted in this paper. In addition, few drawbacks regarding the hybrid CI algorithms are explained. Current trends in CI techniques from the past researches have also been discussed in the domain of power system optimization. Lastly, some future research directions are suggested for further advancement of hybrid techniques.}
}
@article{TURHAN20075237,
title = {Statistical and computational intelligence tools for the analyses of warp tension in different back-rest oscillations},
journal = {Information Sciences},
volume = {177},
number = {23},
pages = {5237-5252},
year = {2007},
note = {Including: Mathematics of Uncertainty},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2007.06.029},
url = {https://www.sciencedirect.com/science/article/pii/S0020025507003246},
author = {Yıldıray Turhan and Sezai Tokat and Recep Eren},
keywords = {Neural networks, Radial basis function, Cross-validation, Data regression, Warp tension, Back-rest oscillation, Weft density},
abstract = {In this paper, experimental, computational intelligence based and statistical investigations of warp tensions in different back-rest oscillations are presented. Firstly, in the experimental stage, springs having different stiffnesses are used to obtain different back-rest oscillations. For each spring, fabrics are woven in different weft densities and the warp tensions are measured and saved during weaving process. Secondly, in the statistical investigation, the experimental data are analyzed by using linear multiple and quadratic multiple-regression models. Later, in the computational intelligence based investigation, the data obtained from the experimental study are analyzed by using artificial neural networks that are universal approximators which provide a massively parallel processing and decentralized computing. Specially, radial basis function neural network structure is chosen. In this structure, cross-validation technique is used in order to determine the number of radial basis functions. Finally, the results of regression analysis, the computational intelligence based analysis and experimental measurements are compared by using the coefficient of determination. From the results, it is shown that the computational intelligence based analysis indicates a better agreement with the experimental measurement than the statistical analysis.}
}
@article{CHAUNCEY2023100182,
title = {A framework and exemplars for ethical and responsible use of AI Chatbot technology to support teaching and learning},
journal = {Computers and Education: Artificial Intelligence},
volume = {5},
pages = {100182},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100182},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000619},
author = {Sarah A. Chauncey and H. Patricia McKenna},
keywords = {AI ethics, AI responsibility, AI-Rich learning environments, Cognitive flexibility, Critical thinking, Self-regulation},
abstract = {The aim of this paper is to investigate the ethical and responsible use of AI chatbots in education in support of critical thinking, cognitive flexibility and self-regulation in terms of their potential to enhance and motivate teaching and learning in contemporary education environments. AI chatbots such as ChatGPT by OpenAI appear to be improving in conversational and other capabilities and this paper explores such advances using version 4. Based on a review of the research literature, a conceptual framework is formulated for responsible use of AI chatbots in education supporting cognitive flexibility in AI-rich learning environments. The framework is then operationalized for use in this paper through the development of exemplars for math, english language arts (ELA), and studying with ChatGPT to close learning gaps in an effort to foster more ethical and responsible approaches to the design and development of AI chatbots for application and use in teaching and learning environments. This paper extends earlier foundational work on cognitive flexibility and AI chatbots as well as work on cognitive flexibility in support of creativity and innovation with AI chatbots in urban civic spaces.}
}
@article{KARTHIK2024106286,
title = {Improving brain tumor treatment with better imaging and real-time therapy using quantum dots},
journal = {Biomedical Signal Processing and Control},
volume = {95},
pages = {106286},
year = {2024},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2024.106286},
url = {https://www.sciencedirect.com/science/article/pii/S1746809424003446},
author = {A. Karthik and S. {Shiek Aalam} and M. Sivakumar and M.V. {Rama Sundari} and J. {Dafni Rose} and Muniyandy Elangovan and A. Rajaram},
keywords = {NIR- quantum dots, Magnetic resonance imaging, Radiotherapy, Brain Tumor},
abstract = {Recent advancements in medical imaging and therapeutic technologies have propelled innovative strategies in brain tumor treatment. This study introduces a comprehensive methodology merging Quantum Dots (QDs) and Real-Time Imaging-Guided Therapeutics (RIGT) to refine the precision of brain tumor radiotherapy. Focusing on the synthesis of near-infrared quantum dots (NIR-QDs), the study emphasizes the critical role of meticulous surface functionalization in achieving biocompatibility and stability. The methodology integrates 3D brain MRI images into the ingeniously devised Real-Time Imaging-Guided Therapeutics (RIGT) system, facilitating precise tumor localization and adaptive treatment protocol adjustments. Novel hybrid architecture is introduced for real-time MRI data analysis, enabling intricate tumor segmentation, feature extraction, localization, and synthetic image generation. This fusion of technologies, empowered by artificial intelligence, equips healthcare professionals with comprehensive insights into tumor intricacies and potential treatment outcomes. The proposed methodology's transformative objective seeks to redefine brain tumor treatment by seamlessly integrating advanced imaging modalities, cutting-edge nanotechnology, and AI-driven precision therapeutics. It envisions establishing a new paradigm in brain tumor treatment, promising heightened efficacy and minimized risks for patients. The study's numerical findings showcase the AI-powered image analysis capabilities of the Hybrid CNN-GAN network. Demonstrating superior performance in tumor segmentation, the results exhibit an Intersection over Union (IoU) of 0.89, Dice Coefficient of 0.95, F1-score of 0.94, and Structural Similarity Index (SSI) of 0.91. Additionally, computational efficiency is evident, with a short processing time of 65 ms and balanced CPU and GPU usage at 80 % and 90 %, respectively. In summary, this study presents an innovative methodology for brain tumor treatment, underpinned by exceptional numerical results validating its efficacy and computational efficiency.}
}
@article{HALLINAN2001506,
title = {Thinking Beyond the Fringe},
journal = {Trends in Cognitive Sciences},
volume = {5},
number = {12},
pages = {506-507},
year = {2001},
issn = {1364-6613},
doi = {https://doi.org/10.1016/S1364-6613(00)01802-7},
url = {https://www.sciencedirect.com/science/article/pii/S1364661300018027},
author = {Jennifer Hallinan},
keywords = {explicit models of memory, stochastic generative approach, evolution of the neural modularity, metarepresentation}
}
@incollection{MISHRA2024231,
title = {Chapter Twelve - Unravelling the gut microbiome: Connecting with AI for deeper insights},
editor = {Akanksha Srivastava and Vaibhav Mishra},
series = {Methods in Microbiology},
publisher = {Academic Press},
volume = {55},
pages = {231-246},
year = {2024},
booktitle = {Artificial Intelligence in Microbiology: Scope and Challenges Volume 1},
issn = {0580-9517},
doi = {https://doi.org/10.1016/bs.mim.2024.05.012},
url = {https://www.sciencedirect.com/science/article/pii/S058095172400028X},
author = {Vaibhav Mishra and Chhavi Atri and Raj Pandey and Akanksha Srivastava},
keywords = {Artificial intelligence, Gut microbes, Microbiology, Gastroenterology, Machine learning, Deep learning},
abstract = {Artificial intelligence (AI) remains a relatively unfamiliar concept for many, but its significance in the biomedical field is gaining recognition as the world undergoes transformative changes. Furthermore, AI possesses the potential to emulate critical thinking, reasoning, problem-solving abilities, and logical capacities of machines. Additionally, in the realm of gut microbiota research, AI emerges as a valuable asset. The synergy between gut microbes and AI not only holds promise for treating diverse gastroenterological diseases but also aids in comprehending the intricate relationships between gut microbes and microbes of resides into the other body parts. Moreover, AI facilitates a deeper understanding of different facets within gut-microbes interaction research. These direct communications are governed by chemical messengers, hormones, and neurotransmitters, detectable through biosensor chips employing machine learning (ML). Additionally, the indirect regulation of gut function by the brain via the hypothalamic-pituitary-adrenal (HPA) axis can be analysed using different computational models. This promising prospect remains largely unexplored, and in this chapter, our aim is to delve into and harness the potential of AI in gut microbial research.}
}
@article{BRIDGES2012780,
title = {Thinking Outside the Cleft to Understand Synaptic Activity: Contribution of the Cystine-Glutamate Antiporter (System xc−) to Normal and Pathological Glutamatergic Signaling},
journal = {Pharmacological Reviews},
volume = {64},
number = {3},
pages = {780-802},
year = {2012},
issn = {0031-6997},
doi = {https://doi.org/10.1124/pr.110.003889},
url = {https://www.sciencedirect.com/science/article/pii/S0031699724010159},
author = {Richard Bridges and Victoria Lutgen and Doug Lobner and David A. Baker},
abstract = {System xc− represents an intriguing target in attempts to understand the pathological states of the central nervous system. Also called a cystine-glutamate antiporter, system xc− typically functions by exchanging one molecule of extracellular cystine for one molecule of intracellular glutamate. Nonvesicular glutamate released during cystine-glutamate exchange activates extrasynaptic glutamate receptors in a manner that shapes synaptic activity and plasticity. These findings contribute to the intriguing possibility that extracellular glutamate is regulated by a complex network of release and reuptake mechanisms, many of which are unique to glutamate and rarely depicted in models of excitatory signaling. Because system xc− is often expressed on non-neuronal cells, the study of cystine-glutamate exchange may advance the emerging viewpoint that glia are active contributors to information processing in the brain. It is noteworthy that system xc− is at the interface between excitatory signaling and oxidative stress, because the uptake of cystine that results from cystine-glutamate exchange is critical in maintaining the levels of glutathione, a critical antioxidant. As a result of these dual functions, system xc− has been implicated in a wide array of central nervous system diseases ranging from addiction to neurodegenerative disorders to schizophrenia. In the current review, we briefly discuss the major cellular components that regulate glutamate homeostasis, including glutamate release by system xc−. This is followed by an in-depth discussion of system xc− as it relates to glutamate release, cystine transport, and glutathione synthesis. Finally, the role of system xc− is surveyed across a number of psychiatric and neurodegenerative disorders.}
}
@article{YILMAZ2023100005,
title = {Augmented intelligence in programming learning: Examining student views on the use of ChatGPT for programming learning},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {1},
number = {2},
pages = {100005},
year = {2023},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2023.100005},
url = {https://www.sciencedirect.com/science/article/pii/S2949882123000051},
author = {Ramazan Yilmaz and Fatma Gizem {Karaoglan Yilmaz}},
keywords = {Generative artificial intelligence, ChatGPT, Programming, Programming learning, Student opinions},
abstract = {With the diversification of generative artificial intelligence (AI) applications, the interest in their use in every segment and field of society in recent years has been increasing rapidly. One of these areas is programming learning and program writing processes. One of the generative AI tools used for this purpose is ChatGPT. The use of ChatGPT in program writing processes has become widespread, and this tool has a certain potential in the programming process. However, when the literature is examined, research results related to using ChatGPT for this purpose have yet to be found. The existing literature has a gap that requires exploration. This study aims to analyze the students' perspectives on using ChatGPT in the field of programming and programming learning. The study encompassed a cohort of 41 undergraduate students enrolled in a public university's Computer Technology and Information Systems department. The research was carried out within the scope of the Object-Oriented Programming II course for eight weeks. Throughout the research process, students were given project assignments related to the course every week, and they were asked to use ChatGPT while solving them. The research data was collected using a form consisting of open-ended questions and analyzed through content analysis. The research findings revealed both the advantages and disadvantages of ChatGPT usage, as perceived by the students. The students stated that the main benefits of using ChatGPT in programming learning are providing fast and mostly correct answers to questions, improving thinking skills, facilitating debugging, and increasing self-confidence. On the other hand, the main limitations of using ChatGPT in programming education were getting students used to laziness, being unable to answer some questions, or giving incomplete/incorrect answers, causing professional anxiety in students. Based on the results of the research, it can be said that it would be useful to integrate generative AI tools into programming courses considering the advantages they provide in programming teaching. However, appropriate measures should be taken regarding the limitations it brings. Based on the research findings, several recommendations were proposed regarding the integration of ChatGPT into lessons.}
}
@article{COSTA20055,
title = {Interactive Computation: Stepping Stone in the Pathway From Classical to Developmental Computation},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {141},
number = {5},
pages = {5-31},
year = {2005},
note = {Proceedings of the Workshop on the Foundations of Interactive Computation (FInCo 2005)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2005.05.014},
url = {https://www.sciencedirect.com/science/article/pii/S157106610505187X},
author = {Antônio Carlos da Rocha Costa and Graçaliz Pereira Dimuro},
keywords = {Interactive computation, developmental computation, domain theory, classical theory of computation},
abstract = {This paper reviews and extends previous work on the domain-theoretic notion of Machine Development. It summarizes the concept of Developmental Computation and shows how Interactive Computation can be understood as a stepping stone in the pathway from Classical to Developmental Computation. A critical appraisal is given of Classical Computation, showing in which ways its shortcomings tend to restrict the possible evolution of real computers, and how Interactive and Developmental Computation overcome such shortcomings. The idea that Developmental Computation is more encompassing than Interactive Computation is stressed. A formal framework for Developmental Computation is sketched, and the current frontier of the work on Developmental Computation is briefly exposed.}
}
@article{NOWROOZI201252,
title = {A general computational recognition primed decision model with multi-agent rescue simulation benchmark},
journal = {Information Sciences},
volume = {187},
pages = {52-71},
year = {2012},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2011.09.039},
url = {https://www.sciencedirect.com/science/article/pii/S0020025511005330},
author = {Alireza Nowroozi and Mohammad E. Shiri and Angeh Aslanian and Caro Lucas},
keywords = {Naturalistic decision making, Recognition primed decision model, Computational modeling, Disaster management, RoboCup, Multi-agent rescue simulation benchmark},
abstract = {Analytical decision making strategies rely on weighing pros and cons of multiple options in an unbounded rationality manner. Contrary to these strategies, recognition primed decision (RPD) model which is a primary naturalistic decision making (NDM) approach assumes that experienced and professional decision makers when encounter problems in real operating conditions are able to use their previous experiences and trainings in order to diagnose the problem, recall the appropriate solution, evaluate it mentally, and implement it to handle the problem in a satisficing manner. In this paper, a computational form of RPD, now called C-RPD, is presented. Unified Modeling Language was used as a modeling language to represent the proposed C-RPD model in order to make the implementation easy and obvious. To execute the model, RoboCup Rescue agent simulation environment, which is one of the best and the most famous complex and multi-agent large-scale environments, was selected. The environment simulates the incidence of fire and earthquakes in urban areas where it is the duty of the police forces, firefighters and ambulance teams to control the crisis. Firefighters of SOS team are first modeled and implemented by utilizing C-RPD and then the system is trained using an expert’s experience. There are two evaluations. To find out the convergence of different versions developed during experience adding, some of the developed versions are chosen and evaluated on seven maps. Results show performance improvements. The SOS team ranked first in an official world championship and three official open tournaments.}
}
@article{GOLDSTONE2005424,
title = {Computational models of collective behavior},
journal = {Trends in Cognitive Sciences},
volume = {9},
number = {9},
pages = {424-430},
year = {2005},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2005.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S1364661305002147},
author = {Robert L. Goldstone and Marco A. Janssen},
abstract = {Computational models of human collective behavior offer promise in providing quantitative and empirically verifiable accounts of how individual decisions lead to the emergence of group-level organizations. Agent-based models (ABMs) describe interactions among individual agents and their environment, and provide a process-oriented alternative to descriptive mathematical models. Recent ABMs provide compelling accounts of group pattern formation, contagion and cooperation, and can be used to predict, manipulate and improve upon collective behavior. ABMs overcome an assumption that underlies much of cognitive science – that the individual is the crucial unit of cognition. The alternative advocated here is that individuals participate in collective organizations that they might not understand or even perceive, and that these organizations affect and are affected by individual behavior.}
}
@article{HASUO2017404,
title = {Semantics of higher-order quantum computation via geometry of interaction},
journal = {Annals of Pure and Applied Logic},
volume = {168},
number = {2},
pages = {404-469},
year = {2017},
note = {Eighth Games for Logic and Programming Languages Workshop (GaLoP)},
issn = {0168-0072},
doi = {https://doi.org/10.1016/j.apal.2016.10.010},
url = {https://www.sciencedirect.com/science/article/pii/S0168007216301336},
author = {Ichiro Hasuo and Naohiko Hoshino},
keywords = {Higher-order computation, Quantum computation, Programming language, Geometry of interaction, Denotational semantics, Categorical semantics},
abstract = {While much of the current study on quantum computation employs low-level formalisms such as quantum circuits, several high-level languages/calculi have been recently proposed aiming at structured quantum programming. The current work contributes to the semantical study of such languages by providing interaction-based semantics of a functional quantum programming language; the latter is, much like Selinger and Valiron's, based on linear lambda calculus and equipped with features like the ! modality and recursion. The proposed denotational model is the first one that supports the full features of a quantum functional programming language; we prove adequacy of our semantics. The construction of our model is by a series of existing techniques taken from the semantics of classical computation as well as from process theory. The most notable among them is Girard's Geometry of Interaction (GoI), categorically formulated by Abramsky, Haghverdi and Scott. The mathematical genericity of these techniques—largely due to their categorical formulation—is exploited for our move from classical to quantum.}
}
@article{EVINS2013230,
title = {A review of computational optimisation methods applied to sustainable building design},
journal = {Renewable and Sustainable Energy Reviews},
volume = {22},
pages = {230-245},
year = {2013},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2013.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S1364032113000920},
author = {Ralph Evins},
keywords = {Review, Optimisation, Sustainable, Building, Design, Multi-objective},
abstract = {This paper presents a comprehensive review of all significant research applying computational optimisation to sustainable building design problems. A summary of common heuristic optimisation algorithms is given, covering direct search, evolutionary methods and other bio-inspired algorithms. The main summary table covers 74 works that focus on the application of these methods to different fields of sustainable building design. Key fields are reviewed in detail: envelope design, including constructions and form; configuration and control of building systems; renewable energy generation; and holistic optimisations of several areas simultaneously, with particular focus on residential and retrofit. Improvements to the way optimisation is applied are also covered, including platforms and frameworks, algorithmic comparisons and developments, use of meta-models and incorporation of uncertainty. Trends, including the rise of multi-objective optimisation, are analysed graphically. Likely future developments are discussed.}
}
@article{ROSSITER20241,
title = {MATLAB files to support learning of simple frequency response design},
journal = {IFAC-PapersOnLine},
volume = {58},
number = {26},
pages = {1-6},
year = {2024},
note = {4th IFAC Workshop on Internet Based Control Education - IBCE 2024},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2024.10.261},
url = {https://www.sciencedirect.com/science/article/pii/S2405896324020366},
author = {J.A. Rossiter},
keywords = {Control101 toolbox, frequency response, lead and lag compensation, virtual laboratories, independent learning},
abstract = {This paper presents a small number of MATLAB APPs and livescript files designed to help students both understand and implement frequency response tools into feedback design. The paper presents the thinking behind the use of MATLAB and the topic itself before then describing the proposed resources in detail.}
}
@incollection{GOODSON2010175,
title = {Chapter 10 - Using Computational Modeling to Understand Microtubule Dynamics: A Primer for Cell Biologists},
editor = {Leslie Wilson and John J. Correia},
series = {Methods in Cell Biology},
publisher = {Academic Press},
volume = {95},
pages = {175-188},
year = {2010},
booktitle = {Microtubules, in vitro},
issn = {0091-679X},
doi = {https://doi.org/10.1016/S0091-679X(10)95010-3},
url = {https://www.sciencedirect.com/science/article/pii/S0091679X10950103},
author = {Holly V. Goodson and Ivan V. Gregoretti},
abstract = {Experimental cell biology, biochemistry, and structural biology have provided a wealth of information about microtubule function and mechanism, but we are reaching a limit as to what can be understood from experiment alone. Standard biochemical approaches are not sufficient to make quantitative predictions about microtubule behavior, and they are limited in their ability to test existing conceptual models of microtubule mechanism. Because microtubules are so complex, achieving a deep understanding of microtubule behavior and mechanism will require the input of mathematical and computational modeling. However, this type of analysis can be daunting to the uninitiated. The purpose of this chapter is to provide a straightforward introduction to the various types of modeling and how they can be used to study microtubule function, dynamics, and mechanism.}
}
@article{SZUBA1998321,
title = {A molecular quasi-random model of computations applied to evaluate collective intelligence},
journal = {Future Generation Computer Systems},
volume = {14},
number = {5},
pages = {321-339},
year = {1998},
note = {Bio-inspired solutions to parallel processing problems},
issn = {0167-739X},
doi = {https://doi.org/10.1016/S0167-739X(98)00037-5},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X98000375},
author = {Tadeusz Szuba},
keywords = {Collective intelligence, IQ measure, Social structure, PROLOG, Model of computations, Brownian movements},
abstract = {This paper presents a bio-inspired model of computations, the random PROLOG processor (RPP), used for analysis of collective intelligence (CI). In the RPP, clause_molecules (CMs) of facts, rules, goals, or higher-level logical structures enclosed by membranes move quasi-randomly in structured computational_PROLOG_space (CS). When CMs rendezvous, an inference process can occur iff the logical conditions are fulfilled. CI can be evaluated as follows: (1) the mapping is done of a given social structure into the RPP; (2) the beings and their behavior are translated into PROLOG expressions, carried by CMs; (3) the goal(s) of the social structure are translated into N-element inference (NEI); (4) the efficiency of the NEI is evaluated and given as the intelligence quotient of a social structure (IQS) projected onto NEI.}
}
@article{LUCAS20218320,
title = {Implementing a Novel Software Program to Support Pharmacy Students’ Reflective Practice in Scientific Research},
journal = {American Journal of Pharmaceutical Education},
volume = {85},
number = {10},
pages = {8320},
year = {2021},
issn = {0002-9459},
doi = {https://doi.org/10.5688/ajpe8320},
url = {https://www.sciencedirect.com/science/article/pii/S0002945923015012},
author = {Cherie Lucas and Simon Buckingham Shum and Ming Liu and Mary Bebawy},
keywords = {reflection, formative feedback, pharmacy education, pharmaceutical research},
abstract = {ABSTRACT
Objective. To explore pharmacy students’ perceptions of a novel web application tool (AcaWriter) implemented in a Master of Pharmacy curriculum to support reflective thinking in scientific research. Methods. A qualitative research design involving a 50-minute focus group (n=12) was used. The focus group session was audio-taped, transcribed verbatim, and analyzed thematically using the Braun and Clarke framework. Results. Analysis generated four themes related to AcaWriter’s utility in enhancing students’ research thinking and capacity. The themes identified included: ease of use to prompt reflection, tangible tool with non-judgmental capacity; benefits for enhancing self and peer reflection on research techniques and group dynamics; benefits of the reflective writing process to enhance research capacity compared with engaging in reflective dialogue; and benefits beyond the writing process: cultivating self-improvement and self-confidence. Conclusion. The findings of this study show that a novel web application implemented within a pharmacy curriculum can assist students’ self and peer reflection on a research task. Further research is needed to explore the impact of using this tool and its relationship with academic performance and outcomes.}
}
@article{DUBLJEVIC2024102480,
title = {Colleges and universities are important stakeholders for regulating large language models and other emerging AI},
journal = {Technology in Society},
volume = {76},
pages = {102480},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102480},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24000289},
author = {Veljko Dubljević},
keywords = {Artificial intelligence (AI), Ethics, Public policy, Legitimacy, Oversight},
abstract = {AI technology has already gone through one “winter,” and alarmist thinking may cause yet another one. Calls for a moratorium on AI research increase the salience of the public request for comment on “AI accountability.” Prohibitive approaches are an overreaction, especially when leveraged on virtual (non-embodied) AI agents. While there are legitimate concerns regarding expansion of AI models like ChatGPT in society, a better approach would be to forge a partnership between academia and industry, and utilize infrastructure of campuses to authenticate users and oversee new AI research. The public could also be involved with public libraries authenticating users. This staged approach to embedding AI in society would facilitate addressing ethical concerns, and implementing virtual AI agents in society in a responsible and safe manner.}
}
@article{JACKSON20091397,
title = {There may be more to reaching than meets the eye: Re-thinking optic ataxia},
journal = {Neuropsychologia},
volume = {47},
number = {6},
pages = {1397-1408},
year = {2009},
note = {Perception and Action},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2009.01.035},
url = {https://www.sciencedirect.com/science/article/pii/S0028393209000475},
author = {Stephen R. Jackson and Roger Newport and Masud Husain and Jane E. Fowlie and Michael O’Donoghue and Nin Bajaj},
keywords = {Optic ataxia, Neuropsychology of action, Reaching},
abstract = {Optic ataxia (OA) is generally thought of as a disorder of visually guided reaching movements that cannot be explained by any simple deficit in visual or motor processing. In this paper we offer a new perspective on optic ataxia; we argue that the popular characterisation of this disorder is misleading and is unrepresentative of the pattern of reaching errors typically observed in OA patients. We begin our paper by reviewing recent neurophysiological, neuropsychological, and functional brain imaging studies that have led to the proposal that the medial parietal cortex in the vicinity of the parietal-occipital junction (POJ) – the key anatomical site associated with OA – represents reaching movements in eye-centred coordinates, and that this ability is impaired in optic ataxia. Our perspective stresses the importance of the POJ and superior parietal regions of the human PPC for representing reaching movements in both extrinsic (eye-centred) and intrinsic (postural) coordinates, and proposes that it is the ability to simultaneously represent multiple spatial locations that must be directly compared with one another that is impaired in non-foveal OA patients. In support of this idea we review recent fMRI and behavioural studies conducted by our group that have investigated the anatomical correlates of posturally guided movements, and the movements guided by postural cues in patients presenting with optic ataxia.}
}
@article{KEOGH2007249,
title = {Keeping the patient asleep and alive: Towards a computational cognitive model of disturbance management in anaesthesia},
journal = {Cognitive Systems Research},
volume = {8},
number = {4},
pages = {249-261},
year = {2007},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2006.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S1389041707000034},
author = {K. Keogh and E.A. Sonenberg},
keywords = {Behavioural analysis, Computational cognitive modelling, Disturbance management},
abstract = {We have analysed rich, dynamic data about the behaviour of anaesthetists during the management of a simulated critical incident in the operating theatre. We use a paper based analysis and a partial implementation to further the development of a computational cognitive model for disturbance management in anaesthesia. We suggest that our data analysis pattern may be used for the analysis of behavioural data describing cognitive and observable events in other complex dynamic domains.}
}
@article{PALKOVICS2016144,
title = {Exploration of cognition–affect and Type 1–Type 2 dichotomies in a computational model of decision making},
journal = {Cognitive Systems Research},
volume = {40},
pages = {144-160},
year = {2016},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2016.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S1389041715300115},
author = {Michael Anton Palkovics and Martin Takáč},
keywords = {Affective computing, Dual process theory, Decision-making},
abstract = {This paper studies the role of cognition and affect in decision-making as well as notions of Type 1 and 2 processes and behaviors typically used in dual process theories. In order to demonstrate that there is no 1:1 correspondence between types of observed behavior and internal processes causing them, and that Type 1 and Type 2 processes can be produced by a single system, we implemented a computational model integrating affective and cognitive processing. Our model is based on the model of Marinier, Laird, and Lewis (2009). We modified it by increasing the agent’s visual field, adding a GOFAI-style cognitive module (sub-goal management) and expanding the environment by a high-threat tile, to which the agent responds with a hard-wired automatic reaction. This allowed us to generate and observe different types of behavior and study interesting interactions between cognitive and affective control. By comparing our re-implementation to the modified agent, we demonstrated clear cases of Type 1 (fast, automatic) and Type 2 (slow, deliberative) behavior, providing further evidence for the “single-system, two processes” hypothesis.}
}
@article{HOU2025,
title = {Data-driven modeling of 600 MW supercritical unit under full operating conditions based on Transformer-XL},
journal = {ISA Transactions},
year = {2025},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2024.12.049},
url = {https://www.sciencedirect.com/science/article/pii/S0019057824006359},
author = {Guolian Hou and Tianhao Zhang and Ting Huang},
keywords = {Supercritical unit, Transformer-XL, Once-through/recirculation/shut-down mode, Quantum chaotic nutcracker optimization algorithm},
abstract = {Improving the flexible and deep peak shaving capability of supercritical (SC) unit under full operating conditions to adapt a larger-scale renewable energy integrated into the power grid is the main choice of novel power system. However, it is particularly challenging to establish an accurate SC unit model under large-scale variable loads and deep peak shaving. To this end, a data-driven modeling strategy combining Transformer-Extra Long (Transformer-XL) and quantum chaotic nutcracker optimization algorithm is proposed. Firstly, three models of the SC unit under once-through/recirculation/shut-down are built via analyzing its mechanism of the operation process, respectively. Secondly, the superior performance of Transformer-XL in obtaining global feature information is employed to effectively solve the problem of high information dependence caused by the strong coupling and nonlinearity of SC unit. Then, the improved quantum chaotic nutcracker optimization algorithm with higher search accuracy is proposed to obtain the optimal parameters of Transformer-XL based on the logistic chaotic mapping and quantum thinking. Feature information dependencies and optimal parameter settings are fully considered in the proposed modeling scheme, which results in an accurate model of SC unit under full operating conditions. Finally, various simulations and comparisons are conducted based on the on-site data of 600 MW SC unit to demonstrate the superiority of the proposed data-driven modeling strategy. According to the improved Transformer-XL, the mean square errors of the proposed SC unit model under once-through/recirculation/shut-down modes are less than 2.500E-03, which verifies the high accuracy of the model. Consequently, the developed model is suitable for application in the controller designing and the operating efficiency and flexibility improvement of SC unit.}
}
@incollection{REIMERS2006119,
title = {[8] Bioconductor: An Open Source Framework for Bioinformatics and Computational Biology},
series = {Methods in Enzymology},
publisher = {Academic Press},
volume = {411},
pages = {119-134},
year = {2006},
booktitle = {DNA Microarrays, Part B: Databases and Statistics},
issn = {0076-6879},
doi = {https://doi.org/10.1016/S0076-6879(06)11008-3},
url = {https://www.sciencedirect.com/science/article/pii/S0076687906110083},
author = {Mark Reimers and Vincent J. Carey},
abstract = {This chapter describes the Bioconductor project and details of its open source facilities for analysis of microarray and other high‐throughput biological experiments. Particular attention is paid to concepts of container and workflow design, connections of biological metadata to statistical analysis products, support for statistical quality assessment, and calibration of inference uncertainty measures when tens of thousands of simultaneous statistical tests are performed.}
}
@article{VARGO2017260,
title = {A systems perspective on markets – Toward a research agenda},
journal = {Journal of Business Research},
volume = {79},
pages = {260-268},
year = {2017},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2017.03.011},
url = {https://www.sciencedirect.com/science/article/pii/S014829631730098X},
author = {Stephen L. Vargo and Kaisa Koskela-Huotari and Steve Baron and Bo Edvardsson and Javier Reynoso and Maria Colurcio},
keywords = {Markets, Systems thinking, Marketing, Complex systems, Research agenda},
abstract = {This paper addresses the implications of an emerging, increasingly important way of thinking about markets: systems thinking. A market is one of the most founational abstractions in marketing and business research; yet, it often receives too little attention. As a result, the taken-for-granted assumptions about markets spur from over-simplified conceptualizations of neoclassical economics that depict markets as static and mechanistic. Systems thinking represents a major change in perspective that involves transcending this mechanistic worldview and thinking instead in terms of wholes, relationships, processes, and patterns. We argue that building a theory of markets based on systems thinking, would enable scholars to develop more realistic models that correspond with fast-changing business environment and therefore, increase both the rigor and relevance of future research. To further this aim, we identify the main implications of systems thinking and formulate them into a research agenda to further the systemic understanding of markets.}
}
@article{IOAKIMIDIS2017280,
title = {Caustics, pseudocaustics and the related illuminated and dark regions with the computational method of quantifier elimination},
journal = {Optics and Lasers in Engineering},
volume = {88},
pages = {280-300},
year = {2017},
issn = {0143-8166},
doi = {https://doi.org/10.1016/j.optlaseng.2016.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S0143816616301348},
author = {Nikolaos I. Ioakimidis},
keywords = {Caustics, Pseudocaustics, Illuminated and dark regions, Cracks, Plates, Elasticity},
abstract = {The method of caustics is a powerful experimental method in elasticity and particularly in fracture mechanics for crack problems. The related method of pseudocaustics is also of interest. Here we apply the computational method of quantifier elimination implemented in the computer algebra system Mathematica in order to determine (i) the non-parametric equation and two properties of the caustic at a crack tip and especially (ii) the illuminated and the dark regions related to caustics and pseudocaustics in plane elasticity and plate problems. The present computations concern: (i) The derivation of the non-parametric equation of the classical caustic about a crack tip through the elimination of the parameter involved (here the polar angle) as well as two geometrical properties of this caustic. (ii) The derivation of the inequalities defining the illuminated region on the screen in the problem of an elastic half-plane loaded normally by a concentrated load with the boundary of this illuminated region related to some extent to the caustic formed. (iii) Similarly for the problem of a clamped circular plate under a uniform loading with respect to the caustic and the pseudocaustic formed. (iv) Analogously for the problem of an equilateral triangular plate loaded by uniformly distributed moments along its whole boundary, which defines the related pseudocaustic. (v) The determination of quantities of interest in mechanics from the obtained caustics or pseudocaustics. The kind of computations in the applications (ii) to (iv), i.e. the derivation of inequalities defining the illuminated region on the screen, seems to be completely new independently of the use here of the method of quantifier elimination. Additional applications are also possible, but some of them require the expansion of the present somewhat limited power of the quantifier elimination algorithms in Mathematica. This is expected to take place in the future.}
}
@article{KE201426,
title = {An implementation of design-based learning through creating educational computer games: A case study on mathematics learning during design and computing},
journal = {Computers & Education},
volume = {73},
pages = {26-39},
year = {2014},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2013.12.010},
url = {https://www.sciencedirect.com/science/article/pii/S0360131513003345},
author = {Fengfeng Ke},
keywords = {Learning by design, Game-based learning, Mathematical disposition, Thinking mathematically, Computer game making},
abstract = {This mixed-method case study examined the potential of computer-assisted, math game making activities in facilitating design-based math learning for school children. Sixty-four middle school children participated in Scratch-based, math game making activities. Data were collected via activity and conversation observation, artifact analysis, interviewing, and survey. The study findings indicated that participants developed significantly more positive dispositions toward mathematics after computer game making. The study also found that experience-driven game design processes helped to activate children's reflection on everyday mathematical experiences. Mathematical thinking and content experience were intertwined within the process of computer game authoring. On the other hand, children designers were involved in game-world and story crafting more than mathematical representation. And it was still challenging for them to perform computer game coding with abstract reasoning.}
}
@article{GILHOOLY2024100071,
title = {AI vs humans in the AUT: Simulations to LLMs},
journal = {Journal of Creativity},
volume = {34},
number = {1},
pages = {100071},
year = {2024},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2023.100071},
url = {https://www.sciencedirect.com/science/article/pii/S2713374523000304},
author = {Ken Gilhooly},
keywords = {AI, Alternative uses, Divergent thinking},
abstract = {This paper reviews studies of proposed creative machines applied to a prototypical creative task, i.e., the Alternative Uses Task (AUT). Although one system (OROC) did simulate some aspects of human strategies for the AUT, most recent attempts have not been simulation-oriented, but rather have used Large Language Model (LLM) systems such as GPT-3 which embody extremely large connectionist networks trained on huge volumes of textual data. Studies reviewed here indicate that LLM based systems are performing on the AUT at near or somewhat above human levels in terms of scores on originality and usefulness. Moreover, similar patterns are found in the data of humans and LLM models in the AUT, such as output order effects and a negative association between originality and value or utility. However, it is concluded that GPT-3 and similar systems, despite generating novel and useful responses, do not display creativity as they lack agency and are purely algorithmic. LLM studies so far in this area have largely been exploratory and future studies should guard against possible training data contamination.}
}
@incollection{MARS20253,
title = {What every cognitive neuroscientist should know about prefrontal cortex evolution},
editor = {Jordan Henry Grafman},
booktitle = {Encyclopedia of the Human Brain (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {3-11},
year = {2025},
isbn = {978-0-12-820481-8},
doi = {https://doi.org/10.1016/B978-0-12-820480-1.00127-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128204801001273},
author = {Rogier B. Mars},
keywords = {Prefrontal cortex, Brain evolution, Foraging, Granular prefrontal cortex, Dorsolateral prefrontal cortex, Cognitive control, Comparative neuroscience, Primate, Connectivity, Human},
abstract = {Most theories of cognitive control assign a vital role to human prefrontal cortex (PFC). Although models of PFC function are abundant, most fail to capture the complexity of this part of the brain. Here we argue that an improved understanding of the evolution of PFC can aid in the formulation of better models. By better understanding what PFC is, why it evolved, and what benefit it provided to our ancestors, we can constrain our thinking and put the plethora of neuroimaging data showing PFC activation into context.}
}
@article{BAHLS2015104,
title = {LaTeXnics: The effect of specialized typesetting software on STEM students’ composition processes},
journal = {Computers and Composition},
volume = {37},
pages = {104-116},
year = {2015},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2015.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S8755461515000511},
author = {Patrick Bahls and Amanda Wray},
keywords = {Computer-Mediated communication, STEM writing, Writing process, LaTeX, Markup languages, Typesetting tools},
abstract = {Undergraduate science, technology, engineering, and mathematics (STEM) students are often trained to use technical typesetting software in order to produce authentic mathematical prose, though little research exists about how this writing technology impacts students’ thinking and computation process. Drawing upon survey and interview research conducted at two liberal arts institutions, the authors investigate student writing practices across several undergraduate mathematics courses that required the use of LaTeX (a common markup language allowing users to specify the appearance of text and its layout on the printed page). This article presents findings about how the use of LaTeX slowed down students’ writing process, encouraging greater revision and reflection as well as allowing students to identify errors in their work at more than one stage in the process. We also explore the affective learning outcomes of STEM students using typesetting software, including increased feelings of confidence and professionalization. This article seeks to contribute to the growing conversation about how STEM students transfer knowledge about writing across disciplines.}
}
@article{TOFFOLI20103,
title = {From Such Simple a Beginning: The Momentous Consequences of Physics' Microscopic Reversibility for Communication and Computation—and Almost Anything Else},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {253},
number = {6},
pages = {3-16},
year = {2010},
note = {Proceedings of the Workshop on Reversible Computation (RC 2009)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2010.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S1571066110000150},
author = {Tommaso Toffoli},
keywords = {invertibility, irreversibility, computation, dynamics, thermodynamics, entropy, second law of thermodynamics},
abstract = {Darwin concludes The Origin of Species with a splendid one-phrase poem,From so simple a beginningendless forms most beautiful and most wonderfulhave been, and are being, evolved. Darwin's “simple beginning” may be identified, in today's terminology, with dissipation—evolution's basic fuel. All the rest is commentary—or, more precisely, corollary. One can aptly apply Darwin's phrase to another kind of “simple beginning,” from which as well “endless forms most beautiful and most wonderful have been, and are being, evolved.” What I have in mind is a concept that is apparently the very antithesis of dissipation, namely, physics' fundamental assumption of invertibility—or “microscopic reversibility.” To paraphrase Dobzhansky, no sensible step can be taken today in information, communication, and computer sciences, as well as in fundamental physics, except in the light of invertibility.}
}

@article{XU2024167,
title = {Towards carbon neutrality in China: A systematic identification of China's sustainable land-use pathways across multiple scales},
journal = {Sustainable Production and Consumption},
volume = {44},
pages = {167-178},
year = {2024},
issn = {2352-5509},
doi = {https://doi.org/10.1016/j.spc.2023.12.008},
url = {https://www.sciencedirect.com/science/article/pii/S235255092300283X},
author = {Zhenci Xu},
keywords = {Carbon neutrality, Land use, Multi-scales, System thinking, China},
abstract = {Sustainable land use is crucial for achieving Carbon Neutrality goals, which requires a scientific identification of optimized pathways for land use patterns across multiple scales. Yet, current land use studies predominantly focus on single scales but lack system thinking and fail to establish complementary cross-regional carbon neutrality collaboration schemes. Applying life-cycle thinking to analyze land use sustainability and carbon neutrality potential at multiple scales could address this challenge. This study aims to present China's first multi-scale spatiotemporal optimization pathway for sustainable land use to improve carbon neutrality potential. It systematically integrates the complex spatial coupling relationships between land use intensity and efficiency. We integrate multi-scale sustainable land use pathways, spanning grid, basin, and administrative levels, and unveil significant variations in land use sustainability and carbon neutrality potential across China. Sixty-three percent of China's land is in low sustainability, and the overall carbon neutrality potential in China is relatively low, with regions accounting for <30 % facing more carbon neutrality missions. Implementing sequential and partitioned governance modes can effectively support China in achieving sustainable land use and advancing Carbon Neutrality goals. Our sustainable land use pathways for China provide valuable insights for systematically undertaking carbon neutrality actions across different scales.}
}
@incollection{CLEEREMANS200581,
title = {Computational correlates of consciousness},
editor = {Steven Laureys},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {150},
pages = {81-98},
year = {2005},
booktitle = {The Boundaries of Consciousness: Neurobiology and Neuropathology},
issn = {0079-6123},
doi = {https://doi.org/10.1016/S0079-6123(05)50007-4},
url = {https://www.sciencedirect.com/science/article/pii/S0079612305500074},
author = {Axel Cleeremans},
abstract = {Over the past few years numerous proposals have appeared that attempt to characterize consciousness in terms of what could be called its computational correlates: Principles of information processing with which to characterize the differences between conscious and unconscious processing. Proposed computational correlates include architectural specialization (such as the involvement of specific regions of the brain in conscious processing), properties of representations (such as their stability in time or their strength), and properties of specific processes (such as resonance, synchrony, interactivity, or information integration). In exactly the same way as one can engage in a search for the neural correlates of consciousness, one can thus search for the computational correlates of consciousness. The most direct way of doing is to contrast models of conscious versus unconscious information processing. In this paper, I review these developments and illustrate how computational modeling of specific cognitive processes can be useful in exploring and in formulating putative computational principles through which to capture the differences between conscious and unconscious cognition. What can be gained from such approaches to the problem of consciousness is an understanding of the function it plays in information processing and of the mechanisms that subtend it. Here, I suggest that the central function of consciousness is to make it possible for cognitive agents to exert flexible, adaptive control over behavior. From this perspective, consciousness is best characterized as involving (1) a graded continuum defined over quality of representation, such that availability to consciousness and to cognitive control correlates with properties of representation, and (2) the implication of systems of meta-representations.}
}
@article{BOELSENROBINSON2021102032,
title = {Mapping factors associated with a successful shift towards healthier food retail in community-based organisations: A systems approach},
journal = {Food Policy},
volume = {101},
pages = {102032},
year = {2021},
issn = {0306-9192},
doi = {https://doi.org/10.1016/j.foodpol.2021.102032},
url = {https://www.sciencedirect.com/science/article/pii/S0306919221000105},
author = {Tara Boelsen-Robinson and Miranda R. Blake and Andrew D. Brown and Oliver Huse and Claire Palermo and Neetu A. George and Anna Peeters},
keywords = {Food retail, Systems mapping, Intervention, Community, Implementation, START map, Nutrition, Policy, Qualitative, Interviews},
abstract = {Background
Food retailers in community settings are gatekeepers to the crucial food systems changes needed to improve population nutrition. Evidence-based models of change are needed to enable shifts in these complex retail environments. Systems thinking offers unique insights by capturing potential unintended consequences and multiple pathways to success. This study sought to create a systems map for retailers, public health practitioners and other stakeholders seeking to implement healthy food retail policies. It aimed to identify (i) points of intervention through which community-based organisations can shift to healthier food provision, and (ii) key feedback loops that could drive potential unintended consequences of such policies in a complex system.
Methods
Semi-structured interviews (n = 26) were conducted, from 2015 to 2018, across four community food retail settings where healthy food retail policies had been implemented in Victoria, Australia. Interviews were coded by identifying causal relationships and their direction between factors. Vensim software was used to merge interview results and then reduce the map to the strongest and most frequent factors and relationships. Illustrative implementation stories and points of intervention were identified.
Findings
The resulting map is titled the Systems Thinking Approach for Retail Transformation (START) map. Five prominent implementation stories incorporating 17 factors highlighted that: 1) retailer resistance to change is strongest in the beginning but decreases with the demonstration of favourable initiative outcomes; 2) successive changes tend to be increasingly complex, and therefore harder for retailers to implement; 3) organisational resourcing can be influenced through multiple pathways; 4) customer acceptability of healthy changes and retailers' willingness to engage in changes influence each other; and 5) challenges in accessing healthy supply options make retailers more resistant to implementing healthy changes.
Conclusions
The application of systems thinking to the challenge of unhealthy food retail creates novel and practical insights for retailers and health promotion practitioners into what actions are most likely to promote healthy changes in complex retail environments.}
}
@article{SKOWRON20115939,
title = {Information systems in modeling interactive computations on granules},
journal = {Theoretical Computer Science},
volume = {412},
number = {42},
pages = {5939-5959},
year = {2011},
note = {Rough Sets and Fuzzy Sets in Natural Computing},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2011.05.045},
url = {https://www.sciencedirect.com/science/article/pii/S0304397511004634},
author = {Andrzej Skowron and Piotr Wasilewski},
keywords = {Interactive computing, Interactive systems, Multi-agent systems, Rough sets, Granular computing, Wisdom technology},
abstract = {In this paper, we discuss the importance of information systems in modeling interactive computations performed on (complex) granules and we propose a formal approach to interactive computations based on generalized information systems and rough sets which can be combined with other soft computing paradigms such as fuzzy sets or evolutionary computing, but also with machine learning and data mining techniques. Information systems are treated as dynamic granules used for representing the results of the interaction of attributes with the environment. Two kinds of attributes are distinguished, namely, the perception attributes, including sensory attributes, and the action attributes. Sensory attributes are the basic perception attributes, other perception attributes are constructed on the basis of the sensory ones. Actions are activated when their guards, being often complex and vague concepts, are satisfied to a satisfactory degree. The guards can be approximated on the basis of measurements performed by sensory attributes rather than defined exactly. Satisfiability degrees for guards are results of reasoning called the adaptive judgment. The approximations are induced using hierarchical modeling. We show that information systems can be used for modeling more advanced forms of interactions in hierarchical modeling. The role of hierarchical interactions is emphasized in the modeling of interactive computations. Some illustrative examples of interactions used in the ACT-R 6.0 system are reported. ACT-R 6.0 is based on a cognitive architecture and can be treated as an example of a highly interactive complex granule which can be involved in hierarchical interactions. For modeling of interactive computations, we propose much more general information systems than the studied dynamic information systems (see, e.g., Ciucci (2010) [8] and Pałasiński and Pancerz (2010) [32]). For example, the dynamic information systems are making it possible to consider incremental changes in information systems. However, they do not contain the perception and action attributes necessary for modeling interactive computations, in particular for modeling intrastep interactions.}
}
@article{USMANI20241044,
title = {The Digital Age: Exploring the Intersection of AI/CI and Human Cognition and Social Interactions},
journal = {Procedia Computer Science},
volume = {239},
pages = {1044-1052},
year = {2024},
note = {CENTERIS – International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies 2023},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.06.268},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924015114},
author = {Usman Ahmad Usmani and Ari Happonen and Junzo Watada},
keywords = {Artificial intelligence, Computational intelligence, Digitalization, Digital transformation, Human cognition, Social interaction, Industry 4.0, Digital capability, Social transformation, Human computer interaction},
abstract = {Although solutions based on artificial and computational intelligence have made life easier, the fast development of technology also raises questions about near future and log term human cognition and social interaction. Through a survey of the literature and qualitative analysis, our work examined current research on how the AI/CI affects human cognitive functions and social interactions. We discuss how AI and CI are influencing e.g. how we humans gather information, build relationships, and communicate with others, with and without the new frontline technologies. Additionally, proposals for future advances are discussed along with the ethical and societal ramifications these technologies have, could and might bring into our lives. We think that by developing a deeper knowledge of how AI/CI affects human cognition and social interaction, new contributions are made to a positive conversation and encourage a responsible approach to incorporating new technologies into our daily lives.}
}
@incollection{HOLCOMBE2005407,
title = {30 Computational modelling of creativity in abstract art},
editor = {Grant Malcolm},
series = {Studies in Multidisciplinarity},
publisher = {Elsevier},
volume = {2},
pages = {407-424},
year = {2005},
booktitle = {Multidisciplinary Approaches to Visual Representations and Interpretations},
issn = {1571-0831},
doi = {https://doi.org/10.1016/S1571-0831(04)80058-3},
url = {https://www.sciencedirect.com/science/article/pii/S1571083104800583},
author = {Mike Holcombe and Samantha Smith and Rowan Merewood and Andy Swingeford},
abstract = {Artistic creativity is studied through the construction of computational models of a number of well-known modern artists. In particular, the work of Piet Mondrian, M.C. Escher and Paul Klee are suitable vehicles for investigation since their work is accompanied by extensive writings describing the ideas and motivation behind their compositions. In particular, we have tried to abstract from their theories, rules that describe the construction process or the properties that their finished artefacts posses in order to create software programs that can articulate these rules. In this way, we are able to simulate either automatically or with user interaction, the process of creating works of art of a similar genre and satisfying the properties desired by the artist. Since the rules are bound to be considerably more complex than those currently exposed, we are looking to use machine-learning techniques to develop more sophisticated agents, which may behave more closely like the actual artist.}
}
@article{LIN2025102895,
title = {Integrating generative AI into digital multimodal composition: A study of multicultural second-language classrooms},
journal = {Computers and Composition},
volume = {75},
pages = {102895},
year = {2025},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2024.102895},
url = {https://www.sciencedirect.com/science/article/pii/S8755461524000719},
author = {Chin-Hsi Lin and Keyi Zhou and Lanqing Li and Lanfang Sun},
keywords = {Generative AI, Multimodal composing, Multicultural education},
abstract = {This study examines the integration of generative AI tools into digital multimodal composition (DMC) within a multicultural context, examining their impact on students’ motivation, writing processes, and outcomes. Eleven culturally diverse students from two high schools in Hong Kong participated in the study. The study developed and employed a novel pedagogical framework, IDEA (Interpret, Design, Evaluate, and Articulate), to seamlessly incorporate generative AI into DMC practices. Data-collection methods included analysis of generative AI tool-usage history, classroom video observations, surveys, and interviews. The findings reveal that students leveraged generative AI’s capabilities across five key areas: content generation, feedback and revision, multilingual support, critical thinking, and visual representation. The integration of AI tools followed distinct stages in the composition process, resulting in enhancements to the vocabulary, grammar, and structural elements of students’ work. This research contributes to the growing body of knowledge on the intersection of generative AI, education, and multimodal literacy, with a particular emphasis on human-AI collaboration in multicultural settings. It also offers valuable insights for educators seeking to enhance students’ DMC skills through the thoughtful integration of generative AI tools, potentially increasing engagement, motivation, and creative expression among learners from diverse cultural backgrounds.}
}
@article{LIU2000261,
title = {Creativity or novelty?: Cognitive-computational versus social-cultural},
journal = {Design Studies},
volume = {21},
number = {3},
pages = {261-276},
year = {2000},
issn = {0142-694X},
doi = {https://doi.org/10.1016/S0142-694X(99)00013-7},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X99000137},
author = {Yu-Tung Liu},
keywords = {creativity, design cognition, computer-aided design, problem-solving, artificial intelligence},
abstract = {This paper proposes a broader framework for understanding creativity by distinguishing different levels of creativity, namely personal and social-cultural creativity, and their interaction. Within this framework, the possible role that computer-aided design systems can play is discussed by analyzing the procedure of rule formation and the phenomena of seeing emergent subshapes.}
}
@article{AUSTIN2006544,
title = {Matrix and finite element stack machines for structural engineering computations with units},
journal = {Advances in Engineering Software},
volume = {37},
number = {8},
pages = {544-559},
year = {2006},
issn = {0965-9978},
doi = {https://doi.org/10.1016/j.advengsoft.2005.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S0965997805001833},
author = {Mark A. Austin},
keywords = {Stack machine, Matrix computations, Physical units, Scripting language design, Finite element analysis},
abstract = {Despite the well known benefits of physical units, matrices, and matrix algebra in engineering computations, most engineering analysis packages are essentially dimensionless. This paper describes the design and implementation of matrix and finite element stack machines for Aladdin, a new computational environment that embeds units inside matrix and finite element calculations. Functionality of the Aladdin stack machine is illustrated by working step by step through the setup and execution of three examples: (1) Parsing and stack machine execution for x=2in; (2) Deflection analysis of a cantilever beam, and (3) Rollup maneuver for a long cantilever beam.}
}
@article{ZHOU2022105384,
title = {Informed speculation with k-level reasoning},
journal = {Journal of Economic Theory},
volume = {200},
pages = {105384},
year = {2022},
issn = {0022-0531},
doi = {https://doi.org/10.1016/j.jet.2021.105384},
url = {https://www.sciencedirect.com/science/article/pii/S0022053121002015},
author = {Hang Zhou},
keywords = {Level- thinking, Investors' sophistication, Market instability},
abstract = {This paper investigates the effect of strategic reasoning on financial markets with a level-k thinking framework. A level-k speculator performs k rounds of iterative reasoning to infer information from asset prices. In contrast to the static rational expectations equilibrium, the level-k framework produces a unified theory of momentum and contrarian trading strategies. Besides, this paper discusses how the distribution of sophistication levels affects several market variables and it sheds new light on empirical patterns such as: (1) overreaction of asset prices, (2) the excess volatility puzzle, and (3) the excessive trading volume puzzle. Moreover, this paper explores whether the level-k strategy converges to the rational expectations equilibrium.}
}
@article{LEWIS2018491,
title = {How Memory Replay in Sleep Boosts Creative Problem-Solving},
journal = {Trends in Cognitive Sciences},
volume = {22},
number = {6},
pages = {491-503},
year = {2018},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2018.03.009},
url = {https://www.sciencedirect.com/science/article/pii/S1364661318300706},
author = {Penelope A. Lewis and Günther Knoblich and Gina Poe},
keywords = {sleep, memory, creativity, reactivation, replay, consolidation},
abstract = {Creative thought relies on the reorganisation of existing knowledge. Sleep is known to be important for creative thinking, but there is a debate about which sleep stage is most relevant, and why. We address this issue by proposing that rapid eye movement sleep, or ‘REM’, and non-REM sleep facilitate creativity in different ways. Memory replay mechanisms in non-REM can abstract rules from corpuses of learned information, while replay in REM may promote novel associations. We propose that the iterative interleaving of REM and non-REM across a night boosts the formation of complex knowledge frameworks, and allows these frameworks to be restructured, thus facilitating creative thought. We outline a hypothetical computational model which will allow explicit testing of these hypotheses.}
}
@article{SNYDER2022100852,
title = {The role of heat resistance in yeast spoilage of thermally processed foods: highlighting the need for a probabilistic, systems-based approach to microbial quality},
journal = {Current Opinion in Food Science},
volume = {46},
pages = {100852},
year = {2022},
issn = {2214-7993},
doi = {https://doi.org/10.1016/j.cofs.2022.100852},
url = {https://www.sciencedirect.com/science/article/pii/S2214799322000546},
author = {Abigail B Snyder},
abstract = {The relationship between stress-tolerance mechanisms (cell-wall structure, metabolism, morphology, etc.) of individual fungi and the physiochemistry of their food environment selects for a small group of specific spoilage organisms (SSOs). However, common process deviations and post-processing contamination widen the lens of potentially relevant spoilage fungi. For example, although heat-resistant molds are considered the SSOs in thermally processed foods, unintended events (deviations, post-processing contamination) lead to spoilage by other propagules, notably yeast. The frequency of these unintended events changes our assessments of which spoilage fungi are relevant to a given food system. Consequently, a framework using probabilistic and systems-based thinking is needed to understand spoilage risk. Toward that goal, simple molecular tools for identification and subtyping are required.}
}
@article{EAMES2021100864,
title = {The finite-to-finite strand of a learning progression for the concept of function: A research synthesis and cognitive analysis},
journal = {The Journal of Mathematical Behavior},
volume = {62},
pages = {100864},
year = {2021},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2021.100864},
url = {https://www.sciencedirect.com/science/article/pii/S0732312321000250},
author = {Cheryl L. Eames and Edith Aurora Graf and Peter W. {van Rijn} and Greg Budzban and Tammy Voepel},
keywords = {Learning progressions, Concept of function, Representation, Secondary students},
abstract = {In this paper we report validation efforts around the finite-to-finite strand of a provisional learning progression (LP) for the concept of function. We regard an LP as an empirically-verified account of how student understandings form over time and in response to instruction. The finite-to-finite strand of the LP was informed by literature on students’ thinking and learning related to functions as well as the Algebra Project’s curricular approach, which is designed for students who are traditionally underserved by mathematics education. Developing and validating an LP is a multi-step, cyclic process. Here we report on one step in this process, an item and response analysis. Data sources include 680 students’ responses to 13 multipart computer-delivered tasks. Results suggest that revisions to the items, associated scoring rubrics, and in some instances the LP are warranted. We illustrate this task, rubric, and LP revision process through an item analysis for a selected task.}
}
@article{MUZAFFAR20224912,
title = {Analysing the Causes of Design Generated Waste through System Dynamics},
journal = {KSCE Journal of Civil Engineering},
volume = {26},
number = {12},
pages = {4912-4925},
year = {2022},
issn = {1226-7988},
doi = {https://doi.org/10.1007/s12205-022-1896-1},
url = {https://www.sciencedirect.com/science/article/pii/S1226798824013461},
author = {Sidra Muzaffar and Khurram Iqbal Ahmad Khan and Muhammad Bilal Tahir and Hamna Bukhari},
keywords = {Construction & demolition waste, Design generated waste, Causal loop diagram, Systems thinking, System dynamics},
abstract = {A drastic rise in construction waste observed has elicited a radical impact on the environment and economy of the world. It is, therefore, necessary to come up with waste minimization management strategies that reflect in-depth review of sources of waste. This in depth review demands understanding the intricacy of causative factors triggering generation of “waste at source” which is the main motive of study and is done through System Dynamics for design phase in context of developing countries. 8 most important causative factors in design phase were shortlisted along with their interrelationships via literature and questionnaire survey. Followed by system thinking approach that addressed the complexities caused by those factors in 2 stages. Firstly, a Causal loop diagram was developed that illustated interrelationship between factors in the form of loops. Later SD model built, evaluated the combinatorial effect of 3 evolved stocks over the fourth stock Design Generated Waste-an emanating phenomenon. Simulation result revealed increasing trend of the stock DGW over a course of time. Therefore, increase in effect of complexities of behavior of design waste causes, will consequently lead to increase in DGW. Managing the complex behavior of these design causes will help control over the DGW w.r.t. time.}
}
@article{MOSTAFA20118782,
title = {A neuro-computational intelligence analysis of the global consumer software piracy rates},
journal = {Expert Systems with Applications},
volume = {38},
number = {7},
pages = {8782-8803},
year = {2011},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2011.01.090},
url = {https://www.sciencedirect.com/science/article/pii/S0957417411001102},
author = {Mohamed M. Mostafa},
keywords = {Global software piracy, Ethical behavior, Neural networks, Bayesian regression, Evolutionary computation models},
abstract = {Software piracy represents a major damage to the moral fabric associated with the respect of intellectual property. The rate of software piracy appears to be increasing globally, suggesting that additional research that uses new approaches is necessary to evaluate the problem. The study remedies previous econometric and methodological shortcomings by applying Bayesian, robust and evolutionary computation robust regression algorithms to formally test empirical literature on software piracy. To gain further insights into software piracy at the global level, the study also uses five neuro-computational intelligence methodologies: multi-layer perceptron neural network (MLP), probabilistic neural network (PNN), radial basis function neural network (RBF), generalized regression neural network (GRNN) and Kohonen’s self-organizing maps (SOM) to classify, predict and cluster software piracy rates among 102 nations. At the empirical level, this research shows that software piracy is significantly affected by the wealth of nation as measured by gross domestic product (GDP), the nation’s expenditure on research and development and the nation’s judicial efficiency. At the methodological level, this research shows that neuro-computational models outperform traditional statistical techniques such as regression analysis, discriminant analysis and cluster analysis in predicting, classifying and clustering software piracy rates due to their robustness and flexibility of modeling algorithms.}
}
@article{TSAI202371,
title = {Exploring the use of large language models (LLMs) in chemical engineering education: Building core course problem models with Chat-GPT},
journal = {Education for Chemical Engineers},
volume = {44},
pages = {71-95},
year = {2023},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2023.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S1749772823000180},
author = {Meng-Lin Tsai and Chong Wei Ong and Cheng-Liang Chen},
keywords = {Engineering education, Industry 4.0 skill, Programming in chemical engineering, Problem-solving, Large language models (LLMs), Chat-GPT},
abstract = {This study highlights the potential benefits of integrating Large Language Models (LLMs) into chemical engineering education. In this study, Chat-GPT, a user-friendly LLM, is used as a problem-solving tool. Chemical engineering education has traditionally focused on fundamental knowledge in the classroom with limited opportunities for hands-on problem-solving. To address this issue, our study proposes an LLMs-assisted problem-solving procedure. This approach promotes critical thinking, enhances problem-solving abilities, and facilitates a deeper understanding of core subjects. Furthermore, incorporating programming into chemical engineering education prepares students with vital Industry 4.0 skills for contemporary industrial practices. During our experimental lecture, we introduced a simple example of building a model to calculate steam turbine cycle efficiency, and assigned projects to students for exploring the possible use of LLMs in solving various aspect of chemical engineering problems. Although it received mixed feedback from students, it was found to be an accessible and practical tool for improving problem-solving efficiency. Analyzing the student projects, we identified five common difficulties and misconceptions and provided helpful suggestions for overcoming them. Our course has limitations regarding using advanced tools and addressing complex problems. We further provide two additional examples to better demonstrate how to integrate LLMs into core courses. We emphasize the importance of universities, professors, and students actively embracing and utilizing LLMs as tools for chemical engineering education. Students must develop critical thinking skills and a thorough understanding of the principles behind LLMs, taking responsibility for their use and creations. This study provides valuable insights for enhancing chemical engineering education's learning experience and outcomes by integrating LLMs.}
}
@article{KLEIN2014437,
title = {Computation and Visualization of Patch Geometries for the Design of Carbon Fiber Reinforced Parts at Early Design Stages},
journal = {Procedia CIRP},
volume = {21},
pages = {437-442},
year = {2014},
note = {24th CIRP Design Conference},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2014.03.133},
url = {https://www.sciencedirect.com/science/article/pii/S2212827114006738},
author = {Daniel Klein and Kaja Scheler and Sandro Wartzack},
keywords = {Lightweight design, Early design stages, Endless fibre reinforced composites},
abstract = {The market for carbon fibers is forecast to experience a double-digit growth over the next years. The reason for this development can be found in the special characteristics of Carbon Fiber Reinforced Plastics (CFRP) like high stiffness and strength at very low weight which make this composite an ideal material for lightweight design. However, the design of parts made of CFRP is a tightrope walk between costs, mechanical characteristics and manufacturability for product developers. On the one hand, the mechanical properties are highly dependent on the ideal fiber orientation within the part and the unique material characteristics can only be exploited with a suitable fiber orientation, but on the other hand, the ideal fiber orientation is often not manufacturable or the required manufacturing technique is too expensive. Therefore, a novel algorithm to support product developers in finding a manufacturable fiber orientation or patch layout which is as close as possible to the ideal fiber orientation is introduced. This algorithm computes and highlights areas with constant fiber orientation (=cluster) based upon the ideal fiber alignment from the CAIO method. With the help of the visualization of the clusters, product developers can be supported in the decision for the best patch placement and geometry as well as in choosing the best manufacturing technique. It is important to point out that the algorithm is intended for endless fiber reinforced parts only.}
}
@article{LIU2019678,
title = {A review of the smart world},
journal = {Future Generation Computer Systems},
volume = {96},
pages = {678-691},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17319532},
author = {Hong Liu and Huansheng Ning and Qitao Mu and Yumei Zheng and Jing Zeng and Laurence T. Yang and Runhe Huang and Jianhua Ma},
keywords = {Smart world, Ubiquitous computing, Ambient intelligence, Cyber–physical–social-thinking, Internet of Things},
abstract = {Smart world is an attractive prospect with comprehensive development of ubiquitous computing involving penetrative intelligence into ubiquitous things, including physical objects (e.g., wearable devices), cyber entities (e.g., cloud services), social people (e.g., social networking) and human thinking (e.g., brain cognition). This work systematically overviews related works in the field of the smart world, and explains prospects in emerging areas. The smart world evolutions are discussed through four progressive phases, and the representative projects are accordingly introduced. Meanwhile, smart world elements and the smart world driven applications are respectively analyzed in the contexts of cyber–physical–social-thinking hyperspace. Moreover, enabling technologies including ubiquitous intelligence, web intelligence, brain informatics, social computing, big data, and security and privacy are respectively discussed. Finally, perspectives referring to ubiquitous sensing, ubiquitous object modeling, smart services, and philosophical, ethical and legal issues, are presented for identifying trends and challenges in the smart world.}
}
@article{TESCH2001633,
title = {Applying optimal control theory for elements of quantum computation in molecular systems},
journal = {Chemical Physics Letters},
volume = {343},
number = {5},
pages = {633-641},
year = {2001},
issn = {0009-2614},
doi = {https://doi.org/10.1016/S0009-2614(01)00748-5},
url = {https://www.sciencedirect.com/science/article/pii/S0009261401007485},
author = {Carmen M. Tesch and Lukas Kurtz and Regina {de Vivie-Riedle}},
abstract = {Elements of quantum computation are implemented in a vibrationally excited molecule applying optimal control theory. The two different IR-active modes of acetylene are taken as a two-qubit-system. Optimal control theory is used to design laser pulses that allow transitions within each qubit separately. Calculations for initial state preparation and basic quantum gates are presented.}
}
@article{RADU2023100008,
title = {Charting opportunities and guidelines for augmented reality in makerspaces through prototyping and co-design research},
journal = {Computers & Education: X Reality},
volume = {2},
pages = {100008},
year = {2023},
issn = {2949-6780},
doi = {https://doi.org/10.1016/j.cexr.2023.100008},
url = {https://www.sciencedirect.com/science/article/pii/S2949678023000028},
author = {Iulian Radu and Josia Yuan and Xiaomeng Huang and Bertrand Schneider},
keywords = {Augmented reality, Makerspaces, Co-design, STEM, Classroom integration},
abstract = {Makerspace environments are becoming popular project-based learning spaces where students interact with physical objects and peer collaboration, while developing 21st century skills and engaging with science, technology, engineering, and math (STEM) topics. At the same time, augmented reality (AR) technology, which combines physical objects with digital visualizations, is becoming increasingly applicable for makerspace activities and has potential to address challenges for student learning in makerspaces. However, there is a lack of understanding of how to use and integrate AR in real makerspace environments. In this research we use a co-design methodology to address the following questions: (1) How can AR be useful for education in makerspaces? (2) How are students impacted by the process of co-designing AR technology? and (3) What are practical considerations for integrating AR in makerspaces? We engaged in a co-design process in a semester-long makerspace course attended by 18 students in a graduate school of education. Through this process, we generated six prototypes with seven student co-designers, exploring AR use in design, fabrication, programming, electronics, and training. We also identified areas where AR technology can benefit makerspaces, such as teaching STEM skills, facilitating construction activities, enhancing contextualization of learning, and debugging. We observed that students participating in co-design demonstrated improved understanding of technology design, enthusiasm for engaging with makerspaces and AR, and increased critical thinking about AR technology. These results suggest considerations and guidelines for integrating AR technology into makerspace environments.}
}
@article{VELIZ2025115299,
title = {Modeling the interconnected drivers of power sector decarbonization in Chile},
journal = {Renewable and Sustainable Energy Reviews},
volume = {211},
pages = {115299},
year = {2025},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2024.115299},
url = {https://www.sciencedirect.com/science/article/pii/S1364032124010256},
author = {Karina D. Véliz and Jeffrey P. Walters and Carlos Fica and Carolina Busco},
keywords = {Decarbonization, Chile, Renewable energy, Systems thinking, Participatory modeling},
abstract = {This study sought to model the interconnected and multidimensional factors influencing the decarbonization of Chile's electricity sector. Factors were identified through a structured review of articles found in the Web of Science. Factor interactions were then characterized through a survey and participatory systems modeling workshop with stakeholders from various fields in the Chilean energy sector. The model emerging from the workshop was structurally analyzed to identify and evaluate system leverage points used to inform recommendations for future policy and practice. A key leverage point identified in this analysis underscores the importance of stakeholder awareness regarding the benefits of renewable energy projects, serving as a crucial catalyst towards decarbonization by fostering citizen support and driving the implementation of favorable public policies. Conversely, the model showed that public opposition to transmission line construction, stemming from health, environmental, and property value concerns, can potentially lead to project delays, increased costs, and challenges in modernizing electrical grids. These findings emphasize the need for public engagement and effective communication to prioritize decarbonization while balancing short-term impacts with long-term benefits. The systemic and process-oriented insights gained from the application of the participatory modeling approach presented in this study, highlight the value of utilizing systems thinking and modeling approaches to inform future decarbonization strategies on a global scale.}
}
@article{MYCKA2006103,
title = {Analog computation beyond the Turing limit},
journal = {Applied Mathematics and Computation},
volume = {178},
number = {1},
pages = {103-117},
year = {2006},
note = {Special Issue on Hypercomputation},
issn = {0096-3003},
doi = {https://doi.org/10.1016/j.amc.2005.09.074},
url = {https://www.sciencedirect.com/science/article/pii/S0096300305008386},
author = {Jerzy Mycka},
abstract = {The main purpose of this paper is quite uncontroversial. First, we recall some models of analog computations (including these allowed to perform Turing uncomputable tasks). Second, we support the suggestions that such hypercomputable capabilities of such systems can be explained by the use of infinite limits. Additionally, the inner restrictions of analog models of computations are indicated.}
}
@article{ROBERTS201648,
title = {Mathematical and computational models of the retina in health, development and disease},
journal = {Progress in Retinal and Eye Research},
volume = {53},
pages = {48-69},
year = {2016},
issn = {1350-9462},
doi = {https://doi.org/10.1016/j.preteyeres.2016.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S1350946216300106},
author = {Paul A. Roberts and Eamonn A. Gaffney and Philip J. Luthert and Alexander J.E. Foss and Helen M. Byrne},
keywords = {Oxygen, Neuroglobin, Photoreceptors, Angiogenesis, Retinitis pigmentosa, Choroidal neovascularisation},
abstract = {The retina confers upon us the gift of vision, enabling us to perceive the world in a manner unparalleled by any other tissue. Experimental and clinical studies have provided great insight into the physiology and biochemistry of the retina; however, there are questions which cannot be answered using these methods alone. Mathematical and computational techniques can provide complementary insight into this inherently complex and nonlinear system. They allow us to characterise and predict the behaviour of the retina, as well as to test hypotheses which are experimentally intractable. In this review, we survey some of the key theoretical models of the retina in the healthy, developmental and diseased states. The main insights derived from each of these modelling studies are highlighted, as are model predictions which have yet to be tested, and data which need to be gathered to inform future modelling work. Possible directions for future research are also discussed. Whilst the present modelling studies have achieved great success in unravelling the workings of the retina, they have yet to achieve their full potential. For this to happen, greater involvement with the modelling community is required, and stronger collaborations forged between experimentalists, clinicians and theoreticians. It is hoped that, in addition to bringing the fruits of current modelling studies to the attention of the ophthalmological community, this review will encourage many such future collaborations.}
}
@article{AMEMIYA2024105836,
title = {Children use disagreement to infer what happened},
journal = {Cognition},
volume = {250},
pages = {105836},
year = {2024},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2024.105836},
url = {https://www.sciencedirect.com/science/article/pii/S0010027724001227},
author = {Jamie Amemiya and Gail D. Heyman and Tobias Gerstenberg},
keywords = {Disagreement, Inference, Prediction, Theory of mind, Ambiguous speech},
abstract = {In a rapidly changing and diverse world, the ability to reason about conflicting perspectives is critical for effective communication, collaboration, and critical thinking. The current pre-registered experiments with children ages 7 to 11 years investigated the developmental foundations of this ability through a novel social reasoning paradigm and a computational approach. In the inference task, children were asked to figure out what happened based on whether two speakers agreed or disagreed in their interpretation. In the prediction task, children were provided information about what happened and asked to predict whether two speakers will agree or disagree. Together, these experiments assessed children's understanding that disagreement often results from ambiguity about what happened, and that ambiguity about what happened is often predictive of disagreement. Experiment 1 (N = 52) showed that children are more likely to infer that an ambiguous utterance occurred after learning that people disagreed (versus agreed) about what happened and found that these inferences become stronger with age. Experiment 2 (N = 110) similarly found age-related change in children's inferences and also showed that children could reason in the forward direction, predicting that an ambiguous utterance would lead to disagreement. A computational model indicated that although children's ability to predict when disagreements might arise may be critical for making the reverse inferences, it did not fully account for age-related change.}
}
@article{BLACKBURNE2025105969,
title = {Communicated priors tune the perception of control},
journal = {Cognition},
volume = {254},
pages = {105969},
year = {2025},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2024.105969},
url = {https://www.sciencedirect.com/science/article/pii/S0010027724002555},
author = {George Blackburne and Chris D. Frith and Daniel Yon},
keywords = {Agency, Control, Expectation, Prediction, Communication},
abstract = {Action allows us to shape the world around us. But to act effectively we need to accurately sense what we can and cannot control. Classic theories across cognitive science suppose that this ‘sense of agency’ is constructed from the sensorimotor signals we experience as we interact with our surroundings. But these sensorimotor signals are inherently ambiguous, and can provide us with a distorted picture of what we can and cannot influence. Here we investigate one way that agents like us might overcome the inherent ambiguity of these signals: by combining noisy sensorimotor evidence with prior beliefs about control acquired through explicit communication with others. Using novel tools to measure and model control decisions, we find that explicit beliefs about the controllability of the environment alter both the sensitivity and bias of agentic choices; meaning that we are both better at detecting and more biased to feel control when we are told to expect it. These seemingly paradoxical effects on agentic choices can be captured by a computational model where expecting to be in control exaggerates the sensitivity or ‘gain’ of the mechanisms we use to detect our influence over our surroundings – making us increasingly sensitised to both true and illusory signs of agency. In combination, these results reveal a cognitive and computational mechanism that allows public communication about what we can and cannot influence to reshape our private sense of control.}
}
@article{SCHULTEMECKLENBECK2013242,
title = {A lack of appetite for information and computation. Simple heuristics in food choice},
journal = {Appetite},
volume = {71},
pages = {242-251},
year = {2013},
issn = {0195-6663},
doi = {https://doi.org/10.1016/j.appet.2013.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S0195666313003668},
author = {Michael Schulte-Mecklenbeck and Matthias Sohn and Emanuel {de Bellis} and Nathalie Martin and Ralph Hertwig},
keywords = {Food choice, Heuristics, Process tracing, Rational choice, MouselabWeb},
abstract = {The predominant, but largely untested, assumption in research on food choice is that people obey the classic commandments of rational behavior: they carefully look up every piece of relevant information, weight each piece according to subjective importance, and then combine them into a judgment or choice. In real world situations, however, the available time, motivation, and computational resources may simply not suffice to keep these commandments. Indeed, there is a large body of research suggesting that human choice is often better accommodated by heuristics—simple rules that enable decision making on the basis of a few, but important, pieces of information. We investigated the prevalence of such heuristics in a computerized experiment that engaged participants in a series of choices between two lunch dishes. Employing MouselabWeb, a process-tracing technique, we found that simple heuristics described an overwhelmingly large proportion of choices, whereas strategies traditionally deemed rational were barely apparent in our data. Replicating previous findings, we also observed that visual stimulus segments received a much larger proportion of attention than any nutritional values did. Our results suggest that, consistent with human behavior in other domains, people make their food choices on the basis of simple and informationally frugal heuristics.}
}
@article{RICHARDSON2022100935,
title = {Extending the two-component model of delusion to substance use disorder etiology and recovery},
journal = {New Ideas in Psychology},
volume = {66},
pages = {100935},
year = {2022},
issn = {0732-118X},
doi = {https://doi.org/10.1016/j.newideapsych.2022.100935},
url = {https://www.sciencedirect.com/science/article/pii/S0732118X22000058},
author = {George B. Richardson and Nathan McGee},
keywords = {Brain disease model of addiction, Two-component model of delusion, Bayes Theorem, Belief, Substance use disorder},
abstract = {The brain disease model (BMDA) and psychosocial models of addiction attend to phenomena at different levels of biological organization, and evidence suggests neither is sufficient to explain substance use disorder (SUD). Here, we extend a Bayesian model of the emergence and persistence of delusions to SUD etiology and recovery, building upon efforts to link lower-level impacts of psychoactive compounds to higher-level phenomena such as attitudes, beliefs, and self-control. According to the resulting two-component model of SUD, psychoactive substances interact with genetic and environmental factors to produce delusions about the biological importance of substance use and its contexts by perturbating basic human affective systems. These delusions are most often revised or rejected based on individuals’ existing belief systems. But in some individuals, factors explaining the persistence of an array of delusions (e.g., lower levels of executive functioning) prevent the evaluation and revision system from rejecting or revising beliefs that attribute high salience to substance-related stimuli. This theory provides novel hypotheses regarding the potential roles of factors such as dichotomous thinking, positive illusions and self-deception, and denial or lack of awareness in SUD etiology and recovery. Furthermore, it provides an account of SUD that may result in less stigma than the BDMA.}
}
@article{GUR2015207,
title = {Space reconstruction by primary visual cortex activity: a parallel, non-computational mechanism of object representation},
journal = {Trends in Neurosciences},
volume = {38},
number = {4},
pages = {207-216},
year = {2015},
issn = {0166-2236},
doi = {https://doi.org/10.1016/j.tins.2015.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S0166223615000351},
author = {Moshe Gur},
keywords = {vision, object representation, recognition, conscious perception, parallel processing},
abstract = {The current view posits that objects, despite changes in appearance, are uniquely encoded by ‘expert’ cells. This view is untenable. First, even if cell ensemble responses are invariant and unique, we are consciously aware of all of the objects’ details. Second, in addition to detail preservation, data show that the current hypothesis fails to account for uniqueness and invariance. I present an alternative view whereby objects’ representation and recognition are based on parallel representation of space by primary visual cortex (V1) responses. Information necessary for invariance and other attributes is handled in series by other cortical areas through integration, interpolation, and hierarchical convergence. The parallel and serial mechanisms combine to enable our flexible space perception. Only in this alternative view is conscious perception consistent with the underlying architecture.}
}
@article{PLATZ2024e4563,
title = {Dichlorocarbene: From Jack Hine to Robert Moss},
journal = {Journal of Physical Organic Chemistry},
volume = {37},
number = {1},
pages = {e4563},
year = {2024},
issn = {0894-3230},
doi = {https://doi.org/10.1002/poc.4563},
url = {https://www.sciencedirect.com/science/article/pii/S089432302300259X},
author = {Matthew S. Platz},
keywords = {carbene, dichlorocarbene, Jack Hine, Robert Moss},
abstract = {A select history of dichlorocarbene chemistry between 1950 and 2010 will be presented. This is not a comprehensive review; rather, it is a personal perspective on the contributions of two respected colleagues, the reactive intermediate that spanned their research efforts, and their important contributions to organic synthesis and mechanistic thinking.}
}
@incollection{ROMO2020150,
title = {Metaphor},
editor = {Mark Runco and Steven Pritzker},
booktitle = {Encyclopedia of Creativity (Third Edition)},
publisher = {Academic Press},
edition = {Third Edition},
address = {Oxford},
pages = {150-156},
year = {2020},
isbn = {978-0-12-815615-5},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.23529-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245235293},
author = {Manuela Romo},
keywords = {Analogical thought, Combinatory process, Computational creativity, Constitutive metaphor, Darwin, Einstein, Lorca, Pedagogical metaphor, Poetry, Scientific discovery},
abstract = {The subject of metaphors is introduced with a definition, stressing its role as a universal process in the development of thinking and language in human beings. A discussion follows on the differences between metaphor and analogy in this thinking process. The classification of metaphors is then addressed, while the body of the text is dedicated to reviewing explanations given from the standpoint of Psychology of Creativity on the nature of this process and its role in creative output. Lastly, the usefulness of metaphors and their dependence on domain specificity is analysed.}
}
@article{MARCIALROMERO2008171,
title = {Sequential Real Number Computation and Recursive Relations},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {202},
pages = {171-189},
year = {2008},
note = {Proceedings of the Fourth International Conference on Computability and Complexity in Analysis (CCA 2007)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2008.03.014},
url = {https://www.sciencedirect.com/science/article/pii/S1571066108001199},
author = {J. Raymundo Marcial-Romero and M. Andrew Moshier},
keywords = {exact real-number computation, sequential computation, recursive relations, semantics, non-determinism, PCF},
abstract = {In the first author's thesis [Marcial-Romero, J. R., “Semantics of a sequential language for exact real-number computation”, PhD thesis at the University of Birmingham, 2004)], a sequential language, LRT, for real number computation is investigated. The thesis includes a proof that all polynomials are programmable, but that work comes short of giving a complete characterization of the expressive power of the language even for first-order functions. The technical problem is that LRT is non-deterministic. So a natural characterization of its expressive power should be in terms of relations rather than functions. In [Brattka, V., Recursive characterization of computable real-valued functions and relations, Theoretical Computer Science 162 (1) (1996) 45–77], Brattka investigates a formalization of recursive relations in the style of Kleene's recursive functions on the natural numbers. This paper establishes the expressive power of LRTp, a variant of LRT, in terms of Brattka's recursive relations. Because Brattka already did the work of establishing the precise connection between his recursive relations and Type 2 Theory of Effectivity, we thus obtain a complete characterization of first-order definability in LRTp.}
}
@article{JONES2015e38,
title = {Complexity and forensic pathology},
journal = {Forensic Science International},
volume = {257},
pages = {e38-e43},
year = {2015},
issn = {0379-0738},
doi = {https://doi.org/10.1016/j.forsciint.2015.08.026},
url = {https://www.sciencedirect.com/science/article/pii/S0379073815003709},
author = {Richard Martin Jones},
keywords = {Complexity, Chaos, Nonlinear, Pathophysiology, Forensic pathology, Forensic medicine},
abstract = {It has become increasingly apparent that nonlinearity and complexity are the norm in human physiological systems, the relevance of which is informing an enhanced understanding of basic pathological processes such as inflammation, the host response to severe trauma, and critical illness. This article will explore how an understanding of nonlinear systems and complexity might inform the study of the pathophysiology of deaths of medicolegal interest, and how ‘complexity thinking’ might usefully be incorporated into modern forensic medicine and forensic pathology research, education and practice.}
}
@article{DALLAGO2016150,
title = {Computation by interaction for space-bounded functional programming},
journal = {Information and Computation},
volume = {248},
pages = {150-194},
year = {2016},
note = {Development on Implicit Computational Complexity (DICE 2013)},
issn = {0890-5401},
doi = {https://doi.org/10.1016/j.ic.2015.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S089054011500142X},
author = {Ugo {Dal Lago} and Ulrich Schöpp},
keywords = {Implicit computational complexity, Logarithmic space, Type system, Geometry of interaction, Functional programming},
abstract = {When programming with sublinear space constraints one often needs to use special implementation techniques even for simple tasks, such as function composition. In this paper, we study how such implementation techniques can be supported in a functional programming language. Our approach is based on modelling computation by interaction using the Int construction of Joyal, Street & Verity. We apply this construction to a term model of a first-order programming language and use the resulting structure to derive the functional programming language intml. Intml can be understood as a programming language simplification of Stratified Bounded Affine Logic. We formulate intml by means of a type system inspired by Baillot & Terui's Dual Light Affine Logic. We show that it captures the complexity classes flogspace and nflogspace. We illustrate its expressiveness by showing how typical graph algorithms, such a test for acyclicity in undirected graphs, can be represented.}
}
@article{CHUI201337,
title = {Simulation Method for Developing Multiple-Use Medical Devices from Re-using and Enhancing Design of Single-Use Device},
journal = {Procedia CIRP},
volume = {5},
pages = {37-41},
year = {2013},
note = {First CIRP Conference on BioManufacturing},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2013.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S2212827113000085},
author = {Chee-Kong Chui and Han-Tong Loh and Jun-Fung Yam},
keywords = {Medical device design, Simulation, Single port access surgery},
abstract = {Single port access surgery requires several specialized and one-time use devices to perform the surgery. By making the specialized devices suitable for multiple use may reduce surgical cost and increase the popularity of single port access surgery. However, this requires a new design thinking that emphasize on modular design and sterilization. We are exploiting simulation and computational intelligence methods to aid the design process that includes splitting an existing single use device design into modules and identifying the parts from the modules for manufacturing. Linking the design of the device with manufacturing can be achieved using feature graphs. This paper relates the development of a multiple use hand instrument for single port access surgery by re- using and enhancing the design of single-use devices with the proposed simulation-based methodology.}
}
@article{BARA2001839,
title = {Model theory of deduction: a unified computational approach},
journal = {Cognitive Science},
volume = {25},
number = {6},
pages = {839-901},
year = {2001},
issn = {0364-0213},
url = {https://www.sciencedirect.com/science/article/pii/S0364021301000568},
author = {Bruno G. Bara and Monica Bucciarelli and Vincenzo Lombardo},
keywords = {Mental models, Deduction, Computational model, Development},
abstract = {One of the most debated questions in psychology and cognitive science is the nature and the functioning of the mental processes involved in deductive reasoning. However, all existing theories refer to a specific deductive domain, like syllogistic, propositional or relational reasoning. Our goal is to unify the main types of deductive reasoning into a single set of basic procedures. In particular, we bring together the microtheories developed from a mental models perspective in a single theory, for which we provide a formal foundation. We validate the theory through a computational model (UNICORE) which allows fine-grained predictions of subjects’ performance in different reasoning domains. The performance of the model is tested against the performance of experimental subjects—as reported in the relevant literature—in the three areas of syllogistic, relational and propositional reasoning. The computational model proves to be a satisfactory artificial subject, reproducing both correct and erroneous performance of the human subjects. Moreover, we introduce a developmental trend in the program, in order to simulate the performance of subjects of different ages, ranging from children (3–6) to adolescents (8–12) to adults (>21). The simulation model performs similarly to the subjects of different ages. Our conclusion is that the validity of the mental model approach is confirmed for the deductive reasoning domain, and that it is possible to devise a unique mechanism able to deal with the specific subareas. The proposed computational model (UNICORE) represents such a unifying structure.}
}
@article{MENGOV20061636,
title = {Fast computation of a gated dipole field},
journal = {Neural Networks},
volume = {19},
number = {10},
pages = {1636-1647},
year = {2006},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2006.05.031},
url = {https://www.sciencedirect.com/science/article/pii/S0893608006001316},
author = {George Mengov and Kalin Georgiev and Stefan Pulov and Trifon Trifonov and Krassimir Atanassov},
keywords = {Gated dipole field, Adaptive resonance theory, Generalized net},
abstract = {We address the need to develop efficient algorithms for numerical simulation of models, based in part or entirely on adaptive resonance theory. We introduce modifications that speed up the computation of the gated dipole field (GDF) in the Exact ART neural network. The speed increase of our solution amounts to at least an order of magnitude for fields with more than 100 gated dipoles. We adopt a ‘divide and rule’ approach towards the original GDF differential equations by grouping them into three categories, and modify each category in a separate way. We decouple the slow-dynamics part — the neurotransmitters from the rest of system, solve their equations analytically, and adapt the solution to the remaining fast-dynamics processes. Part of the node activations are integrated by an unsophisticated numerical procedure switched on and off according to rules. The remaining activations are calculated at equilibrium. We implement this logic in a Generalized Net (GN) — a tool for parallel processes simulation which enables a fresh look at developing efficient models. Our software implementation of generalized nets appears to add little computational overhead.}
}
@article{SHIVHARE2016243,
title = {On the Cognitive Process of Abstraction},
journal = {Procedia Computer Science},
volume = {89},
pages = {243-252},
year = {2016},
note = {Twelfth International Conference on Communication Networks, ICCN 2016, August 19– 21, 2016, Bangalore, India Twelfth International Conference on Data Mining and Warehousing, ICDMW 2016, August 19-21, 2016, Bangalore, India Twelfth International Conference on Image and Signal Processing, ICISP 2016, August 19-21, 2016, Bangalore, India},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.06.051},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916311164},
author = {Radhika Shivhare and Ch. Aswani Kumar},
keywords = {Abstraction, Cognitive Informatics, Concept Algebra, Formal Concept Analysis.},
abstract = {Concepts are the basic elements of propositions. Concepts can be best understood as constituted by its subset of objects (Extent) and subset of attributes (Intent). Psychological capacities of human mind for example, learning, thinking, memorizing can be performed by concepts and their association. In this paper, we will explain how human will be able to generalize concrete concepts of Formal Concept Analysis into abstract concepts. In particular, we model the functionalities of concept algebra by making use of Formal Concept Analysis; we illustrate the proposed model with experiments on sample context. This model simulates the thinking process of human mind.}
}
@incollection{MEDINAFRANCO2015455,
title = {Chapter 21 - Discovery and Development of Lead Compounds from Natural Sources Using Computational Approaches},
editor = {Pulok K. Mukherjee},
booktitle = {Evidence-Based Validation of Herbal Medicine},
publisher = {Elsevier},
address = {Boston},
pages = {455-475},
year = {2015},
isbn = {978-0-12-800874-4},
doi = {https://doi.org/10.1016/B978-0-12-800874-4.00021-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128008744000210},
author = {José L. Medina-Franco},
keywords = {Chemical space, Chemoinformatics, Computer-aided drug design, Dietary components, Drug discovery, Molecular diversity, Pharmacological profiling, Structure–activity relationships, Target fishing, Virtual screening},
abstract = {This chapter discusses the synergy between natural product-based drug discovery and methods used in computer-aided drug design. For centuries, Nature has been the source of compounds that are currently in the clinic or that have been used as molecular probes to identify therapeutic targets. In addition, Nature has inspired the development of a significant number of pharmaceutical agents. In contrast, computational approaches applied to drug discovery date back to only a few decades. Nonetheless, computational methods are evolving at an impressive speed and are making significant contributions to identifying and developing bioactive compounds of therapeutic relevance. Computational methods have a broad range of applications in natural product research including the organization and comprehensive analysis of molecular databases, systematic screening of natural products libraries, computer-aided optimization of lead compounds, and identification of biological activities for natural products of dietary origin.}
}
@article{PEREZ2008755,
title = {A computational evaluation of the effect of intramedullary nail material properties on the stabilization of simulated femoral shaft fractures},
journal = {Medical Engineering & Physics},
volume = {30},
number = {6},
pages = {755-760},
year = {2008},
issn = {1350-4533},
doi = {https://doi.org/10.1016/j.medengphy.2007.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S1350453307001567},
author = {Angel Perez and Andrew Mahar and Charles Negus and Peter Newton and Tom Impelluso},
keywords = {Finite element method, Simulated pediatric femur fractures, Intramedullary nails, Biomechanical stability},
abstract = {Titanium flexible intramedullary nails have become far more prevalent for stabilization of pediatric femur fractures in recent years. While steel may be expected to have superior fracture stability due to its higher elastic modulus; titanium alloy has experimentally demonstrated improved biomechanical stability, as measured by gap closure and nail slippage. The purpose of this study was to verify these observations computationally, and thus, explain why titanium alloy may be better suited for surgical fixation of fractured femurs. A finite element model of a femur with complete mid-diaphyseal fracture and having two 3.5mm nails in a retrograde “C” pattern was created. Static analyses were run in which the nail material properties were titanium alloy or stainless steel, respectively. Gap closure for the stainless steel nails was 1.03mm; while the titanium alloy nails had 0.69mm of closure. Titanium alloy nails slipped slightly less at each loading increment than stainless steel nails. The titanium alloy nails distributed stress more evenly along the nail axis, resulting in lower peak magnitudes. These results agree with previously published clinical and biomechanical studies that reported increased gap closure and nail slippage with stainless steel nails. The increased deformation of the titanium alloy nail likely increases the contact area with the intramedullary canal wall, thus, increasing stability. Additionally, stainless steel nails had higher curve apex von Mises stresses, potentially inducing a stress-shielding effect which could hamper remodeling and consequently increase risk of re-fracture.}
}
@article{PAUSELLI201874,
title = {Computational linguistic analysis applied to a semantic fluency task to measure derailment and tangentiality in schizophrenia},
journal = {Psychiatry Research},
volume = {263},
pages = {74-79},
year = {2018},
issn = {0165-1781},
doi = {https://doi.org/10.1016/j.psychres.2018.02.037},
url = {https://www.sciencedirect.com/science/article/pii/S0165178117309824},
author = {Luca Pauselli and Brooke Halpern and Sean D. Cleary and Benson S. Ku and Michael A. Covington and Michael T. Compton},
keywords = {Automatic Data Processing, Formal Thought Disorder, Psychosis, Schizophrenia, Semantics, Semantic Fluency Tasks},
abstract = {Although rating scales to assess formal thought disorder exist, there are no objective, high-reliability instruments that can quantify and track it. This proof-of-concept study shows that CoVec, a new automated tool, is able to differentiate between controls and patients with schizophrenia with derailment and tangentiality. According to ratings from the derailment and tangentiality items of the Scale for the Assessment of Positive Symptoms, we divided the sample into three groups: controls, patients without formal thought disorder, and patients with derailment/tangentiality. Their lists of animals produced during a one-minute semantic fluency task were processed using CoVec, a newly developed software that measures the semantic similarity of words based on vector semantic analysis. CoVec outputs were Mean Similarity, Coherence, Coherence-5, and Coherence-10. Patients with schizophrenia produced fewer words than controls. Patients with derailment had a significantly lower mean number of words and lower Coherence-5 than controls and patients without derailment. Patients with tangentiality had significantly lower Coherence-5 and Coherence-10 than controls and patients without tangentiality. Despite the small samples of patients with clinically apparent thought disorder, CoVec was able to detect subtle differences between controls and patients with either or both of the two forms of disorganization.}
}
@article{LU2024,
title = {Methods for Calculating Building-Embodied Carbon Emissions for the Whole Design Process},
journal = {Fundamental Research},
year = {2024},
issn = {2667-3258},
doi = {https://doi.org/10.1016/j.fmre.2022.07.015},
url = {https://www.sciencedirect.com/science/article/pii/S266732582400092X},
author = {Mei Lu and Zhixing Luo and Yujie Cang and Nan Zhang and Liu Yang},
keywords = {Design process, embodied carbon emissions, calculation methods, conceptual design, scheme design, construction drawing design},
abstract = {Energy conservation and emissions reduction in the construction industry are important steps in achieving China's goals of peak carbon emissions by 2030 and carbon neutrality by 2060. The premise for building carbon emission (CE) reduction is to produce accurate CE calculations. Existing calculation methods for building CEs have many problems, such as complicated calculations, large data demands, time-consuming and laborious processes, weak design orientation of results, and poor feedback on emission reduction. At the same time, the calculation of CEs during the process of architectural design faces obstacles such as uncertainty of information, incomplete data, and difficulty in obtaining a bill of quantities based on design information. To resolve these obstacles, this study, based on a designer's vocabulary and thinking mode, describes the construction of a “design-oriented” calculation methods for building-embodied carbon emissions (ECEs). The prediction and assessment of the impact on the building environment during the architectural design process were helpful for identifying the key areas for carbon reduction, exploring potential emission reduction hotspots, and providing timely feedback for design optimization, which can have important theoretical value and practical significance in promoting the construction of low-carbon buildings.}
}
@article{HAN2020106264,
title = {A new computational model based on Archimedean copula for probabilistic unbalanced linguistic term set and its application to multiple attribute group decision making},
journal = {Computers & Industrial Engineering},
volume = {140},
pages = {106264},
year = {2020},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2019.106264},
url = {https://www.sciencedirect.com/science/article/pii/S0360835219307338},
author = {Bing Han and Zhifu Tao and Huayou Chen and Ligang Zhou and Jinpei Liu},
keywords = {Multiple attribute group decision making, Probabilistic unbalanced linguistic term set, Archimedean copula, Weighted average aggregation operator},
abstract = {This paper proposes the concept of the probabilistic unbalanced linguistic term set which considers not only the probability of linguistic variables but also the non-uniform and non-symmetric distribution of linguistic labels. A new computational model on basis of Archimedean copula and corresponding co-copula is developed to deal with probabilistic unbalanced linguistic information. The most advantage of the model is that it can keep the closure of the operation. Some operational properties and particular cases are further investigated. We present the concepts of Archimedean copula weighted probabilistic unbalanced linguistic arithmetic average aggregation operator and Archimedean copula weighted probabilistic unbalanced linguistic geometric average aggregation operator, some properties are also discussed. Finally, the effectiveness and universality of the developed approach are illustrated by a hospital selection and comparison analysis. A sensitivity analysis is also performed to test the robustness of proposed methods.}
}
@article{MINOZZI2020101498,
title = {Direct response and the strategy method in an experimental cheap talk game},
journal = {Journal of Behavioral and Experimental Economics},
volume = {85},
pages = {101498},
year = {2020},
issn = {2214-8043},
doi = {https://doi.org/10.1016/j.socec.2019.101498},
url = {https://www.sciencedirect.com/science/article/pii/S2214804319300230},
author = {William Minozzi and Jonathan Woon},
keywords = {Strategic information transmission, Sender-receiver games, Strategy method, Laboratory experiment},
abstract = {In cheap talk games, equilibrium analysis predicts extreme limits on the information that can be transmitted when senders and receivers have different goals. Yet experimental evidence suggests that senders overcommunicate relative to this baseline, revealing more information than predicted in equilibrium. We propose that overcommunication may be due in part to limited cognitive engagement by subjects, captured by level-k thinking. To test this conjecture, we compare two elicitation methods, direct response and the strategy method, holding other elements of the game fixed. Existing experimental studies of cheap talk games use the standard direct response method, while the strategy method—in which subjects make selections for all contingent choices—is believed to encourage more thoughtful decisionmaking. We therefore expect senders to transmit less information with the strategy method than with direct response. In contrast, we find the reverse: the strategy method increased overcommunication. Further examination suggests that this occurred because senders played more naïvely with the strategy method than with direct response. Our findings suggest that the strategy method and direct response do not elicit the same choices in cheap talk games.}
}
@article{CHARPENTIER20163365,
title = {Sensitivity computations in higher order continuation methods},
journal = {Applied Mathematical Modelling},
volume = {40},
number = {4},
pages = {3365-3380},
year = {2016},
issn = {0307-904X},
doi = {https://doi.org/10.1016/j.apm.2015.10.033},
url = {https://www.sciencedirect.com/science/article/pii/S0307904X15006952},
author = {Isabelle Charpentier and Komlanvi Lampoh},
keywords = {Continuation, Homotopy, Sensitivity, Automatic differentiation, Diamant, Complex nonlinear eigenvalue problem,},
abstract = {Sensitivity analysis is a key tool in the study of the relationships between the input parameters of a model and the output solution. Although sensitivity analysis is extensively addressed in the literature, little attention has been brought to the methodological aspects of the sensitivity of nonlinear parametric solutions computed through a continuation technique. This paper proposes four combinations of sensitivity analysis with continuation and homotopy methods, including sensitivity analysis along solution branches or at a particular point. Theoretical aspects are discussed in the higher order continuation framework Diamant. The sensitivity methods are applied to a thermal ignition problem and some free vibration problems. Remarkable eigenvalue maps are produced for the complex nonlinear eigenvalue problems.}
}
@article{WIECHERT20031363,
title = {The role of modeling in computational science education},
journal = {Future Generation Computer Systems},
volume = {19},
number = {8},
pages = {1363-1374},
year = {2003},
note = {Selected papers from the Workshop on Education in Computational Sciences held at the International Conference on Computational Science},
issn = {0167-739X},
doi = {https://doi.org/10.1016/S0167-739X(03)00093-1},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X03000931},
author = {W. Wiechert},
keywords = {Computational science education, Modeling and simulation, Modeling education},
abstract = {Modeling and simulation skills are two core competences of computational science and thus should be a central part of any curriculum. While there is a well-founded methodology for the design of simulation algorithms today the teaching of modeling skills carries some intrinsic problems. The reason is that modeling is still partly an art and partly a science. As an important consequence for university education, the concepts for teaching modeling must be quite different from those for teaching simulation algorithms. Experiences made with the courses on ‘Modeling and Simulation’ at the University of Siegen are summarized and some general concepts for the teaching of modeling skills are presented. In particular, three practical approaches to modeling education are discussed with several examples.}
}
@article{MCCREADY2010274,
journal = {Journal of Pragmatics},
volume = {42},
number = {1},
pages = {274-278},
year = {2010},
issn = {0378-2166},
doi = {https://doi.org/10.1016/j.pragma.2009.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S0378216609001532},
author = {Elin McCready}
}
@article{LOU2022100247,
title = {Two-additive fuzzy measure-based information integration approach to product design alternative evaluation},
journal = {Journal of Industrial Information Integration},
volume = {25},
pages = {100247},
year = {2022},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2021.100247},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X21000467},
author = {Shanhe Lou and Yixiong Feng and Zhiwu Li and Jianrong Tan},
keywords = {Multi-criteria decision-making, Two-additive fuzzy measure, Information integration, Intuitionistic linguistic number},
abstract = {Conceptual design is a pivotal stage of new product development in manufacturing industries. Since multiple design alternatives are put forward at this stage, developing advanced evaluation methods is of great importance. Existing methods adopt additive models to integrate evaluation data. They face some inconsistency issues, e.g. inconsistency in the independent assumption and interdependent data, since evaluation criteria are interactional. Fuzzy measure that replaces the additivity with monotonicity has enabled advances in addressing such issues. This work proposes a two-additive fuzzy measure-based information integration approach to product design alternative evaluation for the first time. The evaluation data given by experts are in the form of intuitionistic linguistic numbers. They are more in accordance with the thinking habits of experts because the hesitation degree in linguistic assessment can be revealed. In order to reduce the subjective bias, the decision-making trial and evaluation laboratory method combining with grey relational analysis is applied to adjust evaluation data. Then monotonous two-additive fuzzy measure is identified by nonlinear programming using these data. It makes a good trade-off between computational complexity and presentation capability. Hence, evaluation data can be integrated by non-additive Choquet integral for ranking design alternatives. In comparison to additive model-based methods, the extra effect on the simultaneous satisfaction of criteria can be effectively revealed by the proposed approach. And the robustness of it is demonstrated by the sensitivity analysis. A case study on an elevator's design alternative evaluation is conducted to illustrate the feasibility and practicability of the proposed approach.}
}
@article{FORTHMANN201959,
title = {Creative ideation, broad retrieval ability, and processing speed: A confirmatory study of nested cognitive abilities},
journal = {Intelligence},
volume = {75},
pages = {59-72},
year = {2019},
issn = {0160-2896},
doi = {https://doi.org/10.1016/j.intell.2019.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S0160289618301211},
author = {Boris Forthmann and David Jendryczko and Jana Scharfen and Ruben Kleinkorres and Mathias Benedek and Heinz Holling},
keywords = {Divergent thinking, Broad retrieval ability, Processing speed, Structural equation modeling},
abstract = {Divergent thinking (DT) ability (i.e., the ability to come up with creative ideas) is a complex cognitive construct that has been associated with several specific components of the Cattel-Horn-Carroll (CHC) model. In this study, we employed a nested latent variable approach to examine the specific role of mental speed (Gs) and general retrieval ability (Gr) in DT ability, which was assessed by DT tasks that instructed to be creative and were scored for creative quality. Specifically, Gs was assumed to facilitate both Gr and DT, and Gr was assumed to contribute to DT. Successive latent variable models with orthogonal factors were tested to reflect these nested cognitive basic abilities. The proposed model of nested factors fit the data well: Latent Gs accounted for variation in Gs, Gr, and DT creative quality scores, latent Gr predicted performance in Gr and DT scores beyond Gs, and latent DT explained variation in DT scores beyond Gs and Gr. In addition, we related the resulting orthogonal latent variables to the external criteria of school grades to illustrate the explanatory power of the modeling approach. This study provides evidence that divergent thinking performance relies on mental speed and retrieval ability, as well as cognitive abilities unique to divergent thinking. We discuss consequences for the understanding of divergent thinking ability in the context of the CHC model.}
}
@article{MATSUDA2005275,
title = {Functional competency and cognitive ability in mild Alzheimer's Disease: relationship between ADL assessed by a relative/ carer-rated scale and neuropsychological performance},
journal = {International Psychogeriatrics},
volume = {17},
number = {2},
pages = {275-288},
year = {2005},
issn = {1041-6102},
doi = {https://doi.org/10.1017/S1041610205001304},
url = {https://www.sciencedirect.com/science/article/pii/S1041610224046805},
author = {Osamu Matsuda and Masahiko Saito},
keywords = {Alzheimer's disease, cognitive deficits, functional competency},
abstract = {ABSTRACT
Background: Alzheimer's disease (AD) is characterized by multiple cognitive deficits and affects functional competency to perform daily activities (ADL). As this may contribute to the patient's overall disability, it is important to identify factors that compromise competency. Objective: The relationship between different cognitive domains and functional activities in AD was studied. Methods: The functional competency of 73 Japanese AD patients, most with mild dementia, was assessed using a 27-item relative/carer-rating scale covering 7 ADL: managing finances, using transportation, taking precautions, self-care, housekeeping, communication and taking medicine. Cognitive assessment used 16 neuropsychological tests from the Japanese version of the WAIS-R and COGNISTAT, covering 9 cognitive domains: orientation, attention, episodic memory, semantic memory, language, visuoperceptual and construction abilities, computational ability, abstract thinking, and psychomotor speed. Results: Multiple regression analysis by the stepwise method indicated that functional competency could, for the most part, be predicted from test scores for orientation, abstract thinking and psychomotor speed. Discussion: The results of this study suggest that impairment of these three cognitive domains plays an important role in the functional deterioration of AD.}
}
@article{QUAN20196515,
title = {Smart Design for Sustainable Neighborhood Development},
journal = {Energy Procedia},
volume = {158},
pages = {6515-6520},
year = {2019},
note = {Innovative Solutions for Energy Transitions},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2019.01.108},
url = {https://www.sciencedirect.com/science/article/pii/S1876610219301183},
author = {Steven Jige Quan},
keywords = {Smart Design, Sustainable Neighborhood Development, Design Decision Making, Multi-objective Optimization, Genetic Algorithms, Pareto optimal},
abstract = {This study proposes the Smart Design method to support the design decision making in the sustainable neighborhood development with multiple objectives. Instead of the “creative design” approach in the scenario making in traditional PSS and recent Geodesign frameworks, the Smart Design method applies the optimization algorithms to search for optimal design solutions in the design space. It integrates the design thinking, computational performance modeling and optimization techniques to efficiently and effectively approximate optimal designs. This method is applied to a hypothetical residential neighborhood design case study with three sustainability objectives: to maximize FAR, to minimize building energy use, and to minimize outdoor human discomfort. Based on the form parameterization, the Nondominated Sorting Genetic Algorithm II (NSGA-II) algorithm is utilized to guide the evolution of the neighborhood design throughout 80 generations, with neighborhood performance modeling tools. The Smart Design method is able to identify 38 representative design solutions as Pareto optimal which are equally optimal. Those solutions set a basis for discussions and negotiations among stake holders to make design decisions with the three objectives. Further research will be focused on addressing the challenges such as recursive objective definitions, parametrization of complex forms, quantification of performances and optimization uncertainties, from simple cases to more realistic and complex designs for sustainable neighborhood development.}
}
@article{VAHDANJOO2025101287,
title = {Digital transformation of the agri-food system},
journal = {Current Opinion in Food Science},
pages = {101287},
year = {2025},
issn = {2214-7993},
doi = {https://doi.org/10.1016/j.cofs.2025.101287},
url = {https://www.sciencedirect.com/science/article/pii/S2214799325000177},
author = {Mahdi Vahdanjoo and Claus Grøn Sørensen and Michael Nørremark},
abstract = {The purpose of this paper is to examine the role of digital transformation in the agri-food sector. The study emphasizes digitalization as both an enabler of production efficiency and a radical innovator redesigning business models and agricultural practices. The study explores the development of applications and products that connect consumers, supply chain actors, and producers, leading to customized food products. It highlights the notion of circular agri-food systems for feedback loops in the value chain, minimizing waste and integrating environmental and social values. Also, the paper explores the challenges in digital adoption, including technical barriers, privacy, and security concerns. To overcome these challenges, an interdisciplinary approach is proposed, merging technological, ecological, economic, and governance insights. Key needs identified for successful digital transformation include enhanced data processing, technological convergence, sustainability awareness, interoperability, and user adoption. The conclusion stresses the importance of invoking systemic thinking, user-friendly designs, and interdisciplinary collaboration in making sure that digital innovations enable a sustainable and resilient food production system.}
}
@article{MEHRYAR2022155854,
title = {Investigating flood resilience perceptions and supporting collective decision-making through fuzzy cognitive mapping},
journal = {Science of The Total Environment},
volume = {837},
pages = {155854},
year = {2022},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2022.155854},
url = {https://www.sciencedirect.com/science/article/pii/S0048969722029515},
author = {Sara Mehryar and Swenja Surminski},
keywords = {Flood resilience, Participatory decision making, Resilience measurement tool, Mind mapping, Fuzzy cognitive mapping},
abstract = {Improving flood resilience of communities requires a holistic understanding of risks and resilience options as well as the preferences and priorities of different stakeholders. Innovations in risk and resilience assessment have helped communities to identify gaps in their flood risk management strategy but selecting and implementing resilience solutions remains a big challenge for many decision-makers. In addition to traditional appraisals and cost-benefit assessments this also calls for a participatory process in which various stakeholders are encouraged to adopt a system-level approach in identifying interventions that can maximise a range of benefits and co-benefits. In this study, we investigate how a combination of modelling and measurement methods can help decision-makers with their flood resilience strategies. We apply a participatory system thinking approach combining Fuzzy Cognitive Mapping (FCM) with a flood resilience measurement framework called Flood Resilience Measurement for Communities (FRMC). We first investigate stakeholders' biases on flood resilience interventions, and then lead them through a system thinking exercise using FCM and FRMC to elicit mental models representing important aspects of flood resilience and their interrelation. These are then aggregated, representing the collective perceptions and knowledge of stakeholders, and used to identify the most beneficial resilience actions in terms of direct and indirect impacts on flood resilience. We apply this approach to the case of Lowestoft, a coastal town in England exposed to significant flood risk. Developed in close collaboration with the local authorities, the ambition is to support decision-making on flood resilience interventions. We find that this combination of methods enables system-level thinking and inclusive decision-making about flood resilience which can ultimately encourage transformative decisions on prioritization of actions and investments.}
}
@article{SWANSON201854,
title = {How failure is productive in the creative process: Refining student explanations through theory-building discussion},
journal = {Thinking Skills and Creativity},
volume = {30},
pages = {54-63},
year = {2018},
note = {The Role of Failure in Promoting Thinking Skills and Creativity},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2018.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S1871187117301785},
author = {Hillary Swanson and Allan Collins},
keywords = {Knowledge in pieces, Microgenetic learning analysis, Knowledge construction, Constructivist instruction, Science learning, Creative thinking, Critical thinking, Creative problem solving},
abstract = {We argue that failure can play a productive role in students’ creative knowledge-construction process. As evidence, we present a fine-grained analysis of a whole-class theory-building discussion with 8th grade students. The goal of the discussion was to construct a theoretical account for why a glass of cold milk warmed quickly at first and then more slowly as it approached room temperature. Though they initially produced scientifically non-normative explanations, by the end of the discussion the class had refined their ideas into an explanation of difference drives rate – a relationship at the heart of Newton’s law of heating and other equilibration phenomena. The students’ flawed initial explanations were productive in the knowledge-construction process, as the raw material they ultimately refined into a more scientific explanation. We argue that the theory-building discussion supported both creative and critical thinking and that this pedagogical approach has the power, more generally, to leverage failure productively for science learning.}
}
@article{RIZZI20131,
title = {Introduction: Core computational principles in natural language syntax},
journal = {Lingua},
volume = {130},
pages = {1-13},
year = {2013},
note = {SI: Syntax and cognition: core ideas and results in syntax},
issn = {0024-3841},
doi = {https://doi.org/10.1016/j.lingua.2012.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0024384112002756},
author = {Luigi Rizzi}
}
@article{LIN20253,
title = {Multiple predictions of others’ actions in the human brain},
journal = {Trends in Neurosciences},
volume = {48},
number = {1},
pages = {3-4},
year = {2025},
issn = {0166-2236},
doi = {https://doi.org/10.1016/j.tins.2024.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S0166223624002182},
author = {Yongling Lin and Marco K. Wittmann},
keywords = {social cognition, neuroimaging, decision making, prediction, theory of mind, computational modelling},
abstract = {The success of our actions often depends on what others are doing. How does the brain discern predictions of others’ actions when situations are ambiguous? Recent work by Ma and colleagues suggests that the brain solves this problem by entertaining multiple predictions of others’ actions, ranked by their likelihood.}
}
@article{SAMARASINGHE2013188,
title = {Mixed-method integration and advances in fuzzy cognitive maps for computational policy simulations for natural hazard mitigation},
journal = {Environmental Modelling & Software},
volume = {39},
pages = {188-200},
year = {2013},
note = {Thematic Issue on the Future of Integrated Modeling Science and Technology},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2012.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S1364815212001909},
author = {Sandhya Samarasinghe and Graham Strickert},
keywords = {Fuzzy cognitive maps, Auto-Associative Neural Networks, Self-organizing maps, Natural hazard mitigation, Earthquakes, Mixed-method triangulation, Policy simulation},
abstract = {Human systems need to be adaptive to the consequences of natural hazards. Public policy decisions on natural hazard mitigation can benefit from computational models that embody a comprehensive view of the system. Such models need to be transparent and integrate both expert and lay expert knowledge and experience in an efficient manner. By integrating hard and soft sciences within an overall systems framework, scientists, policy makers and communities can better understand how to improve adaptive capacity. We present a fuzzy cognitive map based Auto-Associative Neural Networks framework generated from a development mixed method integration (triangulation) for adaptive policy formulations. The specific policies relate to preparation for, response to, and recovery from earthquakes in mountainous ski-field environments – a case study chosen to highlight the framework. Three different data collection techniques – expert geomorphic assessments, semi-structured qualitative interviews with three stakeholder groups (experts and lay experts), and fuzzy cognitive maps (FCM) (node and arc maps of stakeholder perceptions) were employed. FCM were first analysed using Graph theory indices to determine map structure. Special attention was paid to subsequent processing of fuzzy cognitive maps (e.g., condensation and aggregation) with qualitative followed by quantitative means to simplify the FCM from the original total of 300 variables to 5 high-level themes to improve the efficacy of subsequent policy simulations. Specifically, the use of Self Organising Maps (SOM) to group concepts (condensation) and individual stakeholders (aggregation) into social group FCMs is a novel contribution to advancing FCM. In the process, SOM also enabled the embedment of nonlinear relationships inherent in the system in the simplified FCM allowing a platform for realistic and meaningful policy simulations based on collective perceptions. Specifically, each of the three simplified stakeholder group FCM and a total social group FCM was represented by Auto-Associative Neural Networks (AANN) which converts an FCM into a dynamical system that allows policy scenario simulations based on input from both expert and lay expert stakeholders. A policy scenario is the level of importance given to a set of concepts and their effects on the system behaviour as revealed by the simulations. We present the results from one of several policy simulations to highlight the effectiveness of the mixed-method integration leading to simplified-FCM based ANNN simulations. Results revealed the similarities and differences between stakeholder group responses in relation to the scenario analysed and how these formed collective responses in the total social group map. Furthermore, outcomes of group and total social group simulations could be interpreted from individual and group stakeholder FCMs giving credibility to the mixed-method approach.}
}
@article{SAMUELSSON2023100173,
title = {A shape of play to come: Exploring children's play and imaginaries with robots and AI},
journal = {Computers and Education: Artificial Intelligence},
volume = {5},
pages = {100173},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100173},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000528},
author = {Robin Samuelsson},
keywords = {Early childhood, Robots, AI, Play, Playful learning, Sociotechnical imaginaries},
abstract = {We are rapidly moving into an era where AI and robots are part of everyday interactions in society and education, and there are immense discussions today about current and future technologies. Still, children are often not included in this discussion, while there is much to learn from current uses and children's understandings of AI and robotics. The study is based on a seven-month ethnographical work that details the implementation of a robot in two preschool groups of children aged 1–2 and 3–5 (n = 38). The study descriptively combines a framework for children's play analysis with explorative qualitative child interviews (n = 6) with the 3-5-year-olds to examine how children play with the robot and their thinking about a future with robots and AI. The results show how children's play with robots spans all of Hughes's (2011) sixteen play types and integrates robots into play in ways specific to child-robot interaction. The interviews indicate that children have well-formed knowledge about the current uses of robots and AI and elaborate imaginaries about a future with them, including critical boundaries toward robots and AI agents. The evidence shows emerging ways children relate to these. The potential of including children's actions and voices in the ongoing societal and educational debates on AI is discussed.}
}
@article{MAIRAL202262,
title = {What should the university of the future look like?},
journal = {On the Horizon},
volume = {31},
number = {1},
pages = {62-70},
year = {2022},
issn = {1074-8121},
doi = {https://doi.org/10.1108/OTH-08-2022-0050},
url = {https://www.sciencedirect.com/science/article/pii/S1074812122000239},
author = {Ricardo Mairal},
keywords = {Employment, Internationalization, Higher education, Quality, Artificial intelligence, Online and distance education},
abstract = {Purpose
In this paper, the author has tried to outline the main ideas in connection with what the author conceives to be the university of the future, a university that should not only educate people within the university system but also prepare them to fill specific job positions at both local and global levels, apart from necessarily providing them with the critical thinking and competences in autonomous learning that will make them flexible and capable of adapting to the job market and to a fast-changing world in general.
Design/methodology/approach
The author has revised some of the major issues that are going to determine the direction of the university of the future, i.e. the employment opportunities of tomorrow; the role of new technologies, especially the impact of artificial intelligence (AI); quality in higher education; and internationalization.
Findings
The author has also pointed out the importance of the technologies and the great role they indisputably play in present and future education at all levels, a fact that has been particularly and hugely enhanced and promoted by the COVID-19 pandemic situation, thereby facilitating and fostering distance learning. This is very much connected to the application of AI to higher education, another unavoidable issue of utmost importance for the university of the future. While these technological advances present a challenge to universities, which must determine which are necessary and desirable and how to implement them, it is, ultimately, our responsibility to use them, in an ethical way, to the benefit of our students. The university of the future also has to be of high quality, and this involves carrying out important and decisive action having to do with matters of inclusion, hiring policies and the expansion of international opportunities for all parties involved.
Originality/value
This paper outlines the main ideas in connection with what the author conceives to be the university of the future, a university that should not only educate people within the university system but also prepare them to fill specific job positions at both local and global levels, apart from necessarily providing them with the critical thinking and competences in autonomous learning that will make them flexible and capable of adapting to the job market and to a fast-changing world in general. Moreover, the role of new technologies (especially the impact of AI), quality and internationalization are also discussed as relevant factors in this view of the university of the future.}
}
@article{KONOPKA200391,
title = {Selected dreams and nightmares about computational biology},
journal = {Computational Biology and Chemistry},
volume = {27},
number = {2},
pages = {91-92},
year = {2003},
issn = {1476-9271},
doi = {https://doi.org/10.1016/S1476-9271(03)00024-0},
url = {https://www.sciencedirect.com/science/article/pii/S1476927103000240},
author = {Andrzej K Konopka}
}
@article{TOUSSAINT20102,
title = {Computational geometric aspects of rhythm, melody, and voice-leading},
journal = {Computational Geometry},
volume = {43},
number = {1},
pages = {2-22},
year = {2010},
note = {Special Issue on the 14th Annual Fall Workshop},
issn = {0925-7721},
doi = {https://doi.org/10.1016/j.comgeo.2007.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S092577210900042X},
author = {Godfried Toussaint},
keywords = {Musical rhythm, Melody, Voice-leading, Evenness measures, Rhythm similarity, Sequence comparison, Necklaces, Convolution, Computational geometry, Music information retrieval, Algorithms, Computational music theory},
abstract = {Many problems concerning the theory and technology of rhythm, melody, and voice-leading are fundamentally geometric in nature. It is therefore not surprising that the field of computational geometry can contribute greatly to these problems. The interaction between computational geometry and music yields new insights into the theories of rhythm, melody, and voice-leading, as well as new problems for research in several areas, ranging from mathematics and computer science to music theory, music perception, and musicology. Recent results on the geometric and computational aspects of rhythm, melody, and voice-leading are reviewed, connections to established areas of computer science, mathematics, statistics, computational biology, and crystallography are pointed out, and new open problems are proposed.}
}
@article{SOTO2022100963,
title = {Undergraduates’ exploration of contour integration: What is Accumulated?},
journal = {The Journal of Mathematical Behavior},
volume = {66},
pages = {100963},
year = {2022},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2022.100963},
url = {https://www.sciencedirect.com/science/article/pii/S0732312322000311},
author = {Hortensia Soto and Michael Oehrtman},
keywords = {Complex functions, Contour integration, Emerging models},
abstract = {In this work we explored undergraduate students’ geometric and visual interpretations of the inscription for contour integrals, ∫Cfzdz, without them having any prior knowledge of integration of complex-valued functions. Our research participants drew from various sources of geometric and visual interpretations to productively investigate the components of contour integrals, which they conveyed with diagrams and gesture. Although this enabled significant progress, they were overwhelmed coordinating the multiple quantitative relationships and reverted to simplified interpretations such as summing values of z,fz, or ∆z. In other words, they were unable to maintain focus on what was accumulated. Our participants also engaged in the thinking real, doing complex phenomenon which sometimes provided productive feedback to assess their interpretations. We offer potential reasons for students’ struggles including various interpretations for integration of real-valued integration and the layering of inscriptions. We also provide potential instructional strategies based on the participants’ interpretations.}
}
@incollection{LEBARON20061187,
title = {Chapter 24 Agent-based Computational Finance},
editor = {L. Tesfatsion and K.L. Judd},
series = {Handbook of Computational Economics},
publisher = {Elsevier},
volume = {2},
pages = {1187-1233},
year = {2006},
issn = {1574-0021},
doi = {https://doi.org/10.1016/S1574-0021(05)02024-1},
url = {https://www.sciencedirect.com/science/article/pii/S1574002105020241},
author = {Blake LeBaron},
keywords = {learning, evolutionary finance, financial time series, asset pricing, efficient markets, behavioral finance, market microstructure, genetic algorithms, neural networks, artificial financial markets, evolutionary computation},
abstract = {This chapter surveys research on agent-based models used in finance. It will concentrate on models where the use of computational tools is critical for the process of crafting models which give insights into the importance and dynamics of investor heterogeneity in many financial settings.}
}
@article{XUE2024100156,
title = {Conceptual frameworks for the integration of genetic and social epidemiology in complex diseases},
journal = {Global Epidemiology},
volume = {8},
pages = {100156},
year = {2024},
issn = {2590-1133},
doi = {https://doi.org/10.1016/j.gloepi.2024.100156},
url = {https://www.sciencedirect.com/science/article/pii/S2590113324000221},
author = {Diane Xue and Anjum Hajat and Alison E. Fohner},
abstract = {Uncovering the root causes of complex diseases requires complex approaches, yet many studies continue to isolate the effects of genetic and social determinants of disease. Epidemiologic efforts that under-utilize genetic epidemiology methods and findings may lead to incomplete understanding of disease. Meanwhile, genetic epidemiology studies are often conducted without consideration of social and environmental context, limiting the public health impact of genomic discoveries. This divide endures despite shared goals and increases in interdisciplinary data due to a lack of shared theoretical frameworks and differing language. Here, we demonstrate that bridging epidemiological divides does not require entirely new ways of thinking. Existing social epidemiology frameworks including Ecosocial theory and Fundamental Cause Theory, can both be extended to incorporate principles from genetic epidemiology. We show that genetic epidemiology can strengthen, rather than detract from, efforts to understand the impact of social determinants of health. In addition to presenting theoretical synergies, we offer practical examples of how genetics can improve the public health impact of epidemiology studies across the field. Ultimately, we aim to provide a guiding framework for trainees and established epidemiologists to think about diseases and complex systems and foster more fruitful collaboration between genetic and traditional epidemiological disciplines.}
}
@article{BERGSTRA200855,
title = {Parallel Processes with Implicit Computational Capital},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {209},
pages = {55-81},
year = {2008},
note = {Proceedings of the LIX Colloquium on Emerging Trends in Concurrency Theory (LIX 2006)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2008.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S1571066108002193},
author = {J.A. Bergstra and C.A. Middelburg},
keywords = {Process algebra, Implicit computational capital, Preservation of computational money},
abstract = {We propose a process algebra which is concerned with processes that have an implicit computational capital. This process algebra is intended to be helpful when designing computer-based systems of which the behaviour is related to money handling. It goes along with the development that the behaviour of computer-based systems, organizations and persons is increasingly more related to money handling.}
}
@article{EVERS2025180,
title = {Preliminaries to artificial consciousness: A multidimensional heuristic approach},
journal = {Physics of Life Reviews},
volume = {52},
pages = {180-193},
year = {2025},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2025.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S1571064525000028},
author = {K. Evers and M. Farisco and R. Chatila and B.D. Earp and I.T. Freire and F. Hamker and E. Nemeth and P.F.M.J. Verschure and M. Khamassi},
abstract = {The pursuit of artificial consciousness requires conceptual clarity to navigate its theoretical and empirical challenges. This paper introduces a composite, multilevel, and multidimensional model of consciousness as a heuristic framework to guide research in this field. Consciousness is treated as a complex phenomenon, with distinct constituents and dimensions that can be operationalized for study and for evaluating their replication. We argue that this model provides a balanced approach to artificial consciousness research by avoiding binary thinking (e.g., conscious vs. non-conscious) and offering a structured basis for testable hypotheses. To illustrate its utility, we focus on "awareness" as a case study, demonstrating how specific dimensions of consciousness can be pragmatically analyzed and targeted for potential artificial instantiation. By breaking down the conceptual intricacies of consciousness and aligning them with practical research goals, this paper lays the groundwork for a robust strategy to advance the scientific and technical understanding of artificial consciousness.}
}
@article{VAMVOUDAKIS20226,
title = {Nonequilibrium dynamical games: A control systems perspective},
journal = {Annual Reviews in Control},
volume = {53},
pages = {6-18},
year = {2022},
issn = {1367-5788},
doi = {https://doi.org/10.1016/j.arcontrol.2022.03.006},
url = {https://www.sciencedirect.com/science/article/pii/S1367578822000128},
author = {Kyriakos G. Vamvoudakis and Filippos Fotiadis and Aris Kanellopoulos and Nick-Marios T. Kokolakis},
abstract = {Dynamical games model interactions between agents that take place in ever-shifting environments. Due to the increasing penetration of autonomous systems to society, understanding and predicting the outcomes of these games has become crucial. In this work, we highlight the importance of nonequilibrium solutions to dynamical games through the lens of bounded rationality. We describe the principles of level-k thinking and cognitive hierarchy – concepts developed in the field of economics – via mathematical tools and formulation of control theory. We describe the main principles of bounded rationality for nonequilibrium differential games in both nonlinear non-zero-sum and linear zero-sum settings. The importance of those approaches is highlighted in problems of pursuit evasion between Unmanned Aerial Vehicles, while the core of the bounded rationality principles that we employ are extended to discrete stochastic dynamical games. The versatility of the proposed approach is complemented by rigorous mathematical guarantees that enable predictability of the games’ outcomes.}
}
@article{GARFIELD198447,
title = {Artificial intelligence: Using computers to think about thinking, Part 2: Some practical applications of Al},
journal = {Computer Compacts},
volume = {2},
number = {2},
pages = {47-53},
year = {1984},
issn = {0167-7136},
doi = {https://doi.org/10.1016/0167-7136(84)90041-6},
url = {https://www.sciencedirect.com/science/article/pii/0167713684900416},
author = {Eugene Garfield}
}
@article{COLLINS2023101585,
title = {Generative linguistics: ‘Galilean style’},
journal = {Language Sciences},
volume = {100},
pages = {101585},
year = {2023},
issn = {0388-0001},
doi = {https://doi.org/10.1016/j.langsci.2023.101585},
url = {https://www.sciencedirect.com/science/article/pii/S0388000123000505},
author = {John Collins},
keywords = {Chomsky, Centre-embedding, Competence/performance, Computation, Galilean style, Galileo},
abstract = {Generative linguistics is often claimed by Chomsky to have a 'Galilean style', which is intended to position linguistics as a science continuous with standard practise in the natural sciences. These claims, however, are more suggestive than explanatory. The paper will, first, explain just what a Galilean style is. It will then be argued that its application to two key notions in generative linguistics - the competence/performance distinction (with reference to centre-embedding) and the notion of computation - demands a departure from what we might expect of a Galilean style. In this sense, the epithet is misleading. It will also be shown, however, that the 'Galilean' label is appropriate once we factor in the difference between a science concerned with kinematics (the relations between objects in space and time) and one concerned with language.}
}
@article{ZENG2024123400,
title = {Research on the application of knowledge mapping and knowledge structure construction based on adaptive learning model},
journal = {Expert Systems with Applications},
volume = {249},
pages = {123400},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.123400},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424002653},
author = {Xiyin Zeng and Shouqiang Liu},
keywords = {Personalized learing, Pedagogy, Interactive learning environments, Applications},
abstract = {This project has developed a geometry learning software that integrates multiple computer technologies to address the challenges of deep analysis of knowledge points and establishing connections in learning software. The software combines Long Short-Term Memory (LSTM) and Residual Neural Network (ResNet101) to encode text and image features. A self-attention mechanism is used to fuse information from both modalities, enabling decoding of geometric models and classification of corresponding knowledge points.This project uses LSTM and ResNet101 models to extract text and visual features for problem-solving using the Multi Mode Thinking Chain (CoT) method. Classification labels are utilized to generate text responses for problem-solving ideas. Furthermore, a recommendation module is proposed, which combines knowledge tracking and neural collaborative filtering algorithms to capture student behavior and knowledge point vectors. Implicit factors representing students' mastery of different knowledge points are used as inputs in neural collaborative filtering for personalized recommendations. The results demonstrate improvements in accuracy using the ResNet + LSTM multimodal algorithm, achieving a 13 % increase compared to single-modal classification. The multimodal CoT approach also outperforms language models like GPT3.5 and VisualBert by 10 %. Additionally, the combined algorithm of knowledge tracking and neural collaborative filtering shows a 13.3 % higher F1 value compared to ordinary algorithms, confirming the superiority of the adopted method in this project.}
}
@article{GUARINO2022559,
title = {Optimism and pessimism in strategic interactions under ignorance},
journal = {Games and Economic Behavior},
volume = {136},
pages = {559-585},
year = {2022},
issn = {0899-8256},
doi = {https://doi.org/10.1016/j.geb.2022.10.012},
url = {https://www.sciencedirect.com/science/article/pii/S0899825622001506},
author = {Pierfrancesco Guarino and Gabriel Ziegler},
keywords = {Ignorance, Optimism/pessimism, Point/Wald Rationalizability, Interactive epistemology, Wishful thinking, Börgers dominance},
abstract = {We study players interacting under the veil of ignorance, who have—coarse—beliefs represented as subsets of opponents' actions. We analyze when these players follow max⁡min or max⁡max decision criteria, which we identify with pessimistic or optimistic attitudes, respectively. Explicitly formalizing these attitudes and how players reason interactively under ignorance, we characterize the behavioral implications related to common belief in these events: while optimism is related to Point Rationalizability, a new algorithm—Wald Rationalizability—captures pessimism. Our characterizations allow us to uncover novel results: (i) regarding optimism, we relate it to wishful thinking á la Yildiz (2007) and we prove that dropping the (implicit) “belief-implies-truth” assumption reverses an existence failure described therein; (ii) we shed light on the notion of rationality in ordinal games; (iii) we clarify the conceptual underpinnings behind a discontinuity in Rationalizability hinted in the analysis of Weinstein (2016).}
}
@article{DIAS2007382,
title = {Philosophical grounding and computational formalization for practice based engineering knowledge},
journal = {Knowledge-Based Systems},
volume = {20},
number = {4},
pages = {382-387},
year = {2007},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2006.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0950705106001675},
author = {W.P.S. Dias},
keywords = {Practice based knowledge, Connectionist AI techniques, Tacit knowing, Shared practice},
abstract = {Michael Polanyi’s idea of tacit knowing and Martin Heidegger’s concept of pre-theoretical shared practice are presented as providing a strong rationale for the notion of practice based knowledge. Artificial Intelligence (AI) approaches such as Artificial Neural Networks (ANN), Case Based Reasoning (CBR) and Grounded Theory (with Interval Probability Theory) are able to model these philosophical concepts related to practice based knowledge. The AI techniques appropriate for modeling Polanyi’s and Heidegger’s ideas should be founded more on a connectionist rather than a cognitivist paradigm. Examples from engineering practice are used to demonstrate how the above techniques can capture, structure and make available such knowledge to practitioners.}
}
@incollection{SIEGLER20051,
title = {A computational model of conscious and unconscious strategy discovery},
editor = {Robert V. Kail},
series = {Advances in Child Development and Behavior},
publisher = {JAI},
volume = {33},
pages = {1-42},
year = {2005},
issn = {0065-2407},
doi = {https://doi.org/10.1016/S0065-2407(05)80003-5},
url = {https://www.sciencedirect.com/science/article/pii/S0065240705800035},
author = {Robert Siegler and Roberto Araya},
abstract = {Publisher Summary
This chapter deals with a computational model of conscious and conscious strategy discovery and advocates a triangulation strategy for attaining a better understanding of change mechanisms. This triangulation strategy involves going back and forth among traditional studies of age-related change, microgenetic studies of children's gleaming, and computer simulations that generate the changes documented in the other two approaches. The chapter describes a new computational model of conscious and unconscious strategy discovery. Apart from being a crucial component of one of the examples of the triangulation strategy, this simulation significantly extends previous models of strategy choice and discovery. A large majority of studies of cognitive development have been devoted to describe age-related changes. The studies of age-related change have succeeded in providing excellent descriptions of many aspects of cognitive growth. Each of these three approaches—descriptions of age-related change, descriptions of learning, and formal modeling—provides unique information critical to a well-grounded account of developmental change.}
}
@article{TAILLANDIER2025105121,
title = {The dynamic sketch map to support reflection on urban flooding},
journal = {International Journal of Disaster Risk Reduction},
volume = {116},
pages = {105121},
year = {2025},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2024.105121},
url = {https://www.sciencedirect.com/science/article/pii/S2212420924008835},
author = {Franck Taillandier and Patrick Taillandier and Pénélope Brueder and Noé Brosse},
keywords = {Urban flood, Game, Sketch map, Agent-based simulation},
abstract = {Flood risk management is a significant concern for many regions. To reduce the flood impact, it is essential to increase residents' knowledge about this risk and in its management. Despite the many tools and methods available to raise awareness of flood risk, none of them fully meet the challenges of effective communication on flood and flood management by: integrating the perspective of local people, by providing information that is clear and easy to understand, by encouraging debate, discussion and reflection and by positioning flood mitigation measure at the center (positive vision on the risk). To answer this need, this article proposes an innovative approach that combines several methods, including sketch maps, agent-based simulation, and serious games. This combination enables to benefit from these three approaches: the expressiveness of sketch maps and the ability to analyze participants' spatial representations, the capacity of agent-based simulations to aid users in comprehending complex phenomena and dynamics, and the experimental and motivational environment provided by games. To implement this approach, we developed the DYSMA model, which bridges the gap between sketch maps and agent-based simulations by integrating drawn elements as agents, providing a dynamic sketch map. Additionally, we developed the Draw and Flood game, designed to engage the general public in thinking about flood management through the use of dynamic sketch maps. This approach is applied to an illustrative application dedicated to flooding in a small French city.}
}
@article{HODGENS2021102149,
title = {Solving the puzzle of Fe homeostasis by integrating molecular, mathematical, and societal models},
journal = {Current Opinion in Plant Biology},
volume = {64},
pages = {102149},
year = {2021},
note = {Cell biology},
issn = {1369-5266},
doi = {https://doi.org/10.1016/j.pbi.2021.102149},
url = {https://www.sciencedirect.com/science/article/pii/S1369526621001503},
author = {Charles Hodgens and Belinda S. Akpa and Terri A. Long},
keywords = {Iron homeostasis, Simulation-based inference (SBI), Inclusivity},
abstract = {To ensure optimal utilization and bioavailability, iron uptake, transport, subcellular localization, and assimilation are tightly regulated in plants. Herein, we examine recent advances in our understanding of cellular responses to Fe deficiency. We then use intracellular mechanisms of Fe homeostasis to discuss how formalizing cell biology knowledge via a mathematical model can advance discovery even when quantitative data is limited. Using simulation-based inference to identify plausible systems mechanisms that conform to known emergent phenotypes can yield novel, testable hypotheses to guide targeted experiments. However, this approach relies on the accurate encoding of domain-expert knowledge in exploratory mathematical models. We argue that this would be facilitated by fostering more “systems thinking” life scientists and that diversifying your research team may be a practical path to achieve that goal.}
}
@article{LEOPOLD2024102913,
title = {The big mixup: Neural representation during natural modes of primate visual behavior},
journal = {Current Opinion in Neurobiology},
volume = {88},
pages = {102913},
year = {2024},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2024.102913},
url = {https://www.sciencedirect.com/science/article/pii/S0959438824000758},
author = {David A. Leopold},
abstract = {The primate brain has evolved specialized visual capacities to navigate complex physical and social environments. Researchers studying cortical circuits underlying these capacities have traditionally favored the use of simplified tasks and brief stimulus presentations in order to isolate cognitive variables with tight experimental control. As a result, operational theories about visual brain function have come to emphasize feature detection, hierarchical stimulus encoding, top-down task modulation, and functional segregation in distinct cortical areas. Recently, however, experimental paradigms combining natural behavior with electrophysiological recordings have begun to offer a distinctly different portrait of how the brain takes in and analyzes its visual surroundings. The present article reviews recent work in this area, highlighting some of the more surprising findings in domains of social vision and spatial navigation along with shifts in thinking that have begun to emanate from this approach.}
}
@article{DECARVALHO2021107887,
title = {A process for designing innovative mechatronic products},
journal = {International Journal of Production Economics},
volume = {231},
pages = {107887},
year = {2021},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2020.107887},
url = {https://www.sciencedirect.com/science/article/pii/S0925527320302504},
author = {Rogerio Atem {de Carvalho} and Henrique {da Hora} and Rodrigo Fernandes},
keywords = {Mechatronics, Product design, Design thinking, Concurrent engineering, Agilism, Product life cycle, Intellectual property, Innovation management},
abstract = {This article presents a process for the design of innovative mechatronic products that integrates techniques of Design Thinking, Concurrent Engineering and Agilism to Intellectual Property Management activities. Design Thinking is employed in the early stages in order to better explore creativity, whereas Concurrent Engineering and Agilism are applied during the development of the product, in order to deal with emerging requirements and shrinking development times. The product development process is accompanied by Intellectual Property Management activities that address the protection of the project's intellectual assets. In this way, the proposed process represents an addition to theory and practice by smoothly integrating the three most influential product design philosophies of today, while, at the same time, introduces a direction for managing intellectual assets throughout the product lifecycle.}
}
@article{PATAHUDDIN2022100988,
title = {Subtleties in spatial visualization maneuvers: Insights from numerical solutions},
journal = {The Journal of Mathematical Behavior},
volume = {67},
pages = {100988},
year = {2022},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2022.100988},
url = {https://www.sciencedirect.com/science/article/pii/S0732312322000566},
author = {Sitti Maesuri Patahuddin and Ajay Ramful and Tom Lowrie and Ajeevsing Bholoa},
keywords = {Spatial visualization, Spatial reasoning, Mathematics, Geometry, Measurement, Pre-service teacher},
abstract = {This study aimed to identify the role and nature of spatial visualization in the problem solutions of pre-service teachers solving school-mathematics tasks requiring measurement reasoning. The nuances in the pre-service teachers’ strategies were examined for the role of spatial visualization in the solution process. The findings suggest that inadequacies in visualizing the spatial configurations of the tasks led to incorrect numerical solutions despite the presence of conceptual knowledge. Furthermore, the tendency to rely on formula-based approaches appeared to have suppressed the preliminary spatial processing of the configurations. Theoretically, the paper offers insights into the mechanism that may be involved in the solution of spatially-related mathematical tasks. The findings imply that pre-service teachers need to be sufficiently engaged in spatial reasoning activities.}
}
@article{CAI2023101087,
title = {Impact of prompts on students’ mathematical problem posing},
journal = {The Journal of Mathematical Behavior},
volume = {72},
pages = {101087},
year = {2023},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2023.101087},
url = {https://www.sciencedirect.com/science/article/pii/S0732312323000573},
author = {Jinfa Cai and Hua Ran and Stephen Hwang and Yue Ma and Jaepil Han and Faith Muirhead},
keywords = {Problem posing, Problem-posing prompt, Problem-posing processes, Task variables, Task characteristics, Teaching mathematics through problem posing, P-PBL},
abstract = {This study used three pairs of problem-posing tasks to examine the impact of different prompts on students’ problem posing. Two kinds of prompts were involved. The first asked students to pose 2–3 different mathematical problems without specifying other requirements for the problems, whereas the second kind of prompt did specify additional requirements. A total of 2124 students’ responses were analyzed to examine the impact of the prompts along multiple dimensions. In response to problem-posing prompts with more specific requirements, students tended to engage in more in-depth mathematical thinking and posed much more linguistically and semantically complex problems with more relationships or steps required to solve them. The findings from this study not only contribute to our understanding of problem-posing processes but also have direct implications for teaching mathematics through problem posing.}
}
@article{YILMAZ2023100005,
title = {Augmented intelligence in programming learning: Examining student views on the use of ChatGPT for programming learning},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {1},
number = {2},
pages = {100005},
year = {2023},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2023.100005},
url = {https://www.sciencedirect.com/science/article/pii/S2949882123000051},
author = {Ramazan Yilmaz and Fatma Gizem {Karaoglan Yilmaz}},
keywords = {Generative artificial intelligence, ChatGPT, Programming, Programming learning, Student opinions},
abstract = {With the diversification of generative artificial intelligence (AI) applications, the interest in their use in every segment and field of society in recent years has been increasing rapidly. One of these areas is programming learning and program writing processes. One of the generative AI tools used for this purpose is ChatGPT. The use of ChatGPT in program writing processes has become widespread, and this tool has a certain potential in the programming process. However, when the literature is examined, research results related to using ChatGPT for this purpose have yet to be found. The existing literature has a gap that requires exploration. This study aims to analyze the students' perspectives on using ChatGPT in the field of programming and programming learning. The study encompassed a cohort of 41 undergraduate students enrolled in a public university's Computer Technology and Information Systems department. The research was carried out within the scope of the Object-Oriented Programming II course for eight weeks. Throughout the research process, students were given project assignments related to the course every week, and they were asked to use ChatGPT while solving them. The research data was collected using a form consisting of open-ended questions and analyzed through content analysis. The research findings revealed both the advantages and disadvantages of ChatGPT usage, as perceived by the students. The students stated that the main benefits of using ChatGPT in programming learning are providing fast and mostly correct answers to questions, improving thinking skills, facilitating debugging, and increasing self-confidence. On the other hand, the main limitations of using ChatGPT in programming education were getting students used to laziness, being unable to answer some questions, or giving incomplete/incorrect answers, causing professional anxiety in students. Based on the results of the research, it can be said that it would be useful to integrate generative AI tools into programming courses considering the advantages they provide in programming teaching. However, appropriate measures should be taken regarding the limitations it brings. Based on the research findings, several recommendations were proposed regarding the integration of ChatGPT into lessons.}
}
@article{YANG2000103,
title = {Computational verb systems: a new paradigm for artificial intelligence},
journal = {Information Sciences},
volume = {124},
number = {1},
pages = {103-123},
year = {2000},
issn = {0020-0255},
doi = {https://doi.org/10.1016/S0020-0255(99)00135-8},
url = {https://www.sciencedirect.com/science/article/pii/S0020025599001358},
author = {Tao Yang},
keywords = {Verbs, Computational verbs, Computational verb systems, Chaos, Artificial intelligence, Reasoning, Knowledge representation},
abstract = {Computational verb systems can help machines to implement, understand and use verbs as human perception of dynamics. By using computational verbs we can embed dynamical experiences of human experts into artificial intelligence. Computational verbs, which are models of verbs in nature languages, are basic building blocks of computational verb systems. In this paper, computational verbs are used to represent dynamical knowledge embedded by verbs as a new framework of knowledge representation. BE-transformations are used to transform statements containing dynamical verbs into statements only containing static verb BE; namely, BE-propositions. Based on BE-transformations, the computational verb logic can be built. Furthermore, reasoning with computational verbs can be built based on BE-transformations and basic verb logic operations.}
}
@article{MURRAY202483,
title = {Brain mechanisms of rumination and negative self-referential processing in adolescent depression},
journal = {Journal of Affective Disorders},
volume = {366},
pages = {83-90},
year = {2024},
issn = {0165-0327},
doi = {https://doi.org/10.1016/j.jad.2024.08.114},
url = {https://www.sciencedirect.com/science/article/pii/S0165032724013466},
author = {Laura Murray and Nigel M. Jaffe and Anna O. Tierney and Kristina Pidvirny and Emma G. Balkind and Batool S. Abbasi and Miranda Brown and Christian A. Webb},
keywords = {Depression, Adolescence, Ecological momentary assessment, fMRI, Rumination, Self-referent encoding task},
abstract = {Background
Depression is linked to cognitive biases towards more negative and less positive self-relevant information. Rumination, perseverative negative thinking about the past and the self, may contribute to these biases.
Methods
159 adolescents (12–18 years), with a range of depression symptoms, completed the SRET during fMRI. Multiple regressions tested associations between conventional self-report and ecological momentary assessment (EMA) measured rumination, and neural and behavioral responses during a self-referent encoding task (SRET).
Results
Higher rumination (conventional self-report and EMA) was associated with more negative and fewer positive words endorsed and recalled. Higher self-reported (but not EMA) rumination was associated with higher accuracy in recognizing negative words and greater insula and dorsal anterior cingulate activity to negative versus positive words.
Limitations
The sample included mostly non-Hispanic White participants with household incomes above the national average, highlighting the need for replication in more diverse samples. Word endorsement discrepancies required fMRI analyses to model neural response to viewing negative versus positive words.
Conclusions
Adolescents with higher rumination endorsed and recalled more negative and fewer positive words and recognized more negative words during the SRET. Higher insula reactivity, a key region for modulating externally-oriented attention and internally-oriented self-referential processes, may contribute to links between rumination and negative memory biases. These findings provide insight into neurocognitive mechanisms underlying depression.}
}
@article{GILROY201643,
title = {Inherently irrational? A computational model of escalation of commitment as Bayesian Updating},
journal = {Behavioural Processes},
volume = {127},
pages = {43-51},
year = {2016},
note = {SQAB 2015: Choice and Consequences},
issn = {0376-6357},
doi = {https://doi.org/10.1016/j.beproc.2016.02.017},
url = {https://www.sciencedirect.com/science/article/pii/S0376635716300389},
author = {Shawn P. Gilroy and Donald A. Hantula},
keywords = {Escalation, Computer simulation, Decision-making, Bayes theorem},
abstract = {Monte Carlo simulations were performed to analyze the degree to which two-, three- and four-step learning histories of losses and gains correlated with escalation and persistence in extended extinction (continuous loss) conditions. Simulated learning histories were randomly generated at varying lengths and compositions and warranted probabilities were determined using Bayesian Updating methods. Bayesian Updating predicted instances where particular learning sequences were more likely to engender escalation and persistence under extinction conditions. All simulations revealed greater rates of escalation and persistence in the presence of heterogeneous (e.g., both Wins and Losses) lag sequences, with substantially increased rates of escalation when lags comprised predominantly of losses were followed by wins. These methods were then applied to human investment choices in earlier experiments. The Bayesian Updating models corresponded with data obtained from these experiments. These findings suggest that Bayesian Updating can be utilized as a model for understanding how and when individual commitment may escalate and persist despite continued failures.}
}
@article{YAN20158006,
title = {Trustworthiness evaluation and retrieval-based revision method for case-based reasoning classifiers},
journal = {Expert Systems with Applications},
volume = {42},
number = {21},
pages = {8006-8013},
year = {2015},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2015.06.027},
url = {https://www.sciencedirect.com/science/article/pii/S0957417415004297},
author = {Aijun Yan and Dianhui Wang},
keywords = {Case-based reasoning classifiers, Classification accuracy, Case evaluation, Case revision},
abstract = {To achieve better classification performance using case-based reasoning classifiers, we propose a retrieval-based revision method with trustworthiness evaluation for problem solving. An improved case evaluation method is employed to evaluate the trustworthiness of the suggested solution after the reuse step, which will divide the target cases and its suggested solutions into a trustworthy set and an untrustworthy set in accordance with a threshold value of trustworthiness. The attribute weights are adjusted by running a genetic algorithm and are used in the second round of retrieval of the untrustworthy set to obtain the classification results. Experimental results demonstrate that our proposed method performs favorably compared with other methods. Also, the proposed method has less computation complexity for the trustworthiness evaluation, and enhances understanding on thinking and inference for case-based reasoning classifiers.}
}
@article{LITTRELL2020109678,
title = {Not so fast: Individual differences in impulsiveness are only a modest predictor of cognitive reflection},
journal = {Personality and Individual Differences},
volume = {154},
pages = {109678},
year = {2020},
issn = {0191-8869},
doi = {https://doi.org/10.1016/j.paid.2019.109678},
url = {https://www.sciencedirect.com/science/article/pii/S0191886919306105},
author = {Shane Littrell and Jonathan Fugelsang and Evan F. Risko},
keywords = {Cognitive reflection, Impulsiveness, Intuitive thinking, Delay discounting dual process},
abstract = {The extent to which a person engages in reflective thinking while problem-solving is often measured using the Cognitive Reflection Test (CRT; Frederick, 2005). Some past research has attributed poorer performance on the CRT to impulsiveness, which is consistent with the close conceptual relation between Type I processing and dispositional impulsiveness (and the putative relation between a tendency to engage in Type I processing and poor performance on the CRT). However, existing research has been mixed on whether such a relation exists. To address this ambiguity, we report two large sample size studies examining the relation between impulsiveness and CRT performance. Unlike previous studies, we use a number of different measures of impulsiveness, as well as measures of cognitive ability and analytic thinking style. Overall, impulsiveness is clearly related to CRT performance at the bivariate level. However, once cognitive ability and analytic thinking style are controlled, these relations become small and, in some cases, non-significant. Thus, dispositional impulsiveness, in and of itself, is not a strong predictor of CRT performance.}
}
@article{DVIR20061233,
title = {Virtual Leashing: Creating a computational foundation for software protection},
journal = {Journal of Parallel and Distributed Computing},
volume = {66},
number = {9},
pages = {1233-1240},
year = {2006},
note = {Special Issue: Security in grid and distributed systems},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2006.04.013},
url = {https://www.sciencedirect.com/science/article/pii/S074373150600092X},
author = {Ori Dvir and Maurice Herlihy and Nir N. Shavit},
keywords = {Digital rights management, Virtual leashing},
abstract = {We introduce Virtual Leashing,11The techniques described in this paper are protected by U.S. patents, both granted and pending. a new technique for software protection and control. The leashing process removes small fragments of code, pervasive throughout the application, and places them on a secure server. The secure server provides the missing functionality, but never the missing code. Reverse engineering the missing code, even with full tracing of the program's execution and its communication with the server, is computationally hard. Moreover, the server provides the missing functionality asynchronously: the application's performance is independent (within reason) of the secure server's speed. For example, the server might reside on a slow inexpensive chip or a remote Internet server. Leashing makes only modest demands on communication bandwidth, space, and computation.}
}
@article{MANSILHA2019190,
title = {Environmental externalities in broiler production: An analysis based on system dynamics},
journal = {Journal of Cleaner Production},
volume = {209},
pages = {190-199},
year = {2019},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2018.10.179},
url = {https://www.sciencedirect.com/science/article/pii/S0959652618331950},
author = {Ricardo Brandão Mansilha and Dalila Cisco Collatto and Daniel Pacheco Lacerda and Maria Isabel {Wolf Motta Morandi} and Fabio Sartori Piran},
keywords = {Broiler, Environmental externalities, Energy sources, Systems thinking, System dynamics},
abstract = {Broiler represents approximately 1.5% of the Brazilian Gross Domestic Product (GDP). Brazil is one of the world's largest producers and exporters of chicken. Aiming to improve and sustain a competitive advantage, producers have invested in improvements in production systems in general, in particular aviary heating systems. However, producers need to choose the best among several alternatives of energy sources for heating. This decision impacts the environment to a greater or a lesser extent depending on the energy source chosen. The aim of this study is to develop a computational model to understand systemically and dynamically the environmental externalities based on the choice of energy source for aviary heating. The identification of criteria that influence the choice for heating systems was possible through a multiple case-study in the southern region of Brazil. By designing a computational model of system dynamics, it was possible to visualize scenarios using different energy sources and their respective negative environmental externalities. From the analysis of four scenarios, we sought to identify the one with the best relation to environmental and economic performance. It was evidenced that the scenario with the best relation was that using pellets as an energy source for aviary heating. The developed model may be applied to solve similar decision-making problems.}
}
@incollection{CLEMENTI200589,
title = {Chapter 6 - Computational chemistry: Attempting to simulate large molecular systems},
editor = {Clifford E. Dykstra and Gernot Frenking and Kwang S. Kim and Gustavo E. Scuseria},
booktitle = {Theory and Applications of Computational Chemistry},
publisher = {Elsevier},
address = {Amsterdam},
pages = {89-114},
year = {2005},
isbn = {978-0-444-51719-7},
doi = {https://doi.org/10.1016/B978-044451719-7/50049-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780444517197500494},
author = {Enrico Clementi},
abstract = {Publisher Summary
Computational chemistry is a very vast field dealing with atomic and molecular systems, considered at different complexity levels either as discretized quantum mechanical systems, or as statistical ensembles, amenable to Monte Carlo and Molecular Dynamic treatments, or as continuous matter fluid-dynamical distributions, modeled with Navier– Stokes equations. The mainstream computational chemistry was bent to fully solve the correlation problem with a single “technology.” Computational chemistry became a must for more and more chemists, even if the computer users had less and less awareness of the computational details of computer programs, and hardly understood that the computed answer could be incorrect, because of limitations of the selected method. In this computer generation and even more in the following years, internet, communications, commercial computer programs, computer servers, personal computers, desktop, graphics, Window, and Linux were common words, memory and disk space seemed unlimited, price/performance improved yearly, but faith in the computer replaced knowledge of the instrument and its software. Computational chemistry was becoming a part of the global economy.}
}
@article{TRUBA2024101496,
title = {Psycholinguistic underpinnings of image formation: Suggestion and manipulation in the educational network discourse},
journal = {Thinking Skills and Creativity},
volume = {52},
pages = {101496},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101496},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124000348},
author = {Hanna Truba and Sergii Khrapatyi and Kyrylo Harashchuk and Dmytro Shvets and Alina Proskurnia},
keywords = {Psycholinguistics, Image, Suggestion, Manipulation, Attraction, Fascination},
abstract = {This study delves into the intricate psycholinguistic mechanisms that underpin image formation within the educational network discourse, with a specific focus on the dynamics of suggestion and manipulation. In an era where digital communication reigns supreme, understanding how language shapes perceptions and influences behavior is paramount. This research seeks to unravel the complex interplay between suggestion, manipulation, and the formation of images within educational networks. Drawing from insights across disciplines such as psychology, linguistics, and communication studies, this study examines how linguistic cues and contextual factors interact to shape individuals' perceptions and responses within educational settings. Acknowledging the transformative power of language in shaping attitudes, beliefs, and actions, this study aims to shed light on the subtle yet profound ways in which educators employ linguistic strategies to influence discourse within educational networks. By employing a multifaceted approach that integrates theoretical frameworks with empirical analysis, this research endeavors to uncover the underlying mechanisms driving suggestion and manipulation within educational discourse. Through a meticulous examination of textual elements, discourse patterns, and communicative strategies employed by educators in digital environments, this study seeks to elucidate the intricate processes involved in image formation. By exploring the role of suggestion and manipulation in shaping perceptions, attitudes, and behaviors, this research contributes to a deeper understanding of the psycholinguistic underpinnings of educational network discourse. Furthermore, this study not only offers theoretical insights but also practical implications for educators, policymakers, and practitioners involved in educational communication. By highlighting the ethical considerations and implications of linguistic manipulation within educational networks, this research aims to empower stakeholders to navigate digital discourse with greater awareness and discernment. In conclusion, this study represents a significant contribution to the field of thinking skills and creativity by offering new insights into the psycholinguistic dynamics of image formation within educational networks. By unraveling the complexities of suggestion and manipulation, this research opens avenues for further inquiry and underscores the importance of critical thinking and creativity in navigating contemporary digital landscapes.}
}
@incollection{MOL2015158,
title = {Chapter 5 - Computational Design of Biological Systems: From Systems to Synthetic Biology},
editor = {Zaheer Ul-Haq and Jeffry D. Madura},
booktitle = {Frontiers in Computational Chemistry},
publisher = {Bentham Science Publishers},
pages = {158-196},
year = {2015},
isbn = {978-1-60805-865-5},
doi = {https://doi.org/10.1016/B978-1-60805-865-5.50005-8},
url = {https://www.sciencedirect.com/science/article/pii/B9781608058655500058},
author = {Milsee Mol and Shailza Singh},
keywords = {Abstraction, bioengineering, bioinspired, biological parts, computational modelling, computational tools, constructs, dynamic, infectious disease, interdisciplinary, linearization, mathematical framework, nextgen therapeutics, omics, ordinary differential equations, parameters, physical systems, reactions, regulatory circuits, simulation},
abstract = {Abstract:
Today biology is overwhelmed with ‘big data’, amassed from genomic projects carried out in various laboratories around the world using efficient high throughput technologies. Biologists are co-opting mathematical and computational techniques developed to address these data and derive meaningful interpretations. These developments have led to new disciplines: systems and synthetic biology. To explore these two evolving branches of biology one needs to be familiar with technologies such as genomics, bioinformatics and proteomics, mathematical and computational modeling techniques that help predict the dynamic behavior of the biological system, ruling out the trial-and-error methods of traditional genetic engineering. Systems and synthetic biology have developed hand-in-hand towards building artificial biological devices using engineered biological units as basic building blocks. Systems biology is an integrated approach for studying the dynamic and complex behaviors of biological components, which may be difficult to interpret and predict from properties of individual constituents making up the biological systems. While, synthetic biology aims to engineer biologically inspired devices, such as cellular regulatory circuits that do not exist in nature but are designed using well characterized genes, proteins and other biological components in appropriate combinations to perform a desired function. This is analogous to an electronic circuit board design that is fabricated using well characterized electrical components such as resistors, capacitors and so on. The in silico abstractions and predictions should be tightly linked to experimentation to be proved in vitro and in vivo systems for their successful applications in biotechnology. This chapter focuses on mathematical approaches and computational tools available to engineer biological regulatory circuits and how they can be implemented as next generation therapeutics in infectious disease.}
}
@article{ZHU2020102369,
title = {Sentiment and guest satisfaction with peer-to-peer accommodation: When are online ratings more trustworthy?},
journal = {International Journal of Hospitality Management},
volume = {86},
pages = {102369},
year = {2020},
issn = {0278-4319},
doi = {https://doi.org/10.1016/j.ijhm.2019.102369},
url = {https://www.sciencedirect.com/science/article/pii/S0278431918307333},
author = {Liang Zhu and Yan Lin and Mingming Cheng},
keywords = {Peer-to-peer accommodation, Guest satisfaction, Online ratings, Sentiment analysis, Analytical thinking, Authenticity},
abstract = {This study aims to decode guest satisfaction with peer-to-peer accommodations by analyzing the relationship between guests’ sentiment and online ratings and examining how analytical thinking and authenticity influence this relationship. Based on reviews of 4602 Airbnb listings in San Francisco, we empirically find that positive (negative) sentiment is linked to a high (low) rating. We further show that this link is stronger when guests manifest a higher extent of analytical thinking and authenticity. Both Tobit and ordered logit models yield consistent estimation results, showing the robustness of our findings. Our study contributes to the tourism and hospitality literature by theoretically explaining the association between sentiment and ratings. In addition, this paper enriches our knowledge regarding the trustworthiness of Airbnb ratings.}
}
@article{MATTHEWS2021100278,
title = {Reconceptualising feedback: Designing educational tangible technologies to be a creative material},
journal = {International Journal of Child-Computer Interaction},
volume = {29},
pages = {100278},
year = {2021},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2021.100278},
url = {https://www.sciencedirect.com/science/article/pii/S2212868921000210},
author = {Sarah Matthews and Ben Matthews},
keywords = {Tangible technologies, Feedback, Educational technologies, Creative material, Interaction design, Empirical studies},
abstract = {This paper investigates how children who are engaged in a creative project with tangible technology kits make sense of the system feedback the technology provides. A micro-analytic video study was conducted of primary school children designing their own technologies using existing educational microcontrollers. Our investigation reveals that the roles feedback plays in children’s interactions cannot easily be assimilated within the existing approaches to understand feedback that have been articulated in HCI literature. Our qualitative analysis shows how children do not make sense of feedback as semantic communication from the system, but make sense of it with respect to its embeddedness in a sequence of activities they are performing with the system and each other. The principal contribution to emerge from our study is a conception of feedback as a process, rather than as a semantic communicative event, nor a direct coupling of action and system response. Our discussion identifies how feedback participates in the institutional agendas of classrooms (e.g. discovery, computational thinking), and draws out initial implications for the design of feedback in educational tangible technologies, identifying possibilities for how feedback might be redesigned to better promote children’s diagnostic practices with open-ended technology kits.}
}
@incollection{ISMAIL2018165,
title = {Chapter 6 - High-Throughput Screening of Phytochemicals: Application of Computational Methods},
editor = {Satyajit D. Sarker and Lutfun Nahar},
booktitle = {Computational Phytochemistry},
publisher = {Elsevier},
pages = {165-192},
year = {2018},
isbn = {978-0-12-812364-5},
doi = {https://doi.org/10.1016/B978-0-12-812364-5.00006-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128123645000067},
author = {Fyaz M.D. Ismail and Lutfun Nahar and Satyajit D. Sarker},
keywords = {High-throughput screening (HTS), Robotics, Dereplication, Liquid handling systems, Screening , Natural product prototypes, Drug discovery and development, , , },
abstract = {This chapter reviews the origin and evolution of high-throughput screening (HTS) through the experience of the authors, who have either consulted for and/or provided courses to various pharmaceutical companies. It focuses on the role of HTS in natural product (phytochemicals) drug screening and drug discovery. Application of computational methods in HTS for phytochemical is highlighted. Commonly encountered difficulties and solutions to some of the problems are discussed together with selected ‘how to’ protocols to ensure investigators can set up and productively use HTS in their own natural product research. Relevant failures and successes in identifying interesting natural products are also outlined.}
}
@article{CARLOZZI2022263,
title = {Daily Variation in Sleep Quality is Associated With Health-Related Quality of Life in People With Spinal Cord Injury},
journal = {Archives of Physical Medicine and Rehabilitation},
volume = {103},
number = {2},
pages = {263-273.e4},
year = {2022},
issn = {0003-9993},
doi = {https://doi.org/10.1016/j.apmr.2021.07.803},
url = {https://www.sciencedirect.com/science/article/pii/S0003999321013630},
author = {Noelle E. Carlozzi and Jenna Freedman and Jonathan P. Troost and Traci Carson and Ivan R. Molton and Dawn M. Ehde and Kayvan Najarian and Jennifer A. Miner and Nicholas R. Boileau and Anna L. Kratz},
keywords = {Ecological momentary assessment, Quality of life, Rehabilitation, Sleep, Spinal cord injuries},
abstract = {Objective
Although sleep difficulties are common after spinal cord injury (SCI), little is known about how day-to-day fluctuations in sleep quality affects health-related quality of life (HRQOL) among these individuals. We examined the effect of sleep quality on same-day HRQOL using ecological momentary assessment methods over a 7-day period.
Design
Repeated-measures study involving 7 days of home monitoring; participants completed HRQOL measures each night and ecological momentary assessment ratings 3 times throughout the day; multilevel models were used to analyze data.
Setting
Two academic medical centers.
Participants
A total of 170 individuals with SCI (N=170).
Interventions
Not applicable.
Main Outcome Measures
Daily sleep quality was rated on a scale of 0 (worst) to 10 (best) each morning. Participants completed end-of-day diaries each night that included several HRQOL measures (Sleep Disturbance, Sleep-related Impairment, Fatigue, Cognitive Abilities, Pain Intensity, Pain Interference, Ability to Participate in Social Roles and Activities, Depression, Anxiety) and ecological momentary assessment ratings of HRQOL (pain, fatigue, subjective thinking) 3 times throughout each day.
Results
Multilevel models indicated that fluctuations in sleep quality (as determined by end-of-day ratings) were significantly related to next-day ratings of HRQOL; sleep quality was related to other reports of sleep (Sleep Disturbance; Sleep-related Impairment; Fatigue) but not to other aspects of HRQOL. For ecological momentary assessment ratings, nights of poor sleep were related to worse pain, fatigue, and thinking. Generally, sleep quality showed consistent associations with fatigue and thinking across the day, but the association between sleep quality and these ecological momentary assessment ratings weakened over the course of the day.
Conclusions
Findings highlight the important association between sleep and HRQOL for people with SCI. Future work targeting sleep quality improvement may have positive downstream effects for improving HRQOL in people with SCI.}
}
@article{GALITSKY201325,
title = {A computational simulation tool for training autistic reasoning about mental attitudes},
journal = {Knowledge-Based Systems},
volume = {50},
pages = {25-43},
year = {2013},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2013.04.018},
url = {https://www.sciencedirect.com/science/article/pii/S095070511300138X},
author = {Boris Galitsky},
keywords = {Autistic reasoning, Rehabilitation, Theory of mind},
abstract = {It has been discovered more than a decade ago that autistic people cannot properly understand and reproduce mental states and emotions. We hypothesize that people with autism suffer from difficulties in learning social rules from examples. Many remediation strategies have not taken this into account. Therefore an appropriate remediation strategy is to teach not simply via examples but to teach the rule along with it. In this study we suggest a reasoning rehabilitation strategy, based on playing with a computer based mental simulator that is capable of modeling mental and emotional states of the real world. A model of the mental world is presented in 12 steps. We describe our implementation of a natural language multiagent system that simulates this model. In addition we describe the system’s user interface for autistic rehabilitation. This system is subject to short-term and long-term evaluation of rehabilitation of autistic reasoning. Case studies with children who used it extensively are presented. Implications specifically in terms of autistic rehabilitation as well as generally in terms of reasoning about mental states are discussed.}
}
@article{LIU200548,
title = {A computational model for rare-earth ferrimagnets and antiferromagnets},
journal = {Physica B: Condensed Matter},
volume = {367},
number = {1},
pages = {48-52},
year = {2005},
issn = {0921-4526},
doi = {https://doi.org/10.1016/j.physb.2005.05.050},
url = {https://www.sciencedirect.com/science/article/pii/S0921452605007982},
author = {Z.-S. Liu and M. Diviš and V. Sechovský},
keywords = {Intermetallic compounds, Crystal field},
abstract = {A computational model for the calculation of the bulk magnetic properties of rare-earth ferrimagnets and antiferromagnets was developed and justified theoretically in the framework of mean-field theory. To demonstrate its utility, the model was applied to calculate the anisotropic Heisenberg exchange constants of CeTe2 by fitting magnetization curves numerically, and to derive analytical expressions for the spontaneous magnetization as well as the Neél temperature by considering only the crystal-field (CF) ground-state doublet. It turns out that the temperature dependencies of the magnetization and the specific heat calculated with the formulas in absence of an external field are identical with the plots obtained directly with the full lowest CF J-multiplet, manifesting the strong role of the Kramers doublet in the magnetic process at low temperatures. Finally, the model was applied to investigate the effects of the quadrupolar and magneto-elastic (QM) interactions on the magnetic properties of the system.}
}
@article{LI2024101590,
title = {Transforming maker mindsets: A case study of elementary students in a maker education context during lesson study},
journal = {Thinking Skills and Creativity},
volume = {53},
pages = {101590},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101590},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124001287},
author = {Jiajia Li and Zhuang Li and Huixin Gao and Tianying Yun},
keywords = {Maker mindsets, STEM learning, Maker education, Lesson study},
abstract = {Utilizing a case study approach, this research investigates the transformation of elementary students' Maker mindsets within the context of Maker education through a lesson study cycle. The study focuses on the Maker mindsets transformation of three students with varying abilities, deliberately chosen as information-rich participants. A project-specific questionnaire, the Maker Mindsets Scale, was employed to facilitate self-assessment of Maker mindsets before and after intervention. Additionally, teachers' post-lesson discussion meetings were observed, and semi-structured interviews with participating teachers were conducted to gauge their perceptions of students' Maker mindsets transformation. The analysis encompassed students' semi-structured reflection logs and interviews to uncover the underlying factors driving Maker mindsets transformation. The results revealed distinct variations in how students of different abilities perceived their Maker mindsets transformation. Nonetheless, participant teachers consistently observed transformations in STEM (Science, Technology, Engineering, Mathematics) thinking skills, self-efficacy, motivation, and collaborative learning across all students. The study further identifies a collaborative convergence of multiple factors contributing to Maker mindsets transformation, spanning teacher, student, and pedagogical perspectives. These findings carry significant implications for educators, advocating for the implementation of customized strategies, authentic contextualization, structured methodologies, and collaborative frameworks to holistically nurture Maker mindsets evolution. Moreover, our study underscores the practicality of the LS approach in fostering collaborative development of innovative pedagogical strategies aimed at fostering Maker mindsets formation.}
}
@incollection{DERINGER201359,
title = {9.02 - Computational Methods for Solids},
editor = {Jan Reedijk and Kenneth Poeppelmeier},
booktitle = {Comprehensive Inorganic Chemistry II (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Amsterdam},
pages = {59-87},
year = {2013},
isbn = {978-0-08-096529-1},
doi = {https://doi.org/10.1016/B978-0-08-097774-4.00902-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780080977744009025},
author = {V.L. Deringer and R. Dronskowski},
keywords = {Ab initio calculations, Band structure, Bonding indicators, Chemical bonding, Computational chemistry, Crystal orbitals, Density-functional theory, Electronic-structure calculations, Magnetism, Materials science, Plane-wave basis sets, Pseudopotentials, Quantum chemistry, Solid-state chemistry, Theoretical chemistry, Thermochemistry},
abstract = {Today's scientific progress would be unthinkable without theoretical and computational assistance. This holds true also for the solid-state sciences – which are without doubt a fundamental part of modern inorganic chemistry. This chapter is concerned mainly with first principles or ab initio quantum-chemical methods; the fundamental goal of solving Schrödinger's equation does not change upon going to extended systems, but there are some very important new ideas to consider. First, we describe these essential concepts; however, we do not, nor attempt to, provide an exhaustive overview of electronic-structure theory. Subsequently, we deal with simplifications, which are necessary to make quantum-chemical computations tractable and which possess special importance in the solid state. Simplifying ‘well’ is thus a vital part of any theorist's work. Finally, we describe applications – how chemists ‘see’ bonds in complicated structures, and how the computational toolkit may complement and enhance chemical concepts. They illustrate our most important message: how beautifully rock-solid theories and chemists' ingenious models blend in the solid state.}
}
@article{VARTIAINEN2021100281,
title = {Machine learning for middle schoolers: Learning through data-driven design},
journal = {International Journal of Child-Computer Interaction},
volume = {29},
pages = {100281},
year = {2021},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2021.100281},
url = {https://www.sciencedirect.com/science/article/pii/S2212868921000222},
author = {Henriikka Vartiainen and Tapani Toivonen and Ilkka Jormanainen and Juho Kahila and Matti Tedre and Teemu Valtonen},
keywords = {AI, Machine learning, K-12, Computational thinking, Design-oriented pedagogy, Design-based research},
abstract = {An entire generation of children is growing up with machine learning (ML) systems that are greatly disrupting job markets as well as changing people’s everyday lives. Yet, that development and its societal effects have been given minor attention in computing education in schools, which mainly focuses on rule-based programming. This article presents a pedagogical framework for supporting middle schoolers to become co-designers and makers of their own machine learning applications. It presents a case study conducted in the 6th grade of a Finnish elementary school and analyzes students’ (N=34) evolving ML ideas and explanations. Data consists of a children’s artwork, students’ design ideas and co-designed applications, and structured group interviews organized at the end of the ML project. The qualitative content analysis revealed how hands-on exploration with ML-based technologies supported students in developing various kinds of design ideas that harnessed face recognition, gestures, or voice recognition for solving real-life problems. The results of the study further indicated that co-designing ML applications provided a promising entry point for students to develop their conceptual understanding of ML principles, its workflows, and its role in their everyday practices. The article concludes with a discussion on how to support students to become innovators and software designers in the age of machine learning.}
}
@article{BJORNE2005193,
title = {A model of attentional impairments in autism: first steps toward a computational theory},
journal = {Cognitive Systems Research},
volume = {6},
number = {3},
pages = {193-204},
year = {2005},
note = {Epigenetic Robotics},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2004.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1389041704000749},
author = {Petra Björne and Christian Balkenius},
keywords = {Autism, Attention, Computational model},
abstract = {A computational model with three interacting components for context sensitive reinforcement learning, context processing and automation can autonomously learn a focus attention and a shift attention task. The performance of the model is similar to that of normal children, and when a single parameter is changed, the performance on the two tasks approaches that of autistic children.}
}
@article{REYNANTE2024102287,
title = {Reducing the cognitive abstractness of climate change through an “engineering fiction” learning experience: A natural language processing study},
journal = {Journal of Environmental Psychology},
volume = {95},
pages = {102287},
year = {2024},
issn = {0272-4944},
doi = {https://doi.org/10.1016/j.jenvp.2024.102287},
url = {https://www.sciencedirect.com/science/article/pii/S0272494424000604},
author = {Brandon Reynante and Nicole M. Ardoin and Roy Pea},
keywords = {Artificial intelligence, Climate change education, Climate fiction},
abstract = {The lackluster societal response to the climate crisis is partially attributed to the abstractness of people's mental construals of climate change given its vast spatial and temporal dimensions, which fail to evoke urgency to act. Prior efforts to measure mental construal levels of climate change are inconsistent, insufficient, and labor-intensive. This study developed and implemented learning experiences for integrating engineering design and climate fiction writing to engage 48 high school students in concrete climate change thinking. A novel measure of cognitive abstractness overcomes previous methodological shortcomings by automatically quantifying the linguistic abstractness of participant-authored stories using natural language processing. Comparing participant stories written at the beginning and end of the intervention reveals a significant decrease in linguistic abstractness (Cohen's d = 1.01, p = 0.03). This study contributes to the nascent movement for greater use of narratives as data sources in environmental psychology research, which may uncover new insights into human behavior and decision making.}
}

@article{FRANCIS2022103521,
title = {A framework for dynamic life cycle sustainability assessment and policy analysis of built environment through a system dynamics approach},
journal = {Sustainable Cities and Society},
volume = {76},
pages = {103521},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103521},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721007873},
author = {Ann Francis and Albert Thomas},
keywords = {Sustainability assessment, System dynamics, Dynamic life cycle sustainability assessment (D-LCSA), Computational modelling, Life cycle assessment},
abstract = {Sustainability is gaining attention, particularly in the building sector, owing to its significant influence on economy, society and environment. However, most assessment methods/frameworks available for this sector focus solely or dominantly on the environmental dimension of sustainability. Hence, a sustainability assessment framework for buildings that accounts for the interdependencies amongst social, economic and environmental aspects is essential. Further, buildings also undergo several time-induced changes in their characteristics, such as changes in electricity consumption, material properties, surrounding infrastructure and energy mix that can influence their sustainability. Therefore, this paper introduces a system dynamics-based methodological framework for Dynamic Life Cycle Sustainability Assessment (D-LCSA) capable of incorporating the dynamic changes in the building characteristics with time and capturing the interactions amongst different sustainability indicators. The usability and utility of the framework is demonstrated using a case study residential project in India. The case study results show that ignoring time-dependant dynamic aspects in sustainability assessment of buildings leads to underestimating the overall sustainability impacts by about 50 per cent and specific environmental impacts by about 12 per cent. Therefore, the study reinforces the need to adopt dynamic thinking through modelling and simulation to predict sustainability performance in the built environment.}
}
@article{CORCORAN2020158,
title = {Language as a biomarker for psychosis: A natural language processing approach},
journal = {Schizophrenia Research},
volume = {226},
pages = {158-166},
year = {2020},
note = {Biomarkers in the Attenuated Psychosis Syndrome},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2020.04.032},
url = {https://www.sciencedirect.com/science/article/pii/S0920996420302474},
author = {Cheryl M. Corcoran and Vijay A. Mittal and Carrie E. Bearden and Raquel {E. Gur} and Kasia Hitczenko and Zarina Bilgrami and Aleksandar Savic and Guillermo A. Cecchi and Phillip Wolff},
keywords = {Psychosis, Automated language analysis, Natural language processing, Machine learning, Semantic coherence, Discourse coherence, Referential coherence, Semantic density, Latent semantic analysis, Digital phenotyping, Psychosis risk, Clinical high risk, Ultra high risk, Schizophrenia},
abstract = {Human ratings of conceptual disorganization, poverty of content, referential cohesion and illogical thinking have been shown to predict psychosis onset in prospective clinical high risk (CHR) cohort studies. The potential value of linguistic biomarkers has been significantly magnified, however, by recent advances in natural language processing (NLP) and machine learning (ML). Such methodologies allow for the rapid and objective measurement of language features, many of which are not easily recognized by human raters. Here we review the key findings on language production disturbance in psychosis. We also describe recent advances in the computational methods used to analyze language data, including methods for the automatic measurement of discourse coherence, syntactic complexity, poverty of content, referential coherence, and metaphorical language. Linguistic biomarkers of psychosis risk are now undergoing cross-validation, with attention to harmonization of methods. Future directions in extended CHR networks include studies of sources of variance, and combination with other promising biomarkers of psychosis risk, such as cognitive and sensory processing impairments likely to be related to language. Implications for the broader study of social communication, including reciprocal prosody, face expression and gesture, are discussed.}
}
@article{MARTINEZMINGO2023101154,
title = {Quantum projections on conceptual subspaces},
journal = {Cognitive Systems Research},
volume = {82},
pages = {101154},
year = {2023},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2023.101154},
url = {https://www.sciencedirect.com/science/article/pii/S1389041723000827},
author = {Alejandro Martínez-Mingo and Guillermo Jorge-Botana and José Ángel Martinez-Huertas and Ricardo {Olmos Albacete}},
keywords = {Quantum similarity model, Semantic-vector space models, Computational linguistics, Similarity},
abstract = {One of the main challenges of cognitive science is to explain the representation of conceptual knowledge and the mechanisms involved in evaluating the similarities between these representations. Theories that attempt to explain this phenomenon should account for the fact that conceptual knowledge is not static. In line with this thinking, many studies suggest that the representation of a concept changes depending on context. Traditionally, concepts have been studied as vectors within a geometric space, sometimes called Semantic-Vector Space Models (S-VSMs). However, S-VSMs have certain limitations in emulating human biases or context effects when the similarity of concepts is judged. Such limitations are related to the use of a classical geometric approach that represents a concept as a point in space. Recently, some theories have proposed the use of sequential projections of subspaces based on Quantum Probability Theory (Busemeyer and Bruza, 2012; Pothos et al., 2013). They argue that this theoretical approach may facilitate accounting for human similarity biases and context effects in a more natural way. More specifically, Pothos and Busemeyer (2011) proposed the Quantum Similarity Model (QSM) to determine expectation in conceptual spaces in a non-monotonic logic frame. To the best of our knowledge, previous data-driven studies have used the QSM subspaces in a unidimensional way. In this paper, we present a data-driven method to generate these conceptual subspaces in a multidimensional manner using a traditional S-VSM. We present an illustration of the method taking Tversky’s classical examples to explain the effects of Asymmetry, Triangular Inequality, and the Diagnosticity by means of sequential projections of those conceptual subspaces.}
}
@article{LIBEROS2019319,
title = {Phase singularity point tracking for the identification of typical and atypical flutter patients: A clinical-computational study},
journal = {Computers in Biology and Medicine},
volume = {104},
pages = {319-328},
year = {2019},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2018.11.020},
url = {https://www.sciencedirect.com/science/article/pii/S0010482518303901},
author = {A. Liberos and M. Rodrigo and I. Hernandez-Romero and A. Quesada and F. Fernandez-Aviles and F. Atienza and A.M. Climent and M.S. Guillem},
keywords = {Atrial flutter, Phase map, Cardiac model, Body surface potential mapping},
abstract = {Atrial Flutter (AFL) termination by ablating the path responsible for the arrhythmia maintenance is an extended practice. However, the difficulty associated with the identification of the circuit in the case of atypical AFL motivates the development of diagnostic techniques. We propose body surface phase map analysis as a noninvasive tool to identify AFL circuits. Sixty seven lead body surface recordings were acquired in 9 patients during AFL (i.e. 3 typical, 6 atypical). Computed body surface phase maps from simulations of 5 reentrant behaviors in a realistic atrial structure were also used. Surface representation of the macro-reentrant activity was analyzed by tracking the singularity points (SPs) in surface phase maps obtained from band-pass filtered body surface potential maps. Spatial distribution of SPs showed significant differences between typical and atypical AFL. Whereas for typical AFL patients 70.78 ± 16.17% of the maps presented two SPs simultaneously in the areas defined around the midaxialliary lines, this condition was only satisfied in 5.15 ± 10.99% (p < 0.05) maps corresponding to atypical AFL patients. Simulations confirmed these results. Surface phase maps highlights the reentrant mechanism maintaining the arrhythmia and appear as a promising tool for the noninvasive characterization of the circuit maintaining AFL. The potential of the technique as a diagnosis tool needs to be evaluated in larger populations and, if it is confirmed, may help in planning ablation procedures.}
}
@article{MARIS2022131391,
title = {Structure and dynamics of methacrylamide, a computational and free-jet rotational spectroscopic study},
journal = {Journal of Molecular Structure},
volume = {1248},
pages = {131391},
year = {2022},
issn = {0022-2860},
doi = {https://doi.org/10.1016/j.molstruc.2021.131391},
url = {https://www.sciencedirect.com/science/article/pii/S0022286021015192},
author = {Assimo Maris and Sonia Melandri and Luca Evangelisti and Annalisa Vigorito and Silvia Sigismondi and Camilla Calabrese and Imanol Usabiaga},
keywords = {Amide, Gas-phase structure, Large amplitude motions, Nuclear quadrupole hyperfine structure, Rotational spectroscopy, Quantum mechanical calculations},
abstract = {The conformational space of methacrylamide was explored by quantum mechanical modeling and surveyed in the 59.6–104.0 GHz frequency range using a millimeter-wave Stark-modulated free-jet absorption spectrometer. According to the relative orientation of the two unsaturated bonds, two conformers were observed, namely s-trans (A=5234.360(1), B=3364.9717(8) and C=2173.099(1) MHz) and s-cis (A=5207.292(1), B=3470.930(1) and C=2113.496(1) MHz). The s-trans conformation is the global minimum, with relative energy 4(2) kJ mol−1 and calculated isomerization barrier 15 kJ mol−1. Except for the methyl hydrogen atoms, s-cis-methacrylamide is planar and its methyl internal rotation barrier is 10.2(1) kJ mol−1. In s-trans-methacrylamide the allyl and amino frames form a dihedral angle of about 30° and the methyl internal rotation barrier is 7.4 kJ mol−1. This different behaviour is explained in terms of attractive and repulsive intramolecular interactions between groups: CH2/CO and CH3/NH2 for s-cis, CH2/NH2 and CH3/CO for s-trans. The tunneling splitting related to the double-well potential describing the interconversion between the two equivalent s-trans forms is 837.97(2) MHz and was reproduced by a one-dimensional flexible model using a 3.6 kJ mol−1 interconversion barrier.}
}
@incollection{ALIPPI2019245,
title = {Chapter 12 - Computational Intelligence in the Time of Cyber-Physical Systems and the Internet of Things},
editor = {Robert Kozma and Cesare Alippi and Yoonsuck Choe and Francesco Carlo Morabito},
booktitle = {Artificial Intelligence in the Age of Neural Networks and Brain Computing},
publisher = {Academic Press},
pages = {245-263},
year = {2019},
isbn = {978-0-12-815480-9},
doi = {https://doi.org/10.1016/B978-0-12-815480-9.00012-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128154809000128},
author = {Cesare Alippi and Seiichi Ozawa},
keywords = {Brain computing, Cyber-physical systems, Cybersecurity, Embedded systems, Neurodynamics, IoT, Machine learning, Neural networks},
abstract = {The emergence of nontrivial embedded sensor units and cyber-physical systems and the Internet of Things has made possible the design and implementation of sophisticated applications where large amounts of real-time data are collected, possibly to constitute a big data picture as time passes. Within this framework, intelligence mechanisms based on machine learning, neural networks, and brain computing approaches play a key role to provide systems with advanced functionalities. Intelligent mechanisms are needed to guarantee appropriate performances within an evolving, time-variant environment, optimally harvest the available energy and manage the residual energy, reduce the energy consumption of the whole system, identify and mitigate occurrence of faults, and provide shields against cyberattacks. The chapter introduces the above aspects of intelligence, whose functionalities are needed to boost the next generation of cyber-physical and Internet of Things applications, and the smart world generation whose footprint is already around us.}
}
@article{LOURIDAS1999517,
title = {Design as bricolage: anthropology meets design thinking},
journal = {Design Studies},
volume = {20},
number = {6},
pages = {517-535},
year = {1999},
issn = {0142-694X},
doi = {https://doi.org/10.1016/S0142-694X(98)00044-1},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X98000441},
author = {Panagiotis Louridas},
keywords = {aesthetics, design activity, design cognition, metaphor, psychology of design},
abstract = {We identify a metaphor for the design activity: we view design as bricolage. We start from describing bricolage, and we proceed to the relationship of design to art. We obtain a characterisation of design that enables us to show that both traditional and contemporary design are forms of bricolage. We examine the consequences of `design as bricolage' for the relationship between design and science and for the extent of the design activity.}
}
@article{HARTMANN2021112902,
title = {Model development for evidence-based prioritisation of policy action on emerging chemical and microbial drinking water risks},
journal = {Journal of Environmental Management},
volume = {295},
pages = {112902},
year = {2021},
issn = {0301-4797},
doi = {https://doi.org/10.1016/j.jenvman.2021.112902},
url = {https://www.sciencedirect.com/science/article/pii/S0301479721009646},
author = {Julia Hartmann and Juan Carlos Chacon-Hurtado and Eric Verbruggen and Jack Schijven and Emiel Rorije and Susanne Wuijts and Ana Maria {de Roda Husman} and Jan Peter {van der Hoek} and Lisa Scholten},
keywords = {Multi criteria analysis, MCA, Stakeholder consultation, Water contaminants, Pathogen},
abstract = {While the burden of disease from well-studied drinking water contaminants is declining, risks from emerging chemical and microbial contaminants arise because of social, technological, demographic and climatological developments. At present, emerging chemical and microbial drinking water contaminants are not assessed in a systematic way, but reactively and incidence based. Furthermore, they are assessed separately despite similar pollution sources. As a result, risks might be addressed ineffectively. Integrated risk assessment approaches are thus needed that elucidate the uncertainties in the risk evaluation of emerging drinking water contaminants, while considering risk assessors’ values. This study therefore aimed to (1) construct an assessment hierarchy for the integrated evaluation of the potential risks from emerging chemical and microbial contaminants in drinking water and (2) develop a decision support tool, based on the agreed assessment hierarchy, to quantify (uncertain) risk scores. A multi-actor approach was used to construct the assessment hierarchy, involving chemical and microbial risk assessors, drinking water experts and members of responsible authorities. The concept of value-focused thinking was applied to guide the problem-structuring and model-building process. The development of the decision support tool was done using Decisi-o-rama, an open-source Python library. With the developed decision support tool (uncertain) risk scores can be calculated for emerging chemical and microbial drinking water contaminants, which can be used for the evidence-based prioritisation of actions on emerging chemical and microbial drinking water risks. The decision support tool improves existing prioritisation approaches as it combines uncertain indicator levels with a multi-stakeholder approach and integrated the risk assessment of chemical and microbial contaminants. By applying the concept of value-focused thinking, this study addressed difficulties in evidence-based decision-making related to emerging drinking water contaminants. Suggestions to improve the model were made to guide future research in assisting policy makers to effectively protect public health from emerging drinking water risks.}
}
@article{WANG202428,
title = {Exploring the interplay between core and mood symptoms in schizophrenia: A network analysis},
journal = {Schizophrenia Research},
volume = {269},
pages = {28-35},
year = {2024},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2024.04.016},
url = {https://www.sciencedirect.com/science/article/pii/S0920996424001695},
author = {Yucheng Wang and Yixiao Xu and Peiyi Wu and Yang Zhou and Huanrui Zhang and Zijia Li and Yanqing Tang},
keywords = {Schizophrenia, Core symptoms, Mood symptoms, Network analysis, Symptom interactions},
abstract = {Background
Schizophrenia is a complex neuropsychiatric disorder characterized by positive symptoms, negative symptoms, cognitive deficits, and co-occurring mood symptoms. Network analysis offers a novel approach to investigate the intricate relationships between these symptom dimensions, potentially informing personalized treatment strategies.
Methods
A cross-sectional study was conducted from November 2019 to October 2021, involving 1285 inpatients with schizophrenia in Liaoning Province, China. Symptom severity was assessed using the Positive and Negative Syndrome Scale (PANSS), Hamilton Depression Rating Scale (HAMD-17), Hamilton Anxiety Rating Scale (HAMA-14), and Montreal Cognitive Assessment (MoCA). Network analysis was conducted to investigate the network structure, central symptoms, and bridge symptoms.
Results
The network analysis uncovered profound interconnectivity between core symptoms and the anxiety-depression community. Central symptoms, such as psychic anxiety, poor rapport, delusions, and attention, were identified as potential therapeutic targets. Bridge symptoms, including insomnia, depressed mood, anxiety-somatic, conceptual disorganization, and stereotyped thinking, emerged as key nodes facilitating interactions between symptom communities. The stability and reliability of the networks were confirmed through bootstrapping procedures.
Discussion
The findings highlight the complex interplay between schizophrenia symptoms, emphasizing the importance of targeting affective symptoms and cognitive impairment in treatment. The identification of central and bridge symptoms suggests potential pathways for personalized interventions aimed at disrupting self-reinforcing symptom cycles. The study underscores the need for a transdiagnostic, personalized approach to schizophrenia treatment.}
}
@article{LIN2021103499,
title = {Informational cues or content? Examining project funding decisions by crowdfunders},
journal = {Information & Management},
volume = {58},
number = {7},
pages = {103499},
year = {2021},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2021.103499},
url = {https://www.sciencedirect.com/science/article/pii/S0378720621000732},
author = {Yan Lin and Wai Fong Boh},
keywords = {Experience, Elaboration Likelihood Model, Information Asymmetry, Crowdfunding},
abstract = {We examine how crowdfunder experience affects their reliance on information available on projects. Drawing on elaboration likelihood model and using data from Kickstarter, we apply machine learning techniques and choice modeling to examine the information provided by creators, investigating not only the descriptions, but also the pictures and the videos. We found that more experienced crowdfunders react positively to descriptions exhibiting higher analytical thinking, while less experienced crowdfunders rely more on cues that arouse attention (e.g., number of pictures and positive emotions in videos). We highlight the importance of considering how experience influences crowdfunders’ interpretation of different types of information.}
}
@incollection{PARRY2016255,
title = {Chapter Ten - Using Data Mining and Computational Approaches to Study Intermediate Filament Structure and Function},
editor = {M. Bishr Omary and Ronald K.H. Liem},
series = {Methods in Enzymology},
publisher = {Academic Press},
volume = {568},
pages = {255-276},
year = {2016},
booktitle = {Intermediate Filament Proteins},
issn = {0076-6879},
doi = {https://doi.org/10.1016/bs.mie.2015.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S0076687915004152},
author = {David A.D. Parry},
keywords = {IF chain assembly, Sequence periodicities, Heptad and hendecad substructure, Interchain ionic interactions, IF secondary and tertiary structure, Structural/functional motifs, Mutations},
abstract = {Experimental and theoretical research aimed at determining the structure and function of the family of intermediate filament proteins has made significant advances over the past 20 years. Much of this has either contributed to or relied on the amino acid sequence databases that are now available online, and the data mining approaches that have been developed to analyze these sequences. As the quality of sequence data is generally high, it follows that it is the design of the computational and graphical methodologies that are of especial importance to researchers who aspire to gain a greater understanding of those sequence features that specify both function and structural hierarchy. However, these techniques are necessarily subject to limitations and it is important that these be recognized. In addition, no single method is likely to be successful in solving a particular problem, and a coordinated approach using a suite of methods is generally required. A final step in the process involves the interpretation of the results obtained and the construction of a working model or hypothesis that suggests further experimentation. While such methods allow meaningful progress to be made it is still important that the data are interpreted correctly and conservatively. New data mining methods are continually being developed, and it can be expected that even greater understanding of the relationship between structure and function will be gleaned from sequence data in the coming years.}
}
@article{GENT202336,
title = {Computing comes to life},
journal = {New Scientist},
volume = {258},
number = {3442},
pages = {36-39},
year = {2023},
issn = {0262-4079},
doi = {https://doi.org/10.1016/S0262-4079(23)01054-0},
url = {https://www.sciencedirect.com/science/article/pii/S0262407923010540},
author = {Edd Gent},
abstract = {Nature is capable of astonishing feats of computation. Now, we are re-engineering molecules, cells and even whole organisms into living processors, says Edd Gent}
}
@article{SONOBE2022101560,
title = {Development and validation of machine learning prediction model for post-rehabilitation functional outcome after intracerebral hemorrhage},
journal = {Interdisciplinary Neurosurgery},
volume = {29},
pages = {101560},
year = {2022},
issn = {2214-7519},
doi = {https://doi.org/10.1016/j.inat.2022.101560},
url = {https://www.sciencedirect.com/science/article/pii/S2214751922000743},
author = {Shinya Sonobe and Tetsuo Ishikawa and Kuniyasu Niizuma and Eiryo Kawakami and Takuya Ueda and Eichi Takaya and Carlos {Makoto Miyauchi} and Junya Iwazaki and Ryuzaburo Kochi and Toshiki Endo and Arun Shastry and Vijayananda Jagannatha and Ajay Seth and Atsuhiro Nakagawa and Masahiro Yoshida and Teiji Tominaga},
keywords = {Intracerebral hemorrhage, Machine learning prediction, Post-rehabilitation functional outcome, Design thinking},
abstract = {Objective
Predicting outcomes after intracerebral hemorrhage (ICH) may help improve patient outcomes. We developed and validated a machine learning prediction model for post-rehabilitation functional outcomes after ICH. Patient selection and explanatory variable settings were based on clinical significance. Functional outcomes were predicted using ternary classification.
Methods
The subjects were patients aged > 18 years without pre-onset severe disability who developed primary putaminal and/or thalamic hemorrhage and underwent an inpatient rehabilitation program. As explanatory variables, 43 values related to patient background, imaging-related findings, systemic conditions, neurological findings, and blood tests were acquired within 10 days of onset. As an objective variable, the functional outcome at discharge to home or nursing home was acquired using a ternary classification. The dataset consisting of the collected information was split into a training dataset and a test dataset with a ratio of 2:1. A predictive model using a balanced random forest algorithm was created using supervised learning from the training dataset. The predictive performance was validated using a test dataset.
Results
Between January 2018 and June 2019, 100 consecutive patients were included in the study. The areas under the receiver operating characteristic curves for predictions of good, moderate, and poor outcomes were 0.952, 0.790, and 0.921, respectively.
Conclusions
The predictive performance of the model was comparable to that of previous models. Patient selection and variable settings from a clinical perspective may contribute to accurate and detailed predictions. These study designs are based on design thinking and may meet the needs of clinical practice.}
}
@article{CIMIER2025100092,
title = {Multisensory objects’ role on creativity},
journal = {Journal of Creativity},
volume = {35},
number = {1},
pages = {100092},
year = {2025},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2024.100092},
url = {https://www.sciencedirect.com/science/article/pii/S2713374524000189},
author = {Amandine Cimier and Beatrice Biancardi and Jérome Guegan and Frédéric Segonds and Fabrice Mantelet and Camille Jean and Claude Gazo and Stéphanie Buisine},
keywords = {Engineering, Manipulation, Embodied cognition, Kinesthesia, Creativity},
abstract = {In this research, we investigated the role of multisensorial manipulation on creativity, and the influence of inspirational objects on creative outcomes. Object manipulation may support embodied cognition during a generative creative phase (emergence of motor, spatial, emotional ideas, etc.) then exploratory phase (creative fixation, development of a functional creation, etc.). Our protocol involved 136 engineering students divided into 34 groups which were provided with inspirational cubes illustrating manufacturing inventive principles or basic volumes from the Creative Mental Synthesis Task. They could manipulate these objects either in a visuo-haptic condition, or in a visuo-imaginative condition. Our results highlighted a main effect of manipulation, showing that visual-haptic condition led to higher creativity than visual-imaginative condition. We also observed several effects in favor of inspirational cubes with regard to basic volumes: significantly higher creativity, more subjective and inter-subjective facilitation behaviors, more cognitive and emotional operations. Participants also showed at an individual level a better mobilization of the multisensorial senses. Creative thinking may be stimulated when an active manipulation phase is set up before the creative production. This could contribute to improving practice for engineers, particularly for using additive manufacturing and/or during their training at school.}
}
@article{CUNHA2024,
title = {Converging extended reality and Machine Learning to improve the lecturing of geometry in basic education},
journal = {Journal of Engineering Research},
year = {2024},
issn = {2307-1877},
doi = {https://doi.org/10.1016/j.jer.2024.10.016},
url = {https://www.sciencedirect.com/science/article/pii/S2307187724002736},
author = {Carlos R. Cunha and André Moreira and Sílvia Coelho and Vítor Mendonça and João Pedro Gomes},
keywords = {Geometry, Teaching, Learning, Education, Extended reality, Mixed reality, Machine learning},
abstract = {Technology is constantly supporting in the innovation of the teaching-learning process. Today’s students are more demanding actors when it comes to the environment they have at their disposal to learn, experiment and develop their critical thinking. The area of Mathematics has successively suffered from students’ learning difficulties, whether due to lack of motivation, low abstraction ability or lack of new tools for teachers to bring innovation into the classroom and outside it. While being true that digitalization has entered schools, it often follows a basic and simple process of digital replication of approaches and materials that were previously only available on physical media. This work focuses on the use of Extended Realities, more precisely, Mixed Reality, for teaching Mathematics, and very particularly in the teaching of Geometry, through the proposition of a conceptual model that combines the use of Extended Reality and Machine Learning. The proposed model was subject to prototyping, which is presented as a form of laboratory validation as a contribution to innovate the way of how the geometry teaching-learning process is developed and to promote the integration of Extended Reality technologies into the Education Sector as practical tools, as well due to its potential use to obtain useful insights for teachers, and students, throughout the process.}
}
@article{LLOYD2019167,
title = {You make it and you try it out: Seeds of design discipline futures},
journal = {Design Studies},
volume = {65},
pages = {167-181},
year = {2019},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2019.10.008},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X19300675},
author = {Peter Lloyd},
keywords = {design methods, design studies, design research, design process, design thinking},
abstract = {This paper takes a narrative seam through the design discipline, attempting to explain how design methodology, one of the three types of Nigel Cross' designerly ways of knowing, has changed over the 40 years of Design Studies. Specifically, the paper identifies the point when a ‘social turn’ in the discipline occurred, allowing more nuanced and critical studies of designing, and shifting the balance from an objective (‘scientific’) perspective to one more based on relativist approaches. The paper concludes by noting the plurality of present-day study, arguably enabled by design thinking, and sketches what this holds for the future of the discipline. The references in the paper are mainly restricted to those published in, or strongly relating to, Design Studies.}
}
@article{TESFATSION2001281,
title = {Introduction to the special issue on agent-based computational economics},
journal = {Journal of Economic Dynamics and Control},
volume = {25},
number = {3},
pages = {281-293},
year = {2001},
note = {Agent-based Computational Economics (ACE)},
issn = {0165-1889},
doi = {https://doi.org/10.1016/S0165-1889(00)00027-0},
url = {https://www.sciencedirect.com/science/article/pii/S0165188900000270},
author = {Leigh Tesfatsion},
keywords = {Agent-based computational economics},
abstract = {A brief overview of agent-based computational economics (ACE) is given, followed by a synopsis of the articles included in this special issue on ACE and in a companion special issue on ACE scheduled to appear in Computational Economics.}
}
@article{MCDERMOTT20071183,
title = {Level-headed},
journal = {Artificial Intelligence},
volume = {171},
number = {18},
pages = {1183-1186},
year = {2007},
note = {Special Review Issue},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2007.10.013},
url = {https://www.sciencedirect.com/science/article/pii/S0004370207001488},
author = {Drew McDermott},
keywords = {Speculation, Methodology, Natural language},
abstract = {I don't believe that human-level intelligence is a well defined goal. As the cognitive-science community learns more about thinking and computation, the mileposts will keep changing in ways that we can't predict, as will the esteem we assign to past accomplishments. It would be fun to have a computer that could solve brain teasers as well as the average scientist, but focusing on such things, besides being parochial, overlooks the crucial role language plays in everything humans do, a role we understand hardly at all on a computational level. I am optimistic that we will eventually figure language out, but not without new ideas. Plus, when we can talk to machines, will we understand each other?}
}
@article{MIRA2009793,
title = {Sensory representation spaces in neuroscience and computation},
journal = {Neurocomputing},
volume = {72},
number = {4},
pages = {793-805},
year = {2009},
note = {Brain Inspired Cognitive Systems (BICS 2006) / Interplay Between Natural and Artificial Computation (IWINAC 2007)},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2008.04.054},
url = {https://www.sciencedirect.com/science/article/pii/S0925231208004682},
author = {J. Mira and A.E. Delgado},
keywords = {Representation space, Perception, Cortical maps, Semantic gap},
abstract = {Physics, Neuroscience and Computation are concerned with finding the most appropriate representation spaces to describe the interaction of a dynamic system with its environment. In this work first we review the two basic conceptual approaches to the problem of representing an environment, Marr's ascending “constructivism” and Gibson's “direct perception” hypothesis. Later we review the basic neural mechanisms associated with creating meaning in both approaches: lateral inhibition and the creation of cortical maps by resonance to patterns of stimuli of families of spatially ordered neurons. We end by considering the usefulness in artificial intelligence of knowledge about the way in which biological systems construct their representation spaces. We stress the idea regarding events as representation entities and, consequently, using an event time, different from physical time. Semantics emerges from the mechanisms that detect these relevant events in each organisational level and their composition rules to specify the constitutive entities of the next level. This semantic is distributed in the cortical maps of the neuron groups that resound to the corresponding events.}
}
@article{PEREZLOPEZ2024105162,
title = {Cartographic analysis as spatial determinant for climate change adaptation in the Hunter River Estuary, Australia},
journal = {Cities},
volume = {152},
pages = {105162},
year = {2024},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2024.105162},
url = {https://www.sciencedirect.com/science/article/pii/S0264275124003767},
author = {Irene {Perez Lopez} and Sandra Carrasco and Cesar {Mariscal Madrigal}},
keywords = {Ecological design, Estuary urbanism, Climate adaptation, Living infrastructures, Hunter River Australia},
abstract = {This paper explores the hydrological history of the Hunter River and Estuary (Newcastle, Australia), to identify pathways for incorporating climate-sensitive adaptation approaches into urban development and planning. The research method utilises mapping as a methodological discovery tools to visually articulate the correlation of pre-colonial hydrological landscapes, the transformation of the estuary over two centuries, the areas identified as at risk, and the opportunities for developing a climate-resilient estuary. This research aims to contribute to the redefinition of the discourse on the role of estuary planning for changing climate, focusing on four critical aspects: identify the impacts of urbanisation and industrialisation on ecosystems and its correlation with climate hazard at the estuary; visualise such transformations over time and space to identify critical spatial and climate factors threatening inhabitation; propose strategic spatial practices towards adaptation and resilience; and synthesising the options to foster reflective thinking and establish a correlation with novel policies, governance and practices. The study highlights that adopting new urbanism aligned with cultural and ecological principles can mitigate future climate impacts through re-naturalisation and urban adaptation to sea-level rise by focusing on proactive approaches to building resilient communities. This paper also acknowledges the need for site-specific adaptive design and planning strategies at multiple scales and governance levels.}
}
@article{MACHKROL2023259,
title = {An ML-extended conceptual framework for implementing temporal big data analytics in organizations to support their agility},
journal = {Procedia Computer Science},
volume = {225},
pages = {259-268},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.010},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923011687},
author = {Maria Mach-Król and Bartłomiej Hadasik},
keywords = {temporal big data analytics, temporal knowledge, machine learning, organizational agility, feedback loop},
abstract = {The main aim of this paper is to present the machine learning (ML) extension to the authors’ original conceptual framework for implementing temporal big data analytics (TBDA) in organizations. The framework has been also supplemented with a ML-supported feedback loop aimed at ongoing verification of the organization's maturity for TBDA in light of changing needs, requirements, and the company's environment. Such extension is needed to make the TBDA more flexible and adaptable to market environment, thus augmenting organizational agility. The research has been carried following the Design Science Research in Information Systems (DSRIS) methodological approach with the addition of creative thinking. As a result, the extended framework is elaborated, and further improvements and research directions are identified.}
}
@article{ISLAM2025100417,
title = {DFT insights into the mechanical properties of NMs},
journal = {Results in Surfaces and Interfaces},
volume = {18},
pages = {100417},
year = {2025},
issn = {2666-8459},
doi = {https://doi.org/10.1016/j.rsurfi.2025.100417},
url = {https://www.sciencedirect.com/science/article/pii/S2666845925000042},
author = {Md. Aminul Islam and Nayem Hossain and Zahid Ahsan and Masud Rana and Mustafizur Rahman and Md. Abdullah},
keywords = {DFT, NMs, Elasticity, Mechanical properties, Quantum effects, Surface phenomena},
abstract = {NMs, whose dimensions are below 100 nm, provide unique mechanical properties from quantum effects, surface phenomena, and small-scale interactions that account for their importance in energy storage, biomedicine, nanoelectronics, etc. This review discusses computational prediction of mechanical properties (for example, elasticity, strength, and fracture behavior) in NMs, especially using Density Functional Theory as a central tool. By conducting DFT calculations, we can analyze how NMs will behave across different mechanical states, which is critical for designing properties for advanced applications. Problems related to the application of DFT (e.g., high computational cost and failure in modeling defects or exchange-correlation functionals) are discussed. Despite these challenges, DFT must provide insights that complement other tools and strategies. However, further development is essential for improving its quantitative predictability on temperature and multiscale models. Future work is needed to integrate ML with DFT further to refine the accuracy and computational efficiency, thereby extending the capability of DFT to accelerate the discovery of new NMs with superior mechanical properties.}
}
@article{SALMON2022105511,
title = {Bicycle crash contributory factors: A systematic review},
journal = {Safety Science},
volume = {145},
pages = {105511},
year = {2022},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2021.105511},
url = {https://www.sciencedirect.com/science/article/pii/S0925753521003544},
author = {Paul M. Salmon and Mitch Naughton and Adam Hulme and Scott McLean},
keywords = {Cyclists, Cyclist crashes, Systems thinking, Road safety, Crash causation},
abstract = {There is a growing body of road safety research that seeks to identify crash contributory factors beyond road users, their vehicles, and the immediate road environment. Although cyclist safety represents a critical research area, this ‘systems thinking’ approach has received less attention in bicycle crash analysis. This article presents the findings from a systematic literature review which aimed to synthesise the peer reviewed literature regarding bicycle crash contributory factors (defined as factors which play a contributory role in bicycle crashes, as opposed to risk factors which are factors which may increase the probability of crashes). Crash contributory factors were extracted from included articles and mapped onto a systems thinking framework comprising seven hierarchical road transport system levels. The findings show that a majority of the included studies identified contributory factors relating to the road environment, cycling infrastructure, and cyclist and driver behaviour. No studies identified contributory factors outside of cyclists and road users, bicycles and vehicles, and the road environment and few specifically examined causal relationships between contributory factors. It is concluded that there are gaps in the knowledge base regarding the broader transport system features that play a role in bicycle crashes and how contributory factors interact to create crashes. We argue that more expansive research into the systemic factors involved in bicycle crashes is required and that initial work should focus on the development of new data sources and analysis methods.}
}
@article{YIN2015655,
title = {Automating design with intelligent human–machine integration},
journal = {CIRP Annals},
volume = {64},
number = {2},
pages = {655-677},
year = {2015},
issn = {0007-8506},
doi = {https://doi.org/10.1016/j.cirp.2015.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S000785061500147X},
author = {Yue H. Yin and Andrew Y.C. Nee and S.K. Ong and Jian Y. Zhu and Pei H. Gu and Lien J. Chen},
keywords = {Design automation, Human–machine integration, Intelligent design, Imaginal thinking, Ontology},
abstract = {This paper reviews the state-of-the-art methodologies for automating design with intelligent human–machine integration from the perspectives of ontology and epistemology. The human–machine integrated automating design paradigm is reviewed systematically based on a proposed prototype of human–machine integrated design, from the aspects of ontology-based knowledge management with local-to-global ontology transitions, and epistemology-based upward-spiral cognitive process of coupled design ideation. Particularly, imaginal thinking frame is proposed as the foundation of intelligent human–machine interaction that puts human and machine on an equal platform. Further, this paper presents implementations and applications of the automating design paradigm and concludes with the identification of future trend.}
}
@article{GEORGIEV20181,
title = {Enhancing user creativity: Semantic measures for idea generation},
journal = {Knowledge-Based Systems},
volume = {151},
pages = {1-15},
year = {2018},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2018.03.016},
url = {https://www.sciencedirect.com/science/article/pii/S0950705118301394},
author = {Georgi V. Georgiev and Danko D. Georgiev},
keywords = {Creativity, Divergence, Semantic networks, Similarity, WordNet},
abstract = {Human creativity generates novel ideas to solve real-world problems. This thereby grants us the power to transform the surrounding world and extend our human attributes beyond what is currently possible. Creative ideas are not just new and unexpected, but are also successful in providing solutions that are useful, efficient and valuable. Thus, creativity optimizes the use of available resources and increases wealth. The origin of human creativity, however, is poorly understood, and semantic measures that could predict the success of generated ideas are currently unknown. Here, we analyze a dataset of design problem-solving conversations in real-world settings by using 49 semantic measures based on WordNet 3.1 and demonstrate that a divergence of semantic similarity, an increased information content, and a decreased polysemy predict the success of generated ideas. The first feedback from clients also enhances information content and leads to a divergence of successful ideas in creative problem solving. These results advance cognitive science by identifying real-world processes in human problem solving that are relevant to the success of produced solutions and provide tools for real-time monitoring of problem solving, student training and skill acquisition. A selected subset of information content (IC Sánchez–Batet) and semantic similarity (Lin/Sánchez–Batet) measures, which are both statistically powerful and computationally fast, could support the development of technologies for computer-assisted enhancements of human creativity or for the implementation of creativity in machines endowed with general artificial intelligence.}
}
@article{WAUTELET2025125664,
title = {Circulise, a model-driven framework to build and align socio-technical systems for the twin transition: Fanyatu’s case of sustainability in reforestation},
journal = {Expert Systems with Applications},
volume = {262},
pages = {125664},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125664},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424025314},
author = {Yves Wautelet and Xavier Rouget},
keywords = {Circulise, Circular economy development, Cryptocurrency, Reforestation, Sustainability, Sustainability engineering, Twin transition},
abstract = {Building circular economic systems is crucial to address ecological challenges like climate change. The twin transition suggests that, to maximize the impact of sustainable solutions, humans and (disruptive) technologies need to be effectively integrated. Methods to conceptually build such (eco)systems integrating these and assess their ecological impact before implementation are lacking. This paper addresses this gap by proposing the Circulise framework, a model-driven method designed to build circular systems and evaluate their environmental performance. The approach promotes design-thinking to create socio-technical ecosystems that can be evaluated at the light of their alignment with circular economy and/or sustainability principles and be used to generate operational software behavior. The Circulise framework was developed following the methodological guidance of design science research. It is applied in this paper to the case of Fanyatu, a non-profit organization focused on reforestation in the Congo Basin, showing its ability to create a circular ecosystem not only supporting the creation of regenerative CO2-absorbing forests but also empowering and improving the quality of life of the local communities involved in the planting of trees. In Fanyatu’s case, Circulise’s strategic planning and technology integration lead to virtuous cycles, enabling a snowball effect in forest creation and the promotion of sustainable projects. The framework’s scalability and versatility allow it to be applied across various contexts, enabling the creation of customized circular ecosystems for sustainability tailored to specific human and technological needs.}
}
@article{BILLINGE20243714,
title = {Do materials have a genome, and if they do, what can be done with it?},
journal = {Matter},
volume = {7},
number = {11},
pages = {3714-3727},
year = {2024},
issn = {2590-2385},
doi = {https://doi.org/10.1016/j.matt.2024.06.026},
url = {https://www.sciencedirect.com/science/article/pii/S259023852400345X},
author = {Simon J.L. Billinge},
abstract = {Summary
Materials do not have a genome, yet for the past decade, and into the next decade, in the USA, there has been a presidential and inter-agency funding initiative called the “Materials Genome Initiative (MGI).” This initiative has nothing to do with real genomes, materials, or otherwise. However, in this paper, we, somewhat whimsically, explore some ideas about what a material’s gene could be and how it could be used to further our understanding of materials structure and properties. The result is a slightly non-conventional, less crystal-centric, view of materials structure that we believe can, will, and is resulting in novel materials insights.}
}
@article{HASKOVA2025102515,
title = {Fuzzy calculator – A tool for management needs},
journal = {Journal of Computational Science},
volume = {85},
pages = {102515},
year = {2025},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2024.102515},
url = {https://www.sciencedirect.com/science/article/pii/S1877750324003089},
author = {Simona Hašková and Petr Šuleř and Martin Smrt},
keywords = {Fuzzy calculator, Computer program, Multi-criteria evaluation, Fuzzy logic},
abstract = {Fuzzy logic and fuzzy system models have become popular tools in the field of management as they enable efficient handling of uncertainty. We present a tool based on the authors´ original approach focused on solving complex managerial problems affected by the vagueness or uncertainty caused by the human factor. For this purpose, we show the connection between the functioning principle of the tool and processes occurring in the human mind including a description of its structure as perceived by an external observer. This is followed by an overview of selected fragments of fuzzy propositional logic, the theory of fuzzy sets, and the conclusions derived from it. The main part consists of formulating an algebraic description of the computational process of multi-criteria evaluation of the considered alternative performed by a fuzzy system, which serves as the executive unit of a Fuzzy calculator. This is supplemented by a flowchart diagram illustrating the algorithm of its functioning. The Fuzzy calculator distinguishes itself from other fuzzy systems by standardizing all linguistic variables, regardless of the number of linguistic values, into a unified framework comprising three terms L, M, and H, which are represented using trapezoidal fuzzy numbers, ensuring precise mathematical characterization. During the transformation, the original linguistic terms are preserved by incorporating the positions of their support intervals, thereby maintaining the specificity of the input information. This approach establishes the Fuzzy calculator as a universal and highly adaptable tool, capable of addressing a wide range of practical managerial problems with improved consistency and control.}
}
@article{RONG20121462,
title = {Computational performance of basic state reduction based dynamic programming algorithms for bi-objective 0–1 knapsack problems},
journal = {Computers & Mathematics with Applications},
volume = {63},
number = {10},
pages = {1462-1480},
year = {2012},
issn = {0898-1221},
doi = {https://doi.org/10.1016/j.camwa.2012.03.057},
url = {https://www.sciencedirect.com/science/article/pii/S0898122112002623},
author = {Aiying Rong and José Rui Figueira},
keywords = {Multi-objective optimization, Bi-objective knapsack problem, Dynamic programming, Basic state reduction techniques},
abstract = {This paper studies a group of basic state reduction based dynamic programming (DP) algorithms for the multi-objective 0–1 knapsack problem (MKP), which are related to the backward reduced-state DP space (BRDS) and forward reduced-state DP space (FRDS). The BRDS is widely ignored in the literature because it imposes disadvantage for the single objective knapsack problem (KP) in terms of memory requirements. The FRDS based DP algorithm in a general sense is related to state dominance checking, which can be time consuming for the MKP while it can be done efficiently for the KP. Consequently, no algorithm purely based on the FRDS with state dominance checking has ever been developed for the MKP. In this paper, we attempt to get some insights into the state reduction techniques efficient to the MKP. We first propose an FRDS based algorithm with a local state dominance checking for the MKP. Then we evaluate the relative advantage of the BRDS and FRDS based algorithms by analyzing their computational time and memory requirements for the MKP. Finally different combinations of the BRDS and FRDS based algorithms are developed on this basis. Numerical experiments based on the bi-objective KP instances are conducted to compare systematically between these algorithms and the recently developed BRDS based DP algorithm as well as the existing FRDS based DP algorithm without state dominance checking.}
}
@article{WOOD199740,
title = {Thinking about Networks in the Control of Male Hamster Sexual Behavior},
journal = {Hormones and Behavior},
volume = {32},
number = {1},
pages = {40-45},
year = {1997},
issn = {0018-506X},
doi = {https://doi.org/10.1006/hbeh.1997.1403},
url = {https://www.sciencedirect.com/science/article/pii/S0018506X97914033},
author = {Ruth I. Wood},
abstract = {Motivated social behaviors such as mating are controlled by a complex network of limbic nuclei. Concepts of network organization derived from computational neuroscience may aid our understanding of the links between the neuroanatomical circuitry and what is represented by the anatomy. Research in my laboratory uses mating behavior in the male Syrian hamster as a model to elucidate how chemosensory and steroid cues are integrated in the brain. An interaction of odors and hormones is required for mating in this species. These two essential stimuli are transmitted through separate parallel pathways in the limbic system. The functional organization of the hamster mating behavior circuit is characterized by distributed representation, divergent and convergent neural pathways, and recurrent feedback. Odors and hormones have different modes of action on this neural network. While chemosensory cues stimulate the input units of the network, steroids facilitate behavior through the hidden units. In this manner, steroids appear to create a permissive environment for subsequent activation by odor cues.}
}
@article{ZHOU2024108310,
title = {The neuroanatomical correlates of daily habitual tendencies and mediating effect on the association between daily habitual tendencies and symptoms of behavioral addictions},
journal = {Computers in Human Behavior},
volume = {158},
pages = {108310},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108310},
url = {https://www.sciencedirect.com/science/article/pii/S074756322400178X},
author = {Xinqi Zhou and Qi Liu and Lan Wang and Xianyang Gan and Ran Zhang and Xiqin Liu and Guojuan Jiao and Christian Montag and Weihua Zhao and Benjamin Becker},
keywords = {Habit, Gray matter, vmPFC, Precuneus, Internet gaming disorder, Smartphone use},
abstract = {Habitual behaviors significantly shape our daily actions. Furthermore, habit formation is proposed as a key mechanism contributing to the development and maintenance of addiction. However, the neural substrates underlying daily habitual tendencies and their contribution to behavioral addiction symptoms in everyday life remain poorly understood. To explore these questions, we conducted a comprehensive analysis of data from 219 individuals who underwent neuroimaging (structural MRI) assessments alongside evaluations of their daily habitual tendencies and symptoms of Internet Gaming Disorder (IGD) and Problematic Smartphone Use (PSU). Using voxel-based morphometry, meta-analytic decoding, and mediation analysis, we found that daily habitual tendencies were positively correlated with larger gray matter volumes in the ventromedial prefrontal cortex (vmPFC), precuneus, superior frontal gyrus (SFG), inferior temporal gyrus (ITG), and supplementary motor area (SMA). Notably, the midline regions, including the vmPFC and precuneus, play a crucial role in value-based computation, emotional regulation, social cognition, and self-referential thinking. Individual variations in gray matter volumes within these regions served as mediators, influencing the bidirectional relationship between daily habitual tendencies and IGD symptoms. However, vmPFC variations were specifically found to mediate the pathway from PSU to daily habitual tendencies. Our findings suggest that the morphological architecture of the vmPFC and precuneus is associated with habitual tendencies in daily life and may mediate the development of addictive behaviors. This study contributes to a more nuanced understanding of the neuroanatomical basis of daily habitual tendencies and their role in addictive behaviors.}
}
@article{BUCKER20031309,
title = {Parallel programming in computational science: an introductory practical training course for computer science undergraduates at Aachen University},
journal = {Future Generation Computer Systems},
volume = {19},
number = {8},
pages = {1309-1319},
year = {2003},
note = {Selected papers from the Workshop on Education in Computational Sciences held at the International Conference on Computational Science},
issn = {0167-739X},
doi = {https://doi.org/10.1016/S0167-739X(03)00089-X},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X0300089X},
author = {H.M. Bücker and B. Lang and C.H. Bischof},
keywords = {Parallel programming, Java, Computational science and engineering, Education},
abstract = {Parallel programming of high-performance computers has emerged as a key technology for the numerical solution of large-scale problems arising in computational science and engineering (CSE). The authors believe that principles and techniques of parallel programming are among the essential ingredients of any CSE as well as computer science curriculum. Today, opinions on the role and importance of parallel programming are diverse. Rather than seeing it as a marginal beneficial skill optionally taught at the graduate level, we understand parallel programming as crucial basic skill that should be taught as an integral part of the undergraduate computer science curriculum. A practical training course developed for computer science undergraduates at Aachen University is described. Its goal is to introduce young computer science students to different parallel programming paradigms for shared and distributed memory computers as well as to give a first exposition to the field of computational science by simple, yet carefully chosen sample problems.}
}
@article{ZHANG2024117045,
title = {A bidirectional collaborative method based on an improved artificial fish swarm algorithm for ship pipe and equipment layout design},
journal = {Ocean Engineering},
volume = {296},
pages = {117045},
year = {2024},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2024.117045},
url = {https://www.sciencedirect.com/science/article/pii/S0029801824003822},
author = {Hongshuo Zhang and Yanyun Yu and Qiaoyu Zhang and Yuansong Yang and Haiyang Liu and Yan Lin},
keywords = {Collaborative optimization, Ship engine room layout design, Multi-strategy heuristic algorithm, Hybrid-objective optimization, Coding technique, Automation design},
abstract = {Ship engine room layout design (SERLD) significantly impacts a ship's transportation efficiency and safety by focusing on the layouts of equipment and piping. However, owing to complex constraints, previous research has mainly focused on single-dimensional layout designs and has failed to provide comprehensive references for designers. To address this research gap, this study proposes a collaborative layout method based on a multistrategy hybrid-objective artificial fish swarm algorithm (HMSAFSA). In terms of the underlying mathematical representation, a more stable Manhattan trajectory-based coding method suitable for a collaborative layout is proposed. Building on this coding method, multiple strategies are incorporated into the heuristic AFSA to enhance its optimization and collaborative performance. Collaborative evaluation functions and methods are designed and refined to ensure effective layout results for multiple objectives. Furthermore, a layout procedure incorporating bidirectional guidance strategies and hierarchical thinking is proposed. This method achieves collaborative layouts through the mutual guidance of optimal objectives. Finally, the effectiveness of the proposed method is verified through representative cases of various types of ship engine rooms in practical engineering. The method demonstrates its capability to offer multiple optimal layout schemes, thus presenting substantial value for practical engineering designs.}
}
@article{YU2025110799,
title = {An adaptive incremental solution scheme for the phase field model of fracture},
journal = {Engineering Fracture Mechanics},
volume = {315},
pages = {110799},
year = {2025},
issn = {0013-7944},
doi = {https://doi.org/10.1016/j.engfracmech.2024.110799},
url = {https://www.sciencedirect.com/science/article/pii/S0013794424009627},
author = {Yuanfeng Yu and Chi Hou and Timon Rabczuk and Meiying Zhao},
keywords = {Fracture, Phase field model, Solution scheme, Adaptive increment, Computational time},
abstract = {To increase the phase field model’s computational effectiveness, an efficient and robust adaptive incremental solution scheme is presented in this work. Firstly, a time field change criterion is established based on the variation of phase field variable and its increment, so that the pseudo time increment and load increment can be adaptively regulated with the solution of displacement and phase fields, which cuts down on computation time and the number of iterations. Secondly, the implementation of the scheme is introduced. Finally, the effectiveness of proposed solution scheme is tested through some numerical examples. The results showcase that the proposed strategy can not only acquire accurate load–displacement responses and crack patterns, but also significantly reduce the computational cost. By comparing with the current standard staggered strategy and the monolithic BFGS strategy, the computation time of the presented solution scheme is about 1% of that of the standard strategy, and less than 1/3 of the time of the BFGS strategy. Meanwhile, the presented scheme also exhibits excellent convergence properties.}
}
@article{EGUCHI2016692,
title = {RoboCupJunior for promoting STEM education, 21st century skills, and technological advancement through robotics competition},
journal = {Robotics and Autonomous Systems},
volume = {75},
pages = {692-699},
year = {2016},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2015.05.013},
url = {https://www.sciencedirect.com/science/article/pii/S0921889015001281},
author = {Amy Eguchi},
keywords = {Educational robotics, Robotics competitions, STEM education, Computational thinking, Engineering skills, 21st century skills},
abstract = {RoboCupJunior is an international educational robotics initiative, aiming to promote STEM content and skill learning among participating youth through educational robotics competition inaugurated in 2000. What makes RoboCupJunior quite unique is its relationship with RoboCup which aims to promote robotics and AI research, by offering a publicly appealing, but formidable challenge including development of soccer robots, search and rescue robots, and robots functions at home and at work. This paper introduces a case of RoboCupJunior and the effectiveness of its practice for enhancing learning of STEM contents and skills for innovation and creativity among participating students. It presents the survey results from one of the World Championships held in 2012, the anecdotal and personal account of participating US students on their learning experience from their participation in 2013 World Championship, and participating students’ technological and innovative contributions to highlight the impacts RoboCupJunior has had through over a decade of its practice.}
}
@article{ONTIVEROSARAIZA2025105361,
title = {The Neurobehavioral State hypothesis},
journal = {BioSystems},
volume = {247},
pages = {105361},
year = {2025},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2024.105361},
url = {https://www.sciencedirect.com/science/article/pii/S0303264724002466},
author = {Luis Fernando Ontiveros-Araiza},
keywords = {Brain networks, Neuronal dynamics, Neural code, Neurotransmitter, Electrophysiology, Neuronal computation, Behavior},
abstract = {Since the early attempts to understand the brain made by Greek philosophers more than 2000 years ago, one of the main questions in neuroscience has been how the brain perceives all the stimuli in the environment and uses this information to implement a response. Recent hypotheses of the neural code rely on the existence of an ideal observer, whether on specific areas of the cerebral cortex or distributed network composed of cortical and subcortical elements. The Neurobehavioral State hypothesis stipulates that neurons are in a quasi-stable state due to the dynamic interaction of their molecular components. This increases their computational capabilities and electrophysiological behavior further than a binary active/inactive state. Together, neuronal populations across the brain learn to identify and associate internal and external stimuli with actions and emotions. Furthermore, such associations can be stored through the regulation of neuronal components as new quasi-stable states. Using this framework, behavior arises as the result of the dynamic interaction between internal and external stimuli together with previously established quasi-stable states that delineate the behavioral response. Finally, the Neurobehavioral State hypothesis is firmly grounded on present evidence of the complex dynamics within the brain, from the molecular to the network level, and avoids the need for a central observer by proposing the brain configures itself through experience-driven associations.}
}
@article{ZHANG2023100528,
title = {Foreign language effect in accounting uncertainty expressions: Interpretation and probabilistic estimation},
journal = {Journal of International Accounting, Auditing and Taxation},
volume = {50},
pages = {100528},
year = {2023},
issn = {1061-9518},
doi = {https://doi.org/10.1016/j.intaccaudtax.2023.100528},
url = {https://www.sciencedirect.com/science/article/pii/S1061951823000071},
author = {Yuqian Zhang and Anura {De Zoysa} and Corinne Cortese},
keywords = {Foreign language effect, Uncertainty expressions, Probability estimation, Accounting judgement, Interpretation},
abstract = {The foreign language effect, or thinking in a foreign language, reduces judgment bias under uncertainty. This study investigates how language use (native versus foreign) affects accounting judgment on uncertainty expressions. We conducted two separate experiments: between-subjects and within-subjects, both of which included tasks requiring interpretations and probability estimations based on accounting standard uncertainty expressions. The results demonstrated that foreign language use affected the interpretation of uncertainty expressions and reduced judgment bias in probability estimation, particularly in the context of asset recognition. These findings have important implications for accounting research and reporting.}
}
@article{LEVYGARBOUA2024102438,
title = {Creative cognition as a bandit problem},
journal = {Learning and Individual Differences},
volume = {111},
pages = {102438},
year = {2024},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2024.102438},
url = {https://www.sciencedirect.com/science/article/pii/S1041608024000311},
author = {Louis Lévy-Garboua and Marco Gazel and Noémi Berlin and Jan Dul and Todd Lubart},
keywords = {Creative cognition, Multi-armed bandit problem, Education and creativity, Individual differences in creative potential, Adolescents' behavior},
abstract = {This paper draws a parallel between creative cognition and a multi-armed bandit problem involving learning from experience in an uncertain environment. Special emphasis is put on the optimal sequencing of divergent and convergent behavior by showing that divergence must be inhibited at one point to converge toward creative behavior so that excessive divergence is counterproductive. We test this hypothesis with a behavioral experiment, using measures of individual divergence and convergence components of creative potential in high school students. Results confirmed that a mix of divergence and convergence predicted high performance in a bandit task but not in a purely random task or in a simple repetitive task. These predictions are maintained after controlling for sex, personality, incentives, and other factors. As hypothesized, creative cognition was necessary for high performance under the appropriate conditions. However, it was not necessary to get high grades in a traditional school system.
Educational relevance statement
Relating to the goal of educators and public policies in the 21st century to make children and adolescents more creative, and schools more receptive to creative thinking, this research focuses on the creative potential and behavior of high school students. It provides an evidence-based policy argument in support of the screening and development by the educational sector of the creative potential of students.}
}
@incollection{KARACA2022149,
title = {Chapter 9 - Computational fractional-order calculus and classical calculus AI for comparative differentiability prediction analyses of complex-systems-grounded paradigm},
editor = {Yeliz Karaca and Dumitru Baleanu and Yu-Dong Zhang and Osvaldo Gervasi and Majaz Moonis},
booktitle = {Multi-Chaos, Fractal and Multi-Fractional Artificial Intelligence of Different Complex Systems},
publisher = {Academic Press},
pages = {149-168},
year = {2022},
isbn = {978-0-323-90032-4},
doi = {https://doi.org/10.1016/B978-0-323-90032-4.00006-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780323900324000067},
author = {Yeliz Karaca and Dumitru Baleanu},
keywords = {Complexity, Artificial neural network, Classical calculus, Computational complexity, Data-driven fractional modeling, Differentiability prediction analyses, Fractional calculus, Mathematical biology and neuroscience, Mittag-Leffler function, Optimized fractional-order calculus},
abstract = {Modern science having embarked on the thorough and accurate interpretation of natural and physical phenomena has proven to provide successful models for the analysis of complex systems and harnessing of control over the various processes therein. Computational complexity, in this regard, comes to the foreground by providing applicable sets of ideas or integrative paradigms to recognize and understand the complex systems' intricate properties. Thus, while making the appropriate, adaptable and evolutive decisions in complex dynamic systems, it is essential to acknowledge different degrees of acceptance of the problems and construct the model it to account for its inherent constraints or limits. In this respect, while hypothesis-driven research has its inherent limitations regarding the investigation of multifactorial and heterogeneous diseases, a data-driven approach enables the examination of the way variables impact one another, which paves the way for the interpretation of dynamic and heterogeneous mechanisms of diseases. Fractional Calculus (FC), in this scope characterized by complexity, provides the applicable means and methods to solve integral, differential and integro-differential equations so FC enables the generalization of integration and differentiation possible in a flexible and consistent manner owing to its capability of reflecting the systems' actual state properties, which exhibit unpredictable variations. The fractional integration and differentiation of fractional-order is capable of providing better characterization of nonstationary and locally self-similar attributes in contrast to constant-order fractional calculus. It becomes possible to model many complex systems by fractional-order derivatives based on fractional calculus so that related syntheses can be realized in a robust and effective way. To this end, our study aims at providing an intermediary facilitating function both for the physicians and individuals by establishing accurate and robust model based on the integration of fractional-order calculus and Artificial Neural Network (ANN) for the diagnostic and differentiability predictive purposes with the diseases which display highly complex properties. The integrative approach we have proposed in this study has a multistage quality the steps of which are stated as follows: first of all, the Caputo fractional-order derivative, one of the fractional-order derivatives, has been used with two-parametric Mittag-Leffler function on the stroke dataset and cancer cell dataset, manifesting biological and neurological attributes. In this way, new fractional models with varying degrees have been established. Mittag-Leffler function, with its distributions of extensive application domains, can address irregular and heterogeneous environments for the solution of dynamic problems; thus, Mittag-Leffler function has been opted for accordingly. Following this application, the new datasets (mlf_stroke dataset and mlf_cancer cell dataset) have been obtained by employing Caputo fractional-order derivative with the two-parametric Mittag-Leffler function (α,β). In addition, classical derivative (calculus) was applied to the raw datasets; and cd_stroke dataset and cd_cancer cell dataset were obtained. Secondly, the performance of the new datasets as obtained from the Caputo fractional derivative with the two-parametric Mittag-Leffler function, the datasets obtained from the classical derivative application and the raw datasets have been compared by using feed forward back propagation (FFBP) algorithm, one of the algorithms of ANN (along with accuracy rate, sensitivity, precision, specificity, F1-score, multiclass classification (MCC), ROC curve). Based on the accuracy rate results obtained from the application with FFBP, the Caputo fractional-order derivative model that is most suitable for the diseases has been generated. The experimental results obtained demonstrate the applicability of the complex-systems-grounded paradigm scheme as proposed through this study, which has no existing counterpart. The integrative multi-stage method based on mathematical-informed framework with comparative differentiability prediction analyses can point toward a new direction in the various areas of applied sciences to address formidable challenges of critical decision making and management of chaotic processes in different complex dynamic systems.}
}
@article{CHIEN2009965,
title = {An efficient computational procedure for determining the container-loading pattern},
journal = {Computers & Industrial Engineering},
volume = {56},
number = {3},
pages = {965-978},
year = {2009},
note = {Intelligent Manufacturing and Logistics},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2008.09.019},
url = {https://www.sciencedirect.com/science/article/pii/S036083520800226X},
author = {Chen-Fu Chien and Chia-Yen Lee and Yi-Chao Huang and Wen-Ting Wu},
keywords = {Global logistics, Container-loading, Cutting and packing, Three-dimension knapsack, Decision support system},
abstract = {Supply chain and global logistics are driven by strategically focusing on core competences, outsourcing manufacturing to pursue higher value proposition in the supply chain, radically improving the return of capital investments and providing total solutions to targeted customers. The container-loading research has important industrial and commercial application for global logistics. In practice, loading pooled shipment into containers is a complex procedure that has relied largely on the workers’ experience. We developed an efficient computational procedure involving three-dimensional cutting for determining near-optimal container-loading patterns to minimize the waste of container space. We used numerical examples from a motor company that imports key components from Japan, produces parts in Taiwan, and assembles cars in China to estimate its validity and discussed the effectiveness of the proposed solution. This study concludes with a discussion of future research.}
}
@incollection{HANSKORTELING2022610,
title = {Cognitive Biases},
editor = {Sergio {Della Sala}},
booktitle = {Encyclopedia of Behavioral Neuroscience, 2nd edition (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {610-619},
year = {2022},
isbn = {978-0-12-821636-1},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.24105-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245241059},
author = {J.E. {(Hans) Korteling} and Alexander Toet},
keywords = {Cognitive biases, Cognitive neuroscience, Decision making, Dual process theory, Expertise, Evolutionary psychology, Heuristics, Information processing capacity, Intuition, Neural networks, Rationality},
abstract = {Cognitive biases are systematic cognitive dispositions or inclinations in human thinking and reasoning that often do not comply with the tenets of logic, probability reasoning, and plausibility. These intuitive and subconscious tendencies are at the basis of human judgment, decision making, and the resulting behavior. Psychological frameworks consider biases as resulting from the use of (inappropriate) cognitive heuristics that people apply to deal with data-limitations, from information processing limitations, or from a lack of expertise. Neuro-evolutionary frameworks provide a more profound explanation of biases as originating from the inherent design characteristics of our brain as a neural network that was primarily developed to perform basic physical, perceptual and motor functions, and which also had to promote the survival of our hunter-gatherer ancestors.}
}
@article{TSENG2025106570,
title = {Exploring artificial intelligence literacy and the use of ChatGPT and copilot in instruction on nursing academic report writing},
journal = {Nurse Education Today},
volume = {147},
pages = {106570},
year = {2025},
issn = {0260-6917},
doi = {https://doi.org/10.1016/j.nedt.2025.106570},
url = {https://www.sciencedirect.com/science/article/pii/S026069172500005X},
author = {Li-Ping Tseng and Li-Ping Huang and Wei-Ru Chen},
keywords = {Artificial intelligence literacy, Nursing education, ChatGPT, Copilot, Academic report writing, Scaffolding teaching, Artificial intelligence},
abstract = {Background
Nursing education increasingly emphasizes academic writing and communication, critical for delivering quality patient care and professional advancement. Rapidly emerging artificial intelligence (AI) tools such as ChatGPT and Copilot are transforming educational methodologies, and a focus is being placed on embedding AI literacy to effectively bridge the gap between theoretical knowledge and clinical practice. These technologies have the potential to reshape nursing education in a technology-driven health-care landscape.
Aim
This study investigated the effectiveness of AI literacy and the application of ChatGPT and Copilot in academic nursing report writing. It assessed the level of AI literacy of nursing students, examined the integration of basic AI concepts into a curriculum, and analyzed the impact of these tools compared with traditional teaching methods.
Methods
The study adopted a sample of 203 senior nursing students from Southern Taiwan to compare an AI-enhanced teaching approach using ChatGPT and Copilot with conventional methods. The curriculum, centered on the “Writing Case Reports and Seminars” course, employed the Analyze, Design, Develop, Implement, Evaluate model and incorporated scaffolding techniques to synergistically integrate clinical skills with academic learning. AI literacy was measured using the Meta AI Literacy Scale (MAILS). Summative assessments, adhering to the Taiwan Nursing Association standards, focused on individual and group case report evaluations.
Findings
Following an 18-week AI intervention, the experimental group demonstrated significant improvements in all dimensions of the MAILS. A ChatGPT usage of 100 % was found, with a notable enhancement discovered in the “Nursing Plan” section of case reports. Although the experimental group outperformed the control group in overall case report evaluations, the connections between identified problems and proposed plans were weaker and nursing interventions tended to be less individualized for the experimental group.
Conclusions
The incorporation of AI tools such as ChatGPT and Copilot into a scaffolding teaching framework significantly boosted students' AI literacy and performance in summative assessments. Effective AI training for students, supervised use of these tools, and continuous professional development for educators are paramount to successful implementation. Addressing the current limitations of AI has the potential to further improve academic writing, foster critical thinking, and ensure responsible application in patient care, ultimately leading to higher-quality and more effective nursing education.}
}
@article{CEKMIS2014115,
title = {A computational model for accommodating spatial uncertainty: Predicting inhabitation patterns in open-planned spaces},
journal = {Building and Environment},
volume = {73},
pages = {115-126},
year = {2014},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2013.11.023},
url = {https://www.sciencedirect.com/science/article/pii/S0360132313003430},
author = {Aslı Çekmiş and Işıl Hacıhasanoğlu and Michael J. Ostwald},
keywords = {Fuzzy logic, Fuzzy set, Spatial uncertainty, Occupancy prediction, Open-planned spaces},
abstract = {In the past, a range of computational models have been developed for analysing the social implications of spatial patterns and types. While such models are typically focussed on macro-patterns, often in cellular or linearly-organised spaces, few models exist for predicting where people will cluster within complex environments. One reason for this relates to the inherent uncertainty associated with spatial attributes and consequently of human spatial behaviours. The present paper draws on the concept of fuzzy spatial objects to develop an approach to handle such uncertainty in architecture. Focussing on large, open plan spaces, where the configuration of space does not define strict patterns of usage, the paper proposes a computational model for predicting patterns of spatial inhabitation. This new model relies on the theory of fuzzy sets to propose the existence of a “fuzzy architectural spatial object, (FASO)” which is comprised of spatial units with degrees of membership that reflect the possibility of a person being present in a sub-space or involved in a sub-function within a larger space. This model calculates and visualises the FASOs using a fuzzy inference engine and represents the space as distributed possibilities of presence according to the given data. After describing the model the paper demonstrates its application in the prediction of patterns of usage within a major exhibition space, and then presents a check of the efficacy of this prediction against the actual inhabitation of the space.}
}
@article{STEPHENS200833,
title = {What “counts” as algebra in the eyes of preservice elementary teachers?},
journal = {The Journal of Mathematical Behavior},
volume = {27},
number = {1},
pages = {33-47},
year = {2008},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2007.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0732312307000594},
author = {Ana C. Stephens},
keywords = {Algebra, Elementary mathematics, Teacher conceptions},
abstract = {This study examined conceptions of algebra held by 30 preservice elementary teachers. In addition to exploring participants’ general “definitions” of algebra, this study examined, in particular, their analyses of tasks designed to engage students in relational thinking or a deep understanding of the equal sign as well as student work on these tasks. Findings from this study suggest that preservice elementary teachers’ conceptions of algebra as subject matter are rather narrow. Most preservice teachers equated algebra with the manipulation of symbols. Very few identified other forms of reasoning – in particular, relational thinking – with the algebra label. Several participants made comments implying that student strategies that demonstrate traditional symbol manipulation might be valued more than those that demonstrate relational thinking, suggesting that what is viewed as algebra is what will be valued in the classroom. This possibility, along with implications for mathematics teacher education, will be discussed.}
}
@article{FERNANDEZCABALLERO2003341,
title = {Lateral interaction in accumulative computation: a model for motion detection},
journal = {Neurocomputing},
volume = {50},
pages = {341-364},
year = {2003},
issn = {0925-2312},
doi = {https://doi.org/10.1016/S0925-2312(02)00571-4},
url = {https://www.sciencedirect.com/science/article/pii/S0925231202005714},
author = {Antonio Fernández-Caballero and José Mira Mira and Ana E. Delgado and Miguel A. {Fernández Graciani}},
keywords = {Accumulative computation, Lateral interaction, Double time scale, Motion detection, Image sequences},
abstract = {Some of the major computer vision techniques make use of neural nets. In this paper we present a novel model based on neural networks denominated lateral interaction in accumulative computation (LIAC). This model is based on a series of neuronal models in one layer, namely the local accumulative computation model, the double time scale model and the recurrent lateral interaction model. The LIAC model usefulness in the general task of motion detection may be appreciated by means of some significant examples of object detection in indefinite sequences of synthetic and real images.}
}
@article{OSINGA2022103298,
title = {Big data in agriculture: Between opportunity and solution},
journal = {Agricultural Systems},
volume = {195},
pages = {103298},
year = {2022},
issn = {0308-521X},
doi = {https://doi.org/10.1016/j.agsy.2021.103298},
url = {https://www.sciencedirect.com/science/article/pii/S0308521X21002511},
author = {Sjoukje A. Osinga and Dilli Paudel and Spiros A. Mouzakitis and Ioannis N. Athanasiadis},
keywords = {Big data solutions, Precision Agriculture, Case study, Stakeholders, Technological maturity level, Mixed-method approach},
abstract = {CONTEXT
Big data applications in agriculture evolve fast, as more experience, applications, good practices and computational power become available. Actual solutions to real-life problems are scarce. What characterizes the adoption of big data problems to solutions and to what extent is there a match between them?
OBJECTIVE
We aim to assess the conditions of the adoption of big data technologies in agricultural applications, based on the investigation of twelve real-life practical use cases in the precision agriculture and livestock domain.
METHODS
We use a mixed method approach: a case study research around the twelve use cases of Horizon 2020 project CYBELE, varying from precision arable and livestock farming to fishing and food security, and a stakeholder survey (n = 56). Our analysis focuses on four perspectives: (1) the drivers of change that initiated the use cases; (2) the big data characteristics of the problem; (3) the technological maturity level of the solution both at start and end of the project; (4) the stakeholder perspective.
RESULTS AND CONCLUSIONS
Results show that the use cases’ drivers of change are a combination of data-, technology, research- and commercial interests; most have at least a research drive. The big data characteristics (volume, velocity, variety, veracity) are well-represented, with most emphasis on velocity and variety. Technology readiness levels show that the majority of use cases started at experimental or lab environment stage and aims at a technical maturity of real-world small-scale deployment. Stakeholders’ main concern is cost, user friendliness and to embed the solution within their current work practice. The adoption of better-matching big data solutions is modest. Big data solutions do not work out-of-the-box when changing application domains. Additional technology development is needed for addressing the idiosyncrasies of agricultural applications.
SIGNIFICANCE
We add a practical, empirical assessment of the current status of big data problems and solutions to the existing body of mainly theoretical knowledge. We considered the CYBELE research project as our laboratory for this. Our strength is that we interviewed the use case representatives in person, and that we included the stakeholders’ perspective in our results. Large-scale deployments need effective interdisciplinary approaches and long-term project horizons to address issues emerging from big data characteristics, and to avoid compartmentalization of agricultural sciences. We need both an engineering perspective – to make things work in practice – and a systems thinking perspective – to offer holistic, integrated solutions.}
}
@article{BEHARA2009195,
title = {Parallel finite element computation of incompressible flows},
journal = {Parallel Computing},
volume = {35},
number = {4},
pages = {195-212},
year = {2009},
issn = {0167-8191},
doi = {https://doi.org/10.1016/j.parco.2008.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167819108001348},
author = {Suresh Behara and Sanjay Mittal},
keywords = {Navier–Stokes equations, Parallel computing, Superlinear speedup, Wake, Transition, Wake instabilities},
abstract = {A stabilized finite element formulation for three-dimensional unsteady incompressible flows is implemented on a distributed memory parallel computer. A matrix-free version of the GMRES algorithm is utilized to solve the equation systems in an implicit manner. The scalability of the computations on a 64-processor Linux cluster is evaluated for moderate to large size problems. A method for estimating the speedup for large-scale problems, where computations on a single processor is not possible, is proposed. Superlinear speedup is observed, perhaps for the first time, for a large-scale problem that is associated with more than 44 million nodes and 176 million equations. The performance of the various subactivities of the program is monitored to investigate the cause. It is found that the formation of the RHS vector and the preconditioner achieves a very high level of superlinear speedup as the number of processors increase. As a result, even though the network time for interprocessor communication increases with increase in processors, an overall superlinear speedup is realized for large-scale problems. The superlinear speedup is attributed to cache related effects. A comparison between the performance of matrix and matrix-free versions of the GMRES algorithm is carried out. It is found that for large-scale applications the matrix-free version outperforms its counterpart for reasonable dimensions of the Kyrylov subspace. The effect of mesh partitioning on the scalability is also studied. A significant reduction in communication time is observed with partitioning that leads to an overall improvement of speedup. The parallel implementation is utilized to study the wake instabilities in flow past a stationary circular cylinder at Re=150, 200 and 300. The Re=150 flow is found to be two-dimensional while mode-A and mode-B instabilities are observed at Re=200 and 300, respectively. The Re=300 flow is associated with a low frequency modulation in addition to the vortex shedding frequency.}
}
@article{REGGIO2002459,
title = {Computational analysis of the process for manufacturing seamless tubes},
journal = {Applied Thermal Engineering},
volume = {22},
number = {4},
pages = {459-470},
year = {2002},
issn = {1359-4311},
doi = {https://doi.org/10.1016/S1359-4311(01)00093-X},
url = {https://www.sciencedirect.com/science/article/pii/S135943110100093X},
author = {M. Reggio and F. McKenty and Luc Gravel and J. Cortes and G. Morales and M.-A. {Ladron de Guevara}},
keywords = {Seamless tube, Heat transfer, Computational simulation, CFD},
abstract = {A computer simulation of the transient three-dimensional heat transfer process occurring during the manufacturing of seamless tubes carried out by TAMSA, Tubos de Acero de Mexico, is reported. The work was performed by a team which combines Canadian and Mexican researchers and comprises both experimental and computational aspects. The Mexican team concentrated its efforts on experimentally investigating the metallurgical pattern of the mandrel, while the Canadian team devoted its time to the computer simulation and analysis of heat transfer and flow processes. In this paper, only the latter part is presented. The numerical simulation uses the Star-CD commercial CFD software package which is based on the finite volume methodology. The results show the importance of the cooling water channel configuration in relation to the mandrel temperature distribution and resulting metallurgical structure.}
}
@incollection{ROZINAJOVA201823,
title = {Chapter 2 - Computational Intelligence in Smart Grid Environment},
editor = {Arun Kumar Sangaiah and Michael Sheng and Zhiyong Zhang},
booktitle = {Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications},
publisher = {Academic Press},
pages = {23-59},
year = {2018},
series = {Intelligent Data-Centric Systems},
isbn = {978-0-12-813314-9},
doi = {https://doi.org/10.1016/B978-0-12-813314-9.00002-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128133149000025},
author = {Viera Rozinajová and Anna Bou Ezzeddine and Marek Lóderer and Jaroslav Loebl and Róbert Magyar and Petra Vrablecová},
keywords = {Smart grid, Intelligent data analysis, Computational intelligence, Power load prediction, Optimization, Bio-inspired algorithms, Ensemble models, Support vector regression},
abstract = {This chapter presents one way of incorporating computational intelligence into smart grid environment. We introduce an energy ecosystem, where contemporary technologies are used and by involving advanced methods of data analysis and optimization, we aim to ensure its effective operation. In order to schedule reliable energy supply, the prediction models for power load consumption and for energy spot prices are inevitable. We provide an overview of forecasting and optimization methods and propose solutions, which deal with stream and online processing as well as adaptivity of the proposed solutions. Several different prediction methods including statistical methods and computational intelligence methods, as well as our proposed ensemble and online SVR method are compared. We take into account the current trends of distributed energy generation from renewable sources and anticipate massive usage of electro vehicles in the near future, where the optimization of the whole environment is needed.}
}
@article{TETEWSKY1986202,
title = {Conceptual and lexical determinants of nonentrenched thinking},
journal = {Journal of Memory and Language},
volume = {25},
number = {2},
pages = {202-225},
year = {1986},
issn = {0749-596X},
doi = {https://doi.org/10.1016/0749-596X(86)90030-6},
url = {https://www.sciencedirect.com/science/article/pii/0749596X86900306},
author = {Sheldon J Tetewsky and Robert J Sternberg},
abstract = {Two experiments investigating information-processing consequences of entrenched and nonentrenched concepts are reported. An attempt is made to distinguish between these two kinds of concepts by using two variables—the naturalness of the occurrence described by a concept and the familiarity of the name used to refer to that occurrence. In each experiment a given conceptual system was expressed in four alternative forms by crossing concept familiarity (naturalness) with lexical familiarity. The experiments used a concept-selection task in which subjects were required to characterize an event based on a preliminary piece of information and a final, confirmatory piece of information. The results indicated that the locus of nonentrenchment lies in using a familiar name to identify an unfamiliar occurrence or in using an unfamiliar name to identify a familiar occurrence. An information-processing model of task performance provided a very good account of the latency data and scores from the concept-selection task correlated with scores from a set of psychometric reasoning tests. The distinction between entrenched and nonentrenched concepts can be interpreted in terms of interference theory, and it also has implications for the way we think about induction and human intelligence.}
}
@article{SHAHID2019638,
title = {Computational intelligence techniques for medical diagnosis and prognosis: Problems and current developments},
journal = {Biocybernetics and Biomedical Engineering},
volume = {39},
number = {3},
pages = {638-672},
year = {2019},
issn = {0208-5216},
doi = {https://doi.org/10.1016/j.bbe.2019.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S0208521619300452},
author = {Afzal Hussain Shahid and M.P. Singh},
keywords = {Computational intelligence, Disease diagnosis, Prediction, Detection, Uncertainty, Medical data},
abstract = {Diagnosis, being the first step in medical practice, is very crucial for clinical decision making. This paper investigates state-of-the-art computational intelligence (CI) techniques applied in the field of medical diagnosis and prognosis. The paper presents the performance of these techniques in diagnosing different diseases along with the detailed description of the data used. This paper includes basic as well as hybrid CI techniques that have been used in recent years so as to know the current trends in medical diagnosis domain. The paper presents the merits and demerits of different techniques in general as well as application specific context. This paper discusses some critical issues related to the medical diagnosis and prognosis such as uncertainties in the medical domain, problems in the medical data especially dealing with time-stamped (temporal) data, and knowledge acquisition. Moreover, this paper also discusses the features of good CI techniques in medical diagnosis. Overall, this review provides new insight for future research requirements in the medical diagnosis domain.}
}
@article{LIU2025101664,
title = {Interdigitated microband electrode arrays in paired organic electrosyntheses: Sustainability and practicality},
journal = {Current Opinion in Electrochemistry},
volume = {50},
pages = {101664},
year = {2025},
issn = {2451-9103},
doi = {https://doi.org/10.1016/j.coelec.2025.101664},
url = {https://www.sciencedirect.com/science/article/pii/S2451910325000237},
author = {Tingran Liu and Taku Suzuki-Osborne and James E. Taylor and Frank Marken},
abstract = {Electrochemical synthesis is well established for production of bulk commodities such as copper, aluminium, or ethylene oxide, but electrosynthesis could play an increasingly important role also in a broader range of organic and pharmaceutical syntheses. Electrochemical transformations linked to renewable electricity offer a low-carbon low-waste alternative to traditional chemical reactions (sustainability), although more work is needed to establish processes and reactor technology for easy implementation (practicality). Here, the application of interdigitated microband array electrodes (in conjunction with computational methods) is discussed/contrasted as a tool to (i) avoid the use of added supporting electrolyte, (ii) achieve anode–cathode process pairing, and (iii) allow very simple reactor technology to be introduced compatible with existing chemical reactionware.}
}
@article{SHI2024e35268,
title = {3D dynamic landscape simulation of artificial intelligence in environmental landscape design},
journal = {Heliyon},
volume = {10},
number = {15},
pages = {e35268},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e35268},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024112996},
author = {Binbin Shi},
keywords = {Artificial intelligence, Environmental landscape design, Fuzzy analytical hierarchical process, Geographical information system, 3D dynamic landscape, Interactive design system},
abstract = {Three-dimensional (3D) simulations and precise landscape visualizations are crucial for various applications, like landscape management and planning, computer and connection of the landscape, evaluation, and tracking of land use. The consequences of several plans and a large scene cannot be communicated using older methods of comprehensive environmental planning and development in a timely, rational, and coordinated manner. Architects have trouble incorporating ideas into other comprehensive planning implementation processes. Architects did not thoroughly investigate the neighbourhood's demographics and matching behavioural needs and lacked critical thinking. The 3D dynamic landscape simulation is a detailed computerized three-dimensional simulation of the environment that can be dynamically presented. With the aid of Artificial Intelligence (AI) technology, the system possesses a strong sense of reality, a user-friendly interface, and interactive features that can be tailored to the requirements of the contemporary urban environmental landscape. Regarding exterior publicity, domestic assistance, environmental land use planning, and information systems. The novelty of the proposed Interactive Design System based on AI (IDS-AI) is to create a 3D dynamic landscape model based on a real-life environmental scene, utilizing a Geographic Information System (GIS) to optimize landscape vision. Secondly, 3D environmental landscape design simulation was implemented using GIS spatial analysis in conjunction with the Fuzzy Analytical Hierarchical Process (FAHP) to reduce the data overlap rate and help make an accurate decision. Finally, the design incorporates the development of the interactive interface system application of landscape design and environmental resources for viewing the landscape, the factors that affect them, and the area coverage ratio of various land cover types. The experimental outcomes show that the suggested IDS model increases the gradient sensitivity level of 98.3 % and area coverage ratio of 93.4 % compared to other existing models.}
}
@incollection{ADAMS2016283,
title = {Chapter 16 - Brain Computations in Schizophrenia},
editor = {Ted Abel and Thomas Nickl-Jockschat},
booktitle = {The Neurobiology of Schizophrenia},
publisher = {Academic Press},
address = {San Diego},
pages = {283-295},
year = {2016},
isbn = {978-0-12-801829-3},
doi = {https://doi.org/10.1016/B978-0-12-801829-3.00024-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128018293000240},
author = {R.A. Adams and K.J. Friston},
keywords = {Schizophrenia, Bayesian brain, precision, aberrant salience, reversal, predictive coding, NMDAR, GABA, delusions},
abstract = {Because the brain performs Bayesian inference for the causes of its sensory data, the synaptic gain could encode the precision (inverse variance) of its beliefs using a hierarchical generative model and predictive coding. Several neurobiological risk factors for schizophrenia (NMDAR and GABAergic interneuron hypofunction) reduce both synaptic and “oscillatory” gain at high hierarchical areas. This could impair the encoding of precision at higher levels of the brain’s hierarchical model and increase expected precision at lower levels. This imbalance can account for many neurobiological and phenomenological findings in schizophrenia. Striatal D2R hyperactivity may increase the precision of current policies by inhibiting behavioral or cognitive switching. This could be a (dysfunctional) consequence of or even an attempt to compensate for prefrontal or hippocampal pathology. This D2R hyperactivity may also reduce learning from positive outcomes and affect the encoding of motivational (or informational) salience.}
}
@article{MA2024103893,
title = {Secure outsourced decryption for FHE-based privacy-preserving cloud computing},
journal = {Journal of Information Security and Applications},
volume = {86},
pages = {103893},
year = {2024},
issn = {2214-2126},
doi = {https://doi.org/10.1016/j.jisa.2024.103893},
url = {https://www.sciencedirect.com/science/article/pii/S2214212624001959},
author = {Xirong Ma and Chuan Li and Yuchang Hu and Yunting Tao and Yali Jiang and Yanbin Li and Fanyu Kong and Chunpeng Ge},
keywords = {Privacy-preserving computation, Outsourced computing, Homomorphic encryption},
abstract = {The demand for processing vast volumes of data has surged dramatically due to the advancement of machine learning technology. Large-scale data processing necessitates substantial computational resources, prompting individuals and enterprises to turn to cloud services. Accompanying this trend is a growing concern regarding data leakage and misuse. Homomorphic encryption (HE) is one solution for safeguarding data privacy, enabling encrypted data to be processed securely in the cloud. However, the encryption and decryption routines of some HE schemes require considerable computational resources, presenting non-trivial work for clients. In this paper, we propose an outsourced decryption protocol for the prevailing RLWE-based fully homomorphic encryption schemes. The protocol splits the original decryption into two routines, with the computationally intensive part executed remotely by the cloud. Its security relies on an invariant of the NTRU-search problem with a newly designed blinding key distribution. Cryptographic analyses are conducted to configure protocol parameters across varying security levels. Our experiments demonstrate that the proposed protocol achieves up to a 67% acceleration in the client-side computation, accompanied by a 50% reduction in space usage.}
}
@article{PANANGADEN201410,
title = {Causality in physics and computation},
journal = {Theoretical Computer Science},
volume = {546},
pages = {10-16},
year = {2014},
note = {Models of Interaction: Essays in Honour of Glynn Winskel},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2014.02.041},
url = {https://www.sciencedirect.com/science/article/pii/S0304397514001674},
author = {Prakash Panangaden},
keywords = {Causal structure, Event structure, Spacetime, Petri nets},
abstract = {Glynn Winskel has had enormous influence on the study of causal structure in computer science. In this brief note, I discuss analogous concepts in relativity where also causality plays a fundamental role. I discuss spacetime structure in a series of layers and emphasize the role of causal structure. I close with some comparisons between causality in relativity and in distributed computing systems.}
}
@article{SUTHAR202431,
title = {Practical exercises of computer-aided process synthesis for chemical engineering undergraduates},
journal = {Education for Chemical Engineers},
volume = {48},
pages = {31-43},
year = {2024},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2024.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S1749772824000071},
author = {Krunal J. Suthar and Aesha Mehta and Swapna Rekha Panda and Hitesh Panchal and Rakesh Sinha},
keywords = {computational tools, lifelong learning, laboratory learning, process synthesis},
abstract = {The study presents ten different exercises covering various computational tools. These exercises are practical applications presented to improve the understanding and skills of students in important concepts of chemical-aided process synthesis. A few exercises aim to build a foundation in computational techniques for chemical engineering undergraduates. The exercises are based on a spreadsheet that covers the design of regression analysis to find the optimum Antoine constants, array calculation for multicomponent distillation material balance, and the generation of a Gantt chart to plan and study the activities of batch processes. The other exercises included an introduction to process simulation, simulation, and reactor rating, and a simulation of multicomponent shortcut distillation. These exercises provide students with hands-on experience in utilizing process simulation software essential for analysing and optimizing chemical processes in real-world scenarios. The exercises also included the design of a heat exchanger network and solving a linear programming problem. An anonymous survey was collected from the cohort that had undergone the exercises, and the practical grades were compared with the batch that did not study the proposed exercises. Additionally, student feedback on practical exercises was collected. Based on the experience of the course coordinator and the collected feedback from participants, it was clear that the exercises helped students to inculcate critical thinking and self-learning abilities. An article essentially sheds light on the computer-aided practical exercises that enable chemical engineering graduates to engage in lifelong learning.}
}
@incollection{JOHNSON2009137,
title = {Embodied cognition of movement decisions: a computational modeling approach},
editor = {Markus Raab and Joseph G. Johnson and Hauke R. Heekeren},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {174},
pages = {137-150},
year = {2009},
booktitle = {Mind and Motion: The Bidirectional Link between Thought and Action},
issn = {0079-6123},
doi = {https://doi.org/10.1016/S0079-6123(09)01312-0},
url = {https://www.sciencedirect.com/science/article/pii/S0079612309013120},
author = {Joseph G. Johnson},
keywords = {attention, decision making, motor system},
abstract = {This chapter presents a cognitive computational view of decision making as the search for, and accumulation of, evidence for options under consideration. It is based on existing models that have been successful in traditional decision tasks involving preferential choice. The model assumes shifting attention over time that determines momentary inputs to an evolving preference state. In this chapter, the cognitive model is extended to illustrate how links from the motor system may be incorporated. These links can basically be categorized into one of three influences: modifying the subjective evaluation of choice options, restricting attention, and altering the options that are to be found in the choice set. The implications for the formal model are introduced and preliminary evidence is drawn from the extant literature.}
}
@article{PARK2025,
title = {Development and Validation of the Digital Sensitivity Scale for Adults: Cross-Sectional Observational Study},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/55828},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125000470},
author = {Hae In Park and Minjeong Jeon and Ji Seon Ahn and Kyungmi Chung and Jin Young Park},
keywords = {information literacy, health literacy, computer literacy, self-efficacy, attitude, digital divide},
abstract = {Background
The COVID-19 pandemic has accelerated the digitalization of modern society, extending digital transformation to daily life and psychological evaluation and treatment. However, the development of competencies and literacy in handling digital technology has not kept pace, resulting in a significant disparity among individuals. Existing measurements of digital literacy were developed before widespread information and communications technology device adoption, mainly focusing on one’s perceptions of their proficiency and the utility of device operation. In the contemporary landscape, digital transformation is evolving within specialized domains, necessitating a comprehensive evaluation of digital competencies, attitudes, and proficiency in technology application to bridge the digital divide and ensure digital compliance.
Objective
This study was designed to address the shortcomings of existing scales and formulate a digital sensitivity scale tailored to the requirements of today’s society.
Methods
Initial items of the Yongin Severance Digital Sensitivity Scale (YI-DSS) were collected through a literature review, and expert opinions were gathered to ensure content validity. An exploratory and confirmatory factor analysis included 986 adult participants evaluating 14 digital literacy items and 6 digital efficacy items. The Cronbach α confirmed internal consistency reliability, and 2-tailed t tests, ANOVAs, and post hoc tests analyzed demographic differences in digital literacy and efficacy.
Results
A robust 4-factor digital literacy solution was identified: digital application, digital communication, critical thinking, and digital ethics (Kaiser-Meyer-Olkin=0.891; Bartlett × 2=9829.713; P<.001; Cronbach α=0.782-0.947). A 2-factor solution defined digital efficacy: digital confidence and digital anxiety (Kaiser-Meyer-Olkin=0.735; Bartlett × 2=3282.217; P<.001; Cronbach α=0.787-0.912). Confirmatory factor analysis was conducted for each model (digital literacy model: χ271=676.0, comparative fit index=0.938, Tucker-Lewis index=0.921, standardized root mean square residual=0.73, and root mean square error of approximation=0.093; digital efficacy model: χ28=81.9, comparative fit index=0.977, Tucker-Lewis index=0.958, standardized root mean square residual=0.73, and root mean square error of approximation=0.097), which indicated a good fit. The YI-DSS also showed high correlation with the previously developed Digital Literacy Scale (r=0.809; P<.001).
Conclusions
The YI-DSS, as a self-assessment tool, has the potential to bridge the generational information gap by promoting acceptance, motivation, and adaptation to digital technology. Furthermore, given the remote nature of digital therapeutics, an individual’s familiarity with required technologies and digital communication strongly influences their acceptance of digital treatments and the efficacy thereof. This scale can play a pivotal role in enhancing compliance with digital therapeutics by preemptively assessing individuals’ technological literacy and competency.}
}
@article{KUDARIYAWAR2016193,
title = {Computational study of instabilities in a rectangular natural circulation loop using 3D CFD simulation},
journal = {International Journal of Thermal Sciences},
volume = {101},
pages = {193-206},
year = {2016},
issn = {1290-0729},
doi = {https://doi.org/10.1016/j.ijthermalsci.2015.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1290072915003440},
author = {Jayaraj Yallappa Kudariyawar and Abhijeet Mohan Vaidya and Naresh Kumar Maheshwari and Polepalle Satyamurthy},
keywords = {Natural circulation loop, 3D CFD simulation, Instability},
abstract = {Steady state and transient characteristics of a natural circulation loop working with water are obtained. For this purpose, 3D steady state and transient CFD simulations are performed. The CFD model includes pipe thickness as well as secondary side coolant passage apart from primary side. Steady state and transient characteristics are computed for various configurations i.e. Vertical Heater Vertical Cooler (VHVC), Horizontal Heater Horizontal Cooler (HHHC), etc. Steady state data was compared with available correlations. Flow initiation transients were compared with experimental data. Both the steady state and transient results are found to be in good agreement with previously published data. The reason for formation of unidirectional and bi-directional pulsing in HHHC configuration at different powers is explained with the help of temperature fields at different instants of time. Effect of sudden power rise/power step back on instability in HHHC configuration is estimated using CFD simulations.}
}
@article{RAJAN2024R1221,
title = {Cellular cognition: How single cells learn using non-neural networks},
journal = {Current Biology},
volume = {34},
number = {24},
pages = {R1221-R1223},
year = {2024},
issn = {0960-9822},
doi = {https://doi.org/10.1016/j.cub.2024.11.016},
url = {https://www.sciencedirect.com/science/article/pii/S0960982224015239},
author = {Deepa H. Rajan and Wallace F. Marshall},
abstract = {Summary
Single cells can perform surprisingly complex behaviors and computations, including primitive forms of learning like habituation. New work highlighted here uses mathematical modeling to show that relatively simple biochemical networks can recapitulate many features of habituation in animals.}
}
@article{THOMPSON1983161,
title = {Thinking about thinking},
journal = {Trends in Neurosciences},
volume = {6},
pages = {161-163},
year = {1983},
issn = {0166-2236},
doi = {https://doi.org/10.1016/0166-2236(83)90076-0},
url = {https://www.sciencedirect.com/science/article/pii/0166223683900760},
author = {I.D. Thompson},
abstract = {The Cognitive Neuroscience Institute held its first conference in September 1982, in Kusadasi, Turkey. The institute was recently established in New York to promote research in cognitive neuroscience, and in December 1982 it presented the Hermann von Helmholtz Award to Vernon Mountcastle (see TINS, January 1983, Vol. 6, p. 9). The meeting was attended by individuals whose specialities range from molecular biology to philosophy. Their common aim was to investigate the role of cognitive neuroscience in establishing a theory of mental processing which combines the knowledge derived from cognitive psychology and from neuroscience. How this synthesis is to be achieved, and indeed the extent to which it is possible, was the subject of wide-ranging and often vigorous debate. But, as many disciplines begin to converge on common problems, the prospects for cognitive neuroscience appear encouraging. Thus, as neuroscientists start to unravel the molecular mechanisms of learning and memory, it is interesting to consider what constraints such mechanisms might place on the operational rules for correlating single-neuron activity and behaviour in invertebrates, it has been argued that similar progress in understanding the mammalian brain will come from the application of models, derived from cognitive psychology, to neurophysiology. Artificial intelligence provides an opportunity to model many cognitive processes, but how close do the models come to reflecting underlying mental states? Indeed, the problem or non-problem of self-awareness dominated many conversations, tantalizing some participants by its intractability and accepted by others as a naturally emergent attribute of the mechanics of the mind.}
}
@incollection{JOHNSON201435,
title = {Chapter 3 - Computational and Process Models of Decision Making in Psychology and Behavioral Economics},
editor = {Paul W. Glimcher and Ernst Fehr},
booktitle = {Neuroeconomics (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {San Diego},
pages = {35-47},
year = {2014},
isbn = {978-0-12-416008-8},
doi = {https://doi.org/10.1016/B978-0-12-416008-8.00003-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780124160088000036},
author = {Eric J. Johnson and Roger Ratcliff},
keywords = {Computation Process Models, Decision Neuroscience, Drift-Diffusion Models, economic theory, Intertemporal Choice, Riskless Choice, Risky Choice},
abstract = {This chapter reviews models of choice on two levels: The first concerns the descriptions of choice and their evolution from normative models of how choices should be make to more behaviorally realistic models, more consistent with data showing that choice depends heavily on context. We present brief overviews of risky and riskless choice models and data and for choice over time. We then turn to computational process models, a more recent class of models that make prediction for multiple properties of the decision process beyond simply what is chosen, including predicting the distribution of errors and decision times.These models are typically applied to simpler choices, but have found great use in contemporary neuroscience.}
}
@article{MARTINRAMOS201751,
title = {First exposure to Arduino through peer-coaching: Impact on students' attitudes towards programming},
journal = {Computers in Human Behavior},
volume = {76},
pages = {51-58},
year = {2017},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2017.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0747563217304193},
author = {Pablo Martín-Ramos and Maria João Lopes and M. Margarida {Lima da Silva} and Pedro E.B. Gomes and Pedro S. {Pereira da Silva} and José P.P. Domingues and Manuela {Ramos Silva}},
keywords = {Attitudes survey, Arduino, High school, Programming, Peer coaching},
abstract = {In this paper we report the work that jeKnowledge (Júnior Empresa da Faculdade de Ciências e Tecnologias da Universidade de Coimbra), a student-led initiative, has done in the ‘jeKnowledge academy’ courses to actively engage Portuguese high-school students in STEM education through hands-on projects based on the low-cost Arduino platform. F2F activities, based on a peer-assisted learning strategy, were complemented with tutorials and more advanced project suggestions in a blog. Pre and post surveys on students' attitudes towards programming and peer-coaching were administered to pre-university and first year college participants, finding an overall increase in the Likert scale for all the programming-related constructs under study (confidence, interest, gender, usefulness and professional) after the introductory course. As regards the peer-based learning approach, younger students seemed to be more eager to be taught in a less formal way than their older counterparts. The course resulted in high degrees of satisfaction for both the student tutors and their tutees.}
}
@article{JONES2000571,
title = {Unstructured mesh computations on CCMs},
journal = {Advances in Engineering Software},
volume = {31},
number = {8},
pages = {571-580},
year = {2000},
issn = {0965-9978},
doi = {https://doi.org/10.1016/S0965-9978(00)00012-0},
url = {https://www.sciencedirect.com/science/article/pii/S0965997800000120},
author = {M.T Jones and K Ramachandran},
keywords = {Configurable computing, Floating point, Finite element},
abstract = {Configurable Computing Machines (CCMs) have been able to provide orders of magnitude increases in execution rates for applications such as image processing, signal processing, and automatic target recognition. This paper describes the use of CCMs to accelerate complex, large-scale scientific computations. These applications present a challenge for CCMs because of their large size, hundreds of thousands of lines of code, and the unstructured nature of the computations. This paper describes strategies for accelerating scientific computations on CCMs and demonstrates the effectiveness of one such strategy on the Annapolis Micro Systems WildForce board. Results from this implementation are analyzed.}
}
@article{CRONIN2022100987,
title = {Analysis of tutors’ responses to students’ queries in a second linear algebra course at a mathematics support center},
journal = {The Journal of Mathematical Behavior},
volume = {67},
pages = {100987},
year = {2022},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2022.100987},
url = {https://www.sciencedirect.com/science/article/pii/S0732312322000554},
author = {Anthony Cronin and Sepideh Stewart},
keywords = {Mathematics tutors, Second courses in linear algebra, Mathematics support center, Feedback, Tutors’ tactics, Advanced mathematical thinking},
abstract = {This paper analyses six years of tutor feedback produced after inquiries made by students in a second linear algebra course at a university mathematics support center (MSC). We utilized Mason’s (2002) pedagogical tactics to build a model to analyze MSC tutors' feedback responding to these students’ queries. The aim of this research was to investigate the nature of students’ difficulties with concepts in a second linear algebra course that emphasizes theories and proof, in addition to examining the tactics employed by tutors to resolve student difficulties. We analyzed 227 feedback comments from 44 tutors based on their interactions with 82 students over six years. Our findings indicated that the most common areas of difficulty were basis, vector space, subspace, span, and proof. Tutor tactics deployed included ‘being mathematical’, ‘simplifying and complexifying’, and ‘worked examples’. We also discuss some implications for linear algebra tutor training.}
}
@incollection{BARBAROSSA2018419,
title = {Chapter 16 - The Edge Cloud: A Holistic View of Communication, Computation, and Caching},
editor = {Petar M. Djurić and Cédric Richard},
booktitle = {Cooperative and Graph Signal Processing},
publisher = {Academic Press},
pages = {419-444},
year = {2018},
isbn = {978-0-12-813677-5},
doi = {https://doi.org/10.1016/B978-0-12-813677-5.00016-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012813677500016X},
author = {Sergio Barbarossa and Stefania Sardellitti and Elena Ceci and Mattia Merluzzi},
keywords = {5G networks, Wireless communications, Graph-based learning},
abstract = {The evolution of communication networks shows a clear shift of focus from just improving the communications aspects to enabling new important services, from Industry 4.0 to automated driving, virtual/augmented reality, the Internet of Things (IoT), and so on. This trend is evident in the roadmap planned for the deployment of the fifth-generation (5G) communication networks. This ambitious goal requires a paradigm shift toward a vision that looks at communication, computation, and caching (3C) resources as three components of a single holistic system. The further step is to bring these 3C resources closer to the mobile user, at the edge of the network, to enable very low latency and high reliability services. The scope of this chapter is to show that signal processing techniques can play a key role in this new vision. In particular, we motivate the joint optimization of 3C resources. Then we show how graph-based representations can play a key role in building effective learning methods and devising innovative resource allocation techniques.}
}
@article{CASTRO20242377,
title = {Product Customization based on Digital Twin and Cloud Manufacturing within a Decentralized Production System},
journal = {Procedia Computer Science},
volume = {239},
pages = {2377-2384},
year = {2024},
note = {CENTERIS – International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies 2023},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.06.431},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924016752},
author = {Hélio Castro and Fernando Câmara and Paulo Ávila and Luís Ferreira and Manuela Cruz-Cunha},
keywords = {Industry 4.0, Digital Twin, Cyber-Physical System, Smart Factory, Product Customization, Cloud Manufacturing},
abstract = {Industry 4.0 represents a turning point in the thinking of the production model since it is based on digitalized production systems with the aim of improving productivity, product quality, and delivery time to the customer. The digitalization and evolution of information technology allowed the emulation of production system virtual models, namely in the concept of Digital Twin (DT), with the ability to simulate different scenarios providing support for better decision making. This concept not only represents a virtual copy of the physical world that obtains information about the state of the value chain but also illustrates a system capable of changing the development of the production activity according to the fulfillment of the intended business goals. In literature, the concept of the Digital Twin is exhaustively treated as a stand-alone factory (one digital factory represents one physical factory) and underestimates the possibility of a DT oriented to a customized product (a project) that requires decentralized production systems. This paper brings to discussion the relevance of product customized applying DT to smart customization, and the inclusion of decentralized production systems supported by Cloud Manufacturing.}
}
@article{JOHNSON1997721,
title = {Observations with regard to massively parallel computation for Monte Carlo simulation of stochastic dynamical systems},
journal = {International Journal of Non-Linear Mechanics},
volume = {32},
number = {4},
pages = {721-734},
year = {1997},
note = {Third International Stochastic Structural Dynamics Conference},
issn = {0020-7462},
doi = {https://doi.org/10.1016/S0020-7462(96)00097-2},
url = {https://www.sciencedirect.com/science/article/pii/S0020746296000972},
author = {E.A. Johnson and S.F. Wojtkiewicz and L.A. Bergman and B.F. Spencer},
abstract = {The evolution of stochastic dynamical systems is governed by Fokker-Planck equations if the response process is Markovian. Analytical solutions for the transient response of multidimensional systems exist only for the simplest dynamical systems. The evolution of the transition probability density function over the phase space has been solved numerically for various low dimensional systems subjected to additive and multiplicative white noise excitations using the finite element method. Systems of higher order, however, pose difficulty when using standard finite element formulations due to memory requirements and computational expense. Direct Monte Carlo simulation (MCS), while often regarded as less elegant than other methods, can be used to solve problems of significantly higher complexity. The number of realizations required to accurately produce the transition probability density function over the entire phase space, especially in the tails, is large, but since each realization is entirely independent of the others, the Monte Carlo simulation is easily and efficiently adapted to parallel computation. The advent of high-speed, massively-parallel computers permits a large number of realizations of a complex dynamical system to be simultaneously determined. Consequently, Monte Carlo simulation may be more efficient for higher-dimensional systems than other solution methods currently in use. This investigation will examine some of these observations and compare the performance of MCS on various platforms, in the context of a four-dimensional linear oscillator and a Duffing oscillator subjected to band-limited white noise.}
}
@incollection{RUFFONI2017169,
title = {3.10 Finite Element Analysis in Bone Research: A Computational Method Relating Structure to Mechanical Function☆},
editor = {Paul Ducheyne},
booktitle = {Comprehensive Biomaterials II},
publisher = {Elsevier},
address = {Oxford},
pages = {169-196},
year = {2017},
isbn = {978-0-08-100692-4},
doi = {https://doi.org/10.1016/B978-0-12-803581-8.09798-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128035818097988},
author = {D. Ruffoni and G.H. {van Lenthe}},
keywords = {Bone imaging, Bone research, Computational modeling, Femur, Finite element analysis, Fracture, Hierarchical structure, Micro-computed tomography, Osteoporosis, Radius, Strength, Vertebra},
abstract = {Bone is probably the most frequently investigated biological material and finite element analysis (FEA) is the computational tool most commonly used for the analysis of bone biomechanical function. FEA has been used in bone research for more than 30 years and has had a substantial impact on our understanding of the complex behavior of bone. Bone is structured in a hierarchical way covering many length scales and this chapter reflects this hierarchical organization. In particular, the focus is on the applications of FEA for understanding the relationship between bone structure and its mechanical function at specific hierarchical levels. Depending on the hierarchical level, different issues have been investigated with FEA ranging from more clinically oriented topics related to bone quality (eg, predicting bone strength and fracture risk) to more fundamental problems dealing with the mechanical aspects of biological processes (eg, stress and strain around osteocyte lacunae) as well as with the micromechanical behavior of bone at its ultrastructure. A better understanding of the relationship between structure and mechanical function is expected to be important for the current trends in (bio)materials design, where the structure of biological materials is considered as a possible source of inspiration, as well as for more successful approaches in the prevention and treatment of age- and disease-related fractures.}
}
@article{TEZDUYAR19992039,
title = {Methods for parallel computation of complex flow problems},
journal = {Parallel Computing},
volume = {25},
number = {13},
pages = {2039-2066},
year = {1999},
issn = {0167-8191},
doi = {https://doi.org/10.1016/S0167-8191(99)00080-0},
url = {https://www.sciencedirect.com/science/article/pii/S0167819199000800},
author = {Tayfun Tezduyar and Yasuo Osawa},
keywords = {Computational fluid dynamics, Flow simulation, Stabilization methods, Compressible flow, Incompressible flow, Multidomain computational methods},
abstract = {This paper is an overview of some of the methods developed by the Team for Advanced Flow Simulation and Modeling (T★AFSM) [http://www.mems.rice.edu/TAFSM/] to support flow simulation and modeling in a number of “Targeted Challenges”. The “Targeted Challenges” include unsteady flows with interfaces, fluid–object and fluid–structure interactions, airdrop systems, and air circulation and contaminant dispersion. The methods developed include special numerical stabilization methods for compressible and incompressible flows, methods for moving boundaries and interfaces, advanced mesh management methods, and multi-domain computational methods. We include in this paper a number of numerical examples from the simulation of complex flow problems.}
}
@article{MARTINRAMOS2018420,
title = {Reprint of ‘First exposure to Arduino through peer-coaching: Impact on students' attitudes towards programming’},
journal = {Computers in Human Behavior},
volume = {80},
pages = {420-427},
year = {2018},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2017.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S074756321730691X},
author = {Pablo Martín-Ramos and Maria João Lopes and M. Margarida {Lima da Silva} and Pedro E.B. Gomes and Pedro S. {Pereira da Silva} and José P.P. Domingues and Manuela {Ramos Silva}},
keywords = {Attitudes survey, Arduino, High school, Programming, Peer coaching},
abstract = {In this paper we report the work that jeKnowledge (Júnior Empresa da Faculdade de Ciências e Tecnologias da Universidade de Coimbra), a student-led initiative, has done in the ‘jeKnowledge academy’ courses to actively engage Portuguese high-school students in STEM education through hands-on projects based on the low-cost Arduino platform. F2F activities, based on a peer-assisted learning strategy, were complemented with tutorials and more advanced project suggestions in a blog. Pre and post surveys on students' attitudes towards programming and peer-coaching were administered to pre-university and first year college participants, finding an overall increase in the Likert scale for all the programming-related constructs under study (confidence, interest, gender, usefulness and professional) after the introductory course. As regards the peer-based learning approach, younger students seemed to be more eager to be taught in a less formal way than their older counterparts. The course resulted in high degrees of satisfaction for both the student tutors and their tutees.}
}
@article{GOMEZCARRILLO2023296,
title = {Integrating neuroscience in psychiatry: a cultural–ecosocial systemic approach},
journal = {The Lancet Psychiatry},
volume = {10},
number = {4},
pages = {296-304},
year = {2023},
issn = {2215-0366},
doi = {https://doi.org/10.1016/S2215-0366(23)00006-8},
url = {https://www.sciencedirect.com/science/article/pii/S2215036623000068},
author = {Ana Gómez-Carrillo and Laurence J Kirmayer and Neil Krishan Aggarwal and Kamaldeep S Bhui and Kenneth Po-Lun Fung and Brandon A Kohrt and Mitchell G Weiss and Roberto Lewis-Fernández},
abstract = {Summary
Psychiatry has increasingly adopted explanations for psychopathology that are based on neurobiological reductionism. With the recognition of health disparities and the realisation that someone's postcode can be a better predictor of health outcomes than their genetic code, there are increasing efforts to ensure cultural and social–structural competence in psychiatric practice. Although neuroscientific and social–cultural approaches in psychiatry remain largely separate, they can be brought together in a multilevel explanatory framework to advance psychiatric theory, research, and practice. In this Personal View, we outline how a cultural–ecosocial systems approach to integrating neuroscience in psychiatry can promote social–contextual and systemic thinking for more clinically useful formulations and person-centred care.}
}
@article{MCKELVEY2009476,
title = {Designing an electronic auction market for complex ‘smart parts’ logistics: Options based on LeBaron's computational stock market},
journal = {International Journal of Production Economics},
volume = {120},
number = {2},
pages = {476-494},
year = {2009},
note = {Special Issue on Introduction to Design and Analysis of Production Systems},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2009.03.006},
url = {https://www.sciencedirect.com/science/article/pii/S0925527309000899},
author = {Bill McKelvey and Christine Wycisk and Michael Hülsmann},
keywords = {Supply chain management, Electronic auction market, I&C technologies, Complexity theory, Neural networks},
abstract = {Modern technologies, such as RFID, offer never-before seen learning abilities to parts moving in supply chains. Logistics systems may be understood as complex adaptive logistics systems (CALS). They also may be conceived as electronic auction markets as ‘smart parts’ bid for the best routing and pricing from transportation firms. To ensure the world-wide functionality and efficiency of CALS transportation markets, we suggest the utility of an agent-based computational market design based on Blake LeBaron's stock-market model. Given that parts may be more or less smart, markets more or less complex, and self-organizing CALS systems probabilistically subject to the bullwhip effect, we suggest nine different computational CALS market-design options, offering more adaptivity to unexpected environmental contingencies.}
}
@article{RAJ2021474,
title = {Assessment of antiviral potencies of cannabinoids against SARS-CoV-2 using computational and in vitro approaches},
journal = {International Journal of Biological Macromolecules},
volume = {168},
pages = {474-485},
year = {2021},
issn = {0141-8130},
doi = {https://doi.org/10.1016/j.ijbiomac.2020.12.020},
url = {https://www.sciencedirect.com/science/article/pii/S0141813020351783},
author = {Vinit Raj and Jae Gyu Park and Kiu-Hyung Cho and Pilju Choi and Taejung Kim and Jungyeob Ham and Jintae Lee},
keywords = {Cannabinols,  antiviral assay, SARS-CoV-2 and M enzyme},
abstract = {Effective treatment choices to the severe acute respiratory syndrome coronavirus-2 (SARS-CoV-2) are limited because of the absence of effective target-based therapeutics. The main object of the current research was to estimate the antiviral activity of cannabinoids (CBDs) against the human coronavirus SARS-CoV-2. In the presented research work, we performed in silico and in vitro experiments to aid the sighting of lead CBDs for treating the viral infections of SARS-CoV-2. Virtual screening was carried out for interactions between 32 CBDs and the SARS-CoV-2 Mpro enzyme. Afterward, in vitro antiviral activity was carried out of five CBDs molecules against SARS-CoV-2. Interestingly, among them, two CBDs molecules namely Δ9 -tetrahydrocannabinol (IC50 = 10.25 μM) and cannabidiol (IC50 = 7.91 μM) were observed to be more potent antiviral molecules against SARS-CoV-2 compared to the reference drugs lopinavir, chloroquine, and remdesivir (IC50 ranges of 8.16–13.15 μM). These molecules were found to have stable conformations with the active binding pocket of the SARS-CoV-2 Mpro by molecular dynamic simulation and density functional theory. Our findings suggest cannabidiol and Δ9 -tetrahydrocannabinol are possible drugs against human coronavirus that might be used in combination or with other drug molecules to treat COVID-19 patients.}
}
@article{GUERRAMACIAS2025e41099,
title = {Development of transversal skills in higher education programs in conjunction with online learning: relationship between learning strategies, project-based pedagogical practices, e-learning platforms, and academic performance},
journal = {Heliyon},
