volume = {27},
number = {4},
pages = {233-249},
year = {2007},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2006.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0268401206001435},
author = {B.J. Hicks},
keywords = {Information management, SMEs, Waste, Information systems infrastructure, Strategy, Process improvement},
abstract = {This paper deals with the development of a new approach for supporting the improvement of information management and the overall information systems infrastructure. In particular, the paper discusses the application of lean thinking to information management; where information management can be considered to involve adding value to information by virtue of how it is organised, visualised and represented; and enabling information (value) to flow to the end-user (customer) through the processes of exchange, sharing and collaboration. The potential benefits of lean thinking are discussed and the fundamental barriers for its application to information management are highlighted. These include the need to characterise the nature of waste and establish the five principles of; value, value streams, flow, pull and continuous improvement in the context of information management. It follows that the core contribution of this paper is the development of an understanding of these critical elements and the creation of a conceptual framework for a set of lean principles within the context of information management. This framework offers a unique and arguably generic approach for supporting the retrospective improvement of information management systems and the overall information systems infrastructure.}
}
@article{ADAMS201731,
title = {Patternlets — A teaching tool for introducing students to parallel design patterns},
journal = {Journal of Parallel and Distributed Computing},
volume = {105},
pages = {31-41},
year = {2017},
note = {Keeping up with Technology: Teaching Parallel, Distributed and High-Performance Computing},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2017.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S074373151730014X},
author = {Joel C. Adams},
keywords = {Design patterns, Education, MPI, Multiprocessing, Multithreading, OpenMP, Parallel, Patternlets, Teaching, Threads},
abstract = {Thanks to the ubiquity of multicore processors, today’s CS students must be introduced to parallel computing or they will be ill prepared as modern software developers. Professional developers of parallel software think in terms of parallel design patterns, which are markedly different from traditional (sequential) design patterns. It follows that the more we can teach students to think in terms of parallel patterns, the more their thinking will resemble that of parallel software professionals. In this paper, we present patternlets—minimalist, scalable, syntactically correct programs, each designed to introduce students to a particular parallel design pattern. The collection currently includes 44 patternlets (16 MPI, 17 OpenMP, 9 Pthreads, and 2 heterogeneous), of which we present a representative sample. We also present data that indicate the use of patternlets to introduce parallelism in CS2 produced a modest improvement in student understanding of parallel concepts.}
}
@article{MOGILNER2019R915,
title = {Alex Mogilner},
journal = {Current Biology},
volume = {29},
number = {19},
pages = {R915-R917},
year = {2019},
issn = {0960-9822},
doi = {https://doi.org/10.1016/j.cub.2019.07.077},
url = {https://www.sciencedirect.com/science/article/pii/S0960982219309571},
author = {Alex Mogilner}
}
@article{TAKAMA20151263,
title = {NFC-based Tangible User Interface for Information Curation and Its Application to Analogy Game},
journal = {Procedia Computer Science},
volume = {60},
pages = {1263-1270},
year = {2015},
note = {Knowledge-Based and Intelligent Information & Engineering Systems 19th Annual Conference, KES-2015, Singapore, September 2015 Proceedings},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.08.192},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915023194},
author = {Yasufumi Takama and Tomohiro Ito and Hiroshi Ishikawa},
keywords = {Tangible user interface (TUI), Near field communication (NFC), Smartphone, Information curation, Analogy game},
abstract = {This paper applies a Tangible User Interface (TUI) for information curation using Near Field Communication (NFC) to an analogy game. The increase in text data is more remarkable in current IT society. Although those are usually accessed with using Graphical User Interface (GUI), users except experienced computer users have difficulty in reading and organizing data with GUI. In particular, information curation such as grouping related data / information and finding relationship among them is difficult. In order to solve this problem, an interface that can access text data intuitively is expected. We are developing a TUI based on NFC, by which a user can move and group text data in a similar manner when handling paper documents. As one of the promising applications of the proposed TUI, this paper focuses on creative thinking support, for which touching externalized thought by hand is expected to be effective. An experiment is conducted, in which test participants did an analogy game with using the proposed TUI. The experimental result shows experience of using the TUI affects the participants’ self-evaluation about idea creation.}
}

@article{HONG2024422,
title = {AF-FTTSnet: An end-to-end two-stream convolutional neural network for online quality monitoring of robotic welding},
journal = {Journal of Manufacturing Systems},
volume = {74},
pages = {422-434},
year = {2024},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2024.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S0278612524000724},
author = {Yuxiang Hong and Xingxing He and Jing Xu and Ruiling Yuan and Kai Lin and Baohua Chang and Dong Du},
keywords = {Welding quality monitoring, Visual sensing, Molten pool, Defect prediction, Two-stream network},
abstract = {Online welding quality monitoring (WQM) is crucial for intelligent welding, and deep learning approaches considering spatiotemporal features for WQM tasks show great potential. However, one of the important challenges for existing approaches is to balance the spatiotemporal representation learning capability and computational efficiency, which makes it challenging to adapt welding processes with complex and drastic molten pool dynamic behavior. This paper proposes a novel approach for WQM using molten pool visual sensing and deep learning considering spatiotemporal features, the proposed deep learning network called attention fusion based frame-temporality two-stream network (AF-FTTSnet). Firstly, a passive vision sensor is used to acquire continuous dynamic molten pool images. Meanwhile, temporal difference images are computed to provide novel features and temporal representations. Then, a two-stream feature extraction module is designed to concurrently extract rich spatiotemporal features from molten pool images and temporal difference images. Finally, an attention fusion module with the ability to automatically identify and weight the most relevant features is designed to achieve optimal fusion of the two-stream features. The shop welding experimental results indicate that the proposed AF-FTTSnet model can effectively and robustly recognize five typical welding states during helium arc welding, with an accuracy of 99.26%. This model has been demonstrated to exhibit significant performance improvements compared to mainstream temporal sequence models. Available: https://github.com/Just199806/TSCNN/tree/master.}
}
@article{LAI2023101343,
title = {Optimization of urban and rural ecological spatial planning based on deep learning under the concept of sustainable development},
journal = {Results in Engineering},
volume = {19},
pages = {101343},
year = {2023},
issn = {2590-1230},
doi = {https://doi.org/10.1016/j.rineng.2023.101343},
url = {https://www.sciencedirect.com/science/article/pii/S259012302300470X},
author = {Yilin Lai},
keywords = {Sustainable development, Spatial planning, Remote sensing images, CNN, GPU},
abstract = {At present, the speed of urbanization in China is constantly accelerating. At the same time, due to the severe situation of tight resource constraints, severe environmental pollution, and ecosystem degradation, vigorously promoting the construction of ecological civilization has become a key planning direction. However, traditional urban and rural ecological spatial planning is influenced by factors such as region, terrain, and spatial scale, which cannot adapt to the current spatial planning requirements. To achieve sustainable urban and rural ecological spatial planning, we propose a method that uses the optimized remote sensing images and convolutional neural networks to achieve spatial planning. In the analysis of the application effect of the usage method, the experimental results show that increasing the amount of data such as image size can improve the execution performance of the computer when the computer is not fully utilizing its resources and its computational volume fails to saturate the computational capacity. The parallel configuration designed in this experiment can accelerate the performance of the computer better, and the acceleration effect becomes more obvious as the difficulty of the algorithm increases. The Faster RCNN algorithm proposed in this experiment has the highest retrieval accuracy in the Flickr30K dataset and MS-COCO dataset compared with other algorithms. In Flickr30k data set, compared with other models in the table, the model used in this paper has the highest retrieval accuracy. The retrieval accuracy of R@1, R@5, R@10 increased by 23.1%, 8.1% and 5.3%, respectively. In MS-COCO data set, the retrieval accuracy increased by 19.2%, 13.1% and 8.3% respectively. The above results confirm that the combination of remote sensing images and convolutional neural network technology can perform simple ecological planning of a city's urban and rural areas, which proves that the method proposed in this experiment has practicality.}
}
@article{MULLER1987271,
title = {Computational problems in supernova simulations},
journal = {Computer Physics Communications},
volume = {44},
number = {3},
pages = {271-277},
year = {1987},
issn = {0010-4655},
doi = {https://doi.org/10.1016/0010-4655(87)90082-8},
url = {https://www.sciencedirect.com/science/article/pii/0010465587900828},
author = {Ewald Müller},
abstract = {Theoretical models of type I and type II supernova explosions are reviewed from a computational physics point of view. After discussing briefly the underlying physics the numerical problems and challenges encountered in the simulation of type I and type II supernova are addressed.}
}
@article{LAWRENCE2023100786,
title = {Translational argument technology: Engineering a step change in the argument web},
journal = {Journal of Web Semantics},
volume = {77},
pages = {100786},
year = {2023},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2023.100786},
url = {https://www.sciencedirect.com/science/article/pii/S157082682300015X},
author = {John Lawrence and Jacky Visser and Chris Reed},
keywords = {Argumentation, Argument analytics, Argument mining, Argument technology, Argument web, Debate technology},
abstract = {Following the establishment in 2006 of a representational standard for the computational handling of structures of argumentation, the Argument Interchange Format, it became possible to develop a vision for the coherent integration of multifarious services, components and tools that create, consume, navigate, analyse, evaluate and manipulate arguments and debates. This vision was the Argument Web with theoretical foundations laid by Rahwan et al. (2007), and practical engineering work described by Bex et al. (2013). Over the intervening period, the key challenge has been to demonstrate the practical and societal value of the Argument Web by taking its tools and applications to larger audiences. This paper lays out three approaches by which the Argument Web has been scaled up in this way, each in partnership with the BBC, and each with different kinds of evaluation and impact. Transitioning these technologies to large user groups paves the way for broader-scale uptake of the Argument Web and heralds the translation from lab to real-world application for a substantial research community working in argument technology.}
}
@article{1991202,
title = {Use of computational methods in drug design},
journal = {Chemometrics and Intelligent Laboratory Systems},
volume = {11},
number = {2},
pages = {202-203},
year = {1991},
issn = {0169-7439},
doi = {https://doi.org/10.1016/0169-7439(91)80072-X},
url = {https://www.sciencedirect.com/science/article/pii/016974399180072X}
}
@article{PANESCU2013375,
title = {At the Crossroads between Western and Eastern Views on Psychotherapy: An Integrative Approach},
journal = {Procedia - Social and Behavioral Sciences},
volume = {78},
pages = {375-379},
year = {2013},
note = {PSIWORLD 2012},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2013.04.314},
url = {https://www.sciencedirect.com/science/article/pii/S1877042813008835},
author = {Oana Pănescu and Alexandra Timofte and Melania Macovei and Carmen Popescu},
keywords = {Psychoterapy, Body, Mind, Meditation, Transactional analysis},
abstract = {This paper aims at indicating the convergence points between what is habitually understood as a pair of opposing terms: mind (as in thinking) and body (as in sensation). Structural models in psychotherapy conceptualize human mind in terms of levels of information processing (both internal and external information). We suggest that a mental split between mind and body leads to a feeling of estrangement from self, as well as an estrangement from external world. Drawing on relational approaches on psychotherapy, we suggest that focusing on perceiving own sensations does not necessarily imply a state of personal isolation from outside world; rather, this simultaneously means the perceiving and acceptance of “otherness”.}
}
@article{VERDECCHIA2022100767,
title = {The future of sustainable digital infrastructures: A landscape of solutions, adoption factors, impediments, open problems, and scenarios},
journal = {Sustainable Computing: Informatics and Systems},
volume = {35},
pages = {100767},
year = {2022},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2022.100767},
url = {https://www.sciencedirect.com/science/article/pii/S2210537922000889},
author = {Roberto Verdecchia and Patricia Lago and Carol {de Vries}},
keywords = {Sustainability, Green IT, Energy efficiency, Digital infrastructures, Data centers, Cloud, Landscape, Qualitative research},
abstract = {Background:
Digital infrastructures, i.e., ICT systems, or system-of-systems, providing digital capabilities, such as storage and computational services, are experiencing an ever-growing demand for data consumption, which is only expected to increase in the future. This trend leads to a question we need to answer: How can we evolve digital infrastructures to keep up with the increasing data demand in a sustainable way?
Objective:
The goal of this study is to understand what is the future of sustainable digital infrastructures, in terms of: which solutions are, or will be, available to sustainably evolve digital infrastructures, and which are the related adoption factors, impediments, and open problems.
Method:
We carried out a 3-phase mixed-method qualitative empirical study, comprising semi-structured interviews, followed by focus groups, and a plenary session with parallel working groups. In total, we conducted 13 sessions involving 48 digital infrastructure practitioners and researchers.
Results:
From our investigation emerges a landscape for sustainable digital infrastructures, composed of 30 solutions, 5 adoption factors, 4 impediments, and 13 open problems. We further synthesized our results in 4 incremental scenarios, which outline the future evolution of sustainable digital infrastructures.
Conclusions:
From an initial shift from on-premise to the cloud, as time progresses, digital infrastructures are expected to become increasingly distributed, till it will be possible to dynamically allocate resources by following time, space, and energy. Numerous solutions will support this change, but digital infrastructures are envisaged to be able to evolve sustainably only by (i) gaining a wider awareness of digital sustainability, (ii) holding every party accountable for their sustainability throughout value chains, and (iii) establishing cross-domain collaborations.}
}
@article{HUNT201645,
title = {Levels of participatory conception of fractional quantity along a purposefully sequenced series of equal sharing tasks: Stu's trajectory},
journal = {The Journal of Mathematical Behavior},
volume = {41},
pages = {45-67},
year = {2016},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2015.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S0732312315300122},
author = {Jessica H. Hunt and Arla Westenskow and Juanita Silva and Jasmine Welch-Ptak},
keywords = {Conceptions, Cognition, Learning disabilities, Rational number, Pedagogy, Constructivism},
abstract = {Current intervention research in special education focuses on children's responsiveness to teacher modeled strategies and not conceptual development within children's thinking. As a result, there is a need for research that provides a characterization of key understandings (KUs) of fractional quantity evidenced by children with learning disabilities (LD) and how growth of conceptual knowledge may occur within these children's mathematical activity. This case study extends current literature by presenting KUs of fractional quantity, evidenced through problem solving strategies, observable operations, and naming/quantification of one fifth grader with LD before, during, and after seven instructional sessions situated in equal sharing. The researchers utilized a characterization of evolving fraction conceptions developed from research of children without disabilities that was ultimately productive in facilitating conceptual advances of the child with LD. We hypothesize that the trajectory of the child's conceptions is a case of something more general. Pending future research, the trajectory may be a useful tool to practitioners wishing to plan thoughtful, conceptually-based fraction instruction that is responsive to all children's evolving conceptions of fractions as quantities built through their own mathematical activity.}
}
@article{YUAN2025129490,
title = {Global attention network with rain prior for real time single image deraining},
journal = {Neurocomputing},
volume = {625},
pages = {129490},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.129490},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225001626},
author = {Yuan Yuan and Xuanbin Guo and Dandan Ma},
keywords = {Rain removal, Deep learning, Attention mechanism, Activation function},
abstract = {Poor visibility caused by rainy image can have a negative impact on the performance of computer vision applications. While several image deraining algorithms have been popularly adopted, most of them suffer from two main limitations: (1) they cannot well handle real and complex rain scenes by only focusing on one type of rain in images (e.g. raindrops or rain streaks) whereas the reality often coexists with both types, (2) they face significant difficulties in practical application because of ignoring the speed of inference. To address the above problems, we propose a global attention network (GANet) that can quickly and effectively separate rain streaks and raindrops. Inspired by the fact that rain in images often appears white, we leverage this prior to obtain an initial rain-free background image to guide neural network-based image deraining. Moreover, a new global attention block (GAB) is designed to simultaneously extract the rain features from spatial and channel dimensions. By cascading multiple GABs, the proposed method can effectively obtain the features of rain streaks and raindrops and progressively separates the rain-free image. Furthermore, owing to the nonlinear properties of GAB, the activation functions are omitted, which can speed up the inference time. And the depth-wise and point-wise convolutions are employed to promote computation efficiency as well. Extensive experiments on raindrop and rain streak datasets demonstrate that our method outperforms state-of-the-art methods, achieving up to 37.53 dB PSNR on Rain100L with an inference speed of 39 FPS, which is 2–30 times faster than competitors.}
}
@article{WU2024112197,
title = {A multi-strategy three-way decision approach for tri-state risk loss under q-rung orthopair fuzzy environment},
journal = {Applied Soft Computing},
volume = {167},
pages = {112197},
year = {2024},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2024.112197},
url = {https://www.sciencedirect.com/science/article/pii/S1568494624009712},
author = {Ping Wu and Yihua Zhong and Chuan Chen and Yanlin Wang and Chao Min},
keywords = {Three-way decision, q-rung orthopair fuzzy sets, Tri-state risk loss, Multi-strategy perspective, Threshold theorem},
abstract = {Addressing the decision-making challenge arising from the uncertainty of human cognition, three-way decision (3WD) and q-rung orthopair fuzzy sets (q-ROFSs) are integrated in this paper to propose a multi-strategy three-way decision approach (MS3WDA) for tri-state risk loss (TSRL) under q-rung orthopair fuzzy environment. Based on the ternary thinking of human cognition, the risk loss with hesitation state is considered and constructed under q-rung orthopair fuzzy environment. The TSRL with hesitation state is further constructed by combining the q-rung orthopair fuzzy (q-ROF) information. The conditional probability adopted by the original object classes is improved and extended by the three components of q-ROFSs. Next, the TSRL with q-ROF information and three components of q-ROFSs are integrated with decision-theoretic rough sets (DTRSs) to establish a novel 3WD model. Some relevant properties are also analyzed and discussed for the developed 3WD model. Then, its multi-strategy decision method is proposed based on the multi-strategy perspective. The related strategies with five different levels are designed by considering three different risk appetite perspectives and four different aspects of q-ROF information. The relevant threshold theorems are also given and proved to further provide the theoretical support for our MS3WDA. According to the five different strategies, we further derive the corresponding decision rules of MS3WDA. The key steps and specific algorithm are summarized for MS3WDA. Finally, a case study is provided to demonstrate the practicability and feasibility of MS3WDA. Meanwhile, the rationality, robustness and superiority of MS3WDA are further validated by the sensitivity analysis and comparative analysis.}
}
@article{WU2020107246,
title = {miRNA-324/-133a essential for recruiting new synapse innervations and associative memory cells in coactivated sensory cortices},
journal = {Neurobiology of Learning and Memory},
volume = {172},
pages = {107246},
year = {2020},
issn = {1074-7427},
doi = {https://doi.org/10.1016/j.nlm.2020.107246},
url = {https://www.sciencedirect.com/science/article/pii/S1074742720300903},
author = {Ruixiang Wu and Shan Cui and Jin-Hui Wang},
keywords = {Associative learning, Memory cell, Neural circuit, Barrel cortex, Piriform cortex},
abstract = {After the integrative storage of associated signals, a signal induces the recollection of its associated signal, or the other way around. This associative memory is essential to associative thinking, logical reasoning, imagination and computation. In terms of cellular mechanisms underlying associative memory, new mutual synapse innervations are formed among those coactivated neurons, so that they are recruited to be associative memory cells or associative memory neurons. These associative memory cells receive new synapse innervations alongside innate synapse inputs and encode signals carried by these inputs. We proposed to examine microRNAs as initiative factors for recruiting new synapse innervations and associative memory cells. In a mouse model of associative memory characterized as the reciprocal retrieval of associated whisker and odor signals, barrel and piriform cortical neurons gain their ability to encode whisker and odorant signals based on the newly formed synapse innervations between these coactivated cortices besides innate synapse inputs. miRNA-324 and miRNA-133a are required for recruiting these new synapse innervations and associative memory cells as well as sufficient for facilitating their recruitments, but not for innate synapse inputs. Therefore, the coactivation of sensory cortices through microRNA as initiative factor to recruit new mutual synapse innervations and associative memory cells for associative memory.}
}
@incollection{SARSANI2011231,
title = {Computers and Creativity},
editor = {Mark A. Runco and Steven R. Pritzker},
booktitle = {Encyclopedia of Creativity (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {San Diego},
pages = {231-240},
year = {2011},
isbn = {978-0-12-375038-9},
doi = {https://doi.org/10.1016/B978-0-12-375038-9.00041-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780123750389000418},
author = {M.R. Sarsani},
keywords = {Approaches to creativity, Computer applications, Computer functions, Computers, Computers and creativity, Creativity definitions, Metaphor, Problem solving, Productivity tools},
abstract = {Computers have entered all walks of human life across the world. Computers are being used by people of all ages and in every profession, in their work as well as in their leisure. There is growing interest in the application of computer-based productivity tools to support simulation effects, higher level thinking, metacognitive processes, maintaining interest, promoting learning, developing curiosity, and fostering creativity. The Internet has brought abort a revolution in the world of information technology by providing searching facilities for exploring or seeking information from all over the world (e.g., e-learning, e-shopping, e-mail, Telnet and Usenet, audio and video conferences, etc.). Different viewpoints have been put forward to explain the concept, emphasizing different aspects of creativity. Generally, creativity has been discussed in terms of its end product, creative person, creative process, and creative press or environments. There are no substantial researches directly measuring the effect of the computer simulation technology to support either uncreative drill or creative production. Some researchers speculate that computer simulation technology may have a positive effect on creativity. However, due to a lack of empirical research, the true effect of simulation technology on creativity is still unknown and inconclusive.}
}
@article{DING2012264,
title = {Finding MicroRNA Targets in Plants: Current Status and Perspectives},
journal = {Genomics, Proteomics & Bioinformatics},
volume = {10},
number = {5},
pages = {264-275},
year = {2012},
issn = {1672-0229},
doi = {https://doi.org/10.1016/j.gpb.2012.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S1672022912000733},
author = {Jiandong Ding and Shuigeng Zhou and Jihong Guan},
keywords = {MicroRNA, Target prediction, Degradome-seq, Integration},
abstract = {MicroRNAs (miRNAs), a class of ∼20–24nt long non-coding RNAs, have critical roles in diverse biological processes including development, proliferation, stress response, etc. With the development and availability of experimental technologies and computational approaches, the field of miRNA biology has advanced tremendously over the last decade. By sequence complementarity, miRNAs have been estimated to regulate certain mRNA transcripts. Although it was once thought to be simple and straightforward to find plant miRNA targets, this viewpoint is being challenged by genetic and biochemical studies. In this review, we summarize recent progress in plant miRNA target recognition mechanisms, principles of target prediction, and introduce current experimental and computational tools for plant miRNA target prediction. At the end, we also present our thinking on the outlook for future directions in the development of plant miRNA target finding methods.}
}
@article{BACHMANN2020102937,
title = {Account of consciousness by Christof Koch: Review and questions},
journal = {Consciousness and Cognition},
volume = {82},
pages = {102937},
year = {2020},
issn = {1053-8100},
doi = {https://doi.org/10.1016/j.concog.2020.102937},
url = {https://www.sciencedirect.com/science/article/pii/S1053810020300143},
author = {Talis Bachmann},
keywords = {Consciousness, Integrated information, Cognitive computation, Microgenesis, Phenomenal experience},
abstract = {This review is set to present the gist of the theoretical account of consciousness recently presented by Christof Koch and pose a couple of questions instigated by this account. The expected answers to these questions would hopefully help to advance our understanding of the basic nature of the conscious mind.}
}
@article{HELBING2023102061,
title = {Democracy by Design: Perspectives for Digitally Assisted, Participatory Upgrades of Society},
journal = {Journal of Computational Science},
volume = {71},
pages = {102061},
year = {2023},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2023.102061},
url = {https://www.sciencedirect.com/science/article/pii/S1877750323001217},
author = {Dirk Helbing and Sachit Mahajan and Regula Hänggli Fricker and Andrea Musso and Carina I. Hausladen and Cesare Carissimo and Dino Carpentras and Elisabeth Stockinger and Javier {Argota Sanchez-Vaquerizo} and Joshua C. Yang and Mark C. Ballandies and Marcin Korecki and Rohit K. Dubey and Evangelos Pournaras},
keywords = {Computational diplomacy, Digital democracy, Participation, Collective intelligence, Value-based engineering},
abstract = {The technological revolution, particularly the availability of more data and more powerful computational tools, has led to the emergence of a new scientific field called “Computational Diplomacy”. Our work tries to define its scope and focuses on a popular subarea of it, namely “Digital Democracy”. In recent years, there has been a surge of interest in using digital technologies to promote more participatory forms of democracy. While there are numerous potential benefits to using digital tools to enhance democracy, significant challenges must be addressed. It is essential to ensure that digital technologies are used in an accessible, equitable, and fair manner rather than reinforcing existing power imbalances. This paper investigates how digital tools can be used to help design more democratic societies by investigating three key research areas: (1) the role of digital technologies for facilitating civic engagement in collective decision-making; (2) the use of digital tools to improve transparency and accountability in governance; and (3) the potential for digital technologies to enable the formation of more inclusive and representative democracies. We argue that more research on how digital technologies can be used to support democracy upgrade is needed. Along these lines, we lay out a research agenda for the future.}
}
@article{ELIAZ2010304,
title = {Paying for confidence: An experimental study of the demand for non-instrumental information},
journal = {Games and Economic Behavior},
volume = {70},
number = {2},
pages = {304-324},
year = {2010},
issn = {0899-8256},
doi = {https://doi.org/10.1016/j.geb.2010.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0899825610000229},
author = {Kfir Eliaz and Andrew Schotter},
abstract = {This paper presents experimental evidence that when individuals are about to make a given decision under risk, they are willing to pay for information on the likelihood that this decision is ex-post optimal, even if this information will not affect their decision. Our findings suggest that this demand for non-instrumental information is caused by what we refer to as a “confidence effect”: the desire to increase one's posterior belief by ruling out “bad news”, even when such news would have no effect on one's decision. We conduct various treatments to show that our subjects' behavior is not likely to be caused by an intrinsic preference for information, failure of backward induction or an attempt to minimize thinking costs.}
}
@incollection{ZIELINSKI2024116,
title = {Coupled-Cluster Theories for Excited States},
editor = {Manuel Yáñez and Russell J. Boyd},
booktitle = {Comprehensive Computational Chemistry (First Edition)},
publisher = {Elsevier},
edition = {First Edition},
address = {Oxford},
pages = {116-140},
year = {2024},
isbn = {978-0-12-823256-9},
doi = {https://doi.org/10.1016/B978-0-12-821978-2.00035-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128219782000350},
author = {Patrik Zielinski and Andreas Köhn},
keywords = {Accurate computations, Analytic gradients, Basis-set convergence, Benchmark computations, Cluster expansion, Coupled-cluster theory, Equation of motion, Excited-state properties, Gradient theory, Linear response, Multireference, Open-shell systems, Single-reference, Size consistency, Transition moments},
abstract = {Coupled-cluster theory offers a hierarchy of increasingly accurate methods and provides thus an important basis for accurate quantum chemistry, also for the computation of electronic excited states. This chapter explains and compares the two main approaches, equation-of-motion and linear-response theory and sketches the computation of transition moments and expectation values, as well as analytic geometric gradients. The basic approaches to arrive at approximations are discussed, and recent benchmark works are used to demonstrate their relative accuracy. Some challenges in coupled-cluster theory, like going to large systems, open-shell and multireference theory and the slow basis-set convergence are also covered.}
}
@article{SCHEFFLER201575,
title = {NeurOS™ and NeuroBlocks™ a neural/cognitive operating system and building blocks},
journal = {Biologically Inspired Cognitive Architectures},
volume = {11},
pages = {75-105},
year = {2015},
issn = {2212-683X},
doi = {https://doi.org/10.1016/j.bica.2014.11.011},
url = {https://www.sciencedirect.com/science/article/pii/S2212683X14000747},
author = {Lee Scheffler},
keywords = {Cognition, Perception, Pattern recognition, Memory, Learning, Behavior},
abstract = {NeurOS is an open platform for accelerating research, development and hosting execution of intelligent applications. A NeurOS application is a directed “neural graph” of modular components connected by signal paths, similar to biological brain connectivity and functional block diagrams of neural pathways. Built-in reusable modules (NeuroBlocks) provide a wide range of general- and special-purpose capabilities: inputs/senses, outputs/effectors, processing, memory, pattern learning and recognition, visualization/instrumentation, custom module development, integrating external intelligence capabilities, and sub-graph reuse. NeurOS sub-graph assemblies address neural/cognitive functions including perception, pattern learning and recognition, working memory, imagination, prediction, context priming, attention, abstraction, classification, associational thinking and behavior. NeurOS applications are inherently portable, scalable, networkable, extensible and embeddable. NeurOS development tools provide simple intuitive graphical drag and drop application assembly from components without programming, along with testing, debugging, monitoring and visualization. Prototype NeurOS applications have begun to explore a wide range of intelligent functions in diverse areas, including aspects of pattern recognition, vision, music, reading, puzzle solving, reasoning, behavior. Building working intelligent systems using NeurOS and NeuroBlocks lets researchers and developers focus on their core functions and rapidly iterate and instrument working models, fostering both analytical and biological insight as well as usable systems.}
}
@article{SHARMA201524,
title = {Urban greenways: Operationalizing design syntax and integrating mathematics and science in design},
journal = {Frontiers of Architectural Research},
volume = {4},
number = {1},
pages = {24-34},
year = {2015},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2014.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S2095263514000727},
author = {Archana Sharma},
keywords = {Design thinking, Syntax, Greenway, Urban, Planning, Landscape, STEM integrated design, Inter-disciplinary},
abstract = {The ubiquitous sameness of urban greenways prompts questions on generative design grammar and syntax, whether creative, critical rethinking at that level might be lacking. However the design syntax of urban greenways is not explicitly discussed thus leaving a critical gap in knowledge. This paper begins tackling the larger question by acting on the fundamental subset of it, by operationalizing the design syntax of urban greenways. This is done through mathematics-based graph studies to analyze patterns and shapes, photography based thermal, material and morphology studies, and section analyses to make imagery-derived deductions on the design syntax. Recommendation on approaches to diversify and enrich the design syntax includes a more direct reference from ecosystem science theories such for siting and planning the urban greenways at macro- to meso-scale, a mixed-method approach, combining mathematics, photography and drawings based frames for analyses at meso-, to micro-scale, and a turtle view scale for designing at meso- to micro-scale, with an emphasis on latter.}
}
@incollection{BUTTON199067,
title = {Chapter 4 - Going Up a Blind Alley: Conflating Conversation Analysis and Computational Modelling},
editor = {PAUL LUFF and NIGEL GILBERT and DAVID FROHLICH},
booktitle = {Computers and Conversation},
publisher = {Academic Press},
address = {London},
pages = {67-90},
year = {1990},
isbn = {978-0-08-050264-9},
doi = {https://doi.org/10.1016/B978-0-08-050264-9.50009-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780080502649500099},
author = {Graham Button},
abstract = {Publisher Summary
This chapter discusses the desirability of developing computational models of conversational phenomena, and the supportive role given to conversation analysis (CA) in the development of such models. The arguments presented in this chapter are not an attempt to restrict the range of creative resources that software designers might turn to for inspiration. In particular, it is implicitly endorsed in the attempts to develop descriptively adequate models of conversation for use in computer systems, and explicitly endorsed when it is argued that by providing a simulacrum of conversation one has naturally occurring conversation between computers and humans. The attraction of CA for people who want to develop rules of conversational organization that can be used to program computers is two-fold: (1) CA might seem to provide a ready-made package of conversational rules that they can use or adapt for their purposes; and (2) their models may be authorized by appealing to CA. However, CA is used to authorize computational models of conversation that misrepresent the details of how conversation works.}
}
@incollection{GARDNER2024103,
title = {Chapter 5 - Smart design for socially engaging environments},
editor = {Nicole Gardner},
booktitle = {Scaling the Smart City},
publisher = {Elsevier},
pages = {103-128},
year = {2024},
series = {Smart Cities},
isbn = {978-0-443-18452-9},
doi = {https://doi.org/10.1016/B978-0-443-18452-9.00006-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443184529000069},
author = {Nicole Gardner},
keywords = {Cyber-physical system, Design, Interaction, Physical computing, Play, Smart city, Smart cities, Social engagement, Social capital, Social interaction, Urban play, Urban technology},
abstract = {Smart city initiatives typically aim to optimize the efficiency of essential urban infrastructure and urban service delivery and performance. This chapter considers how smart technologies can also be deployed in ways to catalyze social interactions among citizens in urban public realm spaces to create socially engaging environments. Drawing on a range of concepts such as social cohesion, social capital, and object-centered sociality, this chapter considers how existing and speculative urban technology projects that combine spatial design thinking and physical computing can scaffold and amplify opportunities for social engagement. It considers how urban technology projects that mobilize tactics of proximity, curiosity, and play can create new and different ways for people to relate to each other in urban space.}
}
@incollection{SANTOS2024,
title = {Data analysis on Decision-Making},
booktitle = {Reference Module in Social Sciences},
publisher = {Elsevier},
year = {2024},
isbn = {978-0-443-15785-1},
doi = {https://doi.org/10.1016/B978-0-443-13701-3.00018-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443137013000189},
author = {Eulália Santos and Margarida F. Oliveira},
keywords = {Artificial intelligence, Business, Data analysis, Decision making, Logistics, Machine learning, Mathematical modeling operations research, Mathematical programming, Optimization, Statistic, Strategic management, Technology},
abstract = {Today, data analysis plays a vital role in identifying market trends and supporting strategic decision-making in organizations. To make an effective decision in order to obtain positive results, it is necessary not only to carefully analyze various pieces of information but also to use artificial intelligence and critical thinking. Mathematics plays an essential role in making effective decisions and providing tools and methods for analyzing, modeling and solving both simple and more complex problems.}
}
@article{CHERNYSHOV20151345,
title = {Information Support and Skill Evaluation of Human-Operators},
journal = {IFAC-PapersOnLine},
volume = {48},
number = {3},
pages = {1345-1350},
year = {2015},
note = {15th IFAC Symposium onInformation Control Problems inManufacturing},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2015.06.273},
url = {https://www.sciencedirect.com/science/article/pii/S2405896315005121},
author = {K.R. Chernyshov and E.Ph Jharko},
keywords = {Human-operator, Information support, Flexible simulation, Evaluation of skills, Random processes, Measures of dependence},
abstract = {The paper presents an approach to design an intelligent information support system to be used as a human-operator assistant to control large complex industrial plants. Tasks and structure of such an intelligent information support system (IISS), IISS design stages, methodology of IISS design, toolkits for IISS design are considered. A flexible simulation complex (FSC) as such an intelligent toolkit has been presented. The complex is used as a “kernel” of IISS for human-operators of a nuclear power plant. A new approach to abnormal situations with regard for the heuristic regularities of human-operator thinking process is proposed. The regularities are revealed on basis of recording the motions of the human- operator eyes over the information field of the control board and processing the experimental data obtained. For data processing, a probability theoretical approach is used based on involving the notion of consistency of measures of dependence of random variables.}
}
@incollection{KURGANSKAYA2024760,
title = {Multi-scale modeling of crystal-fluid interactions: State-of-the-art, challenges and prospects},
editor = {Klaus Wandelt and Gianlorenzo Bussetti},
booktitle = {Encyclopedia of Solid-Liquid Interfaces (First Edition)},
publisher = {Elsevier},
edition = {First Edition},
address = {Oxford},
pages = {760-792},
year = {2024},
isbn = {978-0-323-85670-6},
doi = {https://doi.org/10.1016/B978-0-323-85669-0.00034-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780323856690000349},
author = {I. Kurganskaya and R.D. Rohlfs and A. Luttge},
keywords = {Crystal-water interface, Electric double layer, Grand canonical Monte Carlo, Kinetic Monte Carlo, Kinetics, Mineral–water interface, Parameterization, Reaction pathways, Reaction probability, Reaction rates, Statistical mechanics of interfaces, Stepwave, Stochastic model, Upscaling, Voronoi},
abstract = {We describe theoretical and conceptual approaches to treat crystal-fluid interactions across the scales in the communities studying mineral-fluid interactions for a variety of purposes, from understanding fundamental principles to geological reservoir characterization and environmental mitigation. We delineate basics of theory, recent breakthroughs, and challenges in modeling approaches from the atomistic scale to the mesoscale. Quantum Mechanics, Molecular Dynamics, Kinetic Monte Carlo and Voronoi computational geometry are covered. We discuss possible theoretical and conceptual developments to overcome those challenges toward more reliable predictive models. A special attention is given to the development of interfaces between the techniques addressing different scales.}
}
@article{SCHNEIDER2012475,
title = {Eye gaze reveals a fast, parallel extraction of the syntax of arithmetic formulas},
journal = {Cognition},
volume = {125},
number = {3},
pages = {475-490},
year = {2012},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2012.06.015},
url = {https://www.sciencedirect.com/science/article/pii/S0010027712001357},
author = {Elisa Schneider and Masaki Maruyama and Stanislas Dehaene and Mariano Sigman},
keywords = {Arithmetic, Gestalt, Cognitive architecture, Language, Mathematical education},
abstract = {Mathematics shares with language an essential reliance on the human capacity for recursion, permitting the generation of an infinite range of embedded expressions from a finite set of symbols. We studied the role of syntax in arithmetic thinking, a neglected component of numerical cognition, by examining eye movement sequences during the calculation of arithmetic expressions. Specifically, we investigated whether, similar to language, an expression has to be scanned sequentially while the nested syntactic structure is being computed or, alternatively, whether this structure can be extracted quickly and in parallel. Our data provide evidence for the latter: fixations sequences were stereotypically organized in clusters that reflected a fast identification of syntactic embeddings. A syntactically relevant pattern of eye movement was observed even when syntax was defined by implicit procedural rules (precedence of multiplication over addition) rather than explicit parentheses. While the total number of fixations was determined by syntax, the duration of each fixation varied with the complexity of the arithmetic operation at each step. These findings provide strong evidence for a syntactic organization for arithmetic thinking, paving the way for further comparative analysis of differences and coincidences in the instantiation of recursion in language and mathematics.}
}
@article{NSSSN2024106769,
title = {VNSMAS: A constraint-based portfolio profit maximization},
journal = {Computers & Operations Research},
volume = {170},
pages = {106769},
year = {2024},
issn = {0305-0548},
doi = {https://doi.org/10.1016/j.cor.2024.106769},
url = {https://www.sciencedirect.com/science/article/pii/S0305054824002417},
author = {Usha Devi N.S.S.S.N. and R. Mohan},
keywords = {GAN, Reinforcement learning, Stock, Fuzzy},
abstract = {Stock trading has a more significant influence on the global economy. Stock trading with portfolio optimization became challenging due to the complexity of analyzing the high variance in time series stock data. Efficient portfolio management increases profit and avoids risky situations when investing. The present work aims to model a Variable Neighborhood Search Multi-Agent System for Portfolio Optimization (VNSMASPPO) to optimize the profit on defined trading constraints on buying, selling, and holding trading decisions. This work proposes a novel Variable Neighborhood Search-based Multi-Agent System (VNASMAS) algorithm for profit computation with a constraint-based multi-agent system. The stock price history experimental data sets are collected from 8th August 2016 to 31st March 2023 with 14,567 records. The proposed model achieved an RMSE of 10.11, MAE of 2.75, and MAPE of 0.017, outperforming the literature models. VNSMASPPO maximizes the portfolio profit and is a reliable, adaptable approach.}
}
@article{MARITAN2022167351,
title = {Building Structural Models of a Whole Mycoplasma Cell},
journal = {Journal of Molecular Biology},
volume = {434},
number = {2},
pages = {167351},
year = {2022},
issn = {0022-2836},
doi = {https://doi.org/10.1016/j.jmb.2021.167351},
url = {https://www.sciencedirect.com/science/article/pii/S002228362100588X},
author = {Martina Maritan and Ludovic Autin and Jonathan Karr and Markus W. Covert and Arthur J. Olson and David S. Goodsell},
keywords = {whole cell modeling, computational modeling, nucleoid structure, scientific visualization, mycoplasma genitalium},
abstract = {Building structural models of entire cells has been a long-standing cross-discipline challenge for the research community, as it requires an unprecedented level of integration between multiple sources of biological data and enhanced methods for computational modeling and visualization. Here, we present the first 3D structural models of an entire Mycoplasma genitalium (MG) cell, built using the CellPACK suite of computational modeling tools. Our model recapitulates the data described in recent whole-cell system biology simulations and provides a structural representation for all MG proteins, DNA and RNA molecules, obtained by combining experimental and homology-modeled structures and lattice-based models of the genome. We establish a framework for gathering, curating and evaluating these structures, exposing current weaknesses of modeling methods and the boundaries of MG structural knowledge, and visualization methods to explore functional characteristics of the genome and proteome. We compare two approaches for data gathering, a manually-curated workflow and an automated workflow that uses homologous structures, both of which are appropriate for the analysis of mesoscale properties such as crowding and volume occupancy. Analysis of model quality provides estimates of the regularization that will be required when these models are used as starting points for atomic molecular dynamics simulations.}
}
@article{SCHWABER1993126,
title = {Computational modeling of neuronal dynamics for systems analysis: application to neurons of the cardiorespiratory NTS in the rat},
journal = {Brain Research},
volume = {604},
number = {1},
pages = {126-141},
year = {1993},
issn = {0006-8993},
doi = {https://doi.org/10.1016/0006-8993(93)90359-U},
url = {https://www.sciencedirect.com/science/article/pii/000689939390359U},
author = {J.S. Schwaber and E.B. Graves and J.F.R. Paton},
keywords = {Nucleus tractus solitarii, Systems modeling, Cardiovascular reflex, Neuronal dynamics},
abstract = {The study constructs computational models of neurons in order to examine the contribution that their response dynamics may make to functional properties at the system level. As described in the accompanying study, neurons in the cardiorespiratory nucleus tractus solitarii (NTS) of the rat were recorded in vitro. When these cells were intracellularly injected with a constant current pulse, spike discharge patterns and subthreshold voltage trajectories were observed that were time- and voltage-dependent. The accompanying manuscript describes these dynamic responses in 4 classes of putative second-order cells that appear to receive direct primary afferent input, and a previous paper described two populations of rhythmically firing interneurons, one of which is intrinsically auto-active. In the present manuscript experimental neuronal voltage response data was collected across a current injection series for the S3 neuron type described in the accompanying study and for the auto-active neuron described previously. Using this data, computational model neurons have been constructed for these two neurons by using membrane ion channels to produce and match the observed neuronal voltage behavior. The channels were those implicated in the dynamic responses observed in the companion study, and include gNafast, gKdr, gKA, gKCa, gKAHP, gKM, gCaT and gCaL. The description of channel kinetics follows the Hodgkin-Huxley form. Different neuronal sources from the literature of channel kinetics were investigated and assembled into a ‘channel kinetics library’ from which both neuron models were tuned, primarily by adjusting the maximum channel densities, g¯, and time-dependence of kinetics. Methods are described for tuning the channel kinetics library to match various physiological responses. This approach created neuron models that were able to closely replicate the observed complex voltage and spiking responses of the two very different cardiorespiratory NTS neurons. The interaction of voltage- and calcium-dependent conductances were analyzed for their functional contributions by tuning their kinetics. Specific parameters are given that account for the behavior of each model. Sensitivity analyses by perturbing KCa and KA are are shown for both neurons, and I/F curves are presented for the auto-active neuron's simulated and recorded responses. The potential systems-level functional implications resulting from the different kinetics is demonstrated by driving the S3 model neuron in simulation with the pattern of input produced by model primary baroreceptor afferents. The limitations and significance of this approach are discussed. The present study of model neurons are being extended to the larger family of neurons found in the cardiorespiratory NTS (e.g. S1, S2 and S4), are being related to the baroreceptor vagal reflex by in vivo studies, and are being used to explore systems level computation, for example by creating networks reflecting baroreceptor reflex organization. The present kinetics library in principle could be used in this way for other neuronal systems.}
}
@article{BROWN19921,
title = {Some conceptual issues in the modeling and computational analysis of the Canada-U.S. Free Trade Agreement},
journal = {The North American Journal of Economics and Finance},
volume = {3},
number = {1},
pages = {1-20},
year = {1992},
issn = {1062-9408},
doi = {https://doi.org/10.1016/1062-9408(92)90009-G},
url = {https://www.sciencedirect.com/science/article/pii/106294089290009G},
author = {Drusilla K. Brown and Robert M. Stern},
abstract = {We present an interpretive history of the development of the computational analysis of the Canada-U.S. FTA. Several important conceptual issues are identified, including: perfect competition and national product differentiation; imperfect competition and increasing returns to scale; tariff liberalization and monopolistic competition; adjustment and dynamic effects; macroeconomic effects; and other pertinent aspects of market structure and firm behavior.}
}
@article{LAO2022,
title = {Analyzing Suicide Risk From Linguistic Features in Social Media: Evaluation Study},
journal = {JMIR Formative Research},
volume = {6},
number = {8},
year = {2022},
issn = {2561-326X},
doi = {https://doi.org/10.2196/35563},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X22007910},
author = {Cecilia Lao and Jo Lane and Hanna Suominen},
keywords = {evaluation study, interdisciplinary research, linguistics, machine learning, mental health, natural language processing, social media, suicide risk},
abstract = {Background
Effective suicide risk assessments and interventions are vital for suicide prevention. Although assessing such risks is best done by health care professionals, people experiencing suicidal ideation may not seek help. Hence, machine learning (ML) and computational linguistics can provide analytical tools for understanding and analyzing risks. This, therefore, facilitates suicide intervention and prevention.
Objective
This study aims to explore, using statistical analyses and ML, whether computerized language analysis could be applied to assess and better understand a person’s suicide risk on social media.
Methods
We used the University of Maryland Suicidality Dataset comprising text posts written by users (N=866) of mental health–related forums on Reddit. Each user was classified with a suicide risk rating (no, low, moderate, or severe) by either medical experts or crowdsourced annotators, denoting their estimated likelihood of dying by suicide. In language analysis, the Linguistic Inquiry and Word Count lexicon assessed sentiment, thinking styles, and part of speech, whereas readability was explored using the TextStat library. The Mann-Whitney U test identified differences between at-risk (low, moderate, and severe risk) and no-risk users. Meanwhile, the Kruskal-Wallis test and Spearman correlation coefficient were used for granular analysis between risk levels and to identify redundancy, respectively. In the ML experiments, gradient boost, random forest, and support vector machine models were trained using 10-fold cross validation. The area under the receiver operator curve and F1-score were the primary measures. Finally, permutation importance uncovered the features that contributed the most to each model’s decision-making.
Results
Statistically significant differences (P<.05) were identified between the at-risk (671/866, 77.5%) and no-risk groups (195/866, 22.5%). This was true for both the crowd- and expert-annotated samples. Overall, at-risk users had higher median values for most variables (authenticity, first-person pronouns, and negation), with a notable exception of clout, which indicated that at-risk users were less likely to engage in social posturing. A high positive correlation (ρ>0.84) was present between the part of speech variables, which implied redundancy and demonstrated the utility of aggregate features. All ML models performed similarly in their area under the curve (0.66-0.68); however, the random forest and gradient boost models were noticeably better in their F1-score (0.65 and 0.62) than the support vector machine (0.52). The features that contributed the most to the ML models were authenticity, clout, and negative emotions.
Conclusions
In summary, our statistical analyses found linguistic features associated with suicide risk, such as social posturing (eg, authenticity and clout), first-person singular pronouns, and negation. This increased our understanding of the behavioral and thought patterns of social media users and provided insights into the mechanisms behind ML models. We also demonstrated the applicative potential of ML in assisting health care professionals to assess and manage individuals experiencing suicide risk.}
}
@article{ENRIQUEZHIDALGO2025123924,
title = {Evaluation of decision-support tools for coastal flood and erosion control: A multicriteria perspective},
journal = {Journal of Environmental Management},
volume = {373},
pages = {123924},
year = {2025},
issn = {0301-4797},
doi = {https://doi.org/10.1016/j.jenvman.2024.123924},
url = {https://www.sciencedirect.com/science/article/pii/S0301479724039112},
author = {Andrés M. Enríquez-Hidalgo and Andrés Vargas-Luna and Andrés Torres},
keywords = {Decision support tool, Coastal erosion and flood management, Development pathways, Coastal archetypes, Multi-criteria decision analysis},
abstract = {Coastal areas face significant challenges due to natural and anthropogenic changes, such as sea level rise, extreme events and coastal erosion. The coastal management requires the consideration of socioeconomic and environmental factors to address these variables. The selection of an appropriate Decision Support Tool (DST) based on decision matrix method plays a crucial role in implementing coastal management strategies to tackle climate change-related issues. This has posed considerable challenges for decision-makers, aligning with the Sustainable Development Goals (SDG). This review provides an overview of the practical experience in the application of DSTs for coastal erosion and flood risk, emphasizing the use of Multi-Criteria Decision Analysis (MCDA). DST choice depends on the coastal archetype, including its geographical features and sociocultural context. The purpose is to clarify how the integration of DSTs maximizes flexibility and supports the implementation of future Decision Support System (DSS) tailored to the needs of coastal cities with development pathways (DP). This review assesses different MCDA methods, highlighting their applicability, utility, and integration in coastal management, while evaluating each method's strengths, weaknesses, and specific applications, with a focus on sustainability and resilience. The review highlights the necessity of expert knowledge in accurately defining criteria and weighting factors to ensure that the chosen MCDA method reflects the complexities of the coastal environment. Depending on the scenario, methods like PROMETHEE and ELECTRE are recommended for their flexibility and robustness in handling complex decision-making processes, especially in data-rich and well-structured environments. In contrast, TOPSIS and AHP are suitable for scenarios with limited information or requiring minimal interaction with decision-makers. For more challenging contexts, where computational resources and expertise are constrained, methods like MAUT, VIKOR, and TODAIM emerge as viable alternatives due to their adaptability and reduced reliance on extensive datasets.}
}
@article{BLAND2025,
title = {Quantal response equilibrium as a structural model for estimation: The missing manual},
journal = {Games and Economic Behavior},
year = {2025},
issn = {0899-8256},
doi = {https://doi.org/10.1016/j.geb.2025.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S0899825625000211},
author = {James R. Bland and Theodore L. Turocy},
keywords = {Quantal response, Estimation, Computation, Experiments},
abstract = {One of the original objectives of the (logit) quantal response equilibrium (LQRE) model was to provide a method for structural estimation of behavior in games, when behavior deviated from Nash equilibrium predictions. To date, only Chapter 6 of the book on quantal response equilibrium by Goeree et al. (2016) focuses on how such estimation can be implemented. We build on that chapter to provide here a more detailed treatment of the methodological issues of implementing maximum likelihood estimation of QRE. We compare the equilibrium correspondence and empirical payoff approaches to estimation, and identify some considerations in interpreting the results of those approaches when applied to the same data on the same game. We also provide a more detailed “field guide” to using numerical continuation methods to accomplish estimation, including guidance on how to tailor implementations to games with different structures.}
}
@article{PURWANTO2019118170,
title = {Using group model building to develop a causal loop mapping of the water-energy-food security nexus in Karawang Regency, Indonesia},
journal = {Journal of Cleaner Production},
volume = {240},
pages = {118170},
year = {2019},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2019.118170},
url = {https://www.sciencedirect.com/science/article/pii/S0959652619330409},
author = {Aries Purwanto and Janez Sušnik and F.X. Suryadi and Charlotte {de Fraiture}},
keywords = {Group model building, Causal loop diagram, Water-energy-food (WEF) security, Nexus modelling},
abstract = {This paper develops a qualitative causal model of a water, energy, and food (WEF) security nexus system to be used in analysing the interlinkages among those and other sectors that influence and are influenced by each other in a local context. Local stakeholder engagement through a group model building (GMB) approach was applied in Karawang Regency, Indonesia, to develop the model with the goals of improving problem understanding, raising consensus among participants, and building acceptance and commitment regarding the subsequent development of a quantitative nexus model. After recognizing the issues regarding water, energy and food sectors in the study area and eliciting opinions about nexus interactions, the next stage was to build a conceptual framework to describe the nexus system and to develop an integrated causal loop diagram (CLD) that describes critical system (inter-)linkages. The developed Karawang WEF security (K-WEFS) model is composed of six sub-models with water, energy and food sectors as endogenous factors. In addition, population, economic and ecosystem services were considered as exogenous drivers of the system. It is expected that all the major internal and external factors and drivers are covered, including possible feedback mechanisms, and key variables will be analysed further in the system. The future achievement of WEF security targets can be based on robust evaluation and planning processes underpinned by thorough understanding of whole system dynamics and the impacts of changes in the linked sectors, even in a qualitative way. In this way, a first step towards breaking silo thinking in regional planning may be attained.}
}
@article{DELI2021784,
title = {The thermodynamics of cognition: A mathematical treatment},
journal = {Computational and Structural Biotechnology Journal},
volume = {19},
pages = {784-793},
year = {2021},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2021.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S200103702100012X},
author = {Eva Deli and James Peters and Zoltán Kisvárday},
keywords = {Consciousness, Free will, Mental energy, Intellect, Emotional regulation, Fermionic mind hypothesis, Carnot cycle, Landauer's principle},
abstract = {There is a general expectation that the laws of classical physics must apply to biology, particularly the neural system. The evoked cycle represents the brain's energy/information exchange with the physical environment through stimulus. Therefore, the thermodynamics of emotions might elucidate the neurological origin of intellectual evolution, and explain the psychological and health consequences of positive and negative emotional states based on their energy profiles. We utilized the Carnot cycle and Landauer's principle to analyze the energetic consequences of the brain's resting and evoked states during and after various cognitive states. Namely, positive emotional states can be represented by the reversed Carnot cycle, whereas negative emotional reactions trigger the Carnot cycle. The two conditions have contrasting energetic and entropic aftereffects with consequences for mental energy. The mathematics of the Carnot and reversed Carnot cycles, which can explain recent findings in human psychology, might be constructive in the scientific endeavor in turning psychology into hard science.}
}
@incollection{VALLERO2014953,
title = {Chapter 33 - Grand Challenges},
editor = {Daniel Vallero},
booktitle = {Fundamentals of Air Pollution (Fifth Edition)},
publisher = {Academic Press},
edition = {Fifth Edition},
address = {Boston},
pages = {953-961},
year = {2014},
isbn = {978-0-12-401733-7},
doi = {https://doi.org/10.1016/B978-0-12-401733-7.00033-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780124017337000335},
author = {Daniel Vallero},
keywords = {Bayesian, Biogeochemical cycles, Categorical imperative, Circle of poisons, CO, Command and control, Computational tools, Fossil fuels, Fundamentals of air pollution, Geographic information system (GIS), Geostatistics, Global greenhouse gas emissions (GHG), Grand Challenges, Immanuel Kant, Indoor air pollution, Informatics, Kriging, National Academy of Engineering, Precautionary principle, Pre-Kindergarten, Real-world exposures, Reductionist, Risk, Sustainability, Systems thinking, Transdisciplinary, Translational science},
abstract = {This chapter looks to the future of air quality and how the lessons learned in recent decades can be applied to new problems. The challenges include finding ways to prevent emerging economies from repeating the air pollution mistakes and harm that developed nations have experienced in arriving at solutions to air pollution problems. Other challenges include: global problems, such as long-range transport of pollutants, climate change; real-world-exposures (including indoor air pollution); improvements in technologies to remove difficult-to-treat pollutants; and addressing the growing number of mobile sources. This will require more systems thinking and sustainable, transdisciplinary solutions. The legacy of the current cadre of air pollution experts must be one of translational science and the enhancement of early air pollution education for the next generation.}
}
@incollection{HARNAD2005817,
title = {Chapter 36 - A GROUNDED MIND IN A ROBOTIC BODY},
editor = {Henri Cohen and Claire Lefebvre},
booktitle = {Handbook of Categorization in Cognitive Science},
publisher = {Elsevier Science Ltd},
address = {Oxford},
pages = {817-820},
year = {2005},
isbn = {978-0-08-044612-7},
doi = {https://doi.org/10.1016/B978-008044612-7/50091-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780080446127500913},
author = {STEVAN HARNAD},
abstract = {Publisher Summary
This chapter presents the important themes of embodied cognition. In the chapter, Poirier and others first point out that minds (and brains) have bodies, and that this is not only unlikely to be incidental, but also most of the things that minds can do, they do with their bodies. Pure thinking, that is cognition, seems in and of itself to be a disembodied mental activity, conducted autonomously inside our heads without any signs of sensorimotor interaction with the world of objects, organisms, states, events, and properties that most of our thoughts are about. But surely whatever pure thinking does go on in our heads occurs in the service of our present and future doings in the world, and is grounded in our past doings. Both Proulx and Hélie, and Cangelosi are concerned with how to give a cognitive system the sensorimotor capacity, which is the capacity to detect, recognize and do the kinds of things that one is able to do with the kinds of things there are in the world. In other words, it is the capacity to categorize. The shapes that objects project on one's sensory surfaces can be processed by neural networks that do what is called unsupervised learning.}
}
@article{PUTICA2024105836,
title = {Reconceptualizing complex posttraumatic stress disorder: A predictive processing framework for mechanisms and intervention},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {164},
pages = {105836},
year = {2024},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2024.105836},
url = {https://www.sciencedirect.com/science/article/pii/S0149763424003051},
author = {Andrea Putica and James Agathos},
keywords = {Complex Posttraumatic Stress Disorder (C-PTSD), Predictive processing, Trauma, Interoceptive inference, Active inference},
abstract = {In this article, we introduce a framework for interpreting Complex Posttraumatic Stress Disorder (C-PTSD) through predictive processing, a neuroscience concept explaining the brain’s interpretation and prediction of sensory information. While closely related to PTSD, C-PTSD encompasses additional symptom clusters marked by disturbances in self-organization (DSO), such as negative self-concept, affect dysregulation, and relational difficulties, typically resulting from prolonged traumatic stressors. Our model leverages advances in computational psychiatry and neuroscience, offering a mechanistic explanation for these symptoms by illustrating how prolonged trauma disrupts the brain's predictive processing. Specifically, altered predictive mechanisms contribute to C-PTSD's symptomatology, focusing on DSO: (1) Negative self-concept emerges from maladaptive priors that bias perception towards self-criticism, misaligning expected and actual interoceptive states; (2) Misalignment between predicted and actual interoceptive signals leads to affect dysregulation, with sensitivity to bodily cues; and (3) Relationship challenges arise from skewed social prediction errors, fostering mistrust and withdrawal. This precision-focused approach sheds light on the dynamics underpinning C-PTSD and highlights potential intervention targets aimed at recalibrating the predictive processing system.}
}
@article{DAI2024108354,
title = {Leveraging artificial intelligence (AI) in English as a foreign language (EFL) classes: Challenges and opportunities in the spotlight},
journal = {Computers in Human Behavior},
volume = {159},
pages = {108354},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108354},
url = {https://www.sciencedirect.com/science/article/pii/S074756322400222X},
author = {Kun Dai and Quanguo Liu},
keywords = {Artificial intelligence (AI), AI-Powered instruments, Challenges and opportunities, English as a foreign language (EFL) classes, EFL students},
abstract = {The widespread use of Artificial Intelligence (AI) in language education contexts has motivated several scholars around the world to uncover the advantages and disadvantages of AI and AI-powered instruments in different language classrooms. Yet, as the review of earlier investigations revealed, few inquiries have been carried out to divulge the pros and cons of leveraging AI in EFL classes. To narrow this gap, using the phenomenological approach, this inquiry investigated the opportunities and challenges of implementing AI in EFL classes from the perspective of Chinese EFL students. To do so, through the criterion sampling technique, a total of 45 EFL students was recruited from different educational institutions in China. To collect the dataset, participants were asked to complete an open-ended questionnaire. For the sake of triangulation, among the 45 participants, 15 were randomly selected to engage in a follow-up interview session. With the aid of MAXQDA software (version 2023), participants’ perceptions of AI opportunities and challenges were carefully analyzed. Overall, the analysis findings uncovered that leveraging AI in EFL classes can bring numerous opportunities for EFL students, including individualized learning, timely and immediate feedback, rich educational resources, and an interactive learning atmosphere. However, as demonstrated by the analysis outcomes, implementing AI in EFL courses may also face students with a range of challenges and problems. The research outcomes would be of great help to teachers and educational leaders in mitigating the challenges of leveraging AI in language classrooms.}
}
@incollection{PANDEY202563,
title = {Chapter 4 - Impact of quantum computing on healthcare data security},
editor = {Gayathri Nagasubramanian and S. Rakesh Kumar and Valentina {Emilia Balas}},
booktitle = {Quantum Computing for Healthcare Data},
publisher = {Academic Press},
pages = {63-90},
year = {2025},
series = {Advances in Biomedical Informatics},
isbn = {978-0-443-29297-2},
doi = {https://doi.org/10.1016/B978-0-443-29297-2.00002-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780443292972000022},
author = {Manoj Kumar Pandey and Jyoti Upadhyay and Naresh Kumar Kar and Velliangiri Sarveshwaran},
keywords = {Quantum computing, security, cryptography, healthcare, challenges, sustainable development goals},
abstract = {With the potential to completely transform computation, quantum computing (QC) is a young topic at the vanguard of scientific inquiry and technological advancement. QC promises to bring about dramatic improvements in data security and processing capabilities when it is integrated into healthcare systems. Conventional encryption techniques like RSA and ECC are based on discrete logarithms and integer factorization, two cryptographic issues that are currently unsolvable but can be solved by QC. This trend, however, also makes it more likely that current cryptographic systems will be subject to quantum attacks, which will force the creation and use of encryption methods that are resistant to quantum attacks. Additionally, by employing quantum-resistant hashing techniques, QC enables improved data integrity verification, guaranteeing the veracity and validity of medical data. The applied application of quantum-resistant cryptography techniques and the integration of quantum secure protocols into the current healthcare infrastructure still facing some difficulties therefore anyhow these encouraging advancements in this technique. This chapter focuses on the effect of the QC on the security of healthcare data with particular importance on how it revolutionized encryption, data integrity, privacy protection, and other related issues.}
}
@article{CAGNAC2023,
title = {Codes and methods improvements for safety assessment and LTO: varied approaches},
journal = {EPJ - Nuclear Sciences & Technologies},
volume = {9},
year = {2023},
issn = {2491-9292},
doi = {https://doi.org/10.1051/epjn/2023001},
url = {https://www.sciencedirect.com/science/article/pii/S2491929223000109},
author = {Albannie Cagnac and Denis Verrier and Vladislav Pištora},
abstract = {Nuclear safety has always been at the heart of the concerns of nuclear power plant operators and developers, as well as of various nuclear research organizations and regulatory authorities. Over the last decades, all these nuclear actors have developed and integrated a large number of calculation codes and other tools into their safety work. From the system approach to the local understanding of a phenomenon on a given component, from neutronics to operation optimization for long-term operation, these methods and codes have been constantly evolving since their appearance, in order to be able to integrate new plant designs and components, to improve the results of modeling physical phenomena or quantify and thus reduce the uncertainties on these results. Currently, several H2020 Euratom projects are working on the improvement of these codes and methods. This article will focus on three of these projects: CAMIVVER (Codes And Methods Improvements for VVER comprehensive safety assessment), APAL (Advanced PTS Analysis for LTO), and sCO2-4-NPP (innovative SCO2-based heat removal technology for an increased level of safety of Nuclear Power Plants) in order to illustrate our thinking on the improvement of calculation frameworks. First, we will present the work and the approach adopted with regard to the different calculation codes and methods used in each of these three projects. We will then conclude with an overall analysis of these three approaches, highlighting the difficulties and successes of these three projects, and identifying areas of work for the general improvement of the calculation codes.}
}
@article{THOMPSON2024939,
title = {Leveraging marine biotechnology for an All-Atlantic sustainable blue economy},
journal = {Trends in Biotechnology},
volume = {42},
number = {8},
pages = {939-941},
year = {2024},
issn = {0167-7799},
doi = {https://doi.org/10.1016/j.tibtech.2023.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S0167779923003670},
author = {Cristiane Thompson and Alice C. Ortmann and Thulani Makhalanyane and Fabiano Thompson},
keywords = {All Atlantic, food security, biotechnology, low-carbon aquaculture, integrated multitrophic aquaculture, biofloc technology},
abstract = {Despite the lack of research, development, and innovation funds, especially in South Atlantic countries, the Atlantic is suited to supporting a sustainable marine bioeconomy. Novel low-carbon mariculture systems can provide food security, new drugs, and climate mitigation. We suggest how to develop this sustainable marine bioeconomy across the entire Atlantic.}
}
@article{SALCEANU2014837,
title = {The Influence of Computer Games on Children's Development. Exploratory Study on the Attitudes of Parents},
journal = {Procedia - Social and Behavioral Sciences},
volume = {149},
pages = {837-841},
year = {2014},
note = {LUMEN 2014 - From Theory to Inquiry in Social Sciences, Iasi, Romania, 10-12 April 2014},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2014.08.323},
url = {https://www.sciencedirect.com/science/article/pii/S1877042814050368},
author = {Claudia Sălceanu},
keywords = {Computer games, influence on children, positive and negative effects of computer games, parents’ attitudes;},
abstract = {The current study aims to investigate the attitudes of parents (N=1087) regarding the influence of computer games on their children's development in the following aspects: time they spend at the computer to play, types of favourite games, ways of child supervision, benefits and disadvantages of computer games. The results of the research show: 30.47% of children may access the computer anytime they want; the computer is mostly used for games (36.28%); 42.87% of parents supervise their children's activities at the computer only when they have spare time; 50% of parents allow their children to spend 1-2hours at computer games every day, while 28.54% allow 3-4hours (and more) of computer games every day. The biggest benefits of computer games, according to parents, are thinking development (9.60%), observation capacity (8.27%), and creativity (8.01%). The biggest disadvantages of computer games are the lack of physical movement (13.37%), sight disorders (13.15%) and agitation (8.58%). Parents recognize that games can have powerful effects on children, and should therefore set limits on the amount and content of games their children play. In this way, we can realize the potential benefits while minimizing the potential harms.}
}
@article{PERIGNAT201931,
title = {STEAM in practice and research: An integrative literature review},
journal = {Thinking Skills and Creativity},
volume = {31},
pages = {31-43},
year = {2019},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2018.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S1871187118302190},
author = {Elaine Perignat and Jen Katz-Buonincontro},
keywords = {STEAM education, Creativity, Arts-integration, Transdisciplinary, Interdisciplinary},
abstract = {This integrative review examines 44 published articles (empirical, descriptive, and pedagogical frameworks) on the topic of STEAM (Science, Technology, Engineering, Arts, Mathematics) education from 2007 to 2018. Despite the emergence of STEAM as a popular pedagogical approach for enhancing students’ creativity, problem-solving skills, and interest in STEM fields, the definitions and purposes of STEAM education remain ubiquitous. Therefore, the review examined descriptions of the overall purpose of STEAM education, definitions of the STEAM acronym and the ‘A’ in STEAM, creativity as a learning outcome, elements of arts education, and arts education learning outcomes. The review found a myriad of definitions of the STEAM concept in general, a variety of interpretations for the “A” in STEAM, and an overall lack of reported learning outcomes in the areas of creativity, problem-solving, and arts education. The articles also differentiate in methods for merging STEAM disciplines, described in one of five ways: transdisciplinary, interdisciplinary, multi-disciplinary, cross-disciplinary, and arts-integration. Recommendations are provided to advance both research and practice in STEAM education.}
}
@article{CUSHEN2011458,
title = {Aha! Voila! Eureka! Bilingualism and insightful problem solving},
journal = {Learning and Individual Differences},
volume = {21},
number = {4},
pages = {458-462},
year = {2011},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2011.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S1041608011000215},
author = {Patrick J. Cushen and Jennifer Wiley},
keywords = {Bilingualism, Creativity, Insight, Problem solving},
abstract = {What makes a person able to solve problems creatively? One interesting factor that may contribute is experience with multiple languages from an early age. Bilingual individuals who acquire two languages by the age of 6 have been shown to demonstrate superior performance on a number of thinking tasks that require flexibility. However, bilingual advantages have yet to be identified particularly on insight problems that are used as a model of creative problem solving following initial impasse. As such, the goal of the present study was to investigate the influence of language experience on problem solving performance on a matched set of insight and non-insight problems. Results demonstrate an interaction between type of problem (insight versus non-insight) and language status.}
}
@incollection{QAZI2025245,
title = {Chapter 11 - Deep learning in clinical genomics-based cancer diagnosis},
editor = {Khalid Raza},
booktitle = {Deep Learning in Genetics and Genomics},
publisher = {Academic Press},
pages = {245-259},
year = {2025},
isbn = {978-0-443-27574-6},
doi = {https://doi.org/10.1016/B978-0-443-27574-6.00014-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044327574600014X},
author = {Sahar Qazi and Raiyan Ali and Manoj Kumar Jana and Bimal Prasad Jit and Neeraj Gurung and Ashok Sharma},
keywords = {Artificial intelligence, Bioinformatics, Cancer, Deep learning, Diagnosis, Next generation sequencing, Variant calling},
abstract = {Deep learning, an artificial intelligence facet, has impacted distinct fields, including natural language processing and computer vision. Its advancements have transformed how computational and data scientists approach data, turning unstructured information into valuable insights. This is particularly impactful in clinical genomics, where high-throughput sequencing generates vast amounts of data. Techniques such as whole genome sequencing and transcriptomic profiling produce enormous datasets that are challenging to analyze manually. Deep learning tools like “Deep Variant” enhance accuracy in variant calling, improving diagnostic precision. By adapting to factors such as genetic mutations and disease progression, deep learning aids in early cancer diagnosis and better clinical outcomes. This chapter explores these transformative applications in clinical genomic research.}
}
@article{SHOTTER201734,
title = {Persons as dialogical-hermeneutical-relational beings – New circumstances ‘call out’ new responses from us},
journal = {New Ideas in Psychology},
volume = {44},
pages = {34-40},
year = {2017},
note = {SI: The Person},
issn = {0732-118X},
doi = {https://doi.org/10.1016/j.newideapsych.2016.11.007},
url = {https://www.sciencedirect.com/science/article/pii/S0732118X1630157X},
author = {John Shotter},
keywords = {Persons, Ideals, Generalities, Particularities, Hermeneutics, Indeterminacy, Dialogicality},
abstract = {Shifting from a world of already-made-things to a world of things-continually-in-the-making changes everything. Psychology, like all other sciences, tries to proceed by analysis, by breaking down a living, unique, always developing organic whole into a set of general, already-existing, nameable elements. But as Bakhtin makes clear, in discussing how Dostoevsky portrays the inner dynamics of people worrying over how to act for the best in living their lives, such an itemization of merely observed behavioural characteristics leads to a degrading reification of a person's unfinalizability, of their still-developing nature. Below, I first examine the Cartesianism that still seems present in much of our thinking in social inquiry today. I then turn attention to the primacy of our living movements out in the world and their responsiveness to events occurring around us. While finally turning to the fact that, as living beings, what ‘goes on inside us’, is not so important as ‘what we go on inside of’. Although Dostoevsky portrays this indivisible, flowing reality, in terms of a set of discontinuous fragments —because that is the nature of our experience in everyday life — as hermeneutical-dialogical-relational beings, we have a basic capability of organizing them into unitary wholes which sit in the background to everything we think and do.}
}
@article{KISAALITA201658,
title = {Perspectives on context, design teams and diffusion of technological innovations in low-resource settings: A practical approach based on sub-Saharan African projects},
journal = {Technology in Society},
volume = {46},
pages = {58-62},
year = {2016},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2016.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X16300495},
author = {William S. Kisaalita},
keywords = {Technological innovations, Sustainable development, Developing countries, Design teams, Poverty alleviation, Food and energy security},
abstract = {A human-centered design approach for creating science/engineering-driven solutions or innovations, referred to as “connect-the-dots,” is presented. Dots symbolize the best questions and the connections reveal the best order in which these questions should be answered. In this approach, the number of customer or user behavioral changes are critically analyzed, revealing the overall context in which the solution or innovation will operate; especially to undergraduate students creating solutions to problems from settings that are less familiar, from cultural, economic, and geopolitical viewpoints. Solutions or innovations that result in minimal user behavior changes are preferred. Additional benefits include better incorporation of systems theory thinking, ease with which team multidisciplinarity and diversity can be identified, and seamlessly integrating design and research.}
}
@article{YIN2022109800,
title = {Deep learning-accelerated optimization algorithm for controller parameters optimization of doubly-fed induction generators},
journal = {Applied Soft Computing},
volume = {131},
pages = {109800},
year = {2022},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2022.109800},
url = {https://www.sciencedirect.com/science/article/pii/S1568494622008493},
author = {Linfei Yin and Xinghui Cao and Senlin Wang},
keywords = {Deep fully connected models, Gray wolf optimizer, Adaptive differential evolution, Global search, Parameter optimization},
abstract = {In this work, a cooperative Gray wolf Optimizer with adaptive differential Evolution (GOE) is proposed for the multimodal controller parameters optimization of doubly-fed induction generators (DFIGs) based on maximum power point tracking (MPPT) strategies. Moreover, the optimization process of the GOE is accelerated by a deep fully connected model (DFCM). The GOE contains a cooperative gray wolf optimizer (GWO) and adaptive differential evolution (ADE). The cooperative GWO contains alpha, beta, delta, and omega wolves to explore and exploit optimization problems and achieves optimization tasks wider and deeper than GWO. The ADE cooperates with the cooperative GWO to solve global optimization over continuous spaces. The simulation results on seven uni-model benchmark functions show that the GOE accelerated by DFCM obtains acceptable fitness values with 39.99% lesser computation time than the symmetry adapted stochastic search (SASS) algorithm and 80.72% lesser computation time than the Lévy flights-success-history based adaptive differential evolution with constraint handling technique (COLSHADE) algorithm, which are the winners of the CEC2020 Competition on Real-World Single Objective Constrained Optimization. Furthermore, the simulation results on DFIG with MPPT strategies in three real-world cases verify that the GOE accelerated by DFCM can effectively obtain global optimization solutions for non-smooth problems with 99.51% lesser average computation time than the SASS algorithm, 99.63% less than the COLSHADE algorithm, and 89.52% less than other methods. In addition, the accelerated GOE algorithm by DFCM has the feature of faster convergence.}
}
@article{BERX2022107827,
title = {Identification and classification of risk factors for human-robot collaboration from a system-wide perspective},
journal = {Computers & Industrial Engineering},
volume = {163},
pages = {107827},
year = {2022},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2021.107827},
url = {https://www.sciencedirect.com/science/article/pii/S0360835221007312},
author = {Nicole Berx and Wilm Decré and Ido Morag and Peter Chemweno and Liliane Pintelon},
keywords = {Human-robot collaboration, Human factors, Industry 4.0, Safety, Risk factors, Socio-technical},
abstract = {Industry 4.0 systems in general and advanced manufacturing systems such as collaborative robots, in particular, are characterized by a high level of complexity leading to new safety concerns. Safety, specifically for collaborative robots, has been mainly addressed from a technical perspective, to safeguard the physical safety of the operator. Concerns have been raised regarding less focus in Industry 4.0 literature on how other factors, such as psychosocial can produce safety-related risks for the operator in human-robot collaboration. This paper identifies and classifies the risk factors in a human-robot collaboration that have been described in research papers in the last decade. The resulting five classes constitute dimensions that will be used as preliminary building blocks for a safety evaluation framework to be developed in the next step. By evaluating the resulting classes with the underlying dimensions of contemporary socio-technical thinking, this paper demonstrates that these five classes offer a comprehensive, system-wide perspective including risk factors beyond technological considerations. Topics emerging from new risks related to the impact of working with collaborative robots, such as psychosocial, ethical, and cyber risk factors will need to be taken into account in the risk factors that are important to identify, assess and mitigate before working with collaborative robots. Operator involvement and participation, especially throughout the risk assessment and mitigation cycle are recommended as new areas of attention in human-robot collaboration. Going forward, one challenge will be the agility and adaptability of legislation to at least keep track of risk factors emerging from continuously changing technologies and to translate them into practically applicable tools for enterprises and design engineers implementing collaborative applications. Another key challenge will be the measurement of the new emerging and sometimes less technological risks.}
}
@incollection{HE2013241,
title = {5.16 - Flood Inundation Dynamics and Socioeconomic Vulnerability under Environmental Change},
editor = {Roger A. Pielke},
booktitle = {Climate Vulnerability},
publisher = {Academic Press},
address = {Oxford},
pages = {241-255},
year = {2013},
isbn = {978-0-12-384704-1},
doi = {https://doi.org/10.1016/B978-0-12-384703-4.00508-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780123847034005086},
author = {Y. He and F. Pappenberger and D. Manful and H. Cloke and P. Bates and F. Wetterhall and B. Parkes},
keywords = {Flood inundation dynamics, Two-faced flood, Model cascade, Uncertainties, Flood vulnerability, Impact studies, Flood risk, Living with floods, Harnessing floods},
abstract = {Floods are a major threat to human existence and historically have both caused the collapse of civilizations and forced the emergence of new cultures. The physical processes of flooding are complex. Increased population, climate variability, change in catchment and channel management, modified landuse and land cover, and natural change of floodplains and river channels all lead to changes in flood dynamics, and as a direct or indirect consequence, social welfare of humans. Section 5.16.1 explores the risks and benefits brought about by floods and reviews the responses of floods and floodplains to climate and landuse change. Section 5.08.2 reviews the existing modeling tools, and the top–down and bottom–up modeling frameworks that are used to assess impacts on future floods. Section 5.08.3 discusses changing flood risk and socioeconomic vulnerability based on current trends in emerging or developing countries and presents an alternative paradigm as a pathway to resilience. Section 5.08.4 concludes the chapter by stating a portfolio of integrated concepts, measures, and avant-garde thinking that would be required to sustainably manage future flood risk.}
}
@article{LI2024124918,
title = {A method of dense point cloud SLAM based on improved YOLOV8 and fused with ORB-SLAM3 to cope with dynamic environments},
journal = {Expert Systems with Applications},
volume = {255},
pages = {124918},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.124918},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424017858},
author = {Yanke Li and Huabo Shen and Yaping Fu and Kai Wang},
keywords = {SLAM, VSLAM, Neural Network, Deep learning},
abstract = {With the development of society and the advancement of technology, intelligent robots have been widely used in various fields. At the same time, Simultaneous Localization and Mapping (SLAM) technology is a key technology in the research field of intelligent robots. However, in dynamic environments, achieving accurate and robust visual SLAM remains a major challenge. In this paper, we propose a method based on improved YOLOv8 fused with ORB-SLAM3 to address dense point cloud SLAM in dynamic environments. Our proposed method successfully integrates real-time object detection and image segmentation technologies of YOLOv8 into the ORB-SLAM3 framework, achieving high-precision and robust visual SLAM in dynamic environments. In the YOLOv8 framework, we use a balanced convolution method, GSConv, instead of some traditional convolution layers (Conv), which balances accuracy with computational load. Based on the GSConv convolution method, we adopt a new feature fusion module, VoVGSCSP, to replace traditional C2f feature fusion modules, thereby improving the Neck structure of YOLOv8 and achieving a lightweight network model. We compare our proposed method with ORB-SLAM3 and some computer vision algorithms on the TUM dataset. Experimental data confirms that our method outperforms existing visual SLAM algorithms in dynamic environments. In fast-moving dynamic environments, the RMSE of absolute pose estimation of our method is 96.28% lower than that of ORB-SLAM3, and the RMSE of relative pose estimation is 51.57% lower than that of ORB-SLAM3. The experimental results demonstrate that our method significantly improves the accuracy of pose estimation in dynamic environments and greatly enhances the performance compared to ORB-SLAM3.}
}
@article{SIEGELMANN2013117,
title = {Turing on Super-Turing and adaptivity},
journal = {Progress in Biophysics and Molecular Biology},
volume = {113},
number = {1},
pages = {117-126},
year = {2013},
note = {Can Biology Create a Profoundly New Mathematics and Computation?},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2013.03.013},
url = {https://www.sciencedirect.com/science/article/pii/S0079610713000278},
author = {Hava T. Siegelmann},
keywords = {Adaptive computation, Biological computation, Super-Turing computation},
abstract = {Biological processes are often compared to computation and modeled on the Universal Turing Machine. While many systems or aspects of systems can be well described in this manner, Turing computation can only compute what it has been programmed for. It has no ability to learn or adapt to new situations. Yet, adaptation, choice and learning are all hallmarks of living organisms. This suggests that there must be a different form of computation capable of this sort of calculation. It also suggests that there are current computational models of biological systems that may be fundamentally incorrect. We argue that the Super-Turing model is both capable of modeling adaptive computation, and furthermore, a possible answer to the computational model searched for by Turing himself.}
}
@article{TANG2014245,
title = {On the causes of early life experience effects: Evaluating the role of mom},
journal = {Frontiers in Neuroendocrinology},
volume = {35},
number = {2},
pages = {245-251},
year = {2014},
note = {CRH/Stress in Honor of Wylie Vale},
issn = {0091-3022},
doi = {https://doi.org/10.1016/j.yfrne.2013.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S009130221300068X},
author = {Akaysha C. Tang and Bethany C. Reeb-Sutherland and Russell D. Romeo and Bruce S. McEwen},
keywords = {Maternal care, Stress, CORT, HPA, Self-regulation, Novelty, Maternal mediation, Maternal modulation, Early experience, Cognitive development},
abstract = {Early life experiences are thought to have long-lasting effects on cognitive, emotional, and social function during adulthood. Changes in neuroendocrine function, particularly the hypothalamic–pituitary–adrenal (HPA) axis, contribute to these systems-level behavioral effects. In searching for causal mechanisms underlying these early experience effects, pioneering research has demonstrated an important role for maternal care in offspring development, and this has led to two persistent ideas that permeate current research and thinking: first, environmental impact on the developing infant is mediated through maternal care behavior; second, the more care that a mother provides, the better off her offspring. While a good beginning, the reality is likely more complex. In this review, we critically examine these ideas and propose a computationally-motivated theoretical framework, and within this framework, we consider evidence supporting a hypothesis of maternal modulation. These findings may inform policy decisions in the context of child health and development.}
}
@article{BARTOLOZZI2011163,
title = {eMorph: Towards Neuromorphic Robotic Vision},
journal = {Procedia Computer Science},
volume = {7},
pages = {163-165},
year = {2011},
note = {Proceedings of the 2nd European Future Technologies Conference and Exhibition 2011 (FET 11)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2011.09.027},
url = {https://www.sciencedirect.com/science/article/pii/S1877050911005874},
author = {Chiara Bartolozzi and Charles Clercq and Neeraj Mandloi and Francesco Rea and Giacomo Indiveri and Daniel Fasnacht and Giorgio Metta and Michael Hofstätter and Ryad Benosman},
keywords = {neuromorphic, humanoid robot, event-driven computation, vision},
abstract = {The eMorph project aims at introducing a new concept for vision in the field of humanoid robotics. The system that is currently being developed is inspired by the biology of mammalian visual systems, introducing concepts such as stimulus-driven signal acquisition and processing, together with space-variant sensor design coupled with active vision. This approach is leading to the realization of a system that goes beyond current thinking in robotic vision.}
}
@article{PUZANTIAN2021387,
title = {Redesigning a PhD measurement course for a new era in nursing science},
journal = {Journal of Professional Nursing},
volume = {37},
number = {2},
pages = {387-390},
year = {2021},
issn = {8755-7223},
doi = {https://doi.org/10.1016/j.profnurs.2020.04.019},
url = {https://www.sciencedirect.com/science/article/pii/S8755722320300983},
author = {Houry Puzantian and Hala Darwish},
keywords = {Measurement, Quantitative, Nursing research, PhD},
abstract = {Measurement is at the core of the research process. At the PhD level, students need to develop an in-depth understanding of measures relevant to their area of work and refine their knowledge of measurement issues. Traditionally, measurement coursework in Nursing focused on the psychometric evaluation of instruments measuring cognition and behavior. However, in the age of Big Data, precision medicine, and translational science, PhD students need to develop knowledge and skills relevant to these fields and to collaborate with experts from the different disciplines. Therefore, Nursing faculty need to recognize the state-of-the-science of nursing research and tend to a variety of measurement issues across a spectrum of operationalized concepts. Herein we present an overview of learning outcomes, instructional content and methods of delivery for a contemporary PhD-level course on measurement for Nursing Science. We also present our experience in the design, implementation, and evaluation of a novel PhD measurement course.}
}
@article{KAFUKU2019192,
title = {Application of Fuzzy Logic in Selection of Remanufacturing Technology},
journal = {Procedia Manufacturing},
volume = {33},
pages = {192-199},
year = {2019},
note = {Sustainable Manufacturing for Global Circular Economy: Proceedings of the 16th Global Conference on Sustainable Manufacturing},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2019.04.023},
url = {https://www.sciencedirect.com/science/article/pii/S2351978919305001},
author = {John Mbogo Kafuku and Muhamad Zameri {Mat Saman} and Sha’ri Mohd Yusof},
keywords = {Remanufacturing Operations, Technology Selection, Fuzzy Logic, Technology Selection Criteria, Fuzzy Decision Tool},
abstract = {Fuzzy approach is frequently used for selection of manufacturing technology. However, the application of the fuzzy tool for choosing the appropriate remanufacturing technology is seldom applied. This study applies the fuzzy logic approach for the selection of technology in order to minimize vagueness in decision making, thereby making results more similar to experts’ thinking. Through elicitation of experts’ inputs, six cleaning technologies were evaluated and ranked appropriately, using criteria of technology cost, operating cost, and disposal effect. Moreover, the technology selection was computed through experts’ opinion using the fuzzy logic inference system. The results show that when technical function of the technology is at the low level of 20%, the technology quality is as low as 15%, and the technology flexibility is rated as low at 25%; then the technical adequacy of the assessed technology will be as low as 10%. The fuzzy approach shows that technology performance is largely impacted by criteria far beyond the technology itself, including purchasing cost, disposal cost, operating cost, and other support functions to compliment experience of experts. Despite the fact that decision makers are appropriately selecting technology, the application of the fuzzy logic tool helps to accommodate vagueness, ambiguity, and subjective views of experts. Notwithstanding the robustness of the approach, application of software to help selection of technology is more reliable and accurate, reduce time of decision, and can be accessed worldwide.}
}
@article{LI2024120,
title = {Conformal structure-preserving SVM methods for the nonlinear Schrödinger equation with weakly linear damping term},
journal = {Applied Numerical Mathematics},
volume = {205},
pages = {120-136},
year = {2024},
issn = {0168-9274},
doi = {https://doi.org/10.1016/j.apnum.2024.06.024},
url = {https://www.sciencedirect.com/science/article/pii/S0168927424001727},
author = {Xin Li and Luming Zhang},
keywords = {Damped nonlinear Schrödinger equation, Conformal properties, Supplementary variable method, High-order accuracy, Optimization model},
abstract = {In this paper, by applying the supplementary variable method (SVM), some high-order, conformal structure-preserving, linearized algorithms are developed for the damped nonlinear Schrödinger equation. We derive the well-determined SVM systems with the conformal properties and they are then equivalent to nonlinear equality constrained optimization problems for computation. The deduced optimization models are discretized by using the Gauss type Runge-Kutta method and the prediction-correction technique in time as well as the Fourier pseudo-spectral method in space. Numerical results and some comparisons between this method and other reported methods are given to favor the suggested method in the overall performance. It is worthwhile to emphasize that the numerical strategy in this work could be extended to other conservative or dissipative system for designing high-order structure-preserving algorithms.}
}
@article{KONOVALOV20213323,
title = {Dissecting functional contributions of the social brain to strategic behavior},
journal = {Neuron},
volume = {109},
number = {20},
pages = {3323-3337.e5},
year = {2021},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2021.07.025},
url = {https://www.sciencedirect.com/science/article/pii/S0896627321005699},
author = {Arkady Konovalov and Christopher Hill and Jean Daunizeau and Christian C. Ruff},
keywords = {fMRI, TPJ, dmPFC, social, decision making, strategic},
abstract = {Summary
Social interactions routinely lead to neural activity in a “social brain network” comprising, among other regions, the temporoparietal junction (TPJ) and the dorsomedial prefrontal cortex (dmPFC). But what is the function of these areas? Are they specialized for behavior in social contexts or do they implement computations required for dealing with any reactive process, even non-living entities? Here, we use fMRI and a game paradigm separating the need for these two aspects of cognition. We find that most social-brain areas respond to both social and non-social reactivity rather than just to human opponents. However, the TPJ shows a dissociation from the dmPFC: its activity and connectivity primarily reflect context-dependent outcome processing and reactivity detection, while dmPFC engagement is linked to implementation of a behavioral strategy. Our results characterize an overarching computational property of the social brain but also suggest specialized roles for subregions of this network.}
}
@article{BARFAR2019173,
title = {Cognitive and affective responses to political disinformation in Facebook},
journal = {Computers in Human Behavior},
volume = {101},
pages = {173-179},
year = {2019},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2019.07.026},
url = {https://www.sciencedirect.com/science/article/pii/S0747563219302699},
author = {Arash Barfar},
keywords = {Political disinformation, Polarization, Echo chamber, Text analysis, Social media, Facebook},
abstract = {The epidemic of political disinformation in social media has in part triggered the transition to the post-truth era in which emotional and ideological appeals are more influential in shaping public opinion than objective facts. In this study we examined the cognitive and affective responses that political disinformation prompted in Facebook, as the most popular social media platform. Through text analysis of user comments corpora on nearly 2,100 political posts from popular sources in Facebook, we found that compared to true news, political disinformation received significantly less analytic responses from Facebook followers. While the results indicated greater anxiety in responses to true news, responses to political disinformation were filled with greater anger and incivility. We also found similar (low) levels of cognitive thinking in responses to extreme conservative and extreme liberal disinformation. Contrary to prior research findings, our results indicated that responses to extreme liberal disinformation in Facebook were filled with greater anger and incivility. This suggests that the incivility and outrage in online political discourses should not be attributed to a specific political party without considering the concurrent political events.}
}
@article{HAMDI2019772,
title = {Fuzzy Approach for Locating Sensors in Industrial Internet of Things},
journal = {Procedia Computer Science},
volume = {160},
pages = {772-777},
year = {2019},
note = {The 10th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN-2019) / The 9th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH-2019) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.11.012},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919317120},
author = {Sarah El Hamdi and Mustapha Oudani and Abdellah Abouabdellah and Anass Sebbar},
keywords = {I2oT, Architecture, Fuzzy Theory},
abstract = {Nowadays, in this era of a data driven thinking and reflection, data mining and data analysis are keys to any business survival in a competitive conjectural market. The internet of things is an emerging technology that manages to create a path for the new generation of industrial production system. This advanced technology is requirement to the proliferation of Smart factories, it represents the best tool to help this new concept of plants to organize themselves and optimize the available resources and their consumption. The purpose of this paper is two-pronged; a proposal for an architectural framework of the industrial internet of things, and a mathematical formulation based on fuzzy logic to determine the ideal location of sensors at the shop floor taking into consideration several restrictions.}
}
@article{STRATFORD2022115813,
title = {Exploring the potential neurotoxicity of vaping vitamin E or vitamin E acetate},
journal = {Toxicology and Applied Pharmacology},
volume = {434},
pages = {115813},
year = {2022},
issn = {0041-008X},
doi = {https://doi.org/10.1016/j.taap.2021.115813},
url = {https://www.sciencedirect.com/science/article/pii/S0041008X21004178},
author = {Kimberly Stratford and Prabha Kc and Susan Rudy and Anna-Sophie Weidner and Priscilla Callahan-Lyon and Luis G. Valerio},
keywords = {Pulmonary injury, Electronic Nicotine Delivery Systems (ENDS), Tobacco products, Electronic cigarettes, Vitamin E, Vitamin E acetate, E-Cigarette or Vaping Product Use-Associated Lung Injury (EVALI), Vaping, Neurotoxicity, Computational model},
abstract = {Serious adverse health effects have been reported with the use of vaping products, including neurologic disorders and e-cigarette or vaping product use-associated lung injury (EVALI). Vitamin E acetate, likely added as a diluent to cannabis-containing products, was linked to EVALI. Literature searches were performed on vitamin E and vitamin E acetate-associated neurotoxicity. Blood brain barrier (BBB) penetration potential of vitamin E and vitamin E acetate were evaluated using cheminformatic techniques. Review of the literature showed that the neurotoxic potential of inhalation exposures to these compounds in humans is unknown. Physico-chemical properties demonstrate these compounds are lipophilic, and molecular weights indicate vitamin E and vitamin E acetate have the potential for BBB permeability. Computational models also predict both compounds may cross the BBB via passive diffusion. Based on literature search, no experimental nonclinical studies and clinical information on the neurotoxic potential of vitamin E via inhalation. Neurotoxic effects from pyrolysis by-product, phenyl acetate, structurally analogous to vitamin E acetate, suggests vitamin E acetate has potential for central nervous system (CNS) impairment. Cheminformatic model predictions provide a theoretical basis for potential CNS permeability of these inhaled dietary ingredients suggesting prioritization to evaluate for potential hazard to the CNS.}
}
@article{BARTELS2008381,
title = {Principled moral sentiment and the flexibility of moral judgment and decision making},
journal = {Cognition},
volume = {108},
number = {2},
pages = {381-417},
year = {2008},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2008.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0010027708000607},
author = {Daniel M. Bartels},
keywords = {Morality, Judgment, Decision making, Values, Ethics, Intuition, Emotions, Reasoning, Moral rules, Moral dilemmas},
abstract = {Three studies test eight hypotheses about (1) how judgment differs between people who ascribe greater vs. less moral relevance to choices, (2) how moral judgment is subject to task constraints that shift evaluative focus (to moral rules vs. to consequences), and (3) how differences in the propensity to rely on intuitive reactions affect judgment. In Study 1, judgments were affected by rated agreement with moral rules proscribing harm, whether the dilemma under consideration made moral rules versus consequences of choice salient, and by thinking styles (intuitive vs. deliberative). In Studies 2 and 3, participants evaluated policy decisions to knowingly do harm to a resource to mitigate greater harm or to merely allow the greater harm to happen. When evaluated in isolation, approval for decisions to harm was affected by endorsement of moral rules and by thinking style. When both choices were evaluated simultaneously, total harm – but not the do/allow distinction – influenced rated approval. These studies suggest that moral rules play an important, but context-sensitive role in moral cognition, and offer an account of when emotional reactions to perceived moral violations receive less weight than consideration of costs and benefits in moral judgment and decision making.}
}
@article{DELIDDO2021102537,
title = {Let's replay the political debate: Hypervideo technology for visual sensemaking of televised election debates},
journal = {International Journal of Human-Computer Studies},
volume = {145},
pages = {102537},
year = {2021},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2020.102537},
url = {https://www.sciencedirect.com/science/article/pii/S1071581920301397},
author = {Anna {De Liddo} and Nieves Pedreira Souto and Brian Plüss},
keywords = {Sensemaking, Public deliberation, Political election debates, Hypervideo, Advanced visual interfaces, Interactive visualisations, Deliberation within},
abstract = {Despite the widespread proliferation of social media in policy and politics, televised election debates are still a prominent form of large-scale public engagement between politicians and the electorate during election campaigns. Advanced visual interfaces can improve these important spaces of democratic engagement. In this paper, we present a user study in which a new hypervideo technology was compared with a publicly available interface for television replay. The results show that hypervideo navigation, coupled with interactive visualisations, improved sensemaking of televised political debates and promoted people's attitude to challenging personal assumptions. This finding suggests that hypervideo interfaces can play a substantial role in supporting citizens in the complex sensemaking process of informing their political choices during an election campaign, and can be used as instruments to promote critical thinking and political opinion shifting.}
}
@incollection{BURATTINI20021315,
title = {37 - Hybrid Expert Systems: An Approach to Combining Neural Computation and Rule-Based Reasoning},
editor = {Cornelius T. Leondes},
booktitle = {Expert Systems},
publisher = {Academic Press},
address = {Burlington},
pages = {1315-1354},
year = {2002},
isbn = {978-0-12-443880-4},
doi = {https://doi.org/10.1016/B978-012443880-4/50081-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780124438804500818},
author = {Ernesto Burattini and Massimo {De Gregorio} and Guglielmo Tamburrini},
abstract = {Publisher Summary
This chapter examines an approach that integrates neural computation and rule-based reasoning, or the hybrid systems. This integration is actively applied in artificial intelligence and cognitive sciences, such as linguistic theory, natural language processing, and expert systems. The opportunity of employing neural techniques in expert systems is often suggested on the ground that the learning, generalization, fault, and noise tolerance capacities of neural networks can alleviate well-known shortcomings of symbolic problem solvers, such as brittleness in front of incomplete or noisy data, no increase in performance with experience, and time-consuming knowledge acquisition. This chapter explores neurosymbolic integration for rule-based expert systems in connection with automatic data acquisition, rule processing, and explanation. At the periphery of expert systems, sensory processing by neural nets is coupled to rule-based reasoning in order to perform a data acquisition task involving the deployment of expert knowledge and heuristic problem solving. The reaction times of rule-based systems are dramatically reduced by the use of a neurally inspired, parallel inference engine. Informative user interactions with expert systems are achieved by coupling symbolic and neurally supported, pictorial explanation. The relative significance of these aspects of neurosymbolic integration is enhanced by pointing to limitations of neural techniques for automatic knowledge acquisition and robust problem solving in expert systems. These uses of neural nets may often jeopardize an expert system's reliability and reduce its transparency to the user.}
}
@incollection{LEVY1989243,
title = {A Computational Approach to Hippocampal Function},
editor = {Robert D. Hawkins and Gordon H. Bower},
series = {Psychology of Learning and Motivation},
publisher = {Academic Press},
volume = {23},
pages = {243-305},
year = {1989},
booktitle = {Computational Models of Learning in Simple Neural Systems},
issn = {0079-7421},
doi = {https://doi.org/10.1016/S0079-7421(08)60113-9},
url = {https://www.sciencedirect.com/science/article/pii/S0079742108601139},
author = {William B Levy},
abstract = {Publisher Summary
This chapter describes the early, formative stages of a theory of hippocampal function. This theory has been stimulated by the psychological observations indicating a role for the hippocampus in short-term working memory and spatial behavior and develops mainly through the consideration of computational issues. These computational issues are related to the psychological viewpoint through physiological and anatomical observations. The hippocampus participates in the prediction of future representations based on past and present representations. All three classes of representations are derived from a multiplicity of sensory modalities, such as auditory, visual, and olfactory signals from neo- and piriform cortices. This fusion of sensory modalities requires recoding because of computational complexity problems. The CA1 region of the hippocampus is postulated to be a prediction-generating layer or tier. This region produces a prediction based on its input from hippocampal region CA3. The combined hippocampal dentate gyrus/CA3 (DG/CA3) system is postulated to be a preprocessor serving the CA1 prediction layer. The computational complexity problems arise from the combinatorial explosion of possible representations resulting when the hippocampus and supporting limbic structures mix representations from multiple sensory modalities.}
}
@article{SANCHIS2023102162,
title = {Towards a general equilibrium theory of allocation of time for the digital revolution era},
journal = {Technology in Society},
volume = {72},
pages = {102162},
year = {2023},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2022.102162},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X22003037},
author = {Raúl G. Sanchis},
keywords = {Household economics, Time allocation, Consumer behaviour, Firm behaviour, General equilibrium},
abstract = {The Digital Revolution we are witnessing has started a new era in modern societies and economies. Time inputs, whether these are from human beings and non-human, electronical or mechanical devices are increasingly more important, especially –but not uniquely– in most advanced economies and societies. Existing economic theory strives to accommodate time inputs into mainstream economic theory. This paper contributes to the existing literature on time allocation theoretical models by suggesting a general equilibrium framework likely to respond to some existing challenges in modern economies. In the general equilibrium modelling process, some improvements are made to time allocation models from the consumer side which concern the inclusion of non-human time inputs and multitasking, and a novel development on a producer theory of allocation of time is designed to determine the underpinnings of a computationally tractable general equilibrium theory of allocation of time. Both the solution and usefulness of this work will require the help of cutting-edge computational techniques in future work.}
}
@article{AKANDA2025112329,
title = {Understanding comment practices in Scratch: A study of comments in a block-based visual programming language},
journal = {Journal of Systems and Software},
volume = {222},
pages = {112329},
year = {2025},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112329},
url = {https://www.sciencedirect.com/science/article/pii/S016412122400373X},
author = {Wahiduzzaman Akanda and James Clause},
keywords = {Comment, Text-based programming, Visual programming, Scratch, Taxonomy},
abstract = {Comments are vital for software documentation. They provide necessary insights and assist developers in understanding and maintaining the software. Due to their importance, comments have been extensively studied, and much has been learned about them. These existing studies have predominantly focused on text-based languages. Conversely, block-based visual programming languages, particularly Scratch, are becoming increasingly popular. Some studies regarding comments related to the Scratch online community focus on topics such as fostering online community and engagement, sentiment analysis, etc. However, they overlook the visual aspects and the qualitative analysis of comments within code in Scratch projects. This is a meaningful limitation, and this research project studies comments and their pattern in Scratch projects from both textual and visual perspectives. We examined comments collected from different Scratch projects. Each comment was manually annotated based on textual and visual attributes, producing a taxonomy model of comments for a visual programming language. The classification results were analyzed to understand better the practice of commenting in Scratch. Our result revealed that Scratch projects produced noisier(i.e., less understandable) comments than text-based programming languages like Java. In addition, the study also revealed several limitations and shortcomings that could be addressed to improve the commenting experience in Scratch.}
}
@article{SHI2023926,
title = {Decoding Human Biology and Disease Using Single-cell Omics Technologies},
journal = {Genomics, Proteomics & Bioinformatics},
volume = {21},
number = {5},
pages = {926-949},
year = {2023},
issn = {1672-0229},
doi = {https://doi.org/10.1016/j.gpb.2023.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S1672022923001043},
author = {Qiang Shi and Xueyan Chen and Zemin Zhang},
keywords = {Single-cell omics, Computational method, Cellular heterogeneity, Disease, Cancer research},
abstract = {Over the past decade, advances in single-cell omics (SCO) technologies have enabled the investigation of cellular heterogeneity at an unprecedented resolution and scale, opening a new avenue for understanding human biology and disease. In this review, we summarize the developments of sequencing-based SCO technologies and computational methods, and focus on considerable insights acquired from SCO sequencing studies to understand normal and diseased properties, with a particular emphasis on cancer research. We also discuss the technological improvements of SCO and its possible contribution to fundamental research of the human, as well as its great potential in clinical diagnoses and personalized therapies of human disease.}
}
@article{KORMAN201530,
title = {The social life of cognition},
journal = {Cognition},
volume = {135},
pages = {30-35},
year = {2015},
note = {The Changing Face of Cognition},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2014.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S001002771400225X},
author = {Joanna Korman and John Voiklis and Bertram F. Malle},
keywords = {History, Social psychology, Theory of mind, Communication, Robotics, Social cognition, Computation},
abstract = {We begin by illustrating that long before the cognitive revolution, social psychology focused on topics pertaining to what is now known as social cognition: people’s subjective interpretations of social situations and the concepts and cognitive processes underlying these interpretations. We then examine two questions: whether social cognition entails characteristic concepts and cognitive processes, and how social processes might themselves shape and constrain cognition. We suggest that social cognition relies heavily on generic cognition but also on unique concepts (e.g., agent, intentionality) and unique processes (e.g., projection, imitation, joint attention). We further suggest that social processes play a prominent role in the development and unfolding of several generic cognitive processes, including learning, attention, and memory. Finally, we comment on the prospects of a recently developing approach to the study of social cognition (social neuroscience) and two potential future directions (computational social cognition and social–cognitive robotics).}
}
@article{WANG19951,
title = {Peripheral dynamics of the Cl + CH4 → HCl + CH3 reaction. A classical trajectory computation},
journal = {Chemical Physics},
volume = {197},
number = {1},
pages = {1-17},
year = {1995},
issn = {0301-0104},
doi = {https://doi.org/10.1016/0301-0104(95)00134-A},
url = {https://www.sciencedirect.com/science/article/pii/030101049500134A},
author = {Xuebin Wang and M. Ben-Nun and R.D. Levine},
abstract = {The Cl + CH4 → HCl + CH3 reaction is expected to provide a prototype of a peripheral mechanism. This proposal is examined via a classical trajectory computation using a number of model potentials in which the degrees of freedom which do not take part in the net reaction are, or are not, frozen. The models include a full six-atom potential. The essential features of the dynamics are not sensitive to the level of detail with which the CH3 is described, showing that the intramolecular dynamics of the radical do not significantly affect the dynamics of the reactive event. The reaction is found to proceed by two distinct mechanisms: for trajectories with a large impact parameter, a very short lived complex is formed and dissociates to a rotationally cold HCl product, scattered into the forward direction. At smaller impact parameters, the reaction proceeds via a direct mechanism with a rotationally hot HCl which is scattered backward. The computed angular distribution is in agreement with the experiment, which detects HCl in the j = 1, 3 states and suggests that higher rotational states of HCl, which were not probed in the experiment, will also be scattered backward. The role of the initial vibrational excitation of CH4 is discussed.}
}
@incollection{KRAWCZYK2018101,
title = {Chapter 5 - Reasoning Origins: Human Development During Childhood},
editor = {Daniel C. Krawczyk},
booktitle = {Reasoning},
publisher = {Academic Press},
pages = {101-129},
year = {2018},
isbn = {978-0-12-809285-9},
doi = {https://doi.org/10.1016/B978-0-12-809285-9.00005-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128092859000053},
author = {Daniel C. Krawczyk},
keywords = {Analogies, Causal reasoning, Decision making, Development, Developmental stages, Moral reasoning, Relational reasoning},
abstract = {The developmental process is remarkably dynamic. The process is both a biological one and an environmental one with both factors frequently contributing to the output of increasingly sophisticated and abstract reasoning behavior. Children begin with a process of cortical thickening as large numbers of synaptic connections are formed. From age three onward, the cortex undergoes a tuning process as some synaptic connections strengthen and others weaken. The net result of this process is a decrease in cortical volume from age 5 through 20. Children's thinking is guided by a variety of factors. The context of a problem becomes a significant factor in determining how children will reason and developmental reasoning studies require sensitivity toward making the experimental stimuli understandable and interesting to the child. Children exhibit some competencies in causal reasoning and learning from a very young age. Children show increasing reasoning abilities as they develop. Skills such as relational and analogical reasoning grow during the elementary school years and are supported by increases in cognitive control and decreases in impulsivity. The child becomes less concrete in how he or she views and interacts with the world. This increasing abstraction ability encompasses semantic knowledge, deduction, and moral thinking.}
}
@article{FERRES2025,
title = {AI in the Era of GPT: Transforming the Future of Work and Discovery},
journal = {Journal of the American College of Radiology},
year = {2025},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2025.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S1546144025001097},
author = {Juan M.Lavista Ferres and Elliot K. Fishman and Linda C. Chu and Felipe Lopez-Ramirez and Charles K. Crawford and Steven P. Rowe}
}
@article{ALBALAWI201712033,
title = {Distributed Economic MPC with Safety-Based Constraints for Nonlinear Systems**Financial support from the National Science Foundation and the Department of Energy is gratefully acknowledged.},
journal = {IFAC-PapersOnLine},
volume = {50},
number = {1},
pages = {12033-12040},
year = {2017},
note = {20th IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2017.08.2098},
url = {https://www.sciencedirect.com/science/article/pii/S2405896317327581},
author = {Fahad Albalawi and Helen Durand and Panagiotis D. Christofides},
keywords = {Process safety, distributed model predictive control, computation time},
abstract = {Promoting process safety of chemical processes while operating them in an economically-optimal manner is a matter of great importance. In Albalawi et al. (2016), a safety-based economic model predictive control methodology (safety-EMPC) was developed to operate nonlinear processes in an economically-optimal manner while maintaining process safety and closed-loop stability. However, the safety-EMPC control strategy was developed with a centralized economic model predictive control (EMPC) structure; thus, computation time limitations within a sampling period may reduce the effectiveness of such a controller design for promoting process safety. Alternatively, we develop in this work sequential and iterative safety-based distributed EMPC schemes (safety-DEMPC) that may overcome the computation time limitations of the centralized safety-EMPC while maintaining similar closed-loop performance. Using a catalytic reactor example, the two proposed safety-DEMPC schemes were demonstrated to achieve similar closed-loop performance to the centralized safety-EMPC while reducing the on-line computation time requirements compared to the centralized safety-EMPC.}
}
@article{CRAGG1974315,
title = {Thinking about the future: A critique of the limits to growth: Edited by H. S. D. Cole, Christopher Freeman, Marie Jahoda & K. L. R. Pavitt. Chatto & Windus for Sussex University Press, London: 218 pp., £3.00, 1973},
journal = {Biological Conservation},
volume = {6},
number = {4},
pages = {315-316},
year = {1974},
issn = {0006-3207},
doi = {https://doi.org/10.1016/0006-3207(74)90014-7},
url = {https://www.sciencedirect.com/science/article/pii/0006320774900147},
author = {J.B. Cragg}
}
@article{BAUER2024100002,
title = {What if? Numerical weather prediction at the crossroads},
journal = {Journal of the European Meteorological Society},
volume = {1},
pages = {100002},
year = {2024},
issn = {2950-6301},
doi = {https://doi.org/10.1016/j.jemets.2024.100002},
url = {https://www.sciencedirect.com/science/article/pii/S2950630124000024},
author = {Peter Bauer},
keywords = {Numerical weather prediction, Machine learning, High-performance computing},
abstract = {This paper provides an outlook on the future of operational weather prediction given the recent evolution in science, computing and machine learning. In many parts, this evolution strongly deviates from the strategy operational centres have formulated only several years ago. New opportunities in digital technology have greatly accelerated progress, and the full integration of computational science in numerical weather prediction centres is common knowledge now. Within the last few years, a vast machine learning research community has emerged for creating new and tailor-made products, accelerating processing and – most of all – creating emulators for the entire production of global forecasts that outperform traditional systems at the spatial resolution of the training data. In this context, the role of both numerical models and observations is changing from being equation to data driven. Model simulations and reanalyses are becoming the new currency for training machine learning, and operational centres are in a powerful position as they generate these datasets based on decades worth of experience. This environment creates incredible opportunities to progress much faster than in the past but also uncertainties about what the strategic implications on defining cost-effective and sustainable research and operations are, and how to achieve sufficient high-performance computing and data handling capacities. It will take individual national public services a while to understand what to focus on and how to coordinate their substantial investments in staff and infrastructure at institutional, national and international level. This paper addresses this new situation operational weather prediction finds itself in through formulating the most likely “what if?” scenarios for the near future. It also provides an outline for how weather centres could adapt.}
}
@incollection{TANQUE202113,
title = {Chapter 2 - Knowledge Representation and Reasoning in AI-Based Solutions and IoT Applications},
editor = {Gurjit Kaur and Pradeep Tomar and Marcus Tanque},
booktitle = {Artificial Intelligence to Solve Pervasive Internet of Things Issues},
publisher = {Academic Press},
pages = {13-49},
year = {2021},
isbn = {978-0-12-818576-6},
doi = {https://doi.org/10.1016/B978-0-12-818576-6.00002-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128185766000022},
author = {Marcus Tanque},
keywords = {Artificial intelligence, machine learning, intelligent machine, artificial neural networks, cognitive science, deep learning, artificial general networks, knowledge representation, and reasoning, cognitive informatics, Internet of Things},
abstract = {Artificial intelligence (AI)-based solutions, knowledge representation and reasoning, and the Internet of Things applications have transformed how researchers and practitioners view the analytical and computational capabilities. The disruptive evolution of these technologies has encouraged researchers and practitioners to develop integrated AI-based analytical solutions needed for solving pervasive issues affecting computational applications. The capabilities include AI, knowledge Representation and Reasoning and Internet of Things. Such capabilities are designed to support AI-based solutions, knowledge representation and reasoning, and the Internet of Things (IoT) applications. These technology trends involve relevant computational areas, that is, intelligent devices, sensors, autonomous vehicles, robotics, virtual reality, augmented intelligence, and others. The study addresses and validates solutions on how researchers can solve issues that affect AI, knowledge representation and reasoning, and IoT applications.}
}
@article{HAN2025104938,
title = {Synergizing Artificial Intelligence and Probiotics: A Comprehensive Review of Emerging Applications in Health Promotion and Industrial Innovation},
journal = {Trends in Food Science & Technology},
pages = {104938},
year = {2025},
issn = {0924-2244},
doi = {https://doi.org/10.1016/j.tifs.2025.104938},
url = {https://www.sciencedirect.com/science/article/pii/S0924224425000743},
author = {Xin Han and Qingqiu Liu and Yun Li and Meng Zhang and Kaiyang Liu and Lai-Yu Kwok and Heping Zhang and Wenyi Zhang},
keywords = {Artificial Intelligence, Gastrointestinal health, Personalized medicine, Probiotic Metabolite},
abstract = {Background
Probiotics play a vital role in human health, garnering significant scientific and public interest. The integration of artificial intelligence (AI) into probiotic research and applications promises to revolutionize strain discovery, health outcomes, and food industry innovations.
Scope and approach
This review explores the intersection of AI and probiotics, focusing on AI-powered machine learning models that revolutionize strain screening, biomarker prediction, and metabolite analysis. Artificial intelligence enables early diagnosis and personalized nutrition by predicting biomarkers for conditions like inflammatory bowel disease and irritable bowel syndrome. It also identifies key probiotic metabolites, such as antimicrobial peptides, exopolysaccharides, and phenolic compounds, advancing fermentation technology and probiotic efficacy. Challenges, including data quality computational demands, and experimental validation, are also discussed.
Key findings and conclusions
Artificial intelligence outperforms conventional methods, offering rapid, high-precision screening, scalable data analysis, and automated strain optimization. Case studies demonstrate AI models achieving over 97% accuracy in bacterial identification and accelerated metabolite discovery. However, challenges like data quality, computational costs, and model interpretability remain. Overcoming these will strengthen the role of AI in precision nutrition, functional food development, and personalized medicine. This review concludes with future perspectives, emphasizing the potential of AI to revolutionize gut microbiome research and probiotic-based therapeutics.}
}
@article{CARVALHAES2021102165,
title = {An overview & synthesis of disaster resilience indices from a complexity perspective},
journal = {International Journal of Disaster Risk Reduction},
volume = {57},
pages = {102165},
year = {2021},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2021.102165},
url = {https://www.sciencedirect.com/science/article/pii/S221242092100131X},
author = {Thomaz M. Carvalhaes and Mikhail V. Chester and Agami T. Reddy and Braden R. Allenby},
keywords = {Complex adaptive systems, Resilience, Indicators, Disaster index, Urban systems, Socio-ecological systems},
abstract = {Identifying Disaster resilience indices (DRI) for cities and communities remains a common approach for assessing their structural ability and inherent capacity to cope with, recover from, and adapt to disasters. Particularly popular are composite DRI methodologies that are quantitative, top-down, and geographically mappable. DRI have become more comprehensive as the complexity of urban systems is increasingly acknowledged. However, DRI remain criticized as static, reductive, and inadequate when viewed under a complexity paradigm, which views urban systems as Complex Adaptive Systems (CAS), where observed properties (like resilience) emerge from many interactions among heterogenous agents in a network. Literature reviews have covered the state and trends for DRI development. Our objective is to synthesize literature at the nexus of these reviews, CAS, and Socio-ecological Systems (SES) to determine the extent to which commonly adopted indicators relate to widely accepted tenets of CAS. Findings show that DRI indicators usually relate more closely to temporal snapshots of vulnerability, and alternative framings of current indicators along with interdisciplinary approaches could better capture CAS aspects of urban resilience. Research and development should strive to develop DRI based on underlying principles of CAS and SES, and consider adapting top-down quantitative approaches with thick data, network models, and mixed-method triangulations. Explicitly associating complexity theory with DRI can (i) help researchers in socio-technical and socio-ecological domains develop improved resilience indicators and assessment methods that are clearly differentiated from vulnerability metrics, and (ii) guide policy and decision-makers, amid future uncertainty, to better identify, implement and track capacity-enhancing measures.}
}
@article{DEMSAR2007551,
title = {Investigating visual exploration of geospatial data: An exploratory usability experiment for visual data mining},
journal = {Computers, Environment and Urban Systems},
volume = {31},
number = {5},
pages = {551-571},
year = {2007},
note = {Geospatial Analysis and Modeling},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2007.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0198971507000579},
author = {Urška Demšar},
keywords = {Exploratory geovisualisation, Visual data mining, Exploratory usability},
abstract = {This study presents a small exploratory usability experiment with the goal to observe how people visually explore geospatial data. The well-known iris dataset from pattern recognition was put into geographical context for this experiment, in order to provide the participants with a dataset with easily observable spatial and other relationships. The participants were given free hand to explore this dataset with a visual data mining system in any way they liked. The protocols collected during the experiment with the thinking-aloud method were analysed with the aim to understand what types of hypotheses the participants formed, which visualisations they used to either derive, confirm or reject their hypotheses and what exploration strategies they adopted.}
}
@article{CONRAD1991316,
journal = {Bulletin of Mathematical Biology},
volume = {53},
number = {1},
pages = {316-318},
year = {1991},
issn = {0092-8240},
doi = {https://doi.org/10.1016/S0092-8240(05)80052-7},
url = {https://www.sciencedirect.com/science/article/pii/S0092824005800527},
author = {Michael Conrad}
}
@article{FISCHLER1987257,
title = {Parallel guessing: A strategy for high-speed computation},
journal = {Pattern Recognition},
volume = {20},
number = {2},
pages = {257-263},
year = {1987},
issn = {0031-3203},
doi = {https://doi.org/10.1016/0031-3203(87)90059-8},
url = {https://www.sciencedirect.com/science/article/pii/0031320387900598},
author = {M.A. Fischler and O. Firschein},
keywords = {Parallel processing, Image analysis algorithms, Image processing, Architectures},
abstract = {Conventional approaches to speeding up image understanding computation involving conventional serial algorithms attempt to decompose these algorithms into portions that can be computed in parallel. Because many classes of algorithms do not readily decompose, one seeks some other basis for parallelism. In this paper we argue that “parallel guessing” for image analysis is a useful approach, and that several recent scene analysis algorithms are based on this concept. Problems suitable for this approach have the characteristic that either “distance” from a true solution, or the correctness of a guess, can be readily checked. We review image analysis algorithms that have a parallel guessing or randomness flavor.}
}
@article{GIORGI2024119928,
title = {Embedding parametric resonance in a 2:1 wave energy converter to get a broader bandwidth},
journal = {Renewable Energy},
volume = {222},
pages = {119928},
year = {2024},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2023.119928},
url = {https://www.sciencedirect.com/science/article/pii/S0960148123018438},
author = {Giuseppe Giorgi},
keywords = {2:1 parametric resonance, Parametric instability, Wave energy converter, Nonlinear Froude–Krylov force},
abstract = {The effort to increase the converted power is a common challenge to players in the field of wave energy conversion, both academic and industrial. In the case devices are found to be prone to parametric resonance, it typically has a negative impact on power harvesting and may jeopardize the reliability of the device. This paper makes the case that parametric resonance is not a danger that should be avoided, but rather a chance to achieve a broader system response bandwidth and ultimately increase the amount of power available at the power take-off. Since a time-varying wetted surface causes the highly nonlinear phenomenon of parametric resonance, linear models are unable to fully capture this instability. As a result, nonlinear Froude–Krylov forces are herein implemented via a computationally effective method for prismatic floaters that is compatible with both exhaustive simulation methods and real-time computing, as the whole simulations runs up to 50 times faster than real-time. A novel pendulum-based device is intentionally defined to exhibit a 2:1 ratio between heave and pitch natural frequencies, causing parametric instability. Results demonstrate that linear models predict a single zone of meaningful potential power extraction around the pitch natural frequency, as expected; however, by using the designed attitude to develop parametric instability, a second additional region develops near the heave natural period. As a result, the free response bandwidth is in fact increased, making more energy available at the power take-off axis thanks to the nonlinear instability embedded in the wave energy converter.}
}
@article{REN2025109484,
title = {A multi-criteria decision-making method based on discrete Z-numbers and Aczel-Alsina aggregation operators and its application on early diagnosis of depression},
journal = {Engineering Applications of Artificial Intelligence},
volume = {139},
pages = {109484},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.109484},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624016427},
author = {Dong Ren and Xiuqin Ma and Hongwu Qin and Siyue Lei and Xuli Niu},
keywords = {Multi-criteria decision-making, Fuzzy sets, Discrete Z-numbers, Aczel-alsina aggregation operator},
abstract = {In mental health diagnostics, the questionnaire is an effective and cost-effective method. However, the traditional questionnaire test methods for depression and anxiety have great ambiguity. The discrete Z-numbers (DZs) provide solutions for describing and resolving complex fuzzy issues in the intelligent multi-criteria decision-making (MCDM) process. However, large-scale datasets are not suited for the present MCDM techniques due to their extremely high computational cost. Additionally, these techniques are less stable and flexible. To address the above issues, a novel MCDM method is introduced, which is based on the DZs theory and the Aczel-Alsina (AA) aggregation operator (AO) for large-scale datasets. To begin with, centroid points are calculated for DZs, and a series of novel AOs are introduced. And then a score function with a parameter is introduced to balance the influence between the possibility restriction and the fuzzy restriction of DZs. Thirdly, a new MCDM method under DZs is presented based on the proposed AA AOs and score function. Finally, to support the early diagnosis of depression and anxiety, we apply our method to the real-life online Depression, Anxiety, and Stress Scale (DASS) which can be transformed into DZs by our proposed preprocessing method. According to experimental results, our method is applicable to large-scale datasets and has much lower complexity as well as higher flexibility and stability.}
}
@article{GROEGER1987295,
title = {Computation—The final metaphor? An interview with Philip Johnson-Laird},
journal = {New Ideas in Psychology},
volume = {5},
number = {2},
pages = {295-304},
year = {1987},
issn = {0732-118X},
doi = {https://doi.org/10.1016/0732-118X(87)90030-4},
url = {https://www.sciencedirect.com/science/article/pii/0732118X87900304},
author = {J.A. Groeger}
}
@article{ESCOUFLAIRE2024129,
title = {Automated text classification of opinion vs. news French press articles. A comparison of transformer and feature-based approaches},
journal = {Language & Communication},
volume = {99},
pages = {129-140},
year = {2024},
issn = {0271-5309},
doi = {https://doi.org/10.1016/j.langcom.2024.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S0271530924000624},
author = {Louis Escouflaire and Antonin Descampe and Cédrick Fairon},
keywords = {Subjectivity, Transformers, Feature-based model, Text classification, Discourse analysis, Explainability},
abstract = {This study explores Natural Language Processing (NLP) methods for distinguishing between press articles belonging to the journalistic genres of ‘objective’ news and ‘subjective’ opinion. Two classification models are compared: CamemBERT, a French transformer model fine-tuned for the task, and a machine learning model using 32 linguistic features. Trained on 8000 Belgian French articles, both models are evaluated on 1000 Canadian French articles. Results show CamemBERT’s superiority but highlight potential for hybrid approaches and emphasizes the need for robust and transparent methods in NLP. The research contributes to understanding NLP’s role in journalism by addressing challenges of point of view detection in press discourse.}
}
@article{MUGHAL2020159,
title = {Goals of the national mathematics curriculum of Pakistan: educators’ perceptions and challenges toward achievement},
journal = {International Journal of Educational Management},
volume = {35},
number = {1},
pages = {159-172},
year = {2020},
issn = {0951-354X},
doi = {https://doi.org/10.1108/IJEM-04-2020-0203},
url = {https://www.sciencedirect.com/science/article/pii/S0951354X20000678},
author = {Shahid Hussain Mughal and Muhammad Mujtaba Asad and Donnie Adams},
keywords = {Mathematics, Curriculum design, Pedagogy, Content knowledge, National plan},
abstract = {Purpose
The national mathematics curriculum of Pakistan has emphasized on improving content knowledge, reasoning abilities and problem-solving skills of students about thinking, communicating and solving mathematics (national mathematics curriculum of Pakistan, 2006). Whereas, there is a need to understand the point of view of teachers about the challenges they face in achieving the goals of national mathematics curriculum. This will help leading teacher training institutions to revisit their math teacher continuous professional development (CPD) programs and facilitate school leadership in improving the quality of math education in rural schools of the province. However, the purpose of this research study is to figure out the challenges that teachers are facing while achieving the goals of the national curriculum by teaching mathematics at the primary level in educational institutes of Pakistan.
Design/methodology/approach
In this research study qualitative research approaches have been utilized, in which focus group discussions (FGDs) were used as data collection techniques. Furthermore, thematic analysis of the data led toward the development of four overarching themes such as teachers' knowledge about mathematics curriculum, challenges relating to mathematics content and pedagogy, difficulties in developing conceptual understanding and designing lesson plans to address students' diversity.
Findings
The overall findings of this research study suggested that the majority of teachers are facing difficulties in mathematics content teaching such as decimal fraction, unitary method, measurement principles, practical geometry and data handling. Moreover, teachers are also facing challenges and difficulties in developing hands-on and minds-on activities in the teaching of mathematical concepts to the students of primary level in educational institutes of Pakistan.
Practical implications
This research study will facilitate the teachers and stakeholders to address the problematic issues in the domain of content delivery of mathematics. Whereas, this study recommends educating teachers about national mathematics curriculum and to develop a CPD framework for mathematics teachers for the enhancement of their pedagogical content knowledge. The study also recommends orientating school heads about the different aspects of math curriculum so that they can mentor math teachers in achieving math curriculum goals.
Originality/value
This is the first research study of its nature, which targets and highlights the teacher's perceptions toward the achieving the goals of national mathematics curriculum of Pakistan and addressing the pedagogical challenges faced in mathematics teachers. There is a dearth of studies in mathematics education in Sindh province. The issue is of immense importance, the findings will help teachers to improve mathematics instructions at primary level.}
}
@article{NOST202223,
title = {Earth for AI: A Political Ecology of Data-Driven Climate Initiatives},
journal = {Geoforum},
volume = {130},
pages = {23-34},
year = {2022},
issn = {0016-7185},
doi = {https://doi.org/10.1016/j.geoforum.2022.01.016},
url = {https://www.sciencedirect.com/science/article/pii/S0016718522000240},
author = {Eric Nost and Emma Colven},
keywords = {Adaptation, Artificial intelligence, Climate change, Digital geographies, Environmental data justice, Knowledge production},
abstract = {Emerging narratives around artificial intelligence (AI) and machine learning place great faith in these technologies’ ability to ameliorate threats posed by climate change. They promise the capacity to analyze vast amounts of more precise and real-time data, improving how decision-makers predict, respond, and adapt. Yet scholars in political ecology have long observed that technocentric approaches typically reduce complex human-environment relationships in ways that fail to account for social relations and power dynamics. This paper charts the emerging political economy of “climate AI” – the philanthropies, NGOs, private consultancies, and tech giants investing in data-driven climate initiatives. Mapping out two case studies, we show that environmental and climate crises are grist for tech solutions and find that many climate AI actors are interested in it for surveillance, greenwashing, and commodifying algorithms. We pay special attention to how neocolonial and racialized power structures manifest in climate AI and outline three ways for political ecologists and digital geographers to research its socio-materiality: how computational resources are environmentally embedded, how disasters become “shocks” that the AI industry capitalizes on, and how climate AI shapes material investment flows and landscapes. Highlighting how data-driven approaches to climate crises reproduce injustices already faced by marginalized communities, our analysis contributes to research on environmental data justice.}
}
@incollection{LOEWER20012166,
title = {Cognitive Science: Philosophical Aspects},
editor = {Neil J. Smelser and Paul B. Baltes},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences},
publisher = {Pergamon},
address = {Oxford},
pages = {2166-2171},
year = {2001},
isbn = {978-0-08-043076-8},
doi = {https://doi.org/10.1016/B0-08-043076-7/01026-3},
url = {https://www.sciencedirect.com/science/article/pii/B0080430767010263},
author = {B. Loewer},
abstract = {Three questions have dominated the philosophy of mind in the analytic tradition since Descartes. They are: what are thoughts and thinking? How can the mind represent the world? What is consciousness? Most contemporary analytic philosophers attempt to answer these questions within a broadly materialistic framework since they think that there is overwhelming reason to believe that human beings are biological organisms entirely composed of ordinary matter. Recently the central questions in the philosophy of mind have been given some new twists and partial answers by developments within cognitive science. This article reviews some of the main ideas in cognitive science and its impact on these issues in the philosophy of mind.}
}
@article{B2021107538,
title = {A survey on genomic data by privacy-preserving techniques perspective},
journal = {Computational Biology and Chemistry},
volume = {93},
pages = {107538},
year = {2021},
issn = {1476-9271},
doi = {https://doi.org/10.1016/j.compbiolchem.2021.107538},
url = {https://www.sciencedirect.com/science/article/pii/S1476927121001055},
author = {Abinaya B. and Santhi S.},
keywords = {Data sharing, Data access and storage, Data computation, Outsourcing, Privacy-preserving techniques},
abstract = {Nowadays, the purpose of human genomics is widely emerging in health-related problems and also to achieve time and cost-efficient healthcare. Due to advancement in genomics and its research, development in privacy concerns is needed regarding querying, accessing and, storage and computation of the genomic data. While the genomic data is widely accessible, the privacy issues may emerge due to the untrusted third party (adversaries/researchers), they may reveal the information or strategy plans regarding the genome data of an individual when it is requested for research purposes. To mitigate this problem many privacy-preserving techniques are used along with cryptographic methods are briefly discussed. Furthermore, efficiency and accuracy in a secure and private genomic data computation are needed to be researched in future.}
}
@article{ZHOU2024124298,
title = {Hyperspectral imaging combined with blood oxygen saturation for in vivo analysis of small intestinal necrosis tissue},
journal = {Spectrochimica Acta Part A: Molecular and Biomolecular Spectroscopy},
volume = {315},
pages = {124298},
year = {2024},
issn = {1386-1425},
doi = {https://doi.org/10.1016/j.saa.2024.124298},
url = {https://www.sciencedirect.com/science/article/pii/S1386142524004645},
author = {Yao Zhou and LeChao Zhang and DanFei Huang and Yong Zhang and LiBin Zhu and Xiaoqing Chen and Guihua Cui and Qifan Chen and XiaoJing Chen and Shujat Ali},
keywords = {Hyperspectral imaging, Tissue oxygenation, Small intestine tissue, Isosbestic points},
abstract = {Acute mesenteric ischemia (AMI) is a clinically significant vascular and gastrointestinal condition, which is closely related to the blood supply of the small intestine. Unfortunately, it is still challenging to properly discriminate small intestinal tissues with different degrees of ischemia. In this study, hyperspectral imaging (HSI) was used to construct pseudo-color images of oxygen saturation about small intestinal tissues and to discriminate different degrees of ischemia. First, several small intestine tissue models of New Zealand white rabbits were prepared and collected their hyperspectral data. Then, a set of isosbestic points were used to linearly transform the measurement data twice to match the reference spectra of oxyhemoglobin and deoxyhemoglobin, respectively. The oxygen saturation was measured at the characteristic peak band of oxyhemoglobin (560 nm). Ultimately, using the oxygenated hemoglobin reflectance spectrum as the benchmark, we obtained the relative amount of median oxygen saturation in normal tissues was 70.0 %, the IQR was 10.1 %, the relative amount of median oxygen saturation in ischemic tissues was 49.6 %, and the IQR was 14.6 %. The results demonstrate that HSI combined with the oxygen saturation computation method can efficiently differentiate between normal and ischemic regions of the small intestinal tissues. This technique provides a powerful support for internist to discriminate small bowel tissues with different degrees of ischemia, and also provides a new way of thinking for the diagnosis of AMI.}
}
@article{ZOU2025106959,
title = {LCFFNet: A Lightweight Cross-scale Feature Fusion Network for human pose estimation},
journal = {Neural Networks},
volume = {183},
pages = {106959},
year = {2025},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2024.106959},
url = {https://www.sciencedirect.com/science/article/pii/S0893608024008888},
author = {Xuelian Zou and Xiaojun Bi},
keywords = {Human pose estimation, 2d dynamic multi-scale convolution, Contextual semantic information, Adaptive feature fusion},
abstract = {Human pose estimation is one of the most critical and challenging problems in computer vision. It is applied in many computer vision fields and has important research significance. However, it is still a difficult challenge to strike a balance between the number of parameters and computing load of the model and the accuracy of human pose estimation. In this study, we suggest a Lightweight Cross-scale Feature Fusion Network (LCFFNet) to strike a balance between accuracy and computational load and parameter volume. The Lightweight HRNet-Like (LHRNet) network, Cross-Resolution-Aware Semantics Module (CRASM), and Adapt Feature Fusion Module (AFFM) make up LCFFNet. To be more precise, first, we suggest a lightweight LHRNet network that includes Dynamic Multi-scale Convolution Basic (DMSC-Basic block) block, Basic block, and DMSC-Basic block submodules in the network’s three high-resolution subnetwork stages. The proposed dynamic multi-scale convolution in DMSC-Basic block can reduces the amount of model parameters and complexity of the LHRNet network, and has the ability to extract variable pose features. In order to maintain the model’s ability to express features, the Basic block is introduced. As a result, the LHRNet network not only makes the model more lightweight but also enhances its feature expression capabilities. Second, we propose a CRASM module to enhance contextual semantic information while reducing the semantic gap between different scales by fusing features from different scales. Finally, the augmented semantic feature map’s spatial resolution is finally restored from bottom to top using our suggested AFFM, and adaptive feature fusion is used to increase the positioning accuracy of important sites. Our method successfully predicts keypoints with 74.2 % AP, 89.9 % PCKh@0.5 and 66.9 % AP on the MSCOCO 2017, MPII and Crowdpose datasets, respectively. Our model reduces the number of parameters by 89.0 % and the computational complexity by 87.5 % compared with HRNet. The proposed network performs as well as current large-model human pose estimation networks while outperforming state-of the-art lightweight networks.}
}
@article{FERNANDEZ20181,
title = {Natural deep eutectic solvents-mediated extractions: The way forward for sustainable analytical developments},
journal = {Analytica Chimica Acta},
volume = {1038},
pages = {1-10},
year = {2018},
issn = {0003-2670},
doi = {https://doi.org/10.1016/j.aca.2018.07.059},
url = {https://www.sciencedirect.com/science/article/pii/S0003267018309231},
author = {María de los Ángeles Fernández and Joana Boiteux and Magdalena Espino and Federico J.V. Gomez and María Fernanda Silva},
keywords = {Natural deep eutectic solvents, Extraction, Green analytical chemistry, Sample prep, Microextractions},
abstract = {The concept of sustainable development has impacted in analytical chemistry changing the way of thinking processes and methods. It is important for analytical chemists to consider how sample preparation can integrate the basic concepts of Green Chemistry. In this sense, the replacement of traditional organic solvents is of utmost importance. Natural Deep Eutectic Solvents (NADES) have come to light as a green alternative. In the last few years, a growing number of contributions have applied these natural solvents proving their efficiency in terms of extraction ability, analyte stabilization capacity and detection compatibility. However, the arising question that has to be answered is: the use of NADES is enough to green an extraction process? This review presents an overview of knowledge regarding sustainability of NADES-based extraction procedures, focused on reported literature within the timeframe spanning from 2011 up to date. The contributions were analyzed from a green perspective in terms of energy, time, sample and solvent consumption. Moreover, we include a critical analysis to clarify whether the use of NADES as extraction media is enough for greening an analytical methodology; strategies to make them even greener are also presented. Finally, recent trends and future perspectives on how NADES-based extraction approaches in combination with computational methodologies can contribute are discussed.}
}
@article{BYLYA20172358,
title = {Modelling challenges for incremental bulk processes despite advances in simulation technology: example issues and approaches},
journal = {Procedia Engineering},
volume = {207},
pages = {2358-2363},
year = {2017},
note = {International Conference on the Technology of Plasticity, ICTP 2017, 17-22 September 2017, Cambridge, United Kingdom},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2017.10.1008},
url = {https://www.sciencedirect.com/science/article/pii/S1877705817358010},
author = {O.I. Bylya and M. Ward and B. Krishnamurty and S. Tamang and R.A. Vasin},
keywords = {Flow forming, rotary forging, process modelling, simplification approaches. Introduction},
abstract = {Incremental bulk deformation processes have traditionally been difficult to simulate. This paper will argue that, despite advances in computation and software, they remain difficult to model. The main reason for this is the shortage of ideas on what is the real objective of FE modelling for such processes. Even a very detailed model and data obtained in simulation does not give answers to the main question - how to optimise the process parameters? High computational time and volume of information only aggravate the situation. All modern mathematical techniques of dimensionality reduction (such as POD/PGD) lose their power when the priorities and acceptable compromises of modelling are not clear. This paper tries to use a large volume of available experimental and modelling experience to illustrate this problem and look for possible break-through directions.}
}
@incollection{CUMMINS20171,
title = {Chapter 1 - The Agile Enterprise},
editor = {Fred A. Cummins},
booktitle = {Building the Agile Enterprise (Second Edition)},
publisher = {Morgan Kaufmann},
edition = {Second Edition},
address = {Boston},
pages = {1-34},
year = {2017},
series = {The MK/OMG Press},
isbn = {978-0-12-805160-3},
doi = {https://doi.org/10.1016/B978-0-12-805160-3.00001-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128051603000016},
author = {Fred A. Cummins},
keywords = {Agile enterprise, Business impact of technology, Capability-based architecture, Business collaboration management, Value delivery management, Value delivery modeling language},
abstract = {This chapter begins with an introduction to the agile enterprise concept and provides a somewhat historical perspective on the evolution of information technology and its impact on business operations and management. It then introduces three new ways of thinking that are key to today's agile enterprise and are referenced in the subtitle of this book: (1) capability-based architecture, (2) business collaboration management (BCM), and (3) value delivery management (VDM). Finally, the impact of VDM is discussed related to the management of major business changes, along with some critical success factors for the journey to agility.}
}
@article{GADZHIEV2025101314,
title = {Creating A dynamic cognovisor – Brain activity recognition using principal Component analysis and Machine learning models},
journal = {Cognitive Systems Research},
volume = {89},
pages = {101314},
year = {2025},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2024.101314},
url = {https://www.sciencedirect.com/science/article/pii/S1389041724001086},
author = {Ismail M. Gadzhiev and Alexander S. Makarov and Vadim L. Ushakov and Vyacheslav A. Orlov and Georgy A. Ivanitsky and Sergei A. Dolenko},
keywords = {Brain Activity, Cognitive States, Machine Learning, Principal Component Analysis},
abstract = {This study explores the feasibility of developing a dynamic cognovisor capable of recognizing cognitive states and transitions using fMRI data. Data were collected from 31 participants performing spatial and verbal tasks during fMRI scanning and were preprocessed using a nine-step algorithm for artifact removal and denoising. Three types of classification problems were examined, with machine learning methods and dimensionality reduction techniques applied to classify activity states. The best-performing models were identified for each classification problem, providing insights into their applicability. Notably, binary classification of resting versus active states achieved good quality with relatively simple methods. A key finding underscores the importance of accounting for temporal history of the signal prior to the prediction moment to improve model performance.}
}
@article{AI2022631,
title = {Reconsidering autistic ‘camouflaging’ as transactional impression management},
journal = {Trends in Cognitive Sciences},
volume = {26},
number = {8},
pages = {631-645},
year = {2022},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2022.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S1364661322001061},
author = {Wei Ai and William A. Cunningham and Meng-Chuan Lai},
keywords = {autism, camouflaging, impression management, predictive coding, social alignment, wellbeing},
abstract = {Social performances pervade human interactions. Some autistic people describe their social performances as ‘camouflaging’ and engage in these performances to mitigate social challenges and survive in the neurotypical world. Here, we reconsider autistic camouflaging under the unifying framework of impression management (IM) by examining overlapping and unique motivations, neurocognitive mechanisms, and consequences. Predictive coding and Bayesian principles are synthesized into a computational model of IM that applies to autistic and neurotypical people. Throughout, we emphasize the inherently transactional, context-dependent nature of IM, the distinct computational challenges faced by autistic people, and the psychological toll that compelled IM can take. Viewing camouflaging through this lens highlights the pressing needs to change societal attitudes, destigmatize autism, refine social skills-building programs for autistic individuals, and integrate these programs with environment-focused support.}
}
@incollection{STEIN202139,
title = {Chapter 2 - Brain–minds: What’s the best metaphor?},
editor = {Dan J. Stein},
booktitle = {Problems of Living},
publisher = {Academic Press},
pages = {39-59},
year = {2021},
isbn = {978-0-323-90239-7},
doi = {https://doi.org/10.1016/B978-0-323-90239-7.00005-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780323902397000055},
author = {Dan J. Stein},
keywords = {Psychiatry, Philosophy, Realism, Psychiatric classification, Pluralism, Erklären, Verstehen, Epistemic humility, Practical wisdom},
abstract = {This chapter addresses the question of how best to think about the brain–mind from both philosophical and psychiatric perspectives. The section on philosophy of mind notes the positions of physicalism, dualism, and functionalism, and proposes that emergent materialism has particular advantages. The section on psychiatry notes the positions of behaviourism and existentialism. Two key metaphors of the brain–mind are then critiqued: the hydraulic model of psychoanalysis, and the computational model of cognitive science. A third metaphor, that of ‘wetware’, which emphasizes that the brain–mind cannot simply be divided into hardware and software, but rather that it must be approached as a complex psychobiological phenomenon, is proposed. Several advantages of this metaphor are discussed, including that it is consistent with emergent materialism and a view of the brain–mind as embodied and embedded in social activity, as well as with current cognitive-affective and psychiatric science.}
}
@article{GOTTS2019100728,
title = {Agent-based modelling of socio-ecological systems: Models, projects and ontologies},
journal = {Ecological Complexity},
volume = {40},
pages = {100728},
year = {2019},
note = {Agent-based modelling to study resilience in socio-ecological systems},
issn = {1476-945X},
doi = {https://doi.org/10.1016/j.ecocom.2018.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S1476945X18301272},
